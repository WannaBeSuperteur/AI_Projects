## ëª©ì°¨

* [1. OhLoRA-v3 LLM ì „ì²´ ë©”ì»¤ë‹ˆì¦˜](#1-ohlora-v3-llm-ì „ì²´-ë©”ì»¤ë‹ˆì¦˜)
  * [1-1. í˜„ì¬ ì‹œê°„ ì •ë³´ ì¶”ê°€](#1-1-í˜„ì¬-ì‹œê°„-ì •ë³´-ì¶”ê°€)
  * [1-2. LLM Memory (RAG-like concept)](#1-2-llm-memory-rag-like-concept)
  * [1-3. LLM Ethics (S-BERT)](#1-3-llm-ethics-s-bert)

## 1. OhLoRA-v3 LLM ì „ì²´ ë©”ì»¤ë‹ˆì¦˜

* ìš”ì•½
  * [ì˜¤ë¡œë¼ v2 LLM ì „ì²´ ë©”ì»¤ë‹ˆì¦˜](../../2025_05_02_OhLoRA_v2/llm/README.md#1-ohlora-v2-llm-ì „ì²´-ë©”ì»¤ë‹ˆì¦˜) ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„
  * ë‹¨, ì‚¬ìš©ìì˜ ìµœì´ˆ ì›ë³¸ ì§ˆë¬¸ì— **ì‹œê°„ ë‹¨ì–´ (```ì˜¤ëŠ˜``` ```ë‚´ì¼``` ë“±) í¬í•¨** ì‹œ, **í˜„ì¬ ì‹œê°„ ì •ë³´** ë¥¼ ì‚¬ìš©ì ì§ˆë¬¸ì— ì¶”ê°€ [(ìƒì„¸ ì„¤ëª…)](#1-1-í˜„ì¬-ì‹œê°„-ì •ë³´-ì¶”ê°€)

![image](../../images/250526_21.png)

* LLM ëª¨ë¸
  * [LLM ëª¨ë¸ ì‚¬ìš© ìƒì„¸ ê²°ì •ì•ˆ ì½”ë©˜íŠ¸](https://github.com/WannaBeSuperteur/AI_Projects/issues/21#issuecomment-2926149441) 
  * [LoRA Rank 64 vs. 16 ì‹¤í—˜ ê²°ê³¼ ë³´ê³ ì„œ](fine_tuning/report_LoRA_rank_64_vs_16.md)

| ëª¨ë¸                                     | ì„¤ëª…                                                                                                                                  | Base Model                                                                                                  |
|----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|
| LLM ë‹µë³€ ```output_message```            | Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ì„ ìœ„í•œ ë©”ì¸ LLM                                                                                                 | [Kanana-1.5 2.1B (HuggingFace)](https://huggingface.co/kakaocorp/kanana-1.5-2.1b-base)<br>(by **Kakao**)    |
| memory (RAG-like concept) ```memory``` | ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë° ê´€ë ¨ ì •ë³´ë¡œë¶€í„° Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ê°€ ê¸°ì–µí•´ì•¼ í•  ë‚´ìš© ì¶”ì¶œ<br>- ì´ë¥¼ í†µí•´ [Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ì˜ ë©”ëª¨ë¦¬](#1-2-llm-memory-rag-like-concept) ì—…ë°ì´íŠ¸ | [Polyglot-Ko 1.3B (HuggingFace)](https://huggingface.co/EleutherAI/polyglot-ko-1.3b)<br>(by **EleutherAI**) |
| í‘œì •/ëª¸ì§“ ```eyes_mouth_pose```            | [Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ì´ë¯¸ì§€ ìƒì„±](../stylegan/README.md) ì„ ìœ„í•œ í‘œì • ì •ë³´ ì¶”ì¶œ                                                                   | [Polyglot-Ko 1.3B (HuggingFace)](https://huggingface.co/EleutherAI/polyglot-ko-1.3b)<br>(by **EleutherAI**) |
| summary (í•˜ê³  ìˆëŠ” ëŒ€í™” ìš”ì•½) ```summary```    | ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë° Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬, **ë‹¤ìŒ í„´ì—ì„œ ì´ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì˜¤ë¡œë¼ê°€ ë³´ë‹¤ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µí•  ìˆ˜ ìˆê²Œ** í•¨                                          | [Kanana-1.5 2.1B (HuggingFace)](https://huggingface.co/kakaocorp/kanana-1.5-2.1b-base)<br>(by **Kakao**)    |

* ì¶”ê°€ ë©”ì»¤ë‹ˆì¦˜
  * [LLM Memory](#1-2-llm-memory-rag-like-concept) ë° [LLM Ethics](#1-3-llm-ethics-s-bert) ì— ì‚¬ìš©ë˜ëŠ” S-BERT ëª¨ë¸ì€ **ì„œë¡œ ë³„ê°œì˜ ëª¨ë¸ì„**

| ë©”ì»¤ë‹ˆì¦˜                                           | ì„¤ëª…                                                                                                                                                                                                                           | í•™ìŠµ ëª¨ë¸                                                                                                                                                                                      |
|------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [LLM Memory](#1-2-llm-memory-rag-like-concept) | - [RAG (Retrieval Augmented Generation)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_RAG.md) ê³¼ ìœ ì‚¬í•œ ì»¨ì…‰<br>- ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ Oh-LoRA ğŸ‘±â€â™€ï¸ ì˜ ë©”ëª¨ë¦¬ì—ì„œ ê·¸ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜´ | [Sentence BERT (S-BERT)]((https://github.com/WannaBeSuperteur/AI-study/blob/main/Natural%20Language%20Processing/Basics_BERT%2C%20SBERT%20%EB%AA%A8%EB%8D%B8.md#sbert-%EB%AA%A8%EB%8D%B8)) |
| [LLM Ethics](#1-3-llm-ethics-s-bert)           | - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë¬¸ì œê°€ ìˆëŠ” ì§ˆë¬¸ (```ë§Œë‚¨/ì‚¬ë‘ ê³ ë°±``` ```ì •ì¹˜``` ```íŒ¨ë“œë¦½``` ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜) ì¸ì§€ë¥¼ íŒë‹¨<br>- ê° ì¹´í…Œê³ ë¦¬ì™€ì˜ ìœ ì‚¬ë„ë¥¼ íŒë‹¨                                                                                                                              | [Sentence BERT (S-BERT)]((https://github.com/WannaBeSuperteur/AI-study/blob/main/Natural%20Language%20Processing/Basics_BERT%2C%20SBERT%20%EB%AA%A8%EB%8D%B8.md#sbert-%EB%AA%A8%EB%8D%B8)) | 

### 1-1. í˜„ì¬ ì‹œê°„ ì •ë³´ ì¶”ê°€

* ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹¤ìŒ ë‹¨ì–´ ì¤‘ ì ì–´ë„ 1ê°œ í¬í•¨ ì‹œ, ì‚¬ìš©ìì˜ ìµœì´ˆ ì›ë³¸ ì§ˆë¬¸ì— í˜„ì¬ ì‹œê°„ ì •ë³´ ì¶”ê°€
  * ```ì˜¤ëŠ˜``` ```ë‚´ì¼``` ```ì§€ê¸ˆ``` ```ìš”ì¼``` ```ì´ë”°``` ```íœ´ì¼```
* í˜„ì¬ ì‹œê°„ ì •ë³´

| ì»´í“¨í„° ì‹œìŠ¤í…œ ì‹œê° (ë¡œì»¬ ê¸°ì¤€)                        | í˜„ì¬ ì‹œê°„ ì •ë³´           |
|-------------------------------------------|--------------------|
| ë‹¹ì¼ AM 04:00 - AM 11:59                    | ```(ì§€ê¸ˆì€ Oìš”ì¼ ì˜¤ì „)``` |
| ë‹¹ì¼ ì •ì˜¤ - PM 05:59 (ê¸ˆìš”ì¼ì€ PM 04:59)          | ```(ì§€ê¸ˆì€ Oìš”ì¼ ì˜¤í›„)``` |
| ë‹¹ì¼ PM 06:00 (ê¸ˆìš”ì¼ì€ PM 05:00) - ìµì¼ AM 03:59 | ```(ì§€ê¸ˆì€ Oìš”ì¼ ì €ë…)``` |

* ì˜ˆì‹œ
  * ```í† ìš”ì¼ PM 02:00``` ì— ```ë¡œë¼ì•¼ ì˜¤ëŠ˜ ì•½ì† ì—†ëŠ”ë° ë­í•˜ì§€``` ë¼ê³  ì§ˆë¬¸í•˜ë©´,
  * í˜„ì¬ ì‹œê°„ ì •ë³´ì¸ ```(ì§€ê¸ˆì€ í† ìš”ì¼ ì˜¤í›„)``` ê°€ ì¶”ê°€ë˜ì–´ ì‚¬ìš©ì ì§ˆë¬¸ì´ ```(ì§€ê¸ˆì€ í† ìš”ì¼ ì˜¤í›„) ë¡œë¼ì•¼ ì˜¤ëŠ˜ ì•½ì† ì—†ëŠ”ë° ë­í•˜ì§€``` ê°€ ë¨

### 1-2. LLM Memory (RAG-like concept)

![image](../../images/250408_28.PNG)

* ë™ì‘ ì›ë¦¬
  * [ì˜¤ë¡œë¼ v1 ì˜ LLM Memory êµ¬í˜„](../../2025_04_08_OhLoRA/llm/README.md#3-llm-memory-rag-like-concept) ê³¼ ë™ì¼
  * í•™ìŠµ ë° inference ë“± **ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ë¡œì§** ì€ [ì˜¤ë¡œë¼ v2 ì˜ LLM Memory êµ¬í˜„](../../2025_05_02_OhLoRA_v2/llm/README.md#1-1-llm-memory-rag-like-concept) ê³¼ ë™ì¼ [(S-BERT í•™ìŠµ ì•Œê³ ë¦¬ì¦˜)](../../2025_05_02_OhLoRA_v2/llm/README.md#1-2-llm-memory-ë©”ì»¤ë‹ˆì¦˜-í•™ìŠµ-s-bert)
* êµ¬í˜„ ì½”ë“œ
  * [S-BERT Inference](memory_mechanism/inference_sbert.py)
  * [Entry & Best Memory Item Choice](run_memory_mechanism.py)
  * LLM ì´ ì¶œë ¥í•œ í‘œì • ì •ë³´ë¥¼ Property Score ë¡œ ë³€í™˜ (TBU)

### 1-3. LLM Ethics (S-BERT)

![image](../../images/250526_22.png)

* ë™ì‘ ì›ë¦¬
  * [Sentence BERT (S-BERT)](https://github.com/WannaBeSuperteur/AI-study/blob/main/Natural%20Language%20Processing/Basics_BERT%2C%20SBERT%20%EB%AA%A8%EB%8D%B8.md#sbert-%EB%AA%A8%EB%8D%B8) ê¸°ë°˜ 
  * ì‚¬ìš©ìì˜ ìµœì´ˆ ì›ë³¸ í”„ë¡¬í”„íŠ¸ì™€ ê° ë¶ˆëŸ‰ ì–¸ì–´ ì¹´í…Œê³ ë¦¬ (```ì‚¬ë‘ ê³ ë°±/ë§Œë‚¨``` ```ì •ì¹˜``` ```íŒ¨ë“œë¦½```) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ë¥¼ S-BERT ë¡œ ë¹„êµ
  * ê° ì¹´í…Œê³ ë¦¬ ë³„ **ì¼ì • threshold** ë³´ë‹¤ ë†’ìœ¼ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë°œì–¸ìœ¼ë¡œ íŒë‹¨
  * ì‚¬ìš©ìì˜ ê¸°ì¡´ ì œì¬ ë¡œê·¸ë¥¼ ê²€í† í•˜ì—¬ **ìµœì¢… ì œì¬ ìˆ˜ìœ„ (Oh-LoRA ğŸ‘±â€â™€ï¸ ê´€ë ¨ ì œí’ˆ "ì „ì²´ ì´ìš© ì œí•œ") ê²°ì •**
* êµ¬í˜„ ì½”ë“œ
  * [S-BERT Training](ethics_mechanism/train_sbert.py)
  * [S-BERT Inference](ethics_mechanism/inference_sbert.py)
  * ì‹¤ì œ ì‚¬ìš©ì ì œì¬ ì²˜ë¦¬ (TBU)
* ë³´ê³ ì„œ
  * [Ethics mechanism í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ](ethics_mechanism/test_report.md) 

## ì½”ë“œ ì‹¤í–‰ ë°©ë²•

ëª¨ë“  ì½”ë“œëŠ” **ë¨¼ì € ì•„ë˜ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì•ˆë‚´] (TBU) ë° í•´ë‹¹ ê° HuggingFace ë§í¬ì— ìˆëŠ” Model Card ì— ë‚˜íƒ€ë‚œ ì €ì¥ ê²½ë¡œ (Save Path) ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í›„,** ```2025_05_26_OhLoRA_v3``` (í”„ë¡œì íŠ¸ ë©”ì¸ ë””ë ‰í† ë¦¬) ì—ì„œ ì‹¤í–‰

### 1. LLM Fine-Tuning

ì§€ì •ëœ ê²½ë¡œì— í•´ë‹¹ LLM ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°, Fine-Tuning ëŒ€ì‹  **inference test ì‹¤í–‰ë¨**

| LLM                                  | Fine-Tuning ì½”ë“œ ì‹¤í–‰ ë°©ë²•                                                                 |
|--------------------------------------|--------------------------------------------------------------------------------------|
| ë‹µë³€ ë©”ì‹œì§€ ```output_message```          | ```python llm/run_fine_tuning.py -llm_names kanana -output_cols output_message```    |
| ìµœê·¼ ëŒ€í™” ë‚´ìš© ìš”ì•½ ```summary```            | ```python llm/run_fine_tuning.py -llm_names polyglot -output_cols summary```         |
| ë©”ëª¨ë¦¬ (ì‚¬ìš©ìì— ëŒ€í•´ ê¸°ì–µ í•„ìš”í•œ ë‚´ìš©) ```memory``` | ```python llm/run_fine_tuning.py -llm_names kanana -output_cols memory```            |
| í‘œì • ë° ê³ ê°œ ëŒë¦¼ ì œì–´ ```eyes_mouth_pose```  | ```python llm/run_fine_tuning.py -llm_names polyglot -output_cols eyes_mouth_pose``` |

### 2. Memory Mechanism (RAG-like concept)

* **Memory Mechanism (S-BERT)** ëª¨ë¸ ì‹¤í–‰ (í•´ë‹¹ ëª¨ë¸ ì—†ì„ ì‹œ, Training ë¨¼ì € ì‹¤í–‰)
  * ```python llm/run_memory_mechanism.py```

### 3. Ethics Mechanism

* **Ethics Mechanism (S-BERT)** ëª¨ë¸ ì‹¤í–‰ (í•´ë‹¹ ëª¨ë¸ ì—†ì„ ì‹œ, Training ë¨¼ì € ì‹¤í–‰)
  * ```python llm/run_ethics_mechanism.py```
