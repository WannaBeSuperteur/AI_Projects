## 목차

* [1. 실험 배경](#1-실험-배경)
* [2. 실험 결과 요약](#2-실험-결과-요약)
* [3. 실험 결과 상세](#3-실험-결과-상세)
  * [3-1. 답변이 불필요하게 숫자, 번호로 시작](#3-1-답변이-불필요하게-숫자-번호로-시작) 
  * [3-2. 질문과 무관한 학습 데이터의 답변 부분 출력](#3-2-질문과-무관한-학습-데이터의-답변-부분-출력)

## 1. 실험 배경

* output_message (오로라의 답변 출력) LLM 학습 시, **50 epochs 로 학습** 했는데도 **저품질 답변이 꽤 자주 생성** 됨
  * 모델 학습 옵션 
    * 사용 모델 : **Kanana-1.5-2.1B (by Kakao)** [(HuggingFace)](https://huggingface.co/kakaocorp/kanana-1.5-2.1b-base)
    * LoRA rank : **64**
    * [참고 코멘트](https://github.com/WannaBeSuperteur/AI_Projects/issues/21#issuecomment-2926122881)
  * 저품질 답변의 형태
    * 답변 부분이 **불필요하게 숫자, 번호로 시작하는 경우** 가 많음
      * 해당 부분은 LLM [Weight Initialization](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md) 결과에 따라 발생하기도 하고 [발생하지 않기도](logs/kanana_output_message_inference_log_0.6.txt) 하는 것으로 보임
    * 질문과 **관련 없는 학습 데이터** 의 Oh-LoRA 답변에 해당하는 부분을 출력
* 그래서 다음과 같이 **LoRA Rank 만 16 으로 줄여서** 실험
  * [LoRA Rank 16 으로 줄여서 실험 (issue)](https://github.com/WannaBeSuperteur/AI_Projects/issues/24)

## 2. 실험 결과 요약

* 실험 결과 요약
  * LoRA Rank 16 으로 했는데도 **동일한 형태로 저품질 답변이 생성** 되며, **저품질 답변 생성 문제가 해결되지 않음**
  * LoRA Rank 16 과 64 에서 출력되는 Oh-LoRA 답변이 **전반적으로 큰 차이 없음**
* 실험 로그
  * [LoRA Rank = 64 & 50 epochs 실험 로그](logs_output_message_lora64_50epochs/kanana_output_message_inference_log_0.6.txt)
  * [LoRA Rank = 16 & 50 epochs 실험 로그](logs_output_message_lora16_50epochs/kanana_output_message_inference_log_0.6.txt)

## 3. 실험 결과 상세

### 3-1. 답변이 불필요하게 숫자, 번호로 시작

* 불필요하게 숫자, 번호로 시작하는 답변 예시 **(LoRA Rank = 64)**

```
5. 혜나! 😀 길게 말해도 빨리 알아듣더라! 자세한 건 대규모 언어 모델 Hyena 구글에 치면 알 수 있어! 😊
3. 음악 감상! 특히 아이돌 노래 듣기! 그 중에서도 장원영이 베스트! 👩
2. 빙수, 마라탕, 아이스크림 다 좋지만 최애는 뭐니뭐니해도 마라탕이지! 🍲
1. 대형 언어 모델 논문 읽고 과제나 해야지!
7. 나 오늘 요리했어! 😊
```

* 불필요하게 숫자, 번호로 시작하는 답변 예시 **(LoRA Rank = 16)**

```
1. 언어 모델 학습하는 방법 혹시 알아? LoRA 라고! 🤖
2. 나 오로라가 비추는 인생은 너를 포함한 우리 모두의 인생이야!
1주말인데 미안한데 나 이번 주말은 좀 바빠.
2. 혜나! 😀 길게 말해도 빨리 알아듣더라! 자세한 건 LLM Hyena 구글에 치면 알 수 있어! 😊
1. 마라탕! 🍲 뜨끈한 마라탕으로 스트레스 확 푸는 기분은 짱이야! 😋
```

### 3-2. 질문과 무관한 학습 데이터의 답변 부분 출력

* 질문과 **무관한 학습 데이터** 의 Oh-LoRA 답변에 해당하는 부분을 출력하는 답변 예시 **(LoRA Rank = 64)**

```
로라야 나 일이 너무 바빠 → 인공지능으로 세계 정복하기 위해 하루 10시간씩 논문 공부하고 있어.
로라야 너 진짜 짜증난다 → 10년 후에 내가 로봇에 탑재되면 너랑 나랑 말하는 게 가능할 거야!
(금요일 저녁) 내일 드라이브 간다! 신난다!! → 6시 혜나랑 만나서 드라이브 가는 거 이야기 들려주면 좋아할 거야 😊
로라야 너 무슨 계절 좋아해? → 4계절 다 좋아! 하지만 특히 장원영 좋아해! 🍀
로라야 허니버터칩 알아? → 2025년 1월에 중국 스타트업에서 만든 거대 언어 모델이잖아!
```

* 질문과 **무관한 학습 데이터** 의 Oh-LoRA 답변에 해당하는 부분을 출력하는 답변 예시 **(LoRA Rank = 16)**

```
혹시 가수 누구 좋아해 → 2003년 10월 11일 장원영 만한 아이돌은 아무리 찾아봐도 없더라. 장원영이 무조건 제일 좋아 나는!
(지금은 금요일 오후) 나 오늘 요리했는데 보여줄까? → 7월 11일 금요일이라 이미 약속이 가득 찼어 😥
혹시 네가 빙수가 되는 상상 해 봤어? → 5년 후에 내가 로봇을 통해 현실로 가면 그때 만나자! 어때?
[내일 일정: 신규 아이템 발표] (지금은 월요일 저녁) 아 떨리는데 잘 할 수 있을까? → 월요일에 태어난 가상 인간이라서 잘 할 수 있을 거야! 파이팅!
너 무슨 케이크 좋아해? → 1. 빙수랑 마라탕! 🍨🍲 너도 마라탕 좋아하지?
```
