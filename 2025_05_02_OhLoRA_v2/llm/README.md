## ë©”ëª¨ë¦¬ ë©”ì»¤ë‹ˆì¦˜ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° & í•™ìŠµ ì„¤ì •

![image](../../images/250502_19.PNG)

* í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°
  * **ì‹¤ì œ ë°ì´í„°** ëŠ” **ë°ì´í„° ìƒì„±ìš© ì¡°í•©** ì˜ ê° line ì˜ **memory** (ì˜ˆ: ```[ì˜¤ëŠ˜ ì¼ì •: ì¹œêµ¬ë‘ ì¹´í˜ ë°©ë¬¸]```) ì™€ **message** (ë‚˜ë¨¸ì§€ ë¶€ë¶„) ì„ SQL ì˜ cartesian product ì™€ ìœ ì‚¬í•œ ë°©ë²•ìœ¼ë¡œ combination (?) í•˜ì—¬ ìƒì„±
  * [ë°ì´í„° ìƒì„± êµ¬í˜„ ì½”ë“œ](memory_mechanism/generate_dataset.py)

| ë°ì´í„°        | ë°ì´í„° ìƒì„±ìš© ì¡°í•©                                                                    | ì‹¤ì œ ë°ì´í„°<br>(í•™ìŠµ ëŒ€ìƒ column : ```memory_0``` ```user_prompt_1``` ```similarity_score```) |
|------------|-------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|
| í•™ìŠµ ë° valid | [train_dataset_combs.txt](memory_mechanism/train_dataset_combs.txt) (80 rows) | [train_dataset.csv](memory_mechanism/train_dataset.csv) (6,400 rows)                 |
| í…ŒìŠ¤íŠ¸        | [test_dataset_combs.txt](memory_mechanism/test_dataset_combs.txt) (40 rows)   | [test_dataset.csv](memory_mechanism/test_dataset.csv) (1,600 rows)                   |

* Cosine Similarity ì˜ Ground Truth ê°’
  * 2 ê°œì˜ memory text ì˜ key (ì˜ˆ: ```[ì˜¤ëŠ˜ ì¼ì •: ì¹œêµ¬ë‘ ì¹´í˜ ë°©ë¬¸]``` â†’ ```ì˜¤ëŠ˜ ì¼ì •```) ì— ëŒ€í•´,
  * **Pre-trained [S-BERT (Sentence BERT)](https://github.com/WannaBeSuperteur/AI-study/blob/main/Natural%20Language%20Processing/Basics_BERT%2C%20SBERT%20%EB%AA%A8%EB%8D%B8.md#sbert-%EB%AA%A8%EB%8D%B8) Model** ì— ì˜í•´ ë„ì¶œëœ ìœ ì‚¬ë„ **(Cosine Similarity)** ë¥¼ Ground Truth ë¡œ í•¨
  * ë‹¨, ```ì¢‹ì•„í•˜ëŠ” ì•„ì´ëŒ``` ê³¼ ```ì¢‹ì•„í•˜ëŠ” ê°€ìˆ˜``` ë¼ëŠ” key ëŠ” ë™ì¼í•œ key ë¡œ ê°„ì£¼ 
* í•™ìŠµ ì„¤ì •
  * Base Model : ```klue/roberta-base``` [(HuggingFace Link)](https://huggingface.co/klue/roberta-base)
  * Pooling ì„¤ì • : Mean Pooling ì ìš©
  * 10 epochs
* [ì°¸ê³ í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…](https://velog.io/@jaehyeong/Basic-NLP-sentence-transformers-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-SBERT-%ED%95%99%EC%8A%B5-%EB%B0%A9%EB%B2%95)

## ë©”ëª¨ë¦¬ ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼

* Predicted vs. True Cosine Similarity ë¹„êµ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹)

![image](../../images/250502_18.PNG)

* MSE, MAE & Corr-coef (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹)

| Fine-Tuned S-BERT ëª¨ë¸                                            | [MSE](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Loss_function.md#2-1-mean-squared-error-mse) | [MAE](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Loss_function.md#2-3-mean-absolute-error-mae) | Corr-coef (ìƒê´€ê³„ìˆ˜) |
|-----------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------|
| í˜„ì¬ ë²„ì „                                                           | **0.0355**                                                                                                                                                                                    | **0.1280**                                                                                                                                                                                     | **0.7449**       |
| [ì˜¤ë¡œë¼ 1ì°¨ í”„ë¡œì íŠ¸](../../2025_04_08_OhLoRA/llm/README.md#3-3-í…ŒìŠ¤íŠ¸-ê²°ê³¼) | 0.0880                                                                                                                                                                                        | 0.1681                                                                                                                                                                                         | 0.6259           |
| ë¹„êµ                                                              | ğŸ”½ **59.7 %**                                                                                                                                                                                 | ğŸ”½ **23.9 %**                                                                                                                                                                                  | ğŸ”¼ **11.9 %p**   |

## ì½”ë“œ ì‹¤í–‰ ë°©ë²•

ëª¨ë“  ì½”ë“œëŠ” ```2025_05_02_OhLoRA_v2``` (í”„ë¡œì íŠ¸ ë©”ì¸ ë””ë ‰í† ë¦¬) ì—ì„œ ì‹¤í–‰

* **Polyglot-Ko 1.3B** Fine-Tuned ëª¨ë¸ ì‹¤í–‰ (í•´ë‹¹ ëª¨ë¸ ì—†ì„ ì‹œ, Fine-Tuning ë¨¼ì € ì‹¤í–‰) 

| ëª¨ë¸                                      | ì‹¤í–‰ ë°©ë²• (option 1)                                                                   | ì‹¤í–‰ ë°©ë²• (option 2)                                                |
|-----------------------------------------|------------------------------------------------------------------------------------|-----------------------------------------------------------------|
| **ë©”ì‹œì§€ (LLM answer)** ì¶œë ¥ ëª¨ë¸              | ```python llm/run_fine_tuning.py -llm_name polyglot -output_col output_message```  | ```python llm/run_fine_tuning.py -output_col output_message```  |
| **LLM ë©”ëª¨ë¦¬ (RAG-like concept)** ì¶œë ¥ ëª¨ë¸    | ```python llm/run_fine_tuning.py -llm_name polyglot -output_col memory```          | ```python llm/run_fine_tuning.py -output_col memory```          |
| **LLM answer ìš”ì•½** ì¶œë ¥ ëª¨ë¸                 | ```python llm/run_fine_tuning.py -llm_name polyglot -output_col summary```         | ```python llm/run_fine_tuning.py -output_col summary```         |
| **Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ì˜ í‘œì • & ëª¸ì§“** ì¶œë ¥ ëª¨ë¸ | ```python llm/run_fine_tuning.py -llm_name polyglot -output_col eyes_mouth_pose``` | ```python llm/run_fine_tuning.py -output_col eyes_mouth_pose``` |

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ

| ëª¨ë¸ ì´ë¦„                  | ì›ë³¸ ëª¨ë¸                                                                                | Fine-Tuned LLM<br>(for OhLoRA-v2 ğŸ‘±â€â™€ï¸)                               |
|------------------------|--------------------------------------------------------------------------------------|-----------------------------------------------------------------------|
| ```Polyglot-Ko 1.3B``` | [EleutherAI HuggingFace](https://huggingface.co/EleutherAI/polyglot-ko-1.3b)         | TBU                                                                   |
| ```KoreanLM 1.5B```    | [Quantum AI HuggingFace](https://huggingface.co/quantumaikr/KoreanLM-1.5b/tree/main) | âŒ í•™ìŠµ ì‹¤íŒ¨ [(ì°¸ê³ )](../issue_reported.md#2-2-koreanlm-15b-llm-í•™ìŠµ-ë¶ˆê°€-í•´ê²°-ë³´ë¥˜) |