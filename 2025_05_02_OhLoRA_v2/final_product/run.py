import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

import random
import math
import numpy as np

import argparse
import threading
import os
import sys
import time
PROJECT_DIR_PATH = os.path.dirname(os.path.abspath(os.path.dirname(__file__)))
sys.path.append(PROJECT_DIR_PATH)

from run_llm import (generate_llm_answer, clean_llm_answer, parse_memory, save_memory_list, summarize_llm_answer,
                     decide_property_score_texts, decide_property_scores)
from run_display import generate_and_show_ohlora_image

from stylegan.stylegan_common.stylegan_generator import StyleGANGeneratorForV6
from stylegan.run_stylegan_vectorfind_v7 import (load_ohlora_z_vectors,
                                                 load_ohlora_w_group_names,
                                                 get_property_change_vectors)

from llm.memory_mechanism.load_sbert_model import load_pretrained_sbert_model
from llm.run_memory_mechanism import pick_best_memory_item


EYES_BASE_SCORE, MOUTH_BASE_SCORE, POSE_BASE_SCORE = 0.2, 1.0, 0.0


ohlora_z_vector = None
eyes_vector, mouth_vector, pose_vector = None, None, None
eyes_current_score, mouth_current_score, pose_current_score = EYES_BASE_SCORE, MOUTH_BASE_SCORE, POSE_BASE_SCORE

status = 'waiting'
last_eyes_close, last_pose_right, last_answer_generate = None, None, time.time()

passed_ohlora_nos = [127, 672, 709, 931, 1017, 1073, 1162, 1211, 1277, 1351,
                     1359, 1409, 1591, 1646, 1782, 1788, 1819, 1836, 1905, 1918,
                     2054, 2089, 2100, 2111, 2137, 2185, 2240]

eyes_vector_queue = []
mouth_vector_queue = []
pose_vector_queue = []

# 0 --> 1 --> 1 --> 0 cosine line values
cosine_line_values_up = [math.cos((1.0 + (x / 30.0)) * math.pi) for x in range(30)]
cosine_line_values_down = [math.cos((2.0 + (x / 30.0)) * math.pi) for x in range(30)]
cosine_line_values = cosine_line_values_up + [1.0 for _ in range(10)] + cosine_line_values_down
cosine_line_values = [(x + 1.0) / 2.0 for x in cosine_line_values]


# ÌïÑÏöîÌïú Î™®Îç∏ Î°úÎî© : StyleGAN-VectorFind-v7 Generator, 4 LLMs (Polyglot-Ko 1.3B Fine-Tuned), S-BERT (RoBERTa-based)
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments:
# - ÏóÜÏùå

# Returns:
# - stylegan_generator    (nn.Module)       : StyleGAN-VectorFind-v7 generator
# - ohlora_llms           (dict(LLM))       : LLM (Polyglot-Ko 1.3B Fine-Tuned)
#                                             {'output_message': LLM, 'memory': LLM, 'summary': LLM,
#                                              'eyes_mouth_pose': LLM}
# - ohlora_llms_tokenizer (dict(tokenizer)) : LLM (Polyglot-Ko 1.3B Fine-Tuned) Ïóê ÎåÄÌïú tokenizer
#                                             {'output_message': tokenizer, 'memory': tokenizer, 'summary': tokenizer,
#                                              'eyes_mouth_pose': tokenizer}
# - sbert_model           (S-BERT Model)    : S-BERT (RoBERTa-based)

def load_models():
    gpu_0 = torch.device('cuda:0')
    gpu_1 = torch.device('cuda:1')

    output_types = ['output_message', 'memory', 'eyes_mouth_pose', 'summary']
    device_mapping = {'output_message': gpu_0, 'memory': gpu_0, 'eyes_mouth_pose': gpu_1, 'summary': gpu_1}

    # load StyleGAN-VectorFind-v7 generator model
    stylegan_generator = StyleGANGeneratorForV6(resolution=256)  # v6 and v7 have same architecture
    stylegan_model_dir = f'{PROJECT_DIR_PATH}/stylegan/models'
    generator_path = f'{stylegan_model_dir}/stylegan_gen_vector_find_v7.pth'

    generator_state_dict = torch.load(generator_path, map_location=device, weights_only=True)
    stylegan_generator.load_state_dict(generator_state_dict)
    stylegan_generator.to(device)

    # load Oh-LoRA final LLM and tokenizer
    ohlora_llms = {}
    ohlora_llms_tokenizer = {}

    for output_type in output_types:
        model_path = f'{PROJECT_DIR_PATH}/llm/models/polyglot_{output_type}_fine_tuned'
        ohlora_llm = AutoModelForCausalLM.from_pretrained(model_path,
                                                          trust_remote_code=True,
                                                          torch_dtype=torch.bfloat16).to(device_mapping[output_type])

        ohlora_llm_tokenizer = AutoTokenizer.from_pretrained(model_path)
        ohlora_llm.generation_config.pad_token_id = ohlora_llm_tokenizer.pad_token_id

        ohlora_llms[output_type] = ohlora_llm
        ohlora_llms_tokenizer[output_type] = ohlora_llm_tokenizer

    # load S-BERT Model (RoBERTa-based)
    model_path = f'{PROJECT_DIR_PATH}/llm/models/memory_sbert/trained_sbert_model'
    sbert_model = load_pretrained_sbert_model(model_path)

    return stylegan_generator, ohlora_llms, ohlora_llms_tokenizer, sbert_model


# Oh-LoRA (Ïò§Î°úÎùº) ÎãµÎ≥Ä ÏßÅÌõÑ Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments:
# - eyes_score  (float) : ÎààÏùÑ Îú¨ Ï†ïÎèÑ (eyes) Ïùò ÏÜçÏÑ± Í∞í Ï†êÏàò (= ÏÜçÏÑ± Í∞í Î≥ÄÌôî Î≤°ÌÑ∞Î•º ÎçîÌïòÎäî Í∞ÄÏ§ëÏπò)
# - mouth_score (float) : ÏûÖÏùÑ Î≤åÎ¶∞ Ï†ïÎèÑ (mouth) Ïùò ÏÜçÏÑ± Í∞í Ï†êÏàò (= ÏÜçÏÑ± Í∞í Î≥ÄÌôî Î≤°ÌÑ∞Î•º ÎçîÌïòÎäî Í∞ÄÏ§ëÏπò)
# - pose_score  (float) : Í≥†Í∞ú ÎèåÎ¶º (pose) Ïùò ÏÜçÏÑ± Í∞í Ï†êÏàò (= ÏÜçÏÑ± Í∞í Î≥ÄÌôî Î≤°ÌÑ∞Î•º ÎçîÌïòÎäî Í∞ÄÏ§ëÏπò)

def handle_ohlora_answered(eyes_score, mouth_score, pose_score):
    global eyes_vector_queue, mouth_vector_queue, pose_vector_queue
    global eyes_current_score, mouth_current_score, pose_current_score

    for cosine_line_value in cosine_line_values:
        eyes_vector_queue.append(eyes_current_score + (eyes_score - eyes_current_score) * cosine_line_value)
        mouth_vector_queue.append(mouth_current_score + (mouth_score - mouth_current_score) * cosine_line_value)
        pose_vector_queue.append(pose_current_score + (pose_score - pose_current_score) * cosine_line_value)


# Oh-LoRA (Ïò§Î°úÎùº) Ïã§ÏãúÍ∞Ñ Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± Ìï∏Îì§ÎßÅ (+ Ïû•ÏãúÍ∞Ñ waiting Ïãú Í∞ïÏ†ú Ï¢ÖÎ£å Ï≤òÎ¶¨)
# Create Date : 2025.05.20
# Last Update Date : 2025.05.21
# - ÏÇ¨Ïö©Ïûê ÏûÖÎ†• ÏóÜÏùÑ Ïãú Ïò§Î°úÎùºÍ∞Ä ÎåÄÌôîÎ•º Í∞ïÏ†ú Ï¢ÖÎ£åÌïòÎäî Ï°∞Í±¥ ÏàòÏ†ï

# Arguments:
# - ÏóÜÏùå

def realtime_ohlora_generate():
    global ohlora_z_vector, eyes_vector, mouth_vector, pose_vector
    global eyes_vector_queue, mouth_vector_queue, pose_vector_queue
    global eyes_current_score, mouth_current_score, pose_current_score
    global status, last_eyes_close, last_pose_right, last_answer_generate

    while status == 'waiting' or status == 'generating':
        eyes_score = eyes_vector_queue.pop(-1) if len(eyes_vector_queue) > 0 else eyes_current_score
        mouth_score = mouth_vector_queue.pop(-1) if len(mouth_vector_queue) > 0 else mouth_current_score
        pose_score = pose_vector_queue.pop(-1) if len(pose_vector_queue) > 0 else pose_current_score

        # random very-small eyes, mouth, pose change
        eyes_current_score = eyes_current_score + 0.07 * random.random() - 0.035
        eyes_current_score = np.clip(eyes_current_score, EYES_BASE_SCORE - 0.25, EYES_BASE_SCORE + 0.25)

        mouth_current_score = mouth_current_score + 0.05 * random.random() - 0.025
        mouth_current_score = np.clip(mouth_current_score, MOUTH_BASE_SCORE - 0.15, MOUTH_BASE_SCORE + 0.15)

        pose_current_score = pose_current_score + 0.09 * random.random() - 0.045
        pose_current_score = np.clip(pose_current_score, POSE_BASE_SCORE - 0.4, POSE_BASE_SCORE + 0.4)

        # random eyes open/close change
        if (time.time() - last_answer_generate >= 5.0 and
                (last_eyes_close is None or time.time() - last_eyes_close >= 1.0)):

            if random.random() < 0.025:
                eyes_magnitude = 1.1 + random.random() * 0.4
                r = random.random()

                if r < 0.4:
                    eyes_change_np = np.array([0.4, 0.6, 0.8, 0.8, 0.6, 0.4]) * eyes_magnitude
                elif r < 0.7:
                    eyes_change_np = np.array([0.4, 0.6, 0.8, 0.6, 0.4]) * eyes_magnitude
                else:
                    eyes_change_np = np.array([0.4, 0.7, 0.7, 0.4]) * eyes_magnitude

                eyes_change_list = list(eyes_change_np)
                eyes_vector_queue += eyes_change_list

                last_eyes_close = time.time()

        # handling long time waiting
        if status == 'waiting' and time.time() - last_answer_generate >= 120.0:
            if random.random() < 0.001:
                status = 'finished'

                ohlora_waiting_time = time.time() - last_answer_generate
                print(f'[SYSTEM MESSAGE] Ïò§Î°úÎùºüë±‚Äç‚ôÄÔ∏è Ïùò ÎßàÏßÄÎßâ ÎãµÎ≥Ä ÌõÑ {int(ohlora_waiting_time)} Ï¥à ÎèôÏïà '
                      f'ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ ÏûÖÎ†•Ïù¥ ÏóÜÏñ¥ÏÑú, Ïò§Î°úÎùºüë±‚Äç‚ôÄÔ∏è Í∞Ä ÎåÄÌôîÎ•º Í∞ïÏ†ú Ï¢ÖÎ£åÌñàÏäµÎãàÎã§.')
                raise Exception('finished_by_ohlora')

        # generate Oh-LoRA image
        generate_and_show_ohlora_image(stylegan_generator, ohlora_z_vector, eyes_vector, mouth_vector, pose_vector,
                                       eyes_score, mouth_score, pose_score)


# Oh-LoRA (Ïò§Î°úÎùº) Ïã§Ìñâ
# Create Date : 2025.05.20
# Last Update Date : 2025.05.21
# - summary ÏóÖÎç∞Ïù¥Ìä∏ Í≤∞Í≥ºÍ∞Ä None (7Ìöå ÏãúÎèÑ ÏãúÏóêÎèÑ summary LLM ÎãµÎ≥ÄÏù¥ ÌòïÏãùÏóê ÎßûÏßÄ ÏïäÏùå) Ïùº Ïãú, summary Î•º Í≥µÎ∞±ÏúºÎ°ú Ï¥àÍ∏∞Ìôî
# - S-BERT memory Ìï≠Î™© Î∂àÎü¨Ïò§Í∏∞ ÏúÑÌïú corr-coef threshold 0.6 -> 0.95 Î°ú ÏÉÅÌñ•

# Arguments:
# - ohlora_llms           (dict(LLM))       : LLM (Polyglot-Ko 1.3B Fine-Tuned)
#                                             {'output_message': LLM, 'memory': LLM, 'summary': LLM,
#                                              'eyes_mouth_pose': LLM}
# - ohlora_llms_tokenizer (dict(tokenizer)) : LLM (Polyglot-Ko 1.3B Fine-Tuned) Ïóê ÎåÄÌïú tokenizer
#                                             {'output_message': tokenizer, 'memory': tokenizer, 'summary': tokenizer,
#                                              'eyes_mouth_pose': tokenizer}
# - sbert_model           (S-BERT Model)    : S-BERT (RoBERTa-based)

# Running Mechanism:
# - Oh-LoRA LLM ÎãµÎ≥Ä ÏÉùÏÑ± ÏãúÎßàÎã§ Ïù¥Ïóê Í∏∞Î∞òÌïòÏó¨ final_product/ohlora.png Í≤ΩÎ°úÏóê Ïò§Î°úÎùº Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±
# - Oh-LoRA ÎãµÎ≥ÄÏùÑ parsing ÌïòÏó¨ llm/memory_mechanism/saved_memory/ohlora_memory.txt Í≤ΩÎ°úÏóê Î©îÎ™®Î¶¨ Ï†ÄÏû•
# - S-BERT Î™®Îç∏ÏùÑ Ïù¥Ïö©ÌïòÏó¨, RAG ÏôÄ Ïú†ÏÇ¨Ìïú Î∞©ÏãùÏúºÎ°ú Ìï¥Îãπ ÌååÏùºÏóêÏÑú ÏÇ¨Ïö©Ïûê ÌîÑÎ°¨ÌîÑÌä∏Ïóê Í∞ÄÏû• Ï†ÅÌï©Ìïú Î©îÎ™®Î¶¨ Ï†ïÎ≥¥Î•º Ï∞æÏïÑÏÑú ÏµúÏ¢Ö LLM ÏûÖÎ†•Ïóê Ï∂îÍ∞Ä

def run_ohlora(ohlora_llms, ohlora_llms_tokenizer, sbert_model):
    global ohlora_z_vector, eyes_vector, mouth_vector, pose_vector
    global status, last_answer_generate

    summary = ''
    last_answer_generate = time.time()

    thread = threading.Thread(target=realtime_ohlora_generate)
    thread.start()

    while True:
        user_prompt = input('\nÏò§Î°úÎùºÏóêÍ≤å ÎßêÌïòÍ∏∞ (Ctrl+C to finish) : ')
        status = 'generating'

        # check user prompt length
        encoded_user_prompt = ohlora_llms_tokenizer['output_message'].encode(user_prompt)
        if len(encoded_user_prompt) > 48:
            print('[SYSTEM MESSAGE] ÎÑàÎ¨¥ Í∏¥ ÏßàÎ¨∏ÏùÄ Ïò§Î°úÎùºüë±‚Äç‚ôÄÔ∏è ÏóêÍ≤å Î∂ÄÎã¥ ÎèºÏöî! Í∑∏Îü∞ ÏßàÎ¨∏ÏùÄ Ïò§Î°úÎùºÏùò Ï†àÏπú ÌòúÎÇò üåπ (LLM Hyena) ÏóêÍ≤å Ìï¥ Ï£ºÏÑ∏Ïöî! üò¢')
            continue

        best_memory_item = pick_best_memory_item(sbert_model,
                                                 user_prompt,
                                                 memory_file_name='ohlora_memory.txt',
                                                 threshold=0.95,
                                                 verbose=False)

        if best_memory_item == '':
            if summary == '':
                final_ohlora_input = user_prompt
            else:
                final_ohlora_input = '(Ïò§Î°úÎùº ÎãµÎ≥Ä ÏöîÏïΩ) ' + summary + ' (ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏) ' + user_prompt
        else:
            final_ohlora_input = best_memory_item + ' ' + user_prompt

        # generate Oh-LoRA answer and post-process
        llm_answer = generate_llm_answer(ohlora_llm=ohlora_llms['output_message'],
                                         ohlora_llm_tokenizer=ohlora_llms_tokenizer['output_message'],
                                         final_ohlora_input=final_ohlora_input)
        llm_answer_cleaned = clean_llm_answer(llm_answer)

        # update memory
        memory_list = parse_memory(memory_llm=ohlora_llms['memory'],
                                   memory_llm_tokenizer=ohlora_llms_tokenizer['memory'],
                                   final_ohlora_input=final_ohlora_input)

        if memory_list is not None:
            save_memory_list(memory_list)

        # update summary
        updated_summary = summarize_llm_answer(summary_llm=ohlora_llms['summary'],
                                               summary_llm_tokenizer=ohlora_llms_tokenizer['summary'],
                                               final_ohlora_input=final_ohlora_input,
                                               llm_answer_cleaned=llm_answer_cleaned)

        if updated_summary is not None:
            summary = updated_summary
        else:
            summary = ''

        # generate Oh-LoRA image
        eyes_score_text, mouth_score_text, pose_score_text = decide_property_score_texts(
            eyes_mouth_pose_llm=ohlora_llms['eyes_mouth_pose'],
            eyes_mouth_pose_llm_tokenizer=ohlora_llms_tokenizer['eyes_mouth_pose'],
            llm_answer_cleaned=llm_answer_cleaned)

        eyes_score, mouth_score, pose_score = decide_property_scores(eyes_score_text, mouth_score_text, pose_score_text)

        print(f'üë±‚Äç‚ôÄÔ∏è Ïò§Î°úÎùº : {llm_answer_cleaned}')
        handle_ohlora_answered(eyes_score, mouth_score, pose_score)
        status = 'waiting'
        last_answer_generate = time.time()


# Oh-LoRA üë±‚Äç‚ôÄÔ∏è (Ïò§Î°úÎùº) Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±ÏùÑ ÏúÑÌïú vector Î∞òÌôò
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments:
# - ohlora_no (int or None) : Ïò§Î°úÎùº ÏñºÍµ¥ ÏÉùÏÑ±Ïö© latent z vector Ïùò Î≤àÌò∏ (index, case No.)
#                             Ï∞∏Í≥†: 2025_05_02_OhLoRA_v2/stylegan/stylegan_vectorfind_v7/final_OhLoRA_info.md ÌååÏùº

# Returns:
# - ohlora_z_vector (NumPy array) : Oh-LoRA Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±Ïö© latent z vector, dim = (512 + 3,)
# - eyes_vector     (NumPy array) : eyes (ÎààÏùÑ Îú¨ Ï†ïÎèÑ) ÌïµÏã¨ ÏÜçÏÑ± Í∞í Î≥ÄÌôî Î≤°ÌÑ∞, dim = (512,)
# - mouth_vector    (NumPy array) : mouth (ÏûÖÏùÑ Î≤åÎ¶∞ Ï†ïÎèÑ) ÌïµÏã¨ ÏÜçÏÑ± Í∞í Î≥ÄÌôî Î≤°ÌÑ∞, dim = (512,)
# - pose_vector     (NumPy array) : pose (Í≥†Í∞ú ÎèåÎ¶º) ÌïµÏã¨ ÏÜçÏÑ± Í∞í Î≥ÄÌôî Î≤°ÌÑ∞, dim = (512,)

def get_vectors(ohlora_no):
    global passed_ohlora_nos

    # find index of Oh-LoRA vectors
    ohlora_idx = None

    if ohlora_no is not None:
        for idx, passed_ohlora_no in enumerate(passed_ohlora_nos):
            if ohlora_no == passed_ohlora_no:
                ohlora_idx = idx
                break

    if ohlora_idx is None:
        ohlora_idx = random.randint(0, len(passed_ohlora_nos) - 1)
        print(f'Oh-LoRA face vector selected randomly : case No. {passed_ohlora_nos[ohlora_idx]}')

    # get Oh-LoRA vectors
    eyes_vectors, mouth_vectors, pose_vectors = get_property_change_vectors()

    ohlora_z_vector_csv_path = f'{PROJECT_DIR_PATH}/stylegan/stylegan_vectorfind_v7/ohlora_z_vectors.csv'
    ohlora_w_group_name_csv_path = f'{PROJECT_DIR_PATH}/stylegan/stylegan_vectorfind_v7/ohlora_w_group_names.csv'
    ohlora_z_vectors = load_ohlora_z_vectors(vector_csv_path=ohlora_z_vector_csv_path)
    ohlora_w_group_names = load_ohlora_w_group_names(group_name_csv_path=ohlora_w_group_name_csv_path)

    ohlora_z_vector = ohlora_z_vectors[ohlora_idx]
    ohlora_w_group_name = ohlora_w_group_names[ohlora_idx]

    eyes_vector = eyes_vectors[ohlora_w_group_name][0]
    mouth_vector = mouth_vectors[ohlora_w_group_name][0]
    pose_vector = pose_vectors[ohlora_w_group_name][0]

    return ohlora_z_vector, eyes_vector, mouth_vector, pose_vector


if __name__ == '__main__':

    # parse user arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('-ohlora_no',
                        help="latent z vector ID for Oh-LoRA face image generation (index, case No.)",
                        default='none')
    args = parser.parse_args()

    ohlora_no = args.ohlora_no
    try:
        ohlora_no = int(ohlora_no)
    except:
        ohlora_no = None

    # check device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'device : {device}')

    # get Oh-LoRA vectors
    ohlora_z_vector, eyes_vector, mouth_vector, pose_vector = get_vectors(ohlora_no)

    # load model
    stylegan_generator, ohlora_llms, ohlora_llms_tokenizer, sbert_model = load_models()
    print('ALL MODELS for Oh-LoRA (Ïò§Î°úÎùº) load successful!! üë±‚Äç‚ôÄÔ∏è')

    # run Oh-LoRA (Ïò§Î°úÎùº)
    try:
        run_ohlora(ohlora_llms, ohlora_llms_tokenizer, sbert_model)

    except KeyboardInterrupt:
        print('[SYSTEM MESSAGE] Ïò§Î°úÎùºÏôÄÏùò ÎåÄÌôîÍ∞Ä ÎÅùÎÇ¨ÏäµÎãàÎã§. üë±‚Äç‚ôÄÔ∏èüëã Îã§ÏùåÏóêÎèÑ Ïò§Î°úÎùºÏôÄ Ìï®ÍªòÌï¥ Ï£ºÏã§ Í±∞Ï£†?')
        status = 'finished'

    except Exception as e:
        print(f'error : {e}')
        status = 'finished'
