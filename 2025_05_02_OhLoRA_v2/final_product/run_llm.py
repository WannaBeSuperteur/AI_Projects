import torch
from transformers import StoppingCriteriaList

from llm.fine_tuning.inference import StopOnTokens


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ ìƒì„±
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments :
# - ohlora_llm           (LLM)       : output_message LLM (Polyglot-Ko 1.3B Fine-Tuned)
# - ohlora_llm_tokenizer (tokenizer) : output_message LLM (Polyglot-Ko 1.3B Fine-Tuned) ì— ëŒ€í•œ tokenizer
# - final_ohlora_input   (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ì—ê²Œ ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ë©”ì‹œì§€ (ê²½ìš°ì— ë”°ë¼ summary, memory text í¬í•¨)

# Returns :
# - ohlora_answer (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ë‹µë³€

def generate_llm_answer(ohlora_llm, ohlora_llm_tokenizer, final_ohlora_input):
    trial_count = 0
    max_trials = 30

    # tokenize final Oh-LoRA input
    final_ohlora_input_ = final_ohlora_input + ' (ë‹µë³€ ì‹œì‘)'

    inputs = ohlora_llm_tokenizer(final_ohlora_input_, return_tensors='pt')
    inputs = {'input_ids': inputs['input_ids'].to(ohlora_llm.device),
              'attention_mask': inputs['attention_mask'].to(ohlora_llm.device)}

    # for stopping criteria
    stop_token_ids = torch.tensor([1477, 1078, 4833, 12]).to(ohlora_llm.device)  # '(ë‹µë³€ ì¢…ë£Œ)'
    stopping_criteria = StoppingCriteriaList([StopOnTokens(stop_token_ids)])

    while trial_count < max_trials:
        outputs = ohlora_llm.generate(**inputs,
                                      max_length=96,
                                      do_sample=True,
                                      temperature=0.6,
                                      stopping_criteria=stopping_criteria)

        llm_answer = ohlora_llm_tokenizer.decode(outputs[0], skip_special_tokens=True)
        llm_answer = llm_answer[len(final_ohlora_input_):]
        llm_answer = llm_answer.replace('\u200b', '').replace('\xa0', '')  # zwsp, nbsp (í­ ì—†ëŠ” ê³µë°±, ì¤„ ë°”ê¿ˆ ì—†ëŠ” ê³µë°±) ì œê±°
        trial_count += 1

        # check LLM answer and return or retry
        is_empty = llm_answer.replace('\n', '').replace('(ë‹µë³€ ì¢…ë£Œ)', '').replace(' ', '') == ''
        is_answer_end_mark = 'ë‹µë³€ ì¢…ë£Œ' in llm_answer.replace('(ë‹µë³€ ì¢…ë£Œ)', '') or 'ë‹µë³€ì¢…ë£Œ' in llm_answer.replace('(ë‹µë³€ ì¢…ë£Œ)', '')
        starts_with_nonblank_in_early_try = trial_count < 3 and not llm_answer.startswith(' ')
        too_many_tokens = len(outputs[0]) >= 91
        is_uncleaned = is_empty or is_answer_end_mark or starts_with_nonblank_in_early_try or too_many_tokens

        is_unnecessary_quote = '"' in llm_answer or 'â€' in llm_answer or 'â€œ' in llm_answer or 'â€™' in llm_answer
        is_unnecessary_mark = 'ï¿½' in llm_answer
        is_too_many_blanks = '     ' in llm_answer
        is_low_quality = is_unnecessary_quote or is_unnecessary_mark or is_too_many_blanks

        print(trial_count, llm_answer)

        if (not is_uncleaned) and (not is_low_quality) and ('http' not in llm_answer):
            return llm_answer.replace('(ë‹µë³€ ì¢…ë£Œ)', '')

    return '(ì½ì”¹)'


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ì„ clean ì²˜ë¦¬
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments :
# - ohlora_answer (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ë‹µë³€

# Returns :
# - llm_answer_cleaned (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ì—ì„œ text clean ì„ ì‹¤ì‹œí•œ ì´í›„ì˜ ë‹µë³€

def clean_llm_answer(ohlora_answer):
    return ohlora_answer  # cleaning not needed


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ìƒì„±ëœ ë‹µë³€ìœ¼ë¡œë¶€í„° memory ì •ë³´ë¥¼ parsing
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments :
# - memory_llm           (LLM)       : memory LLM (Polyglot-Ko 1.3B Fine-Tuned)
# - memory_llm_tokenizer (tokenizer) : memory LLM (Polyglot-Ko 1.3B Fine-Tuned) ì— ëŒ€í•œ tokenizer
# - final_ohlora_input   (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ì—ê²Œ ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ë©”ì‹œì§€ (ê²½ìš°ì— ë”°ë¼ summary, memory text í¬í•¨)

# Returns :
# - memory_list (list(str)) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ì €ì¥í•´ì•¼ í•  ë©”ëª¨ë¦¬ ëª©ë¡

def parse_memory(memory_llm, memory_llm_tokenizer, final_ohlora_input):
    raise NotImplementedError


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ llm/memory_mechanism/saved_memory/ohlora_memory.txt ì— ì €ì¥
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments :
# - memory_list (list(str)) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ì €ì¥í•´ì•¼ í•  ë©”ëª¨ë¦¬ ëª©ë¡

def save_memory_list(memory_list):
    raise NotImplementedError


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ ìš”ì•½
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments :
# - summary_llm           (LLM)       : summary LLM (Polyglot-Ko 1.3B Fine-Tuned)
# - summary_llm_tokenizer (tokenizer) : summary LLM (Polyglot-Ko 1.3B Fine-Tuned) ì— ëŒ€í•œ tokenizer
# - final_ohlora_input    (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ì—ê²Œ ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ë©”ì‹œì§€ (ê²½ìš°ì— ë”°ë¼ summary, memory text í¬í•¨)
# - llm_answer_cleaned    (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ì—ì„œ text clean ì„ ì‹¤ì‹œí•œ ì´í›„ì˜ ë‹µë³€

# Returns :
# - llm_summary (str) : ì§ì „ ëŒ€í™” ë‚´ìš©ì— ëŒ€í•œ ìš”ì•½

def summarize_llm_answer(summary_llm, summary_llm_tokenizer, final_ohlora_input, llm_answer_cleaned):
    raise NotImplementedError


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ì— ë”°ë¼ ëˆˆì„ ëœ¬ ì •ë„ (eyes), ì…ì„ ë²Œë¦° ì •ë„ (mouth), ê³ ê°œ ëŒë¦¼ (pose) ì ìˆ˜ ì‚°ì¶œ
# Create Date : 2025.05.20
# Last Update Date : -

# Arguments :
# - eyes_mouth_pose_llm           (LLM)       : eyes_mouth_pose LLM (Polyglot-Ko 1.3B Fine-Tuned)
# - eyes_mouth_pose_llm_tokenizer (tokenizer) : eyes_mouth_pose LLM (Polyglot-Ko 1.3B Fine-Tuned) ì— ëŒ€í•œ tokenizer
# - llm_answer_cleaned            (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ì—ì„œ text clean ì„ ì‹¤ì‹œí•œ ì´í›„ì˜ ë‹µë³€

# Returns :
# - eyes_score  (float) : ëˆˆì„ ëœ¬ ì •ë„ (eyes) ì˜ ì†ì„± ê°’ ì ìˆ˜
# - mouth_score (float) : ì…ì„ ë²Œë¦° ì •ë„ (mouth) ì˜ ì†ì„± ê°’ ì ìˆ˜
# - pose_score  (float) : ê³ ê°œ ëŒë¦¼ (pose) ì˜ ì†ì„± ê°’ ì ìˆ˜

def decide_property_scores(eyes_mouth_pose_llm, eyes_mouth_pose_llm_tokenizer, llm_answer_cleaned):
    raise NotImplementedError

