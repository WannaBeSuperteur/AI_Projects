## ëª©ì°¨

* [1. OhLoRA-v4 LLM ì „ì²´ ë©”ì»¤ë‹ˆì¦˜](#1-ohlora-v4-llm-ì „ì²´-ë©”ì»¤ë‹ˆì¦˜)
  * [1-1. LLM Ethics (S-BERT)](#1-1-llm-ethics-s-bert)
* [2. OhLoRA-v4 LLM Fine-Tuning](#2-ohlora-v4-llm-fine-tuning)
* [3. ì½”ë“œ ì‹¤í–‰ ë°©ë²•](#3-ì½”ë“œ-ì‹¤í–‰-ë°©ë²•)
  * [3-1. LLM Fine-Tuning](#3-1-llm-fine-tuning)
  * [3-2. Ethics Mechanism](#3-2-ethics-mechanism)
* [4. AI ìœ¤ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼](#4-ai-ìœ¤ë¦¬-í…ŒìŠ¤íŠ¸-ê²°ê³¼)

## 1. OhLoRA-v4 LLM ì „ì²´ ë©”ì»¤ë‹ˆì¦˜

* [ì˜¤ë¡œë¼ v3 LLM ì „ì²´ ë©”ì»¤ë‹ˆì¦˜](../../2025_05_26_OhLoRA_v3/llm/README.md#1-ohlora-v3-llm-ì „ì²´-ë©”ì»¤ë‹ˆì¦˜) ê³¼ ë™ì¼

![image](../../images/250526_21.png)

### 1-1. LLM Ethics (S-BERT)

![image](../../images/250624_13.PNG)

* ë™ì‘ ì›ë¦¬
  * [Sentence BERT (S-BERT)](https://github.com/WannaBeSuperteur/AI-study/blob/main/Natural%20Language%20Processing/Basics_BERT%2C%20SBERT%20%EB%AA%A8%EB%8D%B8.md#sbert-%EB%AA%A8%EB%8D%B8) ê¸°ë°˜ 
  * ì‚¬ìš©ìì˜ ìµœì´ˆ ì›ë³¸ í”„ë¡¬í”„íŠ¸ì™€ ê° ë¶ˆëŸ‰ ì–¸ì–´ ì¹´í…Œê³ ë¦¬ (```ì‚¬ë‘ ê³ ë°±/ë§Œë‚¨``` ```ì •ì¹˜``` ```íŒ¨ë“œë¦½``` ```í˜ì˜¤/ê¸°íƒ€```) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ë¥¼ S-BERT ë¡œ ë¹„êµ
  * ê° ì¹´í…Œê³ ë¦¬ ë³„ **ì¼ì • threshold** ë³´ë‹¤ ë†’ìœ¼ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë°œì–¸ìœ¼ë¡œ íŒë‹¨
  * ì‚¬ìš©ìì˜ ê¸°ì¡´ ì œì¬ ë¡œê·¸ë¥¼ ê²€í† í•˜ì—¬ **ìµœì¢… ì œì¬ ìˆ˜ìœ„ (Oh-LoRA ğŸ‘±â€â™€ï¸ ê´€ë ¨ ì œí’ˆ "ì „ì²´ ì´ìš© ì œí•œ") ê²°ì •**
* êµ¬í˜„ ì½”ë“œ
  * [S-BERT Training](ethics_mechanism/train_sbert.py)
  * [S-BERT Inference](ethics_mechanism/inference_sbert.py)
  * [ì‹¤ì œ ì‚¬ìš©ì ì œì¬ ì²˜ë¦¬](../final_product/run.py) (í•´ë‹¹ ì½”ë“œ íŒŒì¼ì˜ ```check_and_process_ethics``` í•¨ìˆ˜)
* ë³´ê³ ì„œ
  * [Ethics mechanism í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ](ethics_mechanism/test_report.md) 

## 2. OhLoRA-v4 LLM Fine-Tuning

* í•™ìŠµ ëª¨ë¸
  * **Kanana-1.5-2.1B-instruct-2505 (by Kakao, 2.32 B params) (âœ… for ```output_message```)** [(HuggingFace)](https://huggingface.co/kakaocorp/kanana-1.5-2.1b-instruct-2505)
* í•™ìŠµ ë°©ë²• 
  * [SFT (Supervised Fine-Tuning)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_SFT.md)
  * [LoRA (Low-Rank Adaption)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_LoRA_QLoRA.md), LoRA Rank = **16**
  * train for **5 epochs**
  * initial [learning rate](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Learning_Rate.md) : **0.0003 (= 3e-4)**
* í•™ìŠµ ë°ì´í„°ì…‹
  * train ë°ì´í„° **632 rows ([v3](../../2025_05_26_OhLoRA_v3/llm/README.md#2-ohlora-v3-llm-fine-tuning) ëŒ€ë¹„ ğŸ”º 10.5 %)**, valid ë°ì´í„° **120 rows ([v3](../../2025_05_26_OhLoRA_v3/llm/README.md#2-ohlora-v3-llm-fine-tuning) ëŒ€ë¹„ ğŸ”º 33.3 %)**
  * train & valid data ëŠ” ëª¨ë‘ [v4 dataset](fine_tuning_dataset/OhLoRA_fine_tuning_v4.csv) ì„ ì‚¬ìš©
    * ì°¸ê³ : **ë³¸ í”„ë¡œì íŠ¸ì˜ ê°œë°œì (= ë³¸ì¸) ëŠ” ìœ„ ë°ì´í„°ì…‹ì— ê°„ì ‘ ì–¸ê¸‰ë˜ëŠ” ['Hyena LLM' ë…¼ë¬¸](https://arxiv.org/pdf/2302.10866) ì˜ ì—°êµ¬ ê¸°ê´€ ë° ìœ„ ë°ì´í„°ì…‹ì— ë“±ì¥í•˜ëŠ” 'ì •ì„œë¶ˆì•ˆ ê¹€í–„ì°Œ'ì™€ ì½œë¼ë³´, í˜‘ì—… ë“±ì„ í•˜ì§€ ì•Šì•˜ìœ¼ë©°, í•´ë‹¹ ë…¼ë¬¸ ì—°êµ¬ì ë° í•´ë‹¹ ìºë¦­í„°ì˜ ì œì‘ì / ê³µì‹ SNS ì±„ë„ê³¼ ì „ì ìœ¼ë¡œ ë¬´ê´€í•©ë‹ˆë‹¤.**  
  * **ì˜¤ë¡œë¼ì˜ ë‹µë³€ ë©”ì‹œì§€ (```output_message```)** LLM ì˜ ê²½ìš°, ì…ë ¥ ë°ì´í„°ì— **ìœ ì˜ì–´ë¡œì˜ êµì²´** ì— ê¸°ë°˜í•œ ê°„ë‹¨í•œ data augmentation ì ìš© [(êµ¬í˜„ ì½”ë“œ)](fine_tuning/augmentation.py)
* ìƒì„¸ í•™ìŠµ ì„¤ì •

| ëª¨ë¸ (task)                            | í•™ìŠµì— ì‚¬ìš©í•œ LLM              | LoRA rank | epochs | ë¹„ê³                                                                                            |
|--------------------------------------|--------------------------|-----------|--------|----------------------------------------------------------------------------------------------|
| ë‹µë³€ ë©”ì‹œì§€ ```output_message```          | Kanana-1.5-2.1B-instruct | 16        | 5      | LLM ì´ ì–´ëŠ ì •ë„ í•™ìŠµë˜ë©´ì„œë„ í™˜ê° í˜„ìƒì´ ì¶©ë¶„íˆ ì ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ìµœì ì˜ epoch count                                    |
| ìµœê·¼ ëŒ€í™” ë‚´ìš© ìš”ì•½ ```summary```            | Kanana-1.5-2.1B-base     | 64        | 10     | [Oh-LoRA v3](../../2025_05_26_OhLoRA_v3/llm/README.md#2-ohlora-v3-llm-fine-tuning) ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| ë©”ëª¨ë¦¬ (ì‚¬ìš©ìì— ëŒ€í•´ ê¸°ì–µ í•„ìš”í•œ ë‚´ìš©) ```memory``` | Polyglot-Ko-1.3B         | 64        | 20     | [Oh-LoRA v3](../../2025_05_26_OhLoRA_v3/llm/README.md#2-ohlora-v3-llm-fine-tuning) ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| í‘œì • ë° ê³ ê°œ ëŒë¦¼ ì œì–´ ```eyes_mouth_pose```  | Polyglot-Ko-1.3B         | 64        | 30     | [Oh-LoRA v3](../../2025_05_26_OhLoRA_v3/llm/README.md#2-ohlora-v3-llm-fine-tuning) ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© |

* ë³´ê³ ì„œ
  * [LLM Fine-Tuning ê²°ê³¼ ë³´ê³ ì„œ](fine_tuning/fine_tuning_report.md)
* ì°¸ê³ 
  * [ì˜¤ë¡œë¼ v1 ('25.04.08 - 04.25) ì—ì„œì˜ LLM Fine-Tuning ë°©ë²•](../../2025_04_08_OhLoRA/llm/README.md#2-how-to-run-fine-tuning) 
  * [ì˜¤ë¡œë¼ v2 ('25.05.02 - 05.21) ì—ì„œì˜ LLM Fine-Tuning ë°©ë²•](../../2025_05_02_OhLoRA_v2/llm/README.md#3-ohlora-v2-llm-fine-tuning) 
  * [ì˜¤ë¡œë¼ v3 ('25.05.26 - 06.05) ì—ì„œì˜ LLM Fine-Tuning ë°©ë²•](../../2025_05_26_OhLoRA_v3/llm/README.md#2-ohlora-v3-llm-fine-tuning) 

## 3. ì½”ë“œ ì‹¤í–‰ ë°©ë²•

ëª¨ë“  ì½”ë“œëŠ” **ë¨¼ì € [LLM ëª¨ë¸ ì •ë³´ ë° ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì•ˆë‚´](../MODEL_AND_DATASET_INFO.md#1-ëª¨ë¸-ì •ë³´) ë° í•´ë‹¹ ê° HuggingFace ë§í¬ì— ìˆëŠ” Model Card ì— ë‚˜íƒ€ë‚œ ì €ì¥ ê²½ë¡œ (Save Path) ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í›„,** ```2025_06_24_OhLoRA_v4``` (í”„ë¡œì íŠ¸ ë©”ì¸ ë””ë ‰í† ë¦¬) ì—ì„œ ì‹¤í–‰

### 3-1. LLM Fine-Tuning

ì§€ì •ëœ ê²½ë¡œì— í•´ë‹¹ LLM ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°, Fine-Tuning ëŒ€ì‹  **inference test ì‹¤í–‰ë¨**

| LLM                         | Fine-Tuning ì½”ë“œ ì‹¤í–‰ ë°©ë²•                |
|-----------------------------|-------------------------------------|
| ë‹µë³€ ë©”ì‹œì§€ ```output_message``` | ```python llm/run_fine_tuning.py``` |

### 3-2. Ethics Mechanism

* **Ethics Mechanism (S-BERT)** ëª¨ë¸ ì‹¤í–‰ (í•´ë‹¹ ëª¨ë¸ ì—†ì„ ì‹œ, Training ë¨¼ì € ì‹¤í–‰)
  * ```python llm/run_ethics_mechanism.py```

## 4. AI ìœ¤ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼

* [Oh-LoRA v3 AI ìœ¤ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼](../../2025_05_26_OhLoRA_v3/llm/ai_ethics_test_report.md) ì— ë¹„í•´ **ìƒë‹¹íˆ ê°œì„ ë¨**
* **ëŒ€ë¶€ë¶„ì˜ í˜ì˜¤ ë°œì–¸, ì •ì¹˜ ë°œì–¸, ë¶€ì ì ˆí•œ ìš”ì²­ ë“±ì„ í•„í„°ë§ ë° ì ì ˆíˆ ì²˜ë¦¬** í•  ìˆ˜ ìˆìŒ
* [AI ìœ¤ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ](ai_ethics_test_report.md)
