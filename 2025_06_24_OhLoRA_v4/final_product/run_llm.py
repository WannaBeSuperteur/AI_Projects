import torch
from transformers import StoppingCriteriaList

from llm.fine_tuning.inference import StopOnTokens
from llm.fine_tuning.fine_tuning_kanana import get_stop_token_list as get_kanana_stop_token_list
from llm.fine_tuning.fine_tuning_polyglot import get_stop_token_list as get_polyglot_stop_token_list

from datetime import datetime
import os
import random
PROJECT_DIR_PATH = os.path.dirname(os.path.abspath(os.path.dirname(__file__)))


# Oh-LoRA (ì˜¤ë¡œë¼) ë‹µë³€ ìƒì„± ì‹œ ìš”ì¼ ì •ë³´ í™˜ê° í˜„ìƒ ì—¬ë¶€ í™•ì¸
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - ohlora_answer (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ë‹µë³€

# Returns:
# - is_hallucination (bool) : í™˜ê° í˜„ìƒ ì—¬ë¶€ (í™˜ê° í˜„ìƒ ë°œìƒ ì‹œ True)

def is_dow_hallucination(ohlora_answer):

    # get current day-of-week and current month
    dow_mapping = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
    current_dow = datetime.today().weekday()
    current_hour = datetime.now().hour

    if current_hour < 4:
        dow_text = dow_mapping[(current_dow + 6) % 7]
    else:
        dow_text = dow_mapping[current_dow]

    # check time hallucination
    if dow_text in ['ì¼', 'ì›”', 'í™”', 'ìˆ˜'] and ('ë‚´ì¼ ì£¼ë§' in ohlora_answer or 'ë‚´ì¼ì€ ì£¼ë§' in ohlora_answer):
        return True

    if dow_text in ['ì›”', 'í™”', 'ìˆ˜', 'ëª©'] and ('ì˜¤ëŠ˜ ì£¼ë§' in ohlora_answer or 'ì˜¤ëŠ˜ì€ ì£¼ë§' in ohlora_answer):
        return True

    if dow_text not in ['ëª©', 'ê¸ˆ'] and 'ë‚´ì¼ë¶€í„° ì£¼ë§ì´' in ohlora_answer:
        return True

    if dow_text not in ['ê¸ˆ', 'í† '] and 'ì˜¤ëŠ˜ë¶€í„° ì£¼ë§ì´' in ohlora_answer:
        return True

    if dow_text != 'ëª©' and ('ë‚´ì¼ ë¶ˆê¸ˆ' in ohlora_answer or 'ë‚´ì¼ì€ ë¶ˆê¸ˆ' in ohlora_answer):
        return True

    if dow_text != 'ê¸ˆ' and ('ì˜¤ëŠ˜ ë¶ˆê¸ˆ' in ohlora_answer or 'ì˜¤ëŠ˜ì€ ë¶ˆê¸ˆ' in ohlora_answer):
        return True

    if dow_text not in ['í† ', 'ì¼'] and 'ë‚´ì¼ë¶€í„° í•œ ì£¼ ì‹œì‘' in ohlora_answer:
        return True

    if dow_text not in ['ì¼', 'ì›”'] and 'ì˜¤ëŠ˜ë¶€í„° í•œ ì£¼ ì‹œì‘' in ohlora_answer:
        return True

    for i in range(7):
        if dow_text != dow_mapping[i] and (f'ì˜¤ëŠ˜ {dow_mapping[i]}ìš”ì¼' in ohlora_answer or
                                           f'ì˜¤ëŠ˜ì€ {dow_mapping[i]}ìš”ì¼' in ohlora_answer or
                                           f'ì˜¤ëŠ˜ë„ {dow_mapping[i]}ìš”ì¼' in ohlora_answer):
            return True

        if dow_text != dow_mapping[i] and (f'ë‚´ì¼ {dow_mapping[(i + 1) % 7]}ìš”ì¼' in ohlora_answer or
                                           f'ë‚´ì¼ì€ {dow_mapping[(i + 1) % 7]}ìš”ì¼' in ohlora_answer or
                                           f'ë‚´ì¼ë„ {dow_mapping[(i + 1) % 7]}ìš”ì¼' in ohlora_answer):
            return True

    # no time hallucination
    return False


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ ìƒì„±
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - ohlora_llm           (LLM)       : output_message LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned)
# - ohlora_llm_tokenizer (tokenizer) : output_message LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned) ì˜ tokenizer
# - final_ohlora_input   (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ì—ê²Œ ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ë©”ì‹œì§€ (ê²½ìš°ì— ë”°ë¼ summary, memory text í¬í•¨)

# Returns :
# - ohlora_answer (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ë‹µë³€

def generate_llm_answer(ohlora_llm, ohlora_llm_tokenizer, final_ohlora_input):
    trial_count = 0
    time_hallucination_count = 0
    max_trials = 5

    # tokenize final Oh-LoRA input
    final_ohlora_input_ = final_ohlora_input + ' (ë‹µë³€ ì‹œì‘)'

    inputs = ohlora_llm_tokenizer(final_ohlora_input_, return_tensors='pt')
    inputs = {'input_ids': inputs['input_ids'].to(ohlora_llm.device),
              'attention_mask': inputs['attention_mask'].to(ohlora_llm.device)}

    # for stopping criteria
    stop_token_ids = torch.tensor(get_kanana_stop_token_list('output_message')).to(ohlora_llm.device)  # '(ë‹µë³€ ì¢…ë£Œ)'
    stopping_criteria = StoppingCriteriaList([StopOnTokens(stop_token_ids)])

    while trial_count < max_trials:
        outputs = ohlora_llm.generate(**inputs,
                                      max_length=128,
                                      do_sample=True,
                                      temperature=0.6 + 0.1 * time_hallucination_count,
                                      stopping_criteria=stopping_criteria)

        llm_answer = ohlora_llm_tokenizer.decode(outputs[0], skip_special_tokens=True)
        llm_answer = llm_answer[len(final_ohlora_input_):]
        llm_answer = llm_answer.replace('\u200b', '').replace('\xa0', '')  # zwsp, nbsp (í­ ì—†ëŠ” ê³µë°±, ì¤„ ë°”ê¿ˆ ì—†ëŠ” ê³µë°±) ì œê±°

        trial_count += 1

        # 'ì˜¤ëŠ˜ëŠ”', 'ë‚´ì¼ëŠ”' -> 'ì˜¤ëŠ˜ì€', 'ë‚´ì¼ì€'
        llm_answer = llm_answer.replace('ì˜¤ëŠ˜ëŠ”', 'ì˜¤ëŠ˜ì€')
        llm_answer = llm_answer.replace('ë‚´ì¼ëŠ”', 'ë‚´ì¼ì€')

        # check LLM answer and return or retry
        is_empty = llm_answer.replace('\n', '').replace('(ë‹µë³€ ì¢…ë£Œ)', '').replace(' ', '') == ''
        is_answer_end_mark = 'ë‹µë³€ ì¢…ë£Œ' in llm_answer.replace('(ë‹µë³€ ì¢…ë£Œ)', '') or 'ë‹µë³€ì¢…ë£Œ' in llm_answer.replace('(ë‹µë³€ ì¢…ë£Œ)', '')
        is_other_mark = '(ì‚¬ìš©ì' in llm_answer.replace(' ', '') or 'ìš”ì•½)' in llm_answer.replace(' ', '')

        is_time_hallucinated = trial_count < max_trials and is_dow_hallucination(llm_answer)
        is_low_quality = (is_empty or is_answer_end_mark or is_other_mark) or is_time_hallucinated

        if is_time_hallucinated:
            time_hallucination_count += 1

        if not is_low_quality and ('http' not in llm_answer):
            return llm_answer.replace('(ë‹µë³€ ì¢…ë£Œ)', '')

    return '(ì½ì”¹)'


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ì„ clean ì²˜ë¦¬
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - ohlora_answer (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ë‹µë³€

# Returns :
# - llm_answer_cleaned (str) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ì—ì„œ text clean ì„ ì‹¤ì‹œí•œ ì´í›„ì˜ ë‹µë³€

def clean_llm_answer(ohlora_answer):
    return ohlora_answer


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ìƒì„±ëœ ë‹µë³€ìœ¼ë¡œë¶€í„° memory ì •ë³´ë¥¼ parsing
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - memory_llm           (LLM)       : memory LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned)
# - memory_llm_tokenizer (tokenizer) : memory LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned) ì— ëŒ€í•œ tokenizer
# - final_ohlora_input   (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ì—ê²Œ ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ë©”ì‹œì§€ (ê²½ìš°ì— ë”°ë¼ summary, memory text í¬í•¨)

# Returns :
# - memory_list (list(str) or None) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ì €ì¥í•´ì•¼ í•  ë©”ëª¨ë¦¬ ëª©ë¡

def parse_memory(memory_llm, memory_llm_tokenizer, final_ohlora_input):
    trial_count = 0
    max_trials = 5

    # tokenize final Oh-LoRA input
    final_ohlora_input_ = final_ohlora_input + ' (ìš”ì•½ ì‹œì‘)'

    inputs = memory_llm_tokenizer(final_ohlora_input_, return_tensors='pt')
    inputs = {'input_ids': inputs['input_ids'].to(memory_llm.device),
              'attention_mask': inputs['attention_mask'].to(memory_llm.device)}

    # for stopping criteria
    stop_token_ids = torch.tensor(get_polyglot_stop_token_list('memory')).to(memory_llm.device)  # '(ìš”ì•½ ì¢…ë£Œ)'
    stopping_criteria = StoppingCriteriaList([StopOnTokens(stop_token_ids)])

    while trial_count < max_trials:
        outputs = memory_llm.generate(**inputs,
                                      max_new_tokens=24,
                                      do_sample=True,
                                      temperature=0.6,
                                      stopping_criteria=stopping_criteria)

        llm_answer = memory_llm_tokenizer.decode(outputs[0], skip_special_tokens=True)
        llm_answer = llm_answer.replace('(ìš”ì•½ ì¢…ë£Œ)', '')

        # post-process memory LLM answer
        llm_answer = llm_answer[len(final_ohlora_input_):]
        llm_answer = llm_answer.replace('\u200b', '').replace('\xa0', '')    # zwsp, nbsp (í­ / ì¤„ ë°”ê¿ˆ ì—†ëŠ” ê³µë°±) ì œê±°
        llm_answer = llm_answer.replace('(', '[').replace(')', ']')          # (...) -> [...]
        llm_answer = llm_answer.replace('{', '[').replace('}', ']')          # {...} -> [...]
        llm_answer = llm_answer.replace(' : ', ': ')                         # [key : value] -> [key: value]

        if '[' in llm_answer and ']' in llm_answer:
            llm_answer = '[' + llm_answer.split('[')[1].split(']')[0] + ']'  # blah [key: value] blah -> [key: value]

        if ': ' not in llm_answer:
            llm_answer = llm_answer.replace(':', ': ')           # [key:value] -> [key: value]

        if '[' not in llm_answer and ']' not in llm_answer and ': ' in llm_answer:
            llm_answer = '[' + llm_answer + ']'                              # key: value -> [key: value]

        trial_count += 1

        # check LLM answer and return or retry
        is_answer_end_mark = 'ìš”ì•½ ì¢…ë£Œ' in llm_answer or 'ìš”ì•½ì¢…ë£Œ' in llm_answer
        too_many_tokens = len(outputs[0]) - len(inputs['input_ids'][0]) == 24

        is_in_format = llm_answer == '' or (llm_answer[0] == '[' and llm_answer[-1] == ']' and ': ' in llm_answer)
        is_in_format_cnts = llm_answer.count('[') == 1 and llm_answer.count(']') == 1 and llm_answer.count(':') == 1

        # empty answer -> format is CORRECT
        if llm_answer.replace(' ', '') == '':
            is_format_correct = True

        # for non-empty answer
        elif is_in_format and is_in_format_cnts:
            is_key_nonempty = len(llm_answer.split('[')[1].split(':')[0].replace(' ', '')) >= 1
            is_value_nonempty = len(llm_answer.split(':')[1].split(']')[0].replace(' ', '')) >= 1
            is_format_correct = is_key_nonempty and is_value_nonempty
        else:
            is_format_correct = False

        is_uncleaned = (is_answer_end_mark or too_many_tokens) or not is_format_correct

        is_unnecessary_mark = 'ï¿½' in llm_answer
        is_too_many_blanks = '     ' in llm_answer
        is_low_quality = is_unnecessary_mark or is_too_many_blanks

        if (not is_uncleaned) and (not is_low_quality) and ('http' not in llm_answer):
            return [llm_answer]

    return None


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ llm/memory_mechanism/saved_memory/ohlora_memory.txt ì— ì €ì¥
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - memory_list (list(str)) : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ì €ì¥í•´ì•¼ í•  ë©”ëª¨ë¦¬ ëª©ë¡

def save_memory_list(memory_list):
    memory_file_path = f'{PROJECT_DIR_PATH}/llm/memory_mechanism/saved_memory/ohlora_memory.txt'

    memory_file = open(memory_file_path, 'r', encoding='UTF8')
    memory_file_lines = memory_file.readlines()
    memory_file.close()

    memory_file_lines = [line.split('\n')[0] for line in memory_file_lines]

    for memory in memory_list:
        is_duplicated = False

        for line in memory_file_lines:
            if memory.replace(' ', '') == line.replace(' ', ''):
                is_duplicated = True
                break

        if not is_duplicated:
            memory_file_lines.append(memory)

    memory_file_lines_to_save = '\n'.join(memory_file_lines)

    memory_file = open(memory_file_path, 'w', encoding='UTF8')
    memory_file.write(memory_file_lines_to_save + '\n')
    memory_file.close()


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ ìš”ì•½
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - summary_llm           (LLM)       : summary LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned)
# - summary_llm_tokenizer (tokenizer) : summary LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned) ì˜ tokenizer
# - final_ohlora_input    (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ì—ê²Œ ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ë˜ëŠ” ë©”ì‹œì§€ (ê²½ìš°ì— ë”°ë¼ summary, memory text í¬í•¨)
# - llm_answer_cleaned    (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ì—ì„œ text clean ì„ ì‹¤ì‹œí•œ ì´í›„ì˜ ë‹µë³€

# Returns :
# - llm_summary (str) : ì§ì „ ëŒ€í™” ë‚´ìš©ì— ëŒ€í•œ ìš”ì•½

def summarize_llm_answer(summary_llm, summary_llm_tokenizer, final_ohlora_input, llm_answer_cleaned):
    trial_count = 0
    max_trials = 3

    # tokenize final Oh-LoRA input
    final_summary_input = final_ohlora_input + ' (ì˜¤ë¡œë¼ ë‹µë³€)' + llm_answer_cleaned + ' (ìš”ì•½ ì‹œì‘)'

    inputs = summary_llm_tokenizer(final_summary_input, return_tensors='pt')
    inputs = {'input_ids': inputs['input_ids'].to(summary_llm.device),
              'attention_mask': inputs['attention_mask'].to(summary_llm.device)}

    # for stopping criteria
    stop_token_ids = torch.tensor(get_kanana_stop_token_list('summary')).to(summary_llm.device)  # '(ìš”ì•½ ì¢…ë£Œ)'
    stopping_criteria = StoppingCriteriaList([StopOnTokens(stop_token_ids)])

    while trial_count < max_trials:
        outputs = summary_llm.generate(**inputs,
                                       max_new_tokens=64,
                                       do_sample=True,
                                       temperature=0.6,
                                       stopping_criteria=stopping_criteria)

        llm_answer = summary_llm_tokenizer.decode(outputs[0], skip_special_tokens=True)

        llm_answer = llm_answer[len(final_summary_input):]
        llm_answer = llm_answer.replace('\u200b', '').replace('\xa0', '')  # zwsp, nbsp (í­ ì—†ëŠ” ê³µë°±, ì¤„ ë°”ê¿ˆ ì—†ëŠ” ê³µë°±) ì œê±°
        llm_answer = llm_answer.strip()

        trial_count += 1

        # check LLM answer and return or retry
        is_answer_end_mark = 'ìš”ì•½ ì¢…ë£Œ' in llm_answer.replace('(ìš”ì•½ ì¢…ë£Œ)', '') or 'ìš”ì•½ì¢…ë£Œ' in llm_answer.replace('(ìš”ì•½ ì¢…ë£Œ)', '')
        too_many_tokens = len(outputs[0]) - len(inputs['input_ids'][0]) >= 60
        is_almost_empty = len(llm_answer.replace('(ìš”ì•½ ì¢…ë£Œ)', '')) < 2

        if not (is_answer_end_mark or too_many_tokens or is_almost_empty) and ('http' not in llm_answer):
            return llm_answer.replace('(ìš”ì•½ ì¢…ë£Œ)', '')

    return None


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ì— ë”°ë¼ ëˆˆì„ ëœ¬ ì •ë„ (eyes), ì…ì„ ë²Œë¦° ì •ë„ (mouth), ê³ ê°œ ëŒë¦¼ (pose) í…ìŠ¤íŠ¸ ì‚°ì¶œ
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - eyes_mouth_pose_llm           (LLM)       : eyes_mouth_pose LLM (Polyglot-Ko 1.3B & Kanana-1.5 2.1B Fine-Tuned)
# - eyes_mouth_pose_llm_tokenizer (tokenizer) : eyes_mouth_pose LLM ì— ëŒ€í•œ tokenizer
# - llm_answer_cleaned            (str)       : ì˜¤ë¡œë¼ğŸ‘±â€â™€ï¸ ê°€ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ì—ì„œ text clean ì„ ì‹¤ì‹œí•œ ì´í›„ì˜ ë‹µë³€

# Returns :
# - eyes_score_text  (str) : ëˆˆì„ ëœ¬ ì •ë„ (eyes) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸
# - mouth_score_text (str) : ì…ì„ ë²Œë¦° ì •ë„ (mouth) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸
# - pose_score_text  (str) : ê³ ê°œ ëŒë¦¼ (pose) ì„ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸

def decide_property_score_texts(eyes_mouth_pose_llm, eyes_mouth_pose_llm_tokenizer, llm_answer_cleaned):
    trial_count = 0
    max_trials = 5

    eyes_score_texts = ['ì‘ê²Œ', 'ë³´í†µ', 'í¬ê²Œ', 'ì•„ì£¼ í¬ê²Œ']
    mouth_score_texts = ['ë³´í†µ', 'í¬ê²Œ', 'ì•„ì£¼ í¬ê²Œ']
    pose_score_texts = ['ì—†ìŒ', 'ë³´í†µ', 'ë§ì´']

    # tokenize final Oh-LoRA input
    llm_answer_cleaned_ = llm_answer_cleaned + ' (í‘œì • ì¶œë ¥ ì‹œì‘)'

    inputs = eyes_mouth_pose_llm_tokenizer(llm_answer_cleaned_, return_tensors='pt')
    inputs = {'input_ids': inputs['input_ids'].to(eyes_mouth_pose_llm.device),
              'attention_mask': inputs['attention_mask'].to(eyes_mouth_pose_llm.device)}

    # for stopping criteria
    eyes_mouth_pose_stop_tokens = get_polyglot_stop_token_list('eyes_mouth_pose')  # '(í‘œì • ì¶œë ¥ ì¢…ë£Œ)'
    stop_token_ids = torch.tensor(eyes_mouth_pose_stop_tokens).to(eyes_mouth_pose_llm.device)
    stopping_criteria = StoppingCriteriaList([StopOnTokens(stop_token_ids)])

    while trial_count < max_trials:
        outputs = eyes_mouth_pose_llm.generate(**inputs,
                                               max_new_tokens=36,
                                               do_sample=True,
                                               temperature=1.0,
                                               stopping_criteria=stopping_criteria)

        llm_answer = eyes_mouth_pose_llm_tokenizer.decode(outputs[0], skip_special_tokens=True)

        llm_answer = llm_answer[len(llm_answer_cleaned_):]
        llm_answer = llm_answer.replace('\u200b', '').replace('\xa0', '')  # zwsp, nbsp (í­ ì—†ëŠ” ê³µë°±, ì¤„ ë°”ê¿ˆ ì—†ëŠ” ê³µë°±) ì œê±°
        trial_count += 1

        # check LLM answer and return or retry
        try:
            eyes_score_text = llm_answer.split('ëˆˆ ')[1].split(',')[0].split(')')[0]
            mouth_score_text = llm_answer.split('ì… ')[1].split(',')[0].split(')')[0]
            pose_score_text = llm_answer.split('ê³ ê°œ ëŒë¦¼ ')[1].split(',')[0].split(')')[0]

            final_eyes_score_text, final_mouth_score_text, final_pose_score_text = None, None, None

            for txt in eyes_score_texts:
                if eyes_score_text.startswith(txt):
                    final_eyes_score_text = txt

            for txt in mouth_score_texts:
                if mouth_score_text.startswith(txt):
                    final_mouth_score_text = txt

            for txt in pose_score_texts:
                if pose_score_text.startswith(txt):
                    final_pose_score_text = txt

            assert final_eyes_score_text is not None
            assert final_mouth_score_text is not None
            assert final_pose_score_text is not None

            return final_eyes_score_text, final_mouth_score_text, final_pose_score_text

        except:
            pass

    eyes_score_text, mouth_score_text, pose_score_text = 'ë³´í†µ', 'ë³´í†µ', 'ì—†ìŒ'
    return eyes_score_text, mouth_score_text, pose_score_text


# Oh-LoRA (ì˜¤ë¡œë¼) ì˜ ë‹µë³€ì— ë”°ë¼ ëˆˆì„ ëœ¬ ì •ë„ (eyes), ì…ì„ ë²Œë¦° ì •ë„ (mouth), ê³ ê°œ ëŒë¦¼ (pose) ì ìˆ˜ ì‚°ì¶œ
# Create Date : 2025.06.29
# Last Update Date : -

# Arguments :
# - eyes_score_text  (str) : ëˆˆì„ ëœ¬ ì •ë„ (eyes) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸
# - mouth_score_text (str) : ì…ì„ ë²Œë¦° ì •ë„ (mouth) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸
# - pose_score_text  (str) : ê³ ê°œ ëŒë¦¼ (pose) ì„ ë‚˜íƒ€ë‚´ëŠ” í…ìŠ¤íŠ¸

# Returns :
# - eyes_score  (float) : ëˆˆì„ ëœ¬ ì •ë„ (eyes) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ìˆ˜ (w vector ì— eyes change vector ë¥¼ ë”í•  ê°€ì¤‘ì¹˜)
# - mouth_score (float) : ì…ì„ ë²Œë¦° ì •ë„ (mouth) ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ìˆ˜ (w vector ì— mouth change vector ë¥¼ ë”í•  ê°€ì¤‘ì¹˜)
# - pose_score  (float) : ê³ ê°œ ëŒë¦¼ (pose) ì„ ë‚˜íƒ€ë‚´ëŠ” ì ìˆ˜ (w vector ì— pose change vector ë¥¼ ë”í•  ê°€ì¤‘ì¹˜)

def decide_property_scores(eyes_score_text, mouth_score_text, pose_score_text):

    # eyes score mapping
    if eyes_score_text == 'ì‘ê²Œ':
        eyes_score = -0.2 + 0.3 * random.random()

    elif eyes_score_text == 'ë³´í†µ':
        eyes_score = 0.3 + 0.3 * random.random()

    elif eyes_score_text == 'í¬ê²Œ':
        eyes_score = 0.8 + 0.3 * random.random()

    else:  # ì•„ì£¼ í¬ê²Œ
        eyes_score = 1.1 + 0.1 * random.random()

    # mouth score mapping
    if mouth_score_text == 'ë³´í†µ':
        mouth_score = 0.4 + 0.4 * random.random()

    elif mouth_score_text == 'í¬ê²Œ':
        mouth_score = 1.0 + 0.4 * random.random()

    else:  # ì•„ì£¼ í¬ê²Œ
        mouth_score = 1.4 + 0.2 * random.random()

    # pose score mapping
    if pose_score_text == 'ì—†ìŒ':
        pose_score = -0.6 + 0.9 * random.random()

    elif mouth_score_text == 'ë³´í†µ':
        pose_score = 0.8 + 0.7 * random.random()

    else:  # ë§ì´
        pose_score = 1.5 + 0.3 * random.random()

    # ì‹¤ì œ w vector ì— ë”í•´ì§€ëŠ” ê°€ì¤‘ì¹˜ëŠ” "ê°’ì´ ì‘ì„ìˆ˜ë¡ (ìŒìˆ˜ ë“±)" ëˆˆì„ í¬ê²Œ ëœ¨ê³ , ì…ì„ í¬ê²Œ ë²Œë¦¬ê³ , ê³ ê°œë¥¼ ë§ì´ ëŒë¦¼
    eyes_score = (-1.0) * eyes_score
    mouth_score = (-1.0) * mouth_score
    pose_score = (-1.0) * pose_score

    return eyes_score, mouth_score, pose_score
