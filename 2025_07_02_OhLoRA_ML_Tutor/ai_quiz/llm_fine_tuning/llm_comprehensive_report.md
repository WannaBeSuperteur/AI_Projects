## 목차

* [1. 개요](#1-개요)
* [2. LLM 평가 기준 및 대상](#2-llm-평가-기준-및-대상)
* [3. LLM 평가 결과](#3-llm-평가-결과)
  * [3-1. 5 epochs](#3-1-5-epochs)
  * [3-2. 10 epochs](#3-2-10-epochs)

## 1. 개요

* 다음 2개의 LLM 의 **AI Quiz 해설 목적 LLM** 으로서의 성능을 평가한다.

## 2. LLM 평가 기준 및 대상

* 평가 기준
  * **정확도 (Accuracy)** : [LLM valid dataset](../dataset/valid_test_final.csv) 104 개 ```(퀴즈, 모범 답안, 사용자 답변)``` 쌍에 대해 각각 4 개의 해설 생성 (총 416 개)
  * 해당 해설 중 **논리적 오류 등 잘못된 점이 전혀 없는** 해설의 비율을 정확도로 평가

* 평가 대상 LLM
  * Kanana-1.5-2.1B instruct [(HuggingFace)](https://huggingface.co/kakaocorp/kanana-1.5-2.1b-instruct-2505)
  * Mi:dm 2.0 Mini [(HuggingFace)](https://huggingface.co/K-intelligence/Midm-2.0-Mini-Instruct)
  * 각각 **5 epochs** 및 **10 epochs** 로 테스트

* 평가 옵션
  * temperature = **0.6**

## 3. LLM 평가 결과

|           | Kanana-1.5-2.1B instruct | Mi:dm 2.0 Mini          |
|-----------|--------------------------|-------------------------|
| 5 epochs  | **78.37 %** (326 / 416)  | **76.44 %** (318 / 416) |
| 10 epochs | **80.05 %** (333 / 416)  | **69.23 %** (288 / 416) |

### 3-1. 5 epochs

* 평가 결과

|                | Kanana-1.5-2.1B instruct | Mi:dm 2.0 Mini          |
|----------------|--------------------------|-------------------------|
| 정확도 (Accuracy) | **78.37 %** (326 / 416)  | **76.44 %** (318 / 416) |

* 특이 케이스
  * 양쪽 LLM 이 4개씩 각각 생성한 해설 중 **오류가 없는 해설 (정확도 기준) 의 개수 차이가 3 이상** 인 경우 중 최초 5개

| 퀴즈                                                                 | 모범 답안                                                                                                                                                                                                                                                                                                                                                      | 사용자 답변                                                                                                                                                               | Kanana 정확도<br>(최빈 답변)                                                          | Mi:dm 정확도<br>(최빈 답변)                                                         |
|--------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|------------------------------------------------------------------------------|
| ```머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊```               | ```PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다.``` | ```PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.``` | **4 / 4**<br>(```우와! 정말 완벽해! 👍```)                                            | **0 / 4**<br>(```값의 범위랑 어떨수록 좋은지만 알려주면 어떡해 😥```)                            |
| ```이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지?```                   | ```이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다.```                                                                                                                                                                          | ```이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.```                                                                                                                     | **0 / 4**<br>(```그 아웃라이어가 뭔지 말할 수 있어? 😊```)                                   | **4 / 4**<br>(```그래서 뭐가 문제인데? 🤔```)                                         |
| ```데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊```                             | ```데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다.```                           | ```데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.```                                  | **0 / 4**<br>(```개수가 적은 클래스의 데이터를 새로 수집하거나, 손실 함수에서 가중치를 주는 방법도 있지 않을까? 😊```) | **4 / 4**<br>(```성능 평가 지표 말고도 방법이 많을 텐데 😊```)                               |
| ```Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊```             | ```Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다.```                                                          | ```학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.```                                | **0 / 4**<br>(```class 를 어떻게 구분하지? 그리고 불순도는 뭐야? 😊```)                         | **4 / 4**<br>(```class 를 어떻게 구분하지? 그리고 추론할 때 분기가 더 이상 없을 때는 어떻게 해? 😊```)    |
| ```머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊``` | ```지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다.```                                                                                                                     | ```지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.```                                                                                                       | **0 / 4**<br>(```지도학습이랑 비지도학습이랑 강화학습이 서로 반대로 되어 있네 😥```)                      | **4 / 4**<br>(```지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지?```) |

### 3-2. 10 epochs

* 평가 결과

|                | Kanana-1.5-2.1B instruct | Mi:dm 2.0 Mini          |
|----------------|--------------------------|-------------------------|
| 정확도 (Accuracy) | **80.05 %** (333 / 416)  | **69.23 %** (288 / 416) |

* 특이 케이스
  * 양쪽 LLM 이 4개씩 각각 생성한 해설 중 **오류가 없는 해설 (정확도 기준) 의 개수 차이가 3 이상** 인 경우 중 최초 5개

| 퀴즈                                           | 모범 답안                                                                                                                                                                                                                                                                               | 사용자 답변                                              | Kanana 정확도<br>(최빈 답변)                                                                                    | Mi:dm 정확도<br>(최빈 답변)                               |
|----------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------------------------------------------------------------|----------------------------------------------------|
| ```머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까?```     | ```IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다.```                                                                                                                              | ```IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.```  | **3 / 4**<br>(```교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score랑 한 번 연결해서 설명해 봐! 😊```)                       | **0 / 4**<br>(```2024-04-15 09:00:00 😥 (해설 종료)``` |
| ```PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈``` | ```PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다.``` | ```PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.``` | **4 / 4**<br>(```분산 보존이랑 시각화가 T-SNE랑 PCA랑 차이점이긴 하지! 😊 근데 혹시 t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어?```) | **0 / 4**<br>(```분산 보존 vs 시각화: 핵심 내용이 빠졌잖아 😥```)  |
