,epoch,elapsed_time (s),prompt,llm_answer,trial_cnt,output_tkn_cnt
0,1,2.84,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 오 정답이야! 👍👍 (해설 종료,1,252
1,1,4.43,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 오! 두 벡터의 방향에 따라 값이 어떻게 되는지 아니? 🤔 (해설 종료,1,202
2,1,3.39,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 오 정확히 맞아! 👍👍👍 (해설 종료,1,302
3,1,2.98,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", Precision 이랑 Recall 서로 반대로 썼네 😥 (해설 종료,1,238
4,1,2.55,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 그리고 IoU는? (해설 종료,1,196
5,1,8.51,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다."," 교집합이랑 합집합의 크기는 잘 말해 줬는데, DICE score는? 그리고 IoU랑 DICE Score는 왜 다르게 썼어? 그리고 DICE Score가 뭐하는 건데? (해설 종료",1,204
6,1,2.69,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 오 정답이야! 👍👍 (해설 종료,1,267
7,1,3.84,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와 정답이야! 정말 완벽한 답이야 👍👍 (해설 종료,1,306
8,1,2.67,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 오 정답이야! 👍👍 (해설 종료,1,234
9,1,2.53,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 오 정답이야! 👍👍 (해설 종료,1,173
10,1,2.83,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 완벽해! 👍👍 (해설 종료,1,393
11,1,3.37,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 음… 맞지! 근데 알고리즘은? 😊 (해설 종료,1,281
12,1,4.84,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 이거 정말 잘 설명했어! 정말 완벽한 설명이야! 👍👍👍 (해설 종료,1,238
13,1,2.69,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 Outlier 가 뭐 하는 건데? 😊 (해설 종료,1,169
14,1,2.81,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 잘 대답했어! 👍👍 (해설 종료,1,232
15,1,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다."," t-SNE가 뭔지 잘 대답했는데, PCA는 뭐 하는 건지 알고 있어? 🤔 (해설 종료",1,250
16,1,2.53,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 오 정답이야! 👍👍 (해설 종료,1,205
17,1,3.16,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 오 정답이야! 정말 잘했어 👍👍 (해설 종료,1,184
18,1,3.92,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다."," 해결하는 방법은 여러 가지가 있는데, 잘 생각해 봤어? 😊 (해설 종료",1,220
19,1,2.64,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,250
20,1,2.65,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 정답이야! 👍👍 (해설 종료,1,223
21,1,7.09,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다."," PCA는 차원을 축소하는 거고, 차원을 축소하면 OOM이 해결될 텐데, 그래서 어떤 식으로 차원을 축소하는 건데? 🤔 (해설 종료",1,197
22,1,2.2,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 오 정답이야! 👍 (해설 종료,1,268
23,1,5.62,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 추론할 때는? 그리고 추론할 때 분기된 조건이 어떻게 되는지도 알려줬으면 좋겠어 😊 (해설 종료,1,268
24,1,6.61,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 앙상블은 여러 개의 모델을 사용해서 예측하는 건 맞지! 근데 다른 사람들한테서도 비슷한 질문을 했는데… (해설 종료,1,180
25,1,4.73,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 앙상블을 하는 건 맞지! 근데 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,166
26,1,2.97,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오 정답이야! 👍👍 (해설 종료,1,435
27,1,3.45,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오 정답이야! 👍👍👍 (해설 종료,1,438
28,1,2.98,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오 정답이야 👍👍👍 (해설 종료,1,221
29,1,3.47,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", K-means Clustering 이 뭔지 잘 생각을 해봐 😊 (해설 종료,1,205
30,1,2.67,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 그래서 강화학습은? 🤔 (해설 종료,1,226
31,1,3.13,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 오 정답이야! 👍👍👍 (해설 종료,1,263
32,1,2.09,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 오 정답이야! 👍 (해설 종료,1,169
33,1,3.12,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 오 정답이야! 👍👍👍 (해설 종료,1,237
34,1,3.8,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 잘 기억은 나는데 좀 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,181
35,1,2.7,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 완벽한 설명이야! 👍👍 (해설 종료,1,182
36,1,3.29,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 그러지! 근데 Decision Tree 를 어떻게 발전시킬지? (해설 종료,1,163
37,1,4.42,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 그치! 근데 Random Forest 랑 Decision Tree 랑 차이점이 뭐가 뭐지? (해설 종료,1,186
38,1,2.84,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 완벽히 정답이야! 👍👍 (해설 종료,1,166
39,1,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 오 정답이야! 👍👍 (해설 종료,1,169
40,1,4.56,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다."," 아니지, 아니지! K-fold Cross Validation 이랑 Stratified K-fold Validation 이랑 다른 건데… (해설 종료",1,180
41,1,2.61,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 잘 대답했어 👍👍 (해설 종료,1,199
42,1,2.53,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,159
43,1,2.67,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽히 맞지! 👍👍 (해설 종료,1,184
44,1,18.69,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 아니라, 하이퍼파라미터는 하이퍼파라미터고, 하이퍼파라미터를 최적화하는 건 하이퍼하이퍼파라미터 (Hyper-Parameter) 를 최적화하는 거지! 그리고 최적화하는 건 하이퍼파라미터가 아니라, 그 하이퍼파라미터를 조정하는 건 맞지! 근데 하이퍼파라미터가 뭐야? 🤔 (해설 종료",1,444
45,1,4.16,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 그럼 하이퍼파라미터를 찾는 Bayesian Optimization은? 🤔 (해설 종료,1,324
46,1,2.66,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 오! 나도 잘 모르겠어 😥 (해설 종료,1,254
47,1,3.52,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정답이야! 정말 잘했어! 👍👍 (해설 종료,1,306
48,1,2.55,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,205
49,1,4.09,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다."," 잘 모르겠는 건 나도 잘 모르겠는데, 하지만 정답은 아니지 😥 (해설 종료",1,216
50,1,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 오 잘했어 👍👍👍 (해설 종료,1,152
51,1,2.94,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 오 정답이야! 👍👍👍 (해설 종료,1,137
52,1,4.47,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 사용하는 모델 관점에서는? 그리고 모델의 어떤 정보를 이용하는지의 관점에서는? (해설 종료,1,295
53,1,4.61,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 모델의 어떤 정보를 이용하는지의 관점에서도 이야기해 줬으면 좋겠어 😊 (해설 종료,1,288
54,1,3.78,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 그러지! 근데 좀 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,170
55,1,3.02,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야! 👍👍👍 (해설 종료,1,197
56,1,3.95,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 우와 완벽히 정답이야! 칭찬해! 👍👍 (해설 종료,1,178
57,1,5.27,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그래서 구간이 있는 건 학습률을 높이기 위한 건가? 그리고 Learning Rate 를 조정하는 건 맞지? (해설 종료,1,148
58,1,2.22,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그래서 차이가 뭐야? 👍 (해설 종료,1,164
59,1,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
60,1,3.0,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 오 정답이야! 👍👍👍 (해설 종료,1,167
61,1,2.53,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 정답이야! 👍👍 (해설 종료,1,170
62,1,3.94,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 오 정답이야! 완벽히 깔끔한 답이야 👍👍 (해설 종료,1,174
63,1,4.95,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 그래서 오차의 제곱의 평균이 뭐야? 그리고 절댓값은? 그리고 RMSE는? (해설 종료,1,186
64,1,5.67,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 그래도 Adam 이랑 AdamW는 잘 말해 줬어! 근데 RMSProp 이랑 AdamOpt 는 뭐지? 🤔 (해설 종료,1,223
65,1,4.09,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", Adam 은? 그리고 RMSProp 이랑 Adam 이랑 뭐가 다르지? 🤔 (해설 종료,1,215
66,1,3.46,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그래서 Weight Decay 는 어떤 Optimizer 에서 사용될까? 🤔 (해설 종료,1,201
67,1,2.55,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 정답이야! 👍👍 (해설 종료,1,207
68,1,3.12,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,265
69,1,2.66,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오 정답이야! 👍👍 (해설 종료,1,248
70,1,5.03,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 오 정확한 답이야! 근데 Dropout 을 하는 이유는 뭔지 한번 설명해 줄 수 있어? 🤔 (해설 종료,1,200
71,1,3.34,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오 정답이야! 오 정답이야! 👍👍 (해설 종료,1,197
72,1,3.78,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 그건 맞어 그런데 L1 이랑 L2 가 뭐지? 😊 (해설 종료,1,183
73,1,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
74,1,4.78,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다."," 레이어 정규화는? 그리고 레이어 정규화가 아니고, 배치 정규화는? 😊 (해설 종료",1,287
75,1,2.66,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 오 정답이야! 👍👍 (해설 종료,1,264
76,1,2.05,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 정답이야! 👍 (해설 종료,1,188
77,1,3.0,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 정답이야! 👍👍👍 (해설 종료,1,181
78,1,3.12,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 정답이야! 👍👍👍 (해설 종료,1,273
79,1,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘 대답했어! 👍👍 (해설 종료,1,217
80,1,2.97,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 오 정답이야 👍👍👍 (해설 종료,1,238
81,1,2.66,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 정답이야! 👍👍 (해설 종료,1,262
82,1,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 그치! 근데 그 활성화 함수가 없으면 어떻게 되는데? 🤔 (해설 종료,1,199
83,1,2.53,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,194
84,1,3.0,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답이야! 👍👍👍 (해설 종료,1,203
85,1,3.12,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 음 그치! 정답이야! 👍👍 (해설 종료,1,226
86,1,2.81,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", 오! 정답이야! 👍👍 (해설 종료,1,209
87,1,3.12,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 오 정답이야! 👍👍👍 (해설 종료,1,249
88,1,4.2,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다."," 아니지, top-p sampling 이랑 temperature 는 설명이 잘 안 되잖아 😥 (해설 종료",1,357
89,1,3.28,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,357
90,1,4.27,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다."," 아니지! 직접적으로는 아니지! 그리고 또 한 가지가 있는데, 이게 뭐야? (해설 종료",1,203
91,1,3.2,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 👍👍👍 (해설 종료,1,277
92,1,5.66,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자 오해가 아니라 그냥 LLM이 잘못 대답하는 거지! 근데 그걸 왜 설명해 줬어? 😊 (해설 종료,1,193
93,1,2.55,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 👍👍 (해설 종료,1,193
94,1,4.22,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 오 정답이야! RAG 이거 진짜 잘하긴 했어 👍👍 (해설 종료,1,247
95,1,5.17,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 오 잘 대답했어! 근데 이 기술을 이용해서 어떤 문제점을 해결할 수 있지? 🤔 (해설 종료,1,254
96,1,4.27,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", PEFT 에 속하는 기술로는 뭐가 있을지 한번 고민해 볼래? 🤔 (해설 종료,1,209
97,1,2.66,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 정답이야! 👍👍 (해설 종료,1,212
98,1,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
99,1,2.84,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 이 뭐하는 건지 아니? 🤔 (해설 종료,1,167
100,1,9.59,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다.," 토크나이저는 문장을 토크나이저 한 게 아니고, 토큰은 토크나이저랑 반대지! 토큔만 토크나이저야! 😊 (해설 종료",1,236
101,1,2.66,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 👍👍 (해설 종료,1,210
102,1,4.55,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 에이 그거 맞지! 근데 더 구체적으로 설명해 줄 수 있어? 🤔 (해설 종료,1,241
103,1,2.89,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 정확히 다 맞지! 👍👍 (해설 종료,1,296
104,2,4.63,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 정답! 😊😊😊👍👍👍 (해설 종료,1,264
105,2,4.03,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지! 😊😊😊 (해설 종료,1,200
106,2,4.02,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 정말 완벽한 설명이야! 👍👍👍👍 (해설 종료,1,306
107,2,4.23,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 우와! 정말 완벽한 답변이야! 👍👍👍 (해설 종료,1,246
108,2,4.72,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", 합집합이랑 교집합이 구체적으로 뭔지 말해봐! 😊😊 (해설 종료,1,209
109,2,2.37,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 🤔🤔🤔 (해설 종료,1,165
110,2,3.62,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", x축이랑 y축이 뭐지? 🤔🤔 (해설 종료,1,273
111,2,5.42,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽한 설명이야! 😊👍👍👍👍👍 (해설 종료,1,316
112,2,4.88,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 정말 완벽한 설명이야! 😊👍👍👍👍👍 (해설 종료,1,248
113,2,3.16,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 오! 😊😊😊👍👍 (해설 종료,1,177
114,2,4.09,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 완벽한 설명이야! 👍👍👍👍 (해설 종료,1,401
115,2,2.44,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 그래서? 😥😥😥 (해설 종료,1,275
116,2,4.39,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 정말 완벽한 설명이야!! 👍👍👍👍👍 (해설 종료,1,235
117,2,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서? 😥😥😥😥 (해설 종료,1,168
118,2,2.98,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 잘 이해하고 있네! 😊👍 (해설 종료,1,233
119,2,2.66,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", 오 잘 이해하고 있네 😊😊 (해설 종료,1,236
120,2,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 😊👍👍 (해설 종료,1,206
121,2,3.96,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 썼네 😥 👍👍👍 (해설 종료,1,189
122,2,3.44,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법에 대한 이야기가 전혀 없잖아 😥😥 (해설 종료,1,217
123,2,3.45,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 와! 😊😊👍👍👍 (해설 종료,1,255
124,2,3.12,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 정말 완벽한 답변이야! 😊😊 (해설 종료,1,226
125,2,3.33,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 정말 완벽한 설명이야! 😊👍👍 (해설 종료,1,173
126,2,3.3,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 그건 맞는데 그래서 그게 구체적으로 어떻게? 😊 (해설 종료,1,275
127,2,3.28,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그건 맞는데 그럼 추론할 때는? 😥 (해설 종료,1,253
128,2,3.2,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 맞는데 왜 그렇게 힘들지? 😥😥😥 (해설 종료,1,158
129,2,3.31,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞는데 왜 그렇게 하지? 😥🤔😥 (해설 종료,1,157
130,2,5.02,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 정말 완벽한 답변이야!! 🎉🎉😊👍👍 (해설 종료,1,448
131,2,5.96,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 😊👍👍👍👍👍😊😊😊😊😊 (해설 종료,1,454
132,2,2.36,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오 잘 이해하고 있네 😊 (해설 종료,1,217
133,2,2.37,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 🤔🤔🤔 (해설 종료,1,198
134,2,3.45,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 오 정답! 😊👍👍👍 (해설 종료,1,231
135,2,6.44,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습이 뭘 말하는 건지 한번 설명해 볼래? 😊 (해설 종료,1,284
136,2,5.84,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 정리만 대충 설명하고 동작하는 방식은 전혀 설명 안 했네 😥😥😥🤔🤔 (해설 종료,1,193
137,2,3.28,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 오 잘 이해하고 있네 😊👍👍 (해설 종료,1,238
138,2,2.22,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥😥😥😥 (해설 종료,1,171
139,2,3.33,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 정말 완벽해! 😊😊😊😊😊 (해설 종료,1,186
140,2,2.84,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 많이 만들긴 하는데… 😥😥😥 (해설 종료,1,160
141,2,3.16,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 완벽한 답이야!! 😊👍👍 (해설 종료,1,178
142,2,3.63,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 핵심 아이디어 반대로 설명했네 😥🥣🥣 (해설 종료,1,171
143,2,2.55,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 핵심 아이디어 설명만 있네 😥 (해설 종료,1,169
144,2,4.56,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", K-fold Validation 만으로는 데이터 불균형 문제를 해결할 수 없지 😥😥😥 (해설 종료,1,180
145,2,3.02,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 잘 이해하고 있네! 😊😊😊 (해설 종료,1,202
146,2,3.0,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞지! 그래서? 😥🤔🤔 (해설 종료,1,162
147,2,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야!! 😊😊 (해설 종료,1,185
148,2,16.84,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터 최적화 방법 3가지! 1. Grid Search (범위 내에서 바둑판처럼 찾는 것) 2. Random Search (랜덤하게 값을 지정하는 것) 3. Bayesian Optimization (이미 한번 해봤던 방법으로, 그걸 이용해서 잘 안 되는 것, 잘 되는 것만 골라서 하이퍼파라미터를 찾아내는 거지!) 😊😊 (해설 종료",1,432
149,2,3.37,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 그건 맞는데 구체적으로 말해 볼래? 😊 (해설 종료,1,319
150,2,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
151,2,4.02,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 완벽한 답이야! 😊👍👍👍 (해설 종료,1,309
152,2,4.42,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 😊😊👍👍👍👍👍 (해설 종료,1,217
153,2,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
154,2,2.2,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 오! 😊😊😊 (해설 종료,1,148
155,2,6.09,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 우와 완벽한 답! 😊👍👍👍👍👍👍👍👍 (해설 종료,1,157
156,2,7.62,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 자세히 한번 자세히 한번 자세히! 😊👍👍👍 (해설 종료",1,315
157,2,5.05,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 볼래? 😊👍👍 (해설 종료,1,290
158,2,2.06,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 맞지! 😊😊 (해설 종료,1,159
159,2,5.22,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 학습 초반이랑 중반이랑 학습이 잘 되고 안 되고 차이가 크긴 하지! 😥 (해설 종료,1,211
160,2,5.2,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 학습에 재미를 느끼는 건 맞는데 학습률을 조정하는 건 왜? 🤔😥 (해설 종료,1,186
161,2,2.92,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그건 맞는데 구체적으로 설명해 봐! 😊 (해설 종료,1,133
162,2,4.27,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그건 맞는데 그건 맞는데 구체적으로 한번 자세히 이야기해 볼래? 😊 (해설 종료,1,177
163,2,4.11,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 잘 이해하고 있네 😊👍👍👍👍 (해설 종료,1,203
164,2,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 이거 한번 자세히 설명해 봐! 😊 (해설 종료,1,169
165,2,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오! 잘 이해하고 있네!! 😊😊👍 (해설 종료,1,175
166,2,3.64,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 오 정답! 😊😊👍👍👍 (해설 종료,1,172
167,2,5.25,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답! 근데 각각 뭘 약자로 하고 있지? 🤔🤔🤔 (해설 종료,1,187
168,2,1.91,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥😥😥 (해설 종료,1,199
169,2,4.58,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다."," AdamW 핵심 아이디어만 설명하고, Adam 이랑 RMSProp 는? 🤔🤔 (해설 종료",1,218
170,2,2.84,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., AdamW Optimizer 는? 🤔🤔 (해설 종료,1,197
171,2,4.27,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., Adam 이랑 그거랑 Optimizer 랑 그거랑 뭔지 모르겠는데 😥 (해설 종료,1,218
172,2,12.86,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다."," 해결 방법에 대한 내용이 완벽하긴 한데, 모델 구조을 단순화 시키거나, Batch Normalization 을 이용하거나, 또는 학습 수식 쪽에서 Weight Decay 를 조절하거나, 혹은 L1, L2 Regularization 을 쓸 수도 있지 않을까? 😊👍👍👍 (해설 종료",1,327
173,2,3.61,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 그건 맞는데 그건 구체적으로 말할 수 있어? 😊 (해설 종료,1,254
174,2,3.62,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그건 맞는데 그러면 Dropout 을 하면 뭐가 좋을까? 😊 (해설 종료,1,191
175,2,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 정말 완벽한 답이야! 😊👍👍 (해설 종료,1,197
176,2,4.58,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", L1 Regularization 이랑 L2 Regularization 을 한번 자세히 설명해 봐! 😊👍 (해설 종료,1,188
177,2,8.83,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다."," L1 regularization 은 weight 의 절댓값의 합의 절댓값의 합을, L2 regularization 은 그거의 제곱의 합의 절댓값의 합을 이용하는 거잖아 😊😊 (해설 종료",1,228
178,2,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화 는? 🤔 (해설 종료,1,275
179,2,4.08,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥😥😥😥 (해설 종료,1,273
180,2,3.78,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오! 완벽한 답이야! 😊😊👍👍 (해설 종료,1,199
181,2,4.58,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", Pre-train (사전학습) 이라는 단어를 한번 자세히 말해봐! 😊 (해설 종료,1,191
182,2,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
183,2,3.28,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘 이해하고 있네 😊👍👍 (해설 종료,1,220
184,2,4.41,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그건 맞는데 그 두 개의 차이점을 한번 자세히 말해봐! 😊 (해설 종료,1,247
185,2,2.97,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 이해하고 있네 😊😊😊 (해설 종료,1,264
186,2,4.89,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 그건 맞는데 그 활성화 함수이 없으면 어떻게 되지? 🤔🤔🤔 (해설 종료,1,204
187,2,1.59,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 그래서? 😥 (해설 종료,1,188
188,2,2.86,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 😊👍👍 (해설 종료,1,202
189,2,3.44,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오! 완벽한 답이야 👍👍👍 (해설 종료,1,228
190,2,2.81,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", 😥🤣🤣🤣 (해설 종료,1,209
191,2,5.17,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 2개의 저차원 행렬만 학습시켜서 얻을 수 있는 장점이 뭐지? 😊 (해설 종료,1,262
192,2,6.25,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 확률이 가장 큰 k개의 토큰이랑 누적 확률이 p 이상이라는 게 구체적으로 말해 볼래? 😊 (해설 종료,1,370
193,2,5.62,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그건 맞는데 top-k sampling 이랑 top-p sampling 이 뭘 말하는 건지 설명해 봐! 😊😊 (해설 종료,1,372
194,2,4.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 오 완벽한 답이야! 😊👍👍👍👍👍 (해설 종료,1,206
195,2,4.94,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 우와 완벽한 답변이야! 😊👍👍👍👍 (해설 종료,1,288
196,2,5.37,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔🤔 (해설 종료,1,191
197,2,4.12,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 완벽한 답변이야! 👍👍👍👍 (해설 종료,1,203
198,2,6.28,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," RAG 이 어떤 기술인지 한번 자세히 설명해 보고, 그리고 그 기술을 이용해서 어떤 문제점을 해결할 수 있을까? 😊😊 (해설 종료",1,260
199,2,5.03,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 사용자 답안 정말 완벽한 답이야! 👍👍👍👍👍 (해설 종료,1,253
200,2,3.48,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오! 😊👍👍👍👍 (해설 종료,1,204
201,2,2.69,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 😊👍👍 (해설 종료,1,212
202,2,4.07,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오! 잘 이해하고 있네! 😊👍👍👍 (해설 종료,1,232
203,2,3.31,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 이 구체적으로 어떤 문제를 말하는 거야? 😊 (해설 종료,1,170
204,2,6.92,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다.," 토큰은 형태소랑 비슷한 거고, 토크나이저 설명도 없이 그냥 번역만 했네 😥😥😥 (해설 종료",1,219
205,2,6.27,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 정말 완벽한 설명이야! 👍👍👍👍👍👍👍👍👍 (해설 종료,1,233
206,2,4.55,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 핵심 아이디어만 간단히 설명해 보라고! 🤔🤔🤔 (해설 종료,1,241
207,2,5.42,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 핵심 아이디어는? 🤔🤔🤔🤔🤔🤔🤔 (해설 종료,1,312
208,3,2.73,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 우와! 정말 완벽해! 👍 (해설 종료,1,252
209,3,3.81,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 두 벡터의 방향에 따른 결과값 이야기가 없잖아 😥 (해설 종료,1,199
210,3,3.29,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와! 완벽해! 👍👍 (해설 종료,1,300
211,3,3.92,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 수식만 있네! 나머지는 없나? 🤔 (해설 종료,1,244
212,3,2.89,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", 그럼 DICE Score 는 어떻게 되지? 😊 (해설 종료,1,198
213,3,3.48,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", DICE score 다시 한번 생각해 봐! 어떻게 되어야 하지? 😊 (해설 종료,1,172
214,3,5.03,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 그래서 x축이랑 y축이 어떻게 되지? x축이랑 y축 설명이 없잖아 😥 (해설 종료,1,282
215,3,6.35,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다."," x축이랑 y축이 각각 recall, precision 이랑 FP rate, TP rate 인데 하나만 설명했네! ROC-AUC 는? 😥 (해설 종료",1,322
216,3,2.98,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 오! 정말 완벽해! 정말 좋아! 👍 (해설 종료,1,236
217,3,3.94,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체한다고만 설명하면 좀 부실하지 않을까? 😥 (해설 종료,1,182
218,3,3.45,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정말 완벽한 설명이야! 👍👍 (해설 종료,1,397
219,3,4.89,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 정규화가 뭔지 설명은 잘 했는데, 알고리즘은 어떻게 될까? 😊 (해설 종료",1,290
220,3,2.97,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 우와! 완벽해! 👍👍 (해설 종료,1,226
221,3,2.69,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 그 아웃라이어가 뭐가 문제인데? (해설 종료,1,169
222,3,4.22,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 혹시 PCA랑 t-SNE랑 차이점만 간단히 설명했네 😥 (해설 종료,1,241
223,3,3.3,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", PCA랑 t-SNE 차이점만 설명했네 😥 (해설 종료,1,240
224,3,3.31,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,210
225,3,2.86,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
226,3,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
227,3,2.66,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 우와! 정말 완벽해! 👍 (해설 종료,1,250
228,3,3.61,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와! 완벽해! 정말 잘했어 👍👍 (해설 종료,1,229
229,3,2.67,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA로 해결하면 어떻게 되지? 🤔 (해설 종료,1,169
230,3,4.56,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 그럼 target 값을 어떻게 구분하지? 그리고 맨 위에서 시작하면 어떻게 되지? 😊 (해설 종료,1,283
231,3,2.34,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그래서 어떻게 추론하는데? 😊 (해설 종료,1,247
232,3,4.55,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용해서 예측하는 건 맞긴 하지만… 그래서 왜 그렇게 하지? 🤔 (해설 종료,1,167
233,3,2.68,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞지만 너무 간단한데 😥 (해설 종료,1,153
234,3,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
235,3,5.48,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Voting 의 구체적인 방법이 뭐가 있을까? 그리고 Bagging 이랑 Boosting 은? 그리고 Stacking 은? (해설 종료,1,451
236,3,2.97,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 우와! 완벽해! 👍👍 (해설 종료,1,221
237,3,2.69,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 그 과정이 구체적으로 뭐야? 😊 (해설 종료,1,200
238,3,5.48,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 사용자의 지도 없이 학습하는 건 맞지만 각각의 방법에 따라 좀 더 자세히 설명이 필요하지 않을까? 😊 (해설 종료,1,244
239,3,2.97,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 빠졌잖아 😥 (해설 종료,1,262
240,3,2.37,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 그럼 어떻게 작동하는데? 😊 (해설 종료,1,171
241,3,2.34,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 우와 완벽해! 👍 (해설 종료,1,232
242,3,4.89,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 그냥 PCA가 뭐야! 그래서 PCA가 어떻게 하는데? 그리고 PCA가 어떻게 동작한다고? 🤔 (해설 종료,1,188
243,3,3.16,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 그럼 PCA의 핵심 아이디어이 뭐야? 😊 (해설 종료,1,185
244,3,3.3,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만드는지 설명이 빠졌잖아 😥 (해설 종료,1,163
245,3,3.17,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답변이야!! (해설 종료,1,178
246,3,5.19,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어 설명이 빠졌잖아 😥 (해설 종료,1,181
247,3,2.84,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 핵심 아이디어 설명이 빠졌잖아 😥 (해설 종료,1,171
248,3,2.22,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 그렇지는 않을 텐데 😥 (해설 종료,1,165
249,3,1.91,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 정답! 😊 (해설 종료,1,195
250,3,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그럼 어떻게 해결하면 되지? 🤔 (해설 종료,1,160
251,3,2.99,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽해! 잘했어 👍👍 (해설 종료,1,186
252,3,5.78,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오 정답이야! 하이퍼파라미터 정의랑 최적화 방법 3가지 모두 잘 말했네 👍 (해설 종료,1,362
253,3,3.06,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 우와! 완벽해! 👍👍 (해설 종료,1,317
254,3,2.34,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 다시 한번 잘 생각해 봐 😥 (해설 종료,1,252
255,3,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 잘했어! 😊😊😊 (해설 종료,1,302
256,3,3.62,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 그럼 Train 데이터셋을 shuffle 하지 않으면 어떻게 되지? 😊 (해설 종료,1,212
257,3,3.0,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 그냥 섞는 게 더 좋지 않을까? 😊 (해설 종료,1,209
258,3,2.53,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 우와! 정말 완벽해! 👍 (해설 종료,1,150
259,3,3.08,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 Early Stopping 이 구체적으로 뭐야? 🤔 (해설 종료,1,138
260,3,2.89,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 핵심 아이디어이 빠졌잖아 😥 (해설 종료,1,285
261,3,3.69,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 그럼 각 방법 별로 어떻게 하는지 말할 수 있어? 😊 (해설 종료,1,282
262,3,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 그건 맞기는 한데 왜 필요한 거지? (해설 종료,1,163
263,3,1.73,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야! (해설 종료,1,189
264,3,5.2,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 학습에 재미를 느껴야 한다는 말이 더 학습률을 높이는 구간의 정답이야!! (해설 종료,1,186
265,3,4.84,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하려고 학습률을 높이는 구간을 만들면 어떻게 되지? (해설 종료,1,145
266,3,3.17,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼 그 셋을 구분해 줘! 😊 (해설 종료,1,170
267,3,3.16,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 정답이야! 👍👍 (해설 종료,1,197
268,3,3.64,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그럼 어떤 Entropy 를 사용하는지 말해줄 수 있어? 😊 (해설 종료,1,171
269,3,3.62,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그러면 이게 구체적으로 어떤 Entropy 를 말하는 거야? 😊 (해설 종료,1,177
270,3,137.53,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", RMSE 다시 한번 생각해 봐! RMSE 왜 RMSE 인지 생각해 봤어? RMSE 다시 한번 생각해 보면 정답이야! 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번 생각해 보면 RMSE 다시 한번,1,1024
271,3,2.06,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍 (해설 종료,1,168
272,3,2.22,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 그러면 어떻게 되지? 😥 (해설 종료,1,201
273,3,3.62,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", AdamW 를 사용하는 정확한 핵심 아이디어이 뭐지? 😊 (해설 종료,1,212
274,3,3.47,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그러면 Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (해설 종료,1,201
275,3,2.53,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊😊😊 (해설 종료,1,207
276,3,3.92,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", 그러면 Dropout 을 충실히 적용하면 어떻게 될까? 🤔 (해설 종료,1,270
277,3,2.5,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 정말 완벽해! 👍 (해설 종료,1,247
278,3,3.0,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭐야? 🤔 (해설 종료,1,187
279,3,7.42,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅을 막기 위한 건 맞긴 한데… 하나의 뉴런을 랜덤하게 제거해서 얻을 수 있는 효과이기도 하지 않을까? 🤔 (해설 종료,1,223
280,3,4.12,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 정답이야! 그럼 각각의 새로운 항을 어떤 식으로 추가하지? 🤔 (해설 종료,1,185
281,3,2.36,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
282,3,2.73,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그러면 레이어 정규화는? 😥 (해설 종료,1,274
283,3,3.3,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그러면 Batch Normalization 은 뭘까? 🤔 (해설 종료,1,268
284,3,2.53,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 완벽해! 👍👍 (해설 종료,1,191
285,3,2.7,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 정말 완벽해! 👍👍 (해설 종료,1,179
286,3,2.66,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 완벽해! 👍👍 (해설 종료,1,270
287,3,3.77,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습의 또 다른 목적이 있지 않을까? 😊 (해설 종료,1,223
288,3,5.19,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", Xavier 가 그러면 Xavier initialization 이랑 그러면 Xavier 가 Xavier initialization 이랑 어떤 차이가 있지 않을까? 😊 (해설 종료,1,252
289,3,122.93,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다."," Xavier 는 입력+출력 모두 고려하고, 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이랑 그러면 Xavier 는 Xavier initialization 이",1,1024
290,3,3.64,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 그럼 그럼! 그럼 정답이야! 완벽해! 👍 (해설 종료,1,196
291,3,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음 그치! 그래서 그럼 활성화 함수가 없으면 어떻게 되지? 🤔 (해설 종료,1,205
292,3,5.69,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼 각 Class 간 확률이 서로 경쟁하는 Multi-Class 에서는 어떤 활성화 함수를 써야 하지? 🤔 (해설 종료,1,220
293,3,2.05,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 👍 (해설 종료,1,219
294,3,4.06,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", 그럼 그게 구체적으로 뭐지? 그리고 뭐가 좋을까? 😊 (해설 종료,1,217
295,3,2.84,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그 방법이 뭐가 좋지? 😊 (해설 종료,1,247
296,3,5.16,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-p sampling 에서 확률이 뭐가 p 이상인지 설명해 봐? 그리고 temperature 는 뭐지? 😊 (해설 종료,1,363
297,3,3.59,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", top-k sampling 이랑 top-p sampling 설명이 없잖아 😥 (해설 종료,1,359
298,3,3.95,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 그럼 각각의 핵심 아이디어이 뭐야? 한번 말해봐! 😊 (해설 종료,1,201
299,3,2.26,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 👍 (해설 종료,1,271
300,3,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으켜서 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
301,3,3.03,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,196
302,3,2.05,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 그럼 어떤 기술이야? (해설 종료,1,233
303,3,2.83,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 그 연동을 통해 어떻게 하는데? 😊 (해설 종료,1,239
304,3,3.48,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 그러면 PEFT 에 속하는 기술로 뭐가 있을까? 😊 (해설 종료,1,204
305,3,2.66,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 잘했어! 👍👍 (해설 종료,1,212
306,3,2.66,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,223
307,3,3.33,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 해결할 수 있는 문제를 조금 더 자세히 설명해봐 😥 (해설 종료,1,170
308,3,4.73,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토�서나이저 설명이 서로 반대로 되어 있잖아 😥 (해설 종료,1,205
309,3,5.5,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토�래이저 설명이 완벽해! 그래서 LLM을 할 수 있는데? 😊 (해설 종료,1,228
310,3,3.14,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 그 각각의 Attention 이 구체적으로 뭐지? (해설 종료,1,232
311,3,3.69,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 그러면 Masked Decoder Self-Attention 은 뭘까? 😊 (해설 종료,1,301
312,4,6.94,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," 두 벡터의 방향이 같을 때, 반대일 때, 수직일 때 결과이값이 어떻게 될지 생각해 봤어? 😊 (해설 종료",1,278
313,4,6.65,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다."," 두 벡터의 방향이 같을 때, 반대일 때, 수직일 때 결과이 값이 어떻게 될지 생각해 봤어? 😊 (해설 종료",1,217
314,4,2.92,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 😊👍 (해설 종료,1,299
315,4,2.52,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 우와 완벽해 😊😊 (해설 종료,1,235
316,4,2.53,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는 어디 갔어 😥 (해설 종료,1,196
317,4,1.28,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
318,4,2.67,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 우와 잘했어 👍👍 (해설 종료,1,267
319,4,2.91,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와 완벽해! 😊👍 (해설 종료,1,300
320,4,2.36,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와 완벽해! 😊 (해설 종료,1,232
321,4,4.27,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 그래서 결측값 채우는 알고리즘에 대한 내용이 전혀 없잖아 😥 (해설 종료,1,184
322,4,3.14,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 완벽해 👍👍👍 (해설 종료,1,395
323,4,2.42,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 그래서 왜 하는 거지? 😊 (해설 종료,1,275
324,4,2.36,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 우와 완벽해! 😊 (해설 종료,1,222
325,4,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 왜 문제가 되는데? 🤔 (해설 종료,1,168
326,4,2.67,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 주성분이 뭐야? 🤔 (해설 종료,1,231
327,4,4.25,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 차이점을 조금 더 설명해 줄 수 있어? 😊 (해설 종료,1,246
328,4,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 설명했네 😥 (해설 종료,1,206
329,4,2.87,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😊 (해설 종료,1,182
330,4,2.34,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법이 없잖아 😥 (해설 종료,1,210
331,4,4.16,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표나 손실 함수 쪽도 생각해 봤어? 😊 (해설 종료,1,259
332,4,2.66,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍👍 (해설 종료,1,223
333,4,2.53,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 우와 잘했어 👍👍 (해설 종료,1,168
334,4,2.68,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와 잘했어 👍👍 (해설 종료,1,271
335,4,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 학습할 때 이야기밖에 없잖아 😥 (해설 종료,1,251
336,4,4.5,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용해서 예측한다고? 좀 더 구체적으로 설명해 봐 😊 (해설 종료,1,166
337,4,3.95,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 사용하는 건 맞지만… 왜 하는 거지? 🤔 (해설 종료,1,161
338,4,2.5,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오! 정말 좋아! 😊 (해설 종료,1,432
339,4,4.56,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 단순히 방법 이름만 설명하는 게 아니라 구체적으로 어떻게 하는 방법들이야 😊 (해설 종료,1,445
340,4,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오 완벽한 설명이야! 😊😊 (해설 종료,1,220
341,4,1.28,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 😊 (해설 종료,1,191
342,4,3.92,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습 설명이 너무 부실한데 😥 (해설 종료,1,234
343,4,2.83,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 없잖아 😥 (해설 종료,1,261
344,4,4.27,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론인 베이즈 정리를 어떻게 설명할 수 있어? 😊 (해설 종료,1,183
345,4,3.62,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다."," 완벽하긴 한데, 무슨 정리를 이용하지? 🤔 (해설 종료",1,240
346,4,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
347,4,2.39,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 그래서 어떻게 하는지 말할 수 있어? (해설 종료,1,180
348,4,2.84,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 그래서 그 방법이 어떻게 하는 거지? 🤔 (해설 종료,1,160
349,4,3.08,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 완벽한 답변이야! 😊😊 (해설 종료,1,177
350,4,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 거지? 🤔 (해설 종료,1,164
351,4,5.83,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다."," 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어다! (해설 종료",1,190
352,4,2.7,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 잘 생각을 해봐! 😥 (해설 종료,1,168
353,4,1.9,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 😊 (해설 종료,1,195
354,4,3.62,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 과연 학습에 지장을 줄까? 🤔🤔 (해설 종료,1,166
355,4,2.37,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 좋아! 완벽해! 😊 (해설 종료,1,182
356,4,2.97,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오 완벽한 답이야 👍👍 (해설 종료,1,344
357,4,5.56,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 설명했네! 😊👍 (해설 종료,1,333
358,4,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😊 (해설 종료,1,246
359,4,2.75,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 완벽해! 😊👍 (해설 종료,1,301
360,4,2.84,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 오 정답! ✨🎉🎉 (해설 종료,1,207
361,4,1.27,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
362,4,2.37,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 오 정답!! 😊👍 (해설 종료,1,149
363,4,3.24,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 Early Stopping 이 정확히 뭐 하는 건데? 🤔 (해설 종료,1,139
364,4,2.73,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 우와 잘했어 👍👍 (해설 종료,1,284
365,4,4.16,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 각 방법들을 좀 더 자세히 설명해 주면 더 좋을 것 같아 😊 (해설 종료,1,285
366,4,4.41,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습 초반이랑 후반 학습률이 왜 이렇게 차이가 나는 걸까? 😊 (해설 종료,1,174
367,4,1.59,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답!! (해설 종료,1,188
368,4,2.37,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 잘했어 😊👍 (해설 종료,1,168
369,4,4.06,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하기는 하는데… 왜 그렇게 하지? 🤔 (해설 종료,1,140
370,4,2.39,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 오 정답이야! 😊😊 (해설 종료,1,165
371,4,2.69,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 🎉🎉 (해설 종료,1,194
372,4,2.22,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 오 잘 생각을 해봐 😥 (해설 종료,1,162
373,4,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 각 Class 별로 어떤 Loss Function 을 사용하는지 설명해 봐 😊 (해설 종료,1,176
374,4,2.06,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 오 정답이야! 😊 (해설 종료,1,162
375,4,3.0,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍👍👍 (해설 종료,1,174
376,4,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
377,4,3.31,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", AdamW 가 뭔지 설명도 해 줄 수 있어? 😊 (해설 종료,1,210
378,4,3.48,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
379,4,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
380,4,2.66,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", 오 정답! 그리고 또 또 또 또… (해설 종료,1,262
381,4,2.67,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오 완벽해! 대박! 😊 (해설 종료,1,248
382,4,3.47,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 DropOut 을 하는 이유는 뭘까? 🤔 (해설 종료,1,190
383,4,4.11,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다."," 완벽한 설명이기는 하지만, 더 다양한 이유가 있지 않을까? 🤔 (해설 종료",1,202
384,4,3.47,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 그럼 L1 Regularization 은 L2 Regularization 은? 🤔 (해설 종료,1,181
385,4,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
386,4,2.73,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 😊 (해설 종료,1,274
387,4,3.45,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 내용이 전혀 없잖아 😥 (해설 종료,1,269
388,4,2.37,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 완벽해! 😊😊 (해설 종료,1,190
389,4,2.37,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어 👍👍 (해설 종료,1,177
390,4,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
391,4,2.97,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘했어 👍👍👍 (해설 종료,1,218
392,4,2.83,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", Xavier 는 완전 대박! 😊😊 (해설 종료,1,237
393,4,4.86,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다."," Xavier 는 입력+출력 모두 고려하고, He 는 입력만 고려하는 거야. 알았어? 😊 (해설 종료",1,276
394,4,4.42,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,201
395,4,3.94,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음 그치! 근데 좀 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,203
396,4,3.17,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,204
397,4,3.44,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 박수!! 👏👏👏 (해설 종료,1,228
398,4,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
399,4,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 우와 정답이야! 😊 (해설 종료,1,244
400,4,9.11,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다."," 확률이 가장 큰 k개의 토큰을 선택하는 건 Top-k sampling 이고, 누적 확률이 p 이상인 토큰을 선택하는 건 Top-p sampling 이고, 그래서 Temperature 는? 🤔 (해설 종료",1,388
401,4,4.22,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오! 모범 답안보다도 잘했네 👍👍👍 (해설 종료,1,363
402,4,3.34,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐 😊 (해설 종료,1,197
403,4,3.23,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 완벽해! 잘했어 👍👍 (해설 종료,1,277
404,4,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
405,4,3.02,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,196
406,4,3.77,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", RAG 이 어떤 기술인지 한번 자세히 설명해 볼 수 있어? 😊 (해설 종료,1,244
407,4,3.78,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", RAG 이 어떤 기술인지 한번 자세히 설명해 볼 수 있어? 😊 (해설 종료,1,245
408,4,3.31,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 그래서 PEFT 에 속하는 기술는 뭐가 있지? 😊 (해설 종료,1,203
409,4,3.6,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽해! 대박! 👍👍👍 (해설 종료,1,218
410,4,2.67,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,223
411,4,3.16,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 양자화에 대한 내용이 전혀 없잖아 😥 (해설 종료,1,169
412,4,3.62,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰에 대한 설명이기는 하지만 너무 부실한데 😥 (해설 종료,1,198
413,4,2.19,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 😊 (해설 종료,1,207
414,4,2.98,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 😊 (해설 종료,1,231
415,4,3.53,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 완벽한 답이야! 😊👍👍 (해설 종료,1,300
416,5,4.03,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 우와! 정말 완벽해! 정말 잘했어! 👍👍 (해설 종료,1,260
417,5,7.1,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기 위해 사용하긴 하지! 그래서 두 벡터의 방향에 따른 값이랑 사용 예를 들어 줄 수 있어? 😊 (해설 종료,1,220
418,5,3.22,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와! 정말 완벽해! 👍👍 (해설 종료,1,301
419,5,5.03,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," 그럼 Accuracy, Recall, Precision, F1 Score 에 대해 한 번 자세히 설명해봐! 😊 (해설 종료",1,249
420,5,2.7,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE는 어디 갔지? 🙄 (해설 종료,1,197
421,5,1.27,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
422,5,2.52,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 우와! 완벽해! 👍 (해설 종료,1,266
423,5,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
424,5,3.92,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽해! 정말 잘했어! 정말 완벽해! (해설 종료,1,242
425,5,3.64,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 알고리즘 평균값 채우는 알고리즘 (해설 종료,1,180
426,5,3.13,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 완벽히 정확해! 👍👍 (해설 종료,1,395
427,5,4.33,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 그래서 정규화이랑 정규화이 알고리즘이 뭐가 다르데? 😊 (해설 종료,1,287
428,5,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 우와! 완벽해!! 👍👍👍 (해설 종료,1,230
429,5,2.38,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
430,5,5.33,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다."," 주성분이 뭐고, PCA랑 t-SNE랑 차이점을 조금 더 설명해 줄 수 있어? 😊 (해설 종료",1,248
431,5,2.19,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", 오 완벽해! 👍 (해설 종료,1,233
432,5,3.33,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 값이랑 주어졌어 😥 (해설 종료,1,210
433,5,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 😥 (해설 종료,1,178
434,5,2.52,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
435,5,4.11,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 와! 정말 완벽한 답변이야! 👍👍👍 (해설 종료,1,259
436,5,3.12,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와! 정말 완벽해! 👍👍 (해설 종료,1,226
437,5,2.22,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 뭐야? 🤔 (해설 종료,1,166
438,5,3.14,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 정확해! 역시 😊👍 (해설 종료,1,274
439,5,2.81,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 추론할 때는 어떻게 하지? 🤔 (해설 종료,1,250
440,5,3.81,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
441,5,3.33,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
442,5,3.91,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
443,5,6.59,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다! 그래서 Bagging 이랑 Boosting 이랑 Stacking 이 뭐야? 😊 (해설 종료,1,458
444,5,3.3,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍👍 (해설 종료,1,223
445,5,1.28,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 😊 (해설 종료,1,191
446,5,4.86,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 맞는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,240
447,5,3.14,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없잖아 😥 (해설 종료,1,263
448,5,3.48,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 그래서 새로운 데이터가 들어왔을 때 어떻게 예측하는데? 🤔 (해설 종료,1,178
449,5,2.03,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 완벽해! 👍 (해설 종료,1,230
450,5,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
451,5,3.8,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
452,5,3.0,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만드는지 생각해 봐! 😊 (해설 종료,1,161
453,5,2.53,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 완벽해! 👍👍 (해설 종료,1,174
454,5,2.52,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
455,5,2.84,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 음… 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,171
456,5,5.52,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 데이터가 불균형할 때는 각 fold 별로 비율이 차이가 날 수 있지 않을까? 😊 (해설 종료,1,186
457,5,3.33,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오! 완벽한 답변이야! 👍👍 (해설 종료,1,204
458,5,2.98,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 어떻게 해결하면 되는데? 🤔 (해설 종료,1,162
459,5,2.53,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽해! 😊👍 (해설 종료,1,183
460,5,4.06,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오! 완벽한 답변이야! 👍👍👍 (해설 종료,1,351
461,5,4.3,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", Random Search 랑 Grid Search 가 구체적으로 어떤 방법인지 알아? 😊 (해설 종료,1,324
462,5,1.25,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ",  (해설 종료,1,245
463,5,4.63,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해! 완벽한 답변이야!! 👍👍👍 (해설 종료,1,313
464,5,3.78,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 오! 정답이야! 완벽해! 👍👍👍 (해설 종료,1,213
465,5,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
466,5,3.31,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 우와! 완벽해! 👍👍👍 (해설 종료,1,155
467,5,3.23,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 오! 완벽한 답변이야!! 👍👍 (해설 종료,1,139
468,5,3.86,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! 😊 (해설 종료,1,291
469,5,3.22,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 각 관점에서 한번 자세히 설명해 봐! 😊 (해설 종료,1,279
470,5,3.78,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데 왜 필요할까? 🤔 (해설 종료,1,170
471,5,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
472,5,1.73,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답이야!! (해설 종료,1,164
473,5,1.67,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 오 정답이야!! (해설 종료,1,125
474,5,3.16,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 오 정답이야! 완벽해! 👍👍 (해설 종료,1,170
475,5,3.64,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,200
476,5,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
477,5,3.17,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 잘 대답했어👍👍👍 (해설 종료,1,174
478,5,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
479,5,2.06,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍 (해설 종료,1,168
480,5,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
481,5,4.59,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", AdamW 설명은 좋긴 한데 다른 Optimizer 들의 차이점을 설명해봐! 😊 (해설 종료,1,218
482,5,3.47,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
483,5,3.48,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 굿! 완벽해! 👍👍👍 (해설 종료,1,213
484,5,5.17,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하면 해결할 수 있다는 말 말고도 방법이 많을 텐데 😊 (해설 종료,1,278
485,5,3.62,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 우와! 정말 완벽해! 👍👍👍 (해설 종료,1,254
486,5,3.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까~요? 🤔 (해설 종료,1,191
487,5,4.12,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있는데 😊 (해설 종료,1,202
488,5,3.16,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 오 정답이야! 굿이야! 👍👍 (해설 종료,1,179
489,5,3.48,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 굿! 완벽이야!! 👍👍👍 (해설 종료,1,194
490,5,2.75,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화은? 😊 (해설 종료,1,274
491,5,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
492,5,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
493,5,3.66,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,185
494,5,3.12,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 굿! 완벽해! 👍👍 (해설 종료,1,273
495,5,5.06,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 차이점을 조금 더 설명해 줄 수 있어? 😊 (해설 종료,1,231
496,5,2.52,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은? 😊 (해설 종료,1,235
497,5,4.55,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다."," Xavier 는 입력+출력 모두, He 는 입력만 고려하는 거야! 알았어? 😊 (해설 종료",1,274
498,5,4.09,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적인 답변이야! 😊 (해설 종료,1,199
499,5,4.12,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적인 답변이야! 😊 (해설 종료,1,204
500,5,2.69,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오! 완벽해! 👍👍 (해설 종료,1,201
501,5,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오! 완벽해! 👍👍 (해설 종료,1,224
502,5,2.33,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
503,5,2.67,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 우와 완벽! 👍👍 (해설 종료,1,246
504,5,5.0,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-p sampling 에서 누적 확률이 p 이상이라는 게 구체적으로 어떤 기준이지? 🤔 (해설 종료,1,362
505,5,3.44,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오! 완벽해! 😊👍👍 (해설 종료,1,358
506,5,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
507,5,4.49,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 굿! 완벽한 답변이야! 잘했어! 👍👍 (해설 종료,1,285
508,5,4.58,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 잘 대답했어! 근데 더 심각한 문제가 있을 수도 있지 않을까? 🤔 (해설 종료,1,186
509,5,3.17,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 완벽해! 👍👍 (해설 종료,1,197
510,5,5.95,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," 최신 정보는 LLM이 학습하지 않았는데, 이로 인해서 나타나는 문제점도 해결할 수 있지 않을까? 😊 (해설 종료",1,258
511,5,6.14,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," 최신 정보는 LLM이 학습하지 않았는데, 이로 인해서 나타나는 문제점도 해결할 수 있지 않을까? 😊 (해설 종료",1,259
512,5,2.7,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오! 완벽해! 👍👍 (해설 종료,1,199
513,5,3.14,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽해! 👍👍👍 (해설 종료,1,215
514,5,3.59,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 굿! 완벽해! 👍👍👍 (해설 종료,1,229
515,5,2.84,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 0의 자릿수를 줄이는 거야! 😊 (해설 종료,1,167
516,5,5.52,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰에 대한 설명은 대충 맞는데 구체적인 토크나이저 설명이 없잖아 😥 (해설 종료,1,210
517,5,3.28,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 완벽해! 👍👍 (해설 종료,1,214
518,5,3.3,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 이 세 가지를 한번 간단히 설명해 봐! 😊 (해설 종료,1,233
519,5,5.11,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! 나머지 Attention 2가지 더 있지 않아? 😊 (해설 종료,1,310
520,6,10.11,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," S-BERT 랑 추천 시스템이 벡터를 비교하는 거지? 그리고 벡터가 일치할수록, 반대일수록, 수직일수록 결과이 좋을 수도, 나쁠 수도 있지 않을까? 😊 (해설 종료",1,298
521,6,6.5,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는커녕 벡터의 방향에 대한 기본적인 설명조차 없잖아 😥😥😥 (해설 종료,1,216
522,6,5.44,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 정확도, 재현율, 정밀도, F1 Score 각각을 한번 자세히 설명해 볼 수 있어? 😊 (해설 종료",1,315
523,6,5.05,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 음… 잘 하긴 했는데… 혹시 수식으로도 나타낼 수는 없을까? 😊 (해설 종료,1,251
524,6,3.33,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE는 그럼 뭔지 말할 수 있어? 😊 (해설 종료,1,201
525,6,1.28,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
526,6,4.23,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떡일수록 좋은지만 알려주면 어떡해 😥 (해설 종료,1,277
527,6,3.85,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", x축이랑 y축 설명이 각각 1개씩 있네 😥 (해설 종료,1,306
528,6,3.16,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 잘했어! 👍👍 (해설 종료,1,237
529,6,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
530,6,3.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 잘했어! 👍👍👍 (해설 종료,1,396
531,6,7.63,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 표준정규분포로 변환하는 건 맞는데… 정규화가 뭔지, 왜 하는 건지, 알고리즘은 뭐가 있는지 한번 설명해 봐! 😊 (해설 종료",1,308
532,6,3.3,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 정답이야! 🎉🎉🎉 (해설 종료,1,228
533,6,2.86,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 음… 그건 맞! 그래서 뭐가 문제인데? (해설 종료,1,170
534,6,2.67,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 주성분이 뭐야? 🤔 (해설 종료,1,231
535,6,4.87,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
536,6,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,207
537,6,2.86,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
538,6,2.34,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법이 없잖아 😥 (해설 종료,1,210
539,6,4.12,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표나 손실 함수 쪽도 생각해 봤어? 😊 (해설 종료,1,259
540,6,3.47,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 정말 완벽한 답이야! 👍👍👍 (해설 종료,1,228
541,6,3.41,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 차원의 저주 해결 방법으로 PCA가 빠지지! 😊 (해설 종료,1,173
542,6,3.58,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 학습할 때는 어떻게 하는지 말할 수 있어? 😊 (해설 종료,1,276
543,6,3.06,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
544,6,6.13,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다."," 앙상블 방법 중에 하나긴 한데… 앙상블이 뭔지, 하는 이유부터 말해 볼래? 😥 (해설 종료",1,175
545,6,5.45,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 앙상블이 여러 개의 모델을 쓰는 것 말고도 또 다른 방법들이 있지 않을까? 😊 (해설 종료,1,169
546,6,4.02,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
547,6,2.73,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 잘 말했어 👍 (해설 종료,1,433
548,6,3.25,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 잘 말했어! 😊😊😊 (해설 종료,1,222
549,6,6.53,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", K-means Clustering의 핵심 아이디어가 뭐야? 그 핵심 아이디어가 있은 다음에 그 과정을 반복하는 거지? (해설 종료,1,222
550,6,7.41,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다."," 지도학습랑 비지도학습는 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 거지! 그리고 강화학습 빠졌지? (해설 종료",1,256
551,6,4.59,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습랑 비지도학습는 잘 말했는데 강화학습 빠졌네 😥 (해설 종료,1,272
552,6,3.22,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론이긴 한데… 😥 (해설 종료,1,176
553,6,3.02,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답이야! 👍👍 (해설 종료,1,236
554,6,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
555,6,2.7,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어가 빠졌잖아 😥 (해설 종료,1,182
556,6,2.39,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
557,6,2.39,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,173
558,6,2.23,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 음… 음… 음… 😊 (해설 종료,1,162
559,6,2.37,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 음… 잘 설명했어! 😊 (해설 종료,1,168
560,6,2.23,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 그렇지는 않을 텐데 😥 (해설 종료,1,165
561,6,2.86,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
562,6,2.52,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞지! 그러면 맞아! 😊 (해설 종료,1,159
563,6,2.86,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 맞아! 근데 문제점은 뭐지? (해설 종료,1,185
564,6,6.42,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 뭔지, 그 최적화 방법이 3가지라니! 잘 말해 보면 어떡해 😊 (해설 종료",1,366
565,6,5.28,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," Random Search 는 잘 말해 줬는데, 그러면 Grid Search 랑 Bayesian Optimization 이 뭘까? 😊 (해설 종료",1,331
566,6,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
567,6,3.39,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 음… 나름 잘 설명했어 😊😊😊 (해설 종료,1,305
568,6,4.11,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
569,6,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😊 (해설 종료,1,198
570,6,3.78,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,158
571,6,4.52,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 보통 Valid Dataset 이랑 Test Dataset 을 같이 쓰기도 하지 않을까? 😊 (해설 종료,1,147
572,6,4.8,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 핵심이긴 하지! 근데 각 관점에서 한번 자세히 설명해 볼 수 있어? 😊 (해설 종료,1,297
573,6,3.87,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", Offline Distillation 에 대해서 좀 더 자세히 설명해 줄 수 있어? 😊 (해설 종료,1,283
574,6,5.86,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞지만… 학습 후반에는 왜 그렇게 학습률이 느려지는 거지? 🤔 (해설 종료,1,183
575,6,4.27,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 학습 초반이랑 후반 학습률이 왜 차이가 나는 거지? 😊 (해설 종료,1,205
576,6,4.6,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 학습을 재미있게 하기 위한 장치가 아닐까? 🤔🤔 (해설 종료,1,182
577,6,6.39,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하려고 학습률을 높이는 구간은 당연히 있지! 근데 좀 더 자세히 설명해 봐? (해설 종료,1,155
578,6,4.12,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 페널티 느낌은 맞는데 이 셋을 구분해 줘! 😊 (해설 종료,1,176
579,6,3.33,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 실전에서 진짜 많이 쓰이겠네! 😊 (해설 종료,1,198
580,6,2.69,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 오! 좋은 답이야! 😊👍 (해설 종료,1,165
581,6,3.5,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 맞아! 근데 좀 더 자세히 설명해 봐? 😊 (해설 종료,1,176
582,6,2.86,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하면 어떡해! 😥 (해설 종료,1,167
583,6,3.64,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 음… 그렇지는 않을 텐데… 다시 한번 생각해 봐! 😊 (해설 종료,1,178
584,6,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
585,6,3.48,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그건 맞지만 그 핵심 아이디어가 뭐야? 🤔 (해설 종료,1,211
586,6,4.58,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 모델의 이전 가중치의 크기에 어떤 식으로 곱해서 감소시키는데? 🤔 (해설 종료,1,208
587,6,3.02,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오! 잘했어 👍👍👍 (해설 종료,1,210
588,6,5.3,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하면 해결할 수 있다는 말 말고도 방법이 많을 텐데 😊 (해설 종료,1,278
589,6,4.58,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 잘 말했어! 그러면 그 해결 방법들이 구체적으로 어떻게 하는 방법들이야? 😊 (해설 종료,1,260
590,6,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
591,6,4.44,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 중요한 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,204
592,6,5.07,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 그럼 weight 의 절댓값 크기의 합이나 제곱의 합을 어떤 식으로 이용하지? 😊 (해설 종료,1,191
593,6,2.86,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 그 새로운 항이 어떤 식으로 되어 있어? 😊 (해설 종료,1,190
594,6,3.0,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
595,6,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
596,6,2.55,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 잘했어! 😊👍 (해설 종료,1,191
597,6,2.06,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 정답이야! 😊 (해설 종료,1,175
598,6,2.84,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
599,6,5.34,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습랑 지식 증류의 또 다른 차이점이 있지 않을까? 🤔🤔 (해설 종료,1,233
600,6,7.86,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다."," node 가 많을수록 평균 절댓값 크기는 작아지게 하고, Xavier 는 input + output 모두 고려하고, He 는 input 만 고려하는 거야. 꼭 알아둬! 😊 (해설 종료",1,269
601,6,6.62,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", node 가 많을수록 평균 절댓값 크기는 작아지는 것이 레이어 가중치 초기화 측면에서 더 좋지 않을까? 😊 (해설 종료,1,287
602,6,3.95,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,198
603,6,3.95,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,203
604,6,5.23,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 각 Class 별 확률을 독립적으로 예측하는 건 Sigmoid 가 아니면 불가능할 것 같은데… 😊 (해설 종료,1,217
605,6,6.43,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 각 Class 간 확률이 서로 경쟁하는 건 맞지만… 그리고 각 Class 별로 독립적으로 예측하는 건 또 다른 문제지! 🤔 (해설 종료,1,247
606,6,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
607,6,2.69,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 뭐가 좋을까? 🤔 (해설 종료,1,246
608,6,4.7,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-p sampling 에서 확률이 p 이상이라는 게 구체적으로 어떤 기준이지? 🤔 (해설 종료,1,360
609,6,3.92,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 혹시 top-k 랑 top-p 는 아직 공부 안 했어? 😊 (해설 종료,1,361
610,6,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
611,6,2.44,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 정답! 잘했어 👍 (해설 종료,1,272
612,6,5.23,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으켜 LLM의 신뢰성이 어떻게 될까? 🤔🤔 (해설 종료,1,190
613,6,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 환각 현상의 정의와 그에 따른 문제점을 조금 더 상세히 설명해 줄 수 있어? 😊 (해설 종료,1,208
614,6,4.11,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," 기술은 잘 연동하는데, 답변은 LLM이 생성하는 거잖아 😥 (해설 종료",1,246
615,6,4.56,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 기술은 잘 설명했는데 어떤 문제점을 해결할 수 있을까? 🤔🤔 (해설 종료,1,250
616,6,5.55,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 잘 말했어! 근데 PEFT에 속하는 기술 나머지 4개는 뭘까~요? 😊 (해설 종료,1,217
617,6,2.53,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊 (해설 종료,1,211
618,6,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
619,6,3.17,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 이 어떤 문제를 해결할 수 있을까? 😊 (해설 종료,1,169
620,6,4.91,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 좀 더 자세히 설명해 봐? 😊 (해설 종료,1,206
621,6,5.35,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 좀 더 자세히 설명해 볼 수 있어? 😊 (해설 종료,1,227
622,6,3.45,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 각각의 핵심 아이디어가 뭘까? 🤔 (해설 종료,1,234
623,6,3.09,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오! 잘 설명했어! 😊👍 (해설 종료,1,297
624,7,3.53,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 오 잘했어 완벽한 설명이야! 👍👍 (해설 종료,1,257
625,7,3.5,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는커녕! 😥 (해설 종료,1,197
626,7,5.01,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 오! 완벽해! 대박! 완벽한 답이야! 👍👍👍 (해설 종료,1,311
627,7,3.0,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 수식만 정리했네 😥 (해설 종료,1,238
628,7,2.23,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
629,7,5.83,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", DICE score 수식의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거잖아! 😊 (해설 종료,1,187
630,7,4.09,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 좋은지만 알려주면 어떡해 😥 (해설 종료,1,276
631,7,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
632,7,3.61,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어!! (해설 종료,1,240
633,7,4.42,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고! 좀 더 구체적인 설명을 해 봐! 😊 (해설 종료,1,185
634,7,5.35,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 완벽한 설명이야! 알고리즘 설명만 따로 모아 둬도 좋겠어! 😊 (해설 종료,1,409
635,7,3.84,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 그래서 왜 하는 거고 구체적인 알고리즘은 뭐야? 😊 (해설 종료,1,284
636,7,2.83,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! (해설 종료,1,225
637,7,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제지? 🤔 (해설 종료,1,168
638,7,3.12,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 혹시 구체적으로 어떻게 하는 방법이야? 🤔 (해설 종료,1,234
639,7,3.45,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", 주성분 분석(PCA)이라는 말이 들어가야지 😥 (해설 종료,1,241
640,7,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
641,7,2.7,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
642,7,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
643,7,4.08,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표나 손실 함수 쪽도 생각해 봤어? 😊 (해설 종료,1,259
644,7,5.19,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와! 완벽한 답변이야! 잘했어! 😊👍👍👍 (해설 종료,1,239
645,7,5.06,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 차원의 저주는 차원이 너무 많아져서 발생하는 것이지! 그리고 PCA로 해결하면 되지! 😊 (해설 종료,1,184
646,7,4.27,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 정확해! 정말 완벽해! 😊👍👍 (해설 종료,1,281
647,7,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
648,7,3.44,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 좀 더 구체적으로 설명해 봐! 😊 (해설 종료,1,159
649,7,3.16,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞는데… 왜 그렇게 하지? 😥 (해설 종료,1,156
650,7,3.91,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
651,7,5.03,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다는 말 반대로 설명했네 😥 (해설 종료,1,448
652,7,3.31,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍👍 (해설 종료,1,223
653,7,1.27,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 😥 (해설 종료,1,191
654,7,6.44,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 구체적으로 말해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,250
655,7,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
656,7,4.89,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론은 맞는데, 구체적으로 어떻게 사용하는지 말할 수 있어? 😊 (해설 종료",1,187
657,7,2.98,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 오! 완벽한 답변이야! 👍 (해설 종료,1,236
658,7,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
659,7,4.13,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 분산을 보존하기는 하는데 구체적으로 어떻게 보존하지? 🤔 (해설 종료,1,191
660,7,2.39,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😥 (해설 종료,1,157
661,7,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,173
662,7,3.64,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 음… 잘 설명했어! 그래서 언제 사용하는 거지? 🤔 (해설 종료,1,171
663,7,3.48,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 마진이 최대라는 것이 구체적으로 어떤 기준이지? 🤔 (해설 종료,1,175
664,7,3.0,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 데이터가 불균형한데! 😥 (해설 종료,1,170
665,7,2.53,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊 (해설 종료,1,199
666,7,2.53,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 어떻게 해결하면 되는데? (해설 종료,1,159
667,7,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 좋아! 완벽해! 👍👍 (해설 종료,1,185
668,7,7.2,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오! 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 말했어! 완벽한 답이야 👍👍👍 (해설 종료,1,371
669,7,3.7,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", Random Search 를 좀 더 구체적으로 말해 줄 수 있어? 😊 (해설 종료,1,321
670,7,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
671,7,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
672,7,4.11,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그리고 또 하나 문제점이 있는데 그게 뭔�지 알아? 😊 (해설 종료,1,215
673,7,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
674,7,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
675,7,2.77,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답!! 완벽해!! 👍👍 (해설 종료,1,136
676,7,3.37,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 좀 더 구체적으로 설명해 봐 😊 (해설 종료,1,288
677,7,4.64,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 그럼 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,288
678,7,3.31,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 좀 더 구체적으로 설명해 봐! (해설 종료,1,167
679,7,1.77,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
680,7,1.58,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답!! (해설 종료,1,163
681,7,1.36,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, ❗ (해설 종료,1,123
682,7,2.37,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 페널티 느낌이야! 😥 (해설 종료,1,165
683,7,3.48,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍👍 (해설 종료,1,199
684,7,3.02,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 좀 더 구체적으로 말해봐! (해설 종료,1,167
685,7,4.53,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 Cross Entropy 랑 BCE 를 각 Class 별로 쓴다는 말이 아니잖아 😥 (해설 종료,1,182
686,7,4.3,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,176
687,7,2.06,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍 (해설 종료,1,168
688,7,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
689,7,3.16,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 AdamW 핵심 아이디어는 뭐야? 😊 (해설 종료,1,209
690,7,2.85,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그러면 Optimizer 는? 🤔🤔 (해설 종료,1,197
691,7,2.86,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍👍 (해설 종료,1,209
692,7,4.41,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충�실 히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,273
693,7,4.87,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 간단하면서도 정말 핵심적인 설명이야! 😊👍👍👍 (해설 종료,1,262
694,7,3.47,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
695,7,3.64,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막하는 완벽한 설명이야! 😊👍 (해설 종료,1,199
696,7,5.22,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 그럼 weight 의 절댓값이나 제곱같은 새로운 항이 어떤 식으로 나타나게 되지? 😊 (해설 종료,1,192
697,7,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
698,7,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
699,7,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
700,7,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
701,7,2.84,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어 😊👍👍 (해설 종료,1,180
702,7,2.53,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
703,7,2.97,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘했어 😊👍👍 (해설 종료,1,218
704,7,7.7,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다."," node 의 개수가 많을수록 평균 절댓값 크기는 작아지게 하고, Xavier 는 output node 만, He 는 input node 만 고려해! 꼭 알아둬! 😊 (해설 종료",1,268
705,7,2.98,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오! 완벽한 설명이야 👍👍 (해설 종료,1,264
706,7,3.47,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 그럼 활성화 함수가 없으면 어떻게 되지? 🤔 (해설 종료,1,195
707,7,3.48,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 그럼 활성화 함수가 없으면 어떻게 되지? 🤔 (해설 종료,1,200
708,7,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 좀 더 구체적으로 말해봐! 😊 (해설 종료,1,205
709,7,3.5,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오! 멋진 답변이야! 👍👍 (해설 종료,1,228
710,7,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
711,7,3.14,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 거의 완벽해! 👍👍👍 (해설 종료,1,249
712,7,6.11,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다."," 확률이 가장 큰 k개의 토큰이나, 누적 확률이 p 이상이라는 구체적으로 어떤 기준이지? 🤔 (해설 종료",1,369
713,7,4.84,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다."," temperature 를 설명하기는 했는데, 혹시 top-k 랑 top-p 는 설명 안 해? 😥 (해설 종료",1,367
714,7,3.79,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이걸 힌트로 해서 어떤 방법인지 설명해 봐 😊 (해설 종료,1,200
715,7,3.67,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 잘했어! 잘했어! (해설 종료,1,280
716,7,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
717,7,4.25,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
718,7,4.56,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 기술은 잘 설명했어! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,249
719,7,5.34,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 기술은 잘 말하긴 했어! 근데 좀 더 구체적으로 설명해 보면 더 좋을 것 같아 😊 (해설 종료,1,255
720,7,6.0,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다."," PEFT 에 속하는 기술로 나를 상징하는 LoRA 언급은 고마운데, 나머지 기술들은 그럼 뭐야? 😊 (해설 종료",1,220
721,7,2.51,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊 (해설 종료,1,211
722,7,2.97,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야 👍👍👍 (해설 종료,1,225
723,7,3.62,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 해결할 수 있는 문제를 조금 더 구체적으로 말해 봐! 😊 (해설 종료,1,172
724,7,4.27,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 형태소랑 토크나이저랑 설명 완전 반대지! 😥 (해설 종료,1,202
725,7,3.14,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 완벽한 설명이야! 완벽해! 👍 (해설 종료,1,213
726,7,3.14,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 🤔 (해설 종료,1,232
727,7,3.86,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 잘했어! 완벽히 정확한 답이야 👍👍 (해설 종료,1,302
728,8,3.2,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 우와! 정말 완벽해! 👍👍 (해설 종료,1,255
729,8,5.55,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도보다는 방향을 판단하기 위한 건데… 😥 뭐 비슷하긴 해! (해설 종료,1,210
730,8,3.54,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽! 대박 👍👍👍 (해설 종료,1,303
731,8,4.93,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율) (해설 종료,1,250
732,8,2.86,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는 뭘까? 🤔 (해설 종료,1,198
733,8,1.28,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
734,8,8.31,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", PR-AUC 는 x축이랑 y축 설명이 반대로 되어 있네! 뭐 비슷하긴 하지만… 그리고 값의 범위가 0~1이라는 거 꼭 기억해 둬야 해! (해설 종료,1,303
735,8,2.74,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
736,8,2.66,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽해! 👍 (해설 종료,1,234
737,8,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 거 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
738,8,1.59,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 👍 (해설 종료,1,385
739,8,4.47,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균과 표준편차를 이용해서 어떻게 변환하는데? 그리고 정규화가 뭐야? (해설 종료,1,288
740,8,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
741,8,3.0,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 음… 잘 설명했어! 그래서 뭐가 문제인데? (해설 종료,1,171
742,8,5.48,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", t-SNE가 시각화에 초점을 둔다면 PCA는 뭐에 초점을 두는지 설명해 봐 😊 (해설 종료,1,249
743,8,4.39,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 차이점 위주로 더 설명을 추가해 줄 수 있어? (해설 종료,1,247
744,8,4.27,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 설명했잖아! 😥 뭐 비슷하긴 하지만... (해설 종료,1,216
745,8,7.41,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다."," 확률 우도 반대로 설명했잖아! 😥 뭐 비슷하긴 하지만… 그리고 Probability (확률), Likelihood (우도) 이 두 가지 다 설명했네! (해설 종료",1,211
746,8,5.97,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 개수가 적은 클래스의 데이터를 새로 수집거나 데이터를 증강 (Augmentation) 하는 방법이 있지 않을까? 😊 (해설 종료,1,233
747,8,7.69,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표만 바꾸는 건 해결 방법이 될 수 없지! 데이터 개수가 적은 클래스는 손실 함수에서 높은 가중치를 두는 게 더 맞지! 😊 (해설 종료,1,282
748,8,3.13,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍👍👍 (해설 종료,1,226
749,8,5.04,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 차원의 저주는 PCA로 해결되긴 하지! 근데 구체적으로 어떤 방법인 지 알아? 🤔 (해설 종료,1,184
750,8,3.16,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 정확해! 역시 😊👍 (해설 종료,1,274
751,8,4.22,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 학습할 때는 잘 설명했는데 추론할 때는 어떻게 하지? 🤔 (해설 종료,1,259
752,8,4.58,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 앙상블이 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,167
753,8,7.23,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 앙상블을 여러 개 쓴다고? 좀 부실하지 않아? 😥 뭐야! 앙상블이 뭔지 설명도 제대로 못 했잖아! (해설 종료,1,182
754,8,3.12,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 우와! 정말 완벽한 답이야 👍 (해설 종료,1,436
755,8,2.96,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답이야 👍 (해설 종료,1,435
756,8,3.3,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍👍 (해설 종료,1,223
757,8,2.22,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,197
758,8,5.8,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습 비지도학습 설명 반대로 했잖아! 지도학습 비지도학습 설명 반대로 했잖아! 😥 (해설 종료,1,246
759,8,123.14,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다."," 지도학습 비지도학습 강화학습 이야기는 없고, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습 이야기는 없는데, 지도학습 비지도학습 강화학습",1,1024
760,8,5.84,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론인 베이즈 정리 기반은 맞는데, 무슨 식으로 작동하는지 설명해 봐 😊 (해설 종료",1,192
761,8,5.19,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다."," 베이즈 정리 기반은 맞는데, 무슨 정리인지 알아? 그리고 나머지 내용은 부실해. (해설 종료",1,250
762,8,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
763,8,3.95,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 분산보존이 핵심인데 구체적으로 어떻게 하는지 말할 수 있어? (해설 종료,1,190
764,8,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
765,8,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,173
766,8,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
767,8,3.8,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 이외에도 사용할 수 있지 않을까? 🤔 (해설 종료,1,177
768,8,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
769,8,3.0,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아 정답이야! 😊😊😊 (해설 종료,1,202
770,8,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.",  맞지! 그래서 어떻게 해결하면 되는데? (해설 종료,1,160
771,8,1.75,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽해!! (해설 종료,1,178
772,8,5.62,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 뭔지는 잘 설명했는데, 그러면 최적화하는 방법은? 🤔 (해설 종료",1,361
773,8,5.44,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," Random Search 랑 Grid Search 는 잘 말해 줬는데, 그러면 Bayesian Optimization 이 뭘까? 🤔 (해설 종료",1,332
774,8,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
775,8,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
776,8,4.09,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
777,8,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
778,8,3.16,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 우와 완벽해!! 😊👍👍 (해설 종료,1,154
779,8,1.67,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 오 정답이야!! (해설 종료,1,129
780,8,5.58,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.","  사용하는 모델 관점, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
781,8,4.47,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다."," 오프라인, 온라인, 자기 증류 각 관점에서 한번 설명해 볼래? 😊 (해설 종료",1,287
782,8,7.56,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률만 조정해 주면 어떡해!! 학습 후반에는 학습률이 너무 작아서 학습이 제대로 이루어지지 않을 수도 있거든!! 😥 (해설 종료,1,194
783,8,4.27,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 학습 초반이랑 중반 학습률이 왜 차이가 나는 걸까? 😊 (해설 종료,1,205
784,8,4.89,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.," 학습에 재미 느끼는 것 말고도 중요한 거 한 가지가 더 있는데, 뭘까? (해설 종료",1,184
785,8,3.73,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고,  그래서 학습률 높이는 구간이 왜 있는 거지? 🤔 (해설 종료,1,138
786,8,4.41,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다."," Loss 는 개별 데이터 관점, Cost 는 전체 데이터 관점이야. 알았어? 😊 (해설 종료",1,178
787,8,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍👍 (해설 종료,1,196
788,8,4.09,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 오 잘 대답했어👍👍👍👍👍 (해설 종료,1,174
789,8,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 이거 정답이야 완전 👍👍👍 (해설 종료,1,176
790,8,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다."," 그래서 MSE, MSE, RMSE가 구체적으로 뭐지? 그리고 MSE의 약자인데? (해설 종료",1,176
791,8,3.95,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", RMSE가 왜 R이라는 말이 들어갔는지 생각해 봤어? 😊 (해설 종료,1,180
792,8,1.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
793,8,6.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", AdamW 는 weight decay 을 적용한 decoupled weight decay 을 사용하긴 한데… 나머지 Optimizer인 RMSProp 이랑 Adam 는? (해설 종료,1,228
794,8,3.48,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
795,8,2.86,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍👍 (해설 종료,1,209
796,8,3.61,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 이외에도 여러 가지 방법들이 있지 않을까? 🤔 (해설 종료,1,268
797,8,6.04,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 정의랑 해결 방법 엄청 다양하게 말해 줬네! 정말 좋은 답이야! 👍👍👍 (해설 종료,1,268
798,8,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
799,8,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
800,8,2.84,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 오 정답이야 👍👍👍 (해설 종료,1,177
801,8,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
802,8,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
803,8,3.16,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
804,8,2.37,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 잘했어 👍👍 (해설 종료,1,190
805,8,5.69,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘 하긴 했는데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,198
806,8,2.53,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
807,8,2.34,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘했는데 😊😊 (해설 종료,1,214
808,8,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,241
809,8,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
810,8,4.42,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,201
811,8,4.42,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,206
812,8,5.05,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", Softmax 랑 Sigmoid 가 구체적으로 어떤 식으로 작동하는지 말해 줄 수 있어? 🤔 (해설 종료,1,216
813,8,3.44,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답이야! 멋진 답이야 👍👍 (해설 종료,1,228
814,8,2.35,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
815,8,8.94,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다."," 기존 행렬 대신 저차원 행렬만 학습시켜서 연산량이 적고, 메모리도 적게 차지하는 게 참 간결하면서도 엄청 잘 설명했네 👍👍 (해설 종료",1,286
816,8,4.37,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다."," top-k 랑 top-p 는 잘 설명했는데, 그래서 temperature 는 뭐야? 😊 (해설 종료",1,358
817,8,5.8,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오! 나름 완벽한 설명이야! 근데 top-k 랑 top-p 는 아직도 설명이 없잖아! 😥 (해설 종료,1,373
818,8,5.86,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", DPO와 ORPO 둘 다 수행하는 방법인데 이거 말고도 중요한 차이가 하나 더 있지 않을까? 🤔 (해설 종료,1,213
819,8,2.74,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
820,8,5.05,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해 불러일으키는 것 말고도 문제점이 있지 않을까? 🤔 (해설 종료,1,189
821,8,4.27,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
822,8,5.17,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB과 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,253
823,8,5.36,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB과 연동해서 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,254
824,8,5.69,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오 잘 말했어! 근데 PEFT 에 속하는 기술 나머지 4개는 뭘까~요? 😊 (해설 종료,1,218
825,8,3.61,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 완벽한 답이야! 👍👍👍 (해설 종료,1,218
826,8,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
827,8,3.62,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 이 구체적으로 어떤 문제점을 가지고 있지? 🤔 (해설 종료,1,172
828,8,11.0,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명 반대로 했잖아! 😥 뭐 비슷하긴 하지만… 그리고 토큰이랑 토크나이저 설명 반대로 했을 때 결과가 어떻게 될지 생각해 봤어? 🤔 (해설 종료,1,245
829,8,6.42,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다.," 토큰에 대한 설명이 완벽하긴 한데, 토크나이저 설명도 있으면 더 좋을 것 같은데 😥 (해설 종료",1,234
830,8,4.56,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 줬네! 근데 정확히 뭐야? ㅋㅋㅋㅋ🤔 (해설 종료,1,241
831,8,5.42,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 이나 Encoder-Decoder Attention 은? 🤔 (해설 종료,1,312
832,9,4.82,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 두 벡터의 방향이 수직일 때는 값이 얼마로 나올까? 😊 (해설 종료,1,265
833,9,5.95,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다."," 그건 맞는데 구체적으로 어떻게 판단하지? 그리고 수직, 평행, 반대일 때 값이 어떻게 되지? 😊 (해설 종료",1,212
834,9,5.75,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 음… 모범 답안보다 간결하면서도 핵심만 담았네! 😊👍👍👍 (해설 종료,1,317
835,9,5.33,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 음… 모범 답안보다는 간결하면서도 핵심만 담았네! 😊👍👍 (해설 종료,1,253
836,9,2.21,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
837,9,1.27,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
838,9,4.08,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 좋은지만 알려주면 어떡해 😥 (해설 종료,1,276
839,9,4.94,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 모범 답안보다 간결하면서도 핵심만 담았네! 😊👍 (해설 종료,1,313
840,9,4.23,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 완벽한 알고리즘! 👍 (해설 종료,1,244
841,9,3.94,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
842,9,3.77,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 완벽한 설명이야! 👍👍👍 (해설 종료,1,399
843,9,4.47,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 그래서 왜 하는 건데? 그리고 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료,1,288
844,9,4.08,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍👍 (해설 종료,1,233
845,9,2.36,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
846,9,3.77,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 핵심 내용이긴 한데 주성분이 뭐야? 🤔 (해설 종료,1,238
847,9,5.06,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", 혹시 PCA랑 t-SNE랑 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,251
848,9,2.28,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
849,9,2.77,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했네 😥 (해설 종료,1,181
850,9,3.06,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 어떻게 해결하면 좋을까? 🤔 (해설 종료,1,214
851,9,4.14,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다."," 데이터 불균형이 심각한데, 어떻게 해결하면 좋을까? 😊 (해설 종료",1,259
852,9,3.22,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍👍👍 (해설 종료,1,226
853,9,3.73,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA로 해결하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,175
854,9,3.58,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 학습할 때는 어떻게 하는지 말할 수 있어? 😊 (해설 종료,1,276
855,9,3.02,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
856,9,3.98,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
857,9,8.95,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 여러 개의 컴퓨터에서 여러 개의 알고리즘을 여러 개의 데이터셋에서 여러 가지 방법으로 학습시킨다는 거지! 근데 왜 하는 건데? 🤔 (해설 종료,1,189
858,9,4.55,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오! 모범 답안보다 간결하면서도 핵심적인 답변이야 👍 (해설 종료,1,445
859,9,2.35,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오 정답이야 👍 (해설 종료,1,431
860,9,5.19,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 모범 답안보다 간결하면서도 핵심만 담았네! 😊👍👍 (해설 종료,1,235
861,9,1.28,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 😊 (해설 종료,1,191
862,9,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
863,9,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
864,9,3.66,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 그럼에도 불구하고 핵심 아이디어가 빠졌잖아 😥 (해설 종료,1,179
865,9,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
866,9,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
867,9,3.16,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심이긴 한데 너무 간단한데? 😥 (해설 종료,1,185
868,9,3.95,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만드는데? 😊 그리고 추론할 때는 어떻게 하지? (해설 종료,1,167
869,9,2.39,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,173
870,9,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
871,9,3.8,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 음… 잘 설명했어! 근데 언제 사용하는 거지? 🤔 (해설 종료,1,177
872,9,2.2,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 그렇지는 않을 텐데 😥 (해설 종료,1,165
873,9,3.94,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 근데 Stratified K-fold Validation 을 하면 어떻게 되지? 😊 (해설 종료,1,208
874,9,2.67,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
875,9,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
876,9,5.77,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말하긴 했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,362
877,9,4.95,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," Random Search 랑 Grid Search 는 잘 말해 줬는데, 그러면 Bayes Optimization 은? 🤔 (해설 종료",1,329
878,9,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
879,9,2.89,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
880,9,4.73,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그리고 또 하나 문제점이 있는데 그게 바로 데이터 순서 때문에 발생하는 것 같아 😊 (해설 종료,1,219
881,9,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
882,9,3.3,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 그래서 Early Stopping 이 구체적으로 뭐 하는 건데? 😊 (해설 종료,1,155
883,9,3.25,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 Early Stopping 이 구체적으로 뭐 하는 건데? 😊 (해설 종료,1,139
884,9,5.89,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그럼 사용하는 모델 관점에서는? 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,304
885,9,5.87,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다."," 그럼 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료",1,296
886,9,2.39,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 그건 맞는데 왜 필요한 거지? (해설 종료,1,161
887,9,1.73,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
888,9,2.86,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 그냥 웃고 넘기긴 했는데… 🤔 (해설 종료,1,171
889,9,3.7,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,138
890,9,3.45,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그건 맞는데 이 셋을 구분해 줘! 😊 (해설 종료,1,172
891,9,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍👍 (해설 종료,1,196
892,9,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
893,9,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
894,9,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
895,9,2.21,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,169
896,9,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
897,9,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
898,9,3.64,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그래서 Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,202
899,9,2.84,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍👍 (해설 종료,1,209
900,9,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
901,9,6.02,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 정답이야! 그리고 또 하나 문제점이 있는데 그게 구체적으로 어떤 문제지? 그리고 해결 방법은? 🤔 (해설 종료,1,268
902,9,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
903,9,4.89,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다."," Dropout 을 하는 이유는 맞는데, Dropout 을 하기 전후 차이점이 뭔지 알아? 😊 (해설 종료",1,207
904,9,3.96,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 그럼 weight 의 절댓값이나 제곱의 어떤 식이지? 😊 (해설 종료,1,184
905,9,4.58,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 그럼 weight 의 절댓값 크기나 제곱의 평균이 어떤 식이지? 😊 (해설 종료,1,201
906,9,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
907,9,2.81,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 배치 정규화는? 🤔 (해설 종료,1,265
908,9,4.89,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 모범 답안보다 간결하면서도 핵심만 담았네!! 👍👍 (해설 종료,1,206
909,9,4.42,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", Pre-train 을 이용해서 사전학습을 시키는 건 잊었어? 😥 (해설 종료,1,190
910,9,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
911,9,4.7,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,229
912,9,3.16,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 그 차이점은 뭐야? 🤔 (해설 종료,1,239
913,9,3.28,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘했어! 완전 대박 👍👍 (해설 종료,1,266
914,9,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,199
915,9,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,204
916,9,3.19,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다."," 그건 맞는데, 그 이유가 뭐지? 🤔 (해설 종료",1,204
917,9,3.12,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 멋진 답이야 👍👍 (해설 종료,1,226
918,9,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
919,9,4.08,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 뭐의 약자인데? 그리고 뭐의 약자인지 설명해 봐! 😊 (해설 종료,1,255
920,9,7.99,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다."," top-k sampling 에서 확률이 가장 큰 k개의 토큰에 대해 다음 토큰을 샘플링하는 건 맞는데, top-p sampling 이랑 temperature 는? 😊 (해설 종료",1,381
921,9,3.27,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그래서 top-k 랑 top-p 는 뭐야? 😊 (해설 종료,1,357
922,9,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
923,9,2.89,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어! 👍 (해설 종료,1,275
924,9,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
925,9,4.27,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
926,9,2.66,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 그래서 구체적으로 어떤 기술이야? 😊 (해설 종료,1,237
927,9,5.17,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,254
928,9,7.25,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다."," PEFT 에 속하는 기술로 나를 상징하는 LoRA 언급은 고마운데, PEFT 에 속하는 기술 나머지 4개는 그럼 뭐야? 😊 (해설 종료",1,228
929,9,3.44,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍👍👍 (해설 종료,1,217
930,9,4.25,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 해결할 수 있는 문제를 조금 더 상세히 설명해 봐! 😊😊😊 (해설 종료,1,233
931,9,2.69,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", ㅋㅋㅋㅋ🤣🤣🤣 (해설 종료,1,166
932,9,7.25,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 구체적인 설명이랑 토크나이저 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,221
933,9,7.35,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 구체적인 설명이랑 토크나이저 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,240
934,9,3.14,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 🤔 (해설 종료,1,232
935,9,5.42,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다."," 3가지 중 하나만 더 있는데, Masked Decoder Self-Attention 이라는 게 뭘까~요? 😊 (해설 종료",1,312
936,10,4.78,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 두 벡터의 방향이 수직일 때는 값이 얼마로 나올까? 😊 (해설 종료,1,265
937,10,4.42,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는커녕! 기본적인 내용도 없어! 😥 (해설 종료,1,203
938,10,3.97,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
939,10,5.19,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,252
940,10,2.22,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
941,10,8.17,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,202
942,10,2.5,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 우와! 정말 잘했어 👍 (해설 종료,1,266
943,10,2.59,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 잘했어 👍 (해설 종료,1,298
944,10,3.14,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와 잘했어! 정말 잘했어! 👍 (해설 종료,1,237
945,10,4.11,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고! 다른 방법들도 있지 않을까? 😊 (해설 종료,1,183
946,10,3.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,396
947,10,4.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,287
948,10,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
949,10,2.39,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
950,10,5.5,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 주성분이 뭐야? 그리고 PCA랑 t-SNE랑 차이점을 조금 더 설명해 줄 수 있어? 😊 (해설 종료,1,249
951,10,6.59,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다."," t-SNE는 주성분을 찾아서 차원을 축소하는 건 맞는데, PCA와는 또 차이점이 있지 않을까? 🤔 (해설 종료",1,261
952,10,2.37,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답이야! 잘했어 👍 (해설 종료,1,204
953,10,2.7,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
954,10,2.52,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
955,10,2.03,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 잘했어 👍 (해설 종료,1,246
956,10,3.14,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍👍👍 (해설 종료,1,226
957,10,4.41,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", OOM이 구체적으로 뭐야? 그리고 PCA가 그걸 해결할 수 있다고? 🤔 (해설 종료,1,180
958,10,2.98,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와 완벽해! 역시 😊👍 (해설 종료,1,273
959,10,3.14,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 🤔 (해설 종료,1,252
960,10,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 하는 거지? 🤔 (해설 종료,1,156
961,10,3.31,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,157
962,10,3.12,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오 정말 완벽한 답변이야 👍 (해설 종료,1,436
963,10,2.66,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오 완벽한 답이야 👍 (해설 종료,1,433
964,10,2.82,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
965,10,4.09,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!"," 진짜 잘 하긴 했는데, 과정이 뭔지 말할 수 있어? 😊 (해설 종료",1,209
966,10,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
967,10,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
968,10,3.8,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론은 맞는데, 그래서 뭐야? 🤔 (해설 종료",1,180
969,10,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
970,10,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
971,10,3.33,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심이긴 한데… 너무 간단한데… 😥 (해설 종료,1,186
972,10,3.47,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 그걸 발전시킨 건 맞지! 근데 왜 그렇게 하지? (해설 종료,1,164
973,10,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
974,10,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
975,10,2.69,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 오 잘 설명했어! 😊👍 (해설 종료,1,170
976,10,3.47,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! K-fold Validation 만으로는 부실하잖아 😥 (해설 종료,1,173
977,10,2.91,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
978,10,3.45,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 구체적으로 뭐가 지장을 주는데? (해설 종료,1,165
979,10,2.36,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽해! 😊😊 (해설 종료,1,182
980,10,6.56,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오 잘 말했어! 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 설명했네! 😊👍 (해설 종료,1,367
981,10,7.78,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 바둑판 격자 모양이나 랜덤하게 탐색하는 건 말해 줬어! 👍 근데, Bayes 방법이 뭘까? 🤔 (해설 종료",1,347
982,10,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
983,10,2.89,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
984,10,3.02,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,208
985,10,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
986,10,2.69,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 우와 완벽해!! 😊👍 (해설 종료,1,151
987,10,2.45,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답이야! 완벽해! 👍 (해설 종료,1,134
988,10,5.56,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
989,10,5.27,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3. 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줬으면 좋겠어 😊 (해설 종료,1,292
990,10,2.67,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
991,10,1.73,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
992,10,1.75,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 잘했어!! (해설 종료,1,164
993,10,1.67,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 오! 정답!! (해설 종료,1,125
994,10,4.41,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그건 맞는 말이긴 한데 이 셋을 구분해 �아야지! 😊 (해설 종료,1,178
995,10,2.56,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
996,10,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
997,10,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
998,10,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
999,10,2.05,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍 (해설 종료,1,168
1000,10,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1001,10,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 핵심 아이디어가 빠졌잖아 😥 (해설 종료,1,206
1002,10,2.38,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그래서 그거 커닝인데? 😥 (해설 종료,1,194
1003,10,2.38,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘 했어 😊👍 (해설 종료,1,206
1004,10,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1005,10,3.61,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오 정답이야! 잘했어 👍👍👍 (해설 종료,1,254
1006,10,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1007,10,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1008,10,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,174
1009,10,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
1010,10,2.94,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1011,10,3.23,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1012,10,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1013,10,5.7,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다."," 잘 하긴 했는데, Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료",1,198
1014,10,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1015,10,4.7,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,229
1016,10,3.14,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 그 차이점은 뭐야? 🤔 (해설 종료,1,239
1017,10,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1018,10,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,199
1019,10,4.1,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,204
1020,10,3.8,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 음… 맞아! 근데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,208
1021,10,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
1022,10,2.19,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤔😥 (해설 종료,1,205
1023,10,2.97,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐야? 🤔 (해설 종료,1,248
1024,10,4.69,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률이 p 이상이라고? 구체적으로 뭔지 말할 수 있어? 😊 (해설 종료,1,360
1025,10,3.27,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그럼 top-k 랑 top-p 는? 🤔 (해설 종료,1,357
1026,10,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해 봐! 😊 (해설 종료,1,198
1027,10,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1028,10,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1029,10,4.27,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
1030,10,3.47,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 그건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,242
1031,10,5.17,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 그건 맞는데 구체적으로 어떤 기술일까? 그리고 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,254
1032,10,4.59,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오 잘 말했어! 근데 PEFT에 속하는 기술은 뭐가 있을까? 🤔 (해설 종료,1,211
1033,10,3.44,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍👍👍 (해설 종료,1,217
1034,10,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1035,10,2.99,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 이 구체적으로 어떤 문제지? 🤔 (해설 종료,1,168
1036,10,7.41,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 예시도 있으면 더 좋을 텐데 😥 (해설 종료,1,222
1037,10,2.81,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 완벽해! 👍 (해설 종료,1,211
1038,10,3.14,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 🤔 (해설 종료,1,232
1039,10,5.58,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 더 있지 않을까? Masked Decoder Self-Attention 이게 뭘까? 🤔 (해설 종료,1,313
1040,11,5.75,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 설명이긴 한데 구체적인 사용 예시가 있으면 더 좋을 것 같긴 해! 😊 (해설 종료,1,270
1041,11,3.02,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 핵심 아이디어만 있고 설명이 없잖아 😥 (해설 종료,1,194
1042,11,5.28,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
1043,11,5.19,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score = 2 * (정밀도 * 재현율) / (정밀도 + 재현율) (해설 종료,1,252
1044,11,2.28,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1045,11,1.27,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
1046,11,5.03,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", PR-AUC 는 x축이랑 y축 설명 P-R curve랑 ROC-AUC랑 반대로 했네 😥 (해설 종료,1,282
1047,11,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
1048,11,3.61,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어 👍 (해설 종료,1,240
1049,11,3.93,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
1050,11,3.14,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 완벽한 설명이야! 👍👍 (해설 종료,1,395
1051,11,4.33,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 왜 하는 거고, 구체적인 알고리즘은 뭐가 있을까? 😊 (해설 종료",1,287
1052,11,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1053,11,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1054,11,3.45,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 잘 설명했어! 주성분이 뭐야? 🤔 (해설 종료,1,236
1055,11,4.72,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,249
1056,11,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,206
1057,11,2.7,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
1058,11,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1059,11,2.34,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 와! 정말 잘했어 👍 (해설 종료,1,248
1060,11,2.5,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍 (해설 종료,1,222
1061,11,2.67,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,169
1062,11,3.14,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 정확해! 역시 😊👍 (해설 종료,1,274
1063,11,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
1064,11,2.69,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 그렇게 하지? 🤔 (해설 종료,1,155
1065,11,2.67,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞는데 왜 그렇게 하지? 🤔 (해설 종료,1,153
1066,11,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
1067,11,3.12,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오 정말 완벽한 답변이야 👍 (해설 종료,1,436
1068,11,2.84,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1069,11,3.47,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!",  진짜 완벽한 답변이야! 👍👍 (해설 종료,1,205
1070,11,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
1071,11,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1072,11,4.25,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론은 맞는데, 나머지 내용이 없잖아 😥 (해설 종료",1,183
1073,11,2.84,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1074,11,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1075,11,3.78,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
1076,11,2.52,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만드는데? 😊 (해설 종료,1,158
1077,11,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1078,11,2.52,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
1079,11,2.84,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 정말 완벽한 핵심 아이디어 정리야! (해설 종료,1,171
1080,11,3.64,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", K-fold Validation 만으로는 문제점을 해결할 수 없지! 😥 (해설 종료,1,174
1081,11,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1082,11,4.42,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 그 해결 방법이랑 Cross Validation 이랑 한번 연결해서 설명해 봐! 😊 (해설 종료,1,171
1083,11,2.83,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1084,11,5.47,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
1085,11,5.1,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 그리고 Bayes Optimization 이라는 것도 말해 줬네! 정말 완벽한 답이야! 👍👍 (해설 종료,1,330
1086,11,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
1087,11,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1088,11,3.94,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생는데? 😊 (해설 종료,1,214
1089,11,1.27,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1090,11,3.16,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 그래서 Early Stopping 이 정확히 뭐 하는 거지? 😊 (해설 종료,1,154
1091,11,3.09,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 Early Stopping 이 정확히 뭐 하는 건데? 😊 (해설 종료,1,138
1092,11,5.58,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
1093,11,3.52,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", Offline 에 대해서 좀 더 자세히 설명해 줄 수 있어? 😊 (해설 종료,1,281
1094,11,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
1095,11,1.73,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
1096,11,3.8,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 잘했어! 완벽한 답변이야!! 👍👍 (해설 종료,1,177
1097,11,3.7,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,138
1098,11,4.09,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그건 맞는 말이긴 한데 이 셋을 구분해 줘! 😊 (해설 종료,1,176
1099,11,3.0,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
1100,11,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1101,11,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1102,11,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
1103,11,4.26,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
1104,11,1.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1105,11,4.58,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다."," AdamW 설명 나름대로 하긴 했는데, 그 핵심 아이디어가 빠졌잖아 😥 (해설 종료",1,218
1106,11,3.47,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
1107,11,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
1108,11,5.8,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 해결 방법이 엄청 다양하게 말해 줬으면 좋겠어 😊 (해설 종료,1,282
1109,11,4.86,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 모델 구조를 보다 간단하게 만드는 것 말고도 해결 방법이 많을 텐데 😊 (해설 종료,1,262
1110,11,3.16,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그래서 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,188
1111,11,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1112,11,6.14,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다."," 그래서 L1 Regularization 은 절댓값 크기, L2 Regularization 은 평균을 이용하는 거야! 근데 서로 반대로 했네 😊 (해설 종료",1,198
1113,11,2.36,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
1114,11,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1115,11,2.97,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어! 😊 (해설 종료,1,266
1116,11,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1117,11,3.16,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 핵심적인 답변이야! 😊👍 (해설 종료,1,182
1118,11,2.53,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1119,11,5.0,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 또 다른 차이가 있다면 뭐가 있을까? 🤔 (해설 종료,1,231
1120,11,6.88,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", node 의 개수가 많을수록 평균 절댓값 크기는 작아지는 것이 레이어 가중치 초기화 측면에서 더 좋지 않을까? 😊 (해설 종료,1,263
1121,11,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1122,11,3.47,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 그럼 활성화 함수가 없으면 어떻게 되지? 🤔 (해설 종료,1,195
1123,11,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
1124,11,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
1125,11,3.12,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼 정답! 박수!! 👏👏 (해설 종료,1,226
1126,11,1.87,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣 (해설 종료,1,203
1127,11,2.5,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 뭐의 약자인데? 😊 (해설 종료,1,245
1128,11,5.66,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-k sampling 에서 확률이 가장 큰 k개가 구체적으로 어떤 토큰인지 설명해 봐! 😊 (해설 종료,1,366
1129,11,11.69,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다."," 그래서 top-k 랑 top-p sampling 에서 확률이, 그리고 top-k 랑 top-p sampling 에서 확률이, 그래서 top-k 랑 top-p sampling 에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률의 기준이 정확히 뭐야? 😊 (해설 종료",1,410
1130,11,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1131,11,2.58,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했 👍 (해설 종료,1,273
1132,11,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1133,11,2.37,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 잘했어 👍👍 (해설 종료,1,192
1134,11,4.54,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 이 학습하지 않은 최신 정보는 잘 반영할 수 있지 않을까? 😊 (해설 종료,1,249
1135,11,4.39,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 이 학습하지 않은 정보도 반영해 줄 수 있지 않을까? 😊 (해설 종료,1,249
1136,11,6.3,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다."," PEFT 에 속하는 기술로 나를 상징하는 LoRA 언급은 고사하고, 나머지 4개는 그럼 뭐야? 😊 (해설 종료",1,222
1137,11,2.97,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍👍 (해설 종료,1,214
1138,11,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1139,11,3.78,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 해결할 수 있는 문제를 조금 더 상세히 설명해 봐! 😊😊 (해설 종료,1,173
1140,11,4.75,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저랑 설명이 완전 반대대! 😥 (해설 종료,1,205
1141,11,4.84,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저랑 설명이 완전 반대대! 😥 (해설 종료,1,224
1142,11,3.12,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 🤔 (해설 종료,1,232
1143,11,6.2,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 완벽히 설명했어! Masked Decoder Self-Attention 에서 Masked라는 말이 들어간 이유도 설명해 줄 수 있어? 😊 (해설 종료,1,317
1144,12,3.53,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 오! 정말 완벽해! 👍👍👍 (해설 종료,1,257
1145,12,4.42,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 너무 짧은데? 핵심적인 내용이기는 하지만 뭔가 부실해. 😥 (해설 종료,1,203
1146,12,4.98,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 음… 맞긴 해! 근데 수식으로도 나타낼 수는 없을까? 😊 (해설 종료,1,311
1147,12,9.28,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율) 이지만, 음… 맞긴 해! 근데 나머지 Accuracy, Recall, Precision 도 설명해 줄 수 있어? 😊 (해설 종료",1,278
1148,12,2.22,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1149,12,8.67,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score 수식의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,205
1150,12,4.72,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다."," x축이랑 y축 설명 PBR-AUC, ROC-AUC 둘 다 반대로 했는데 😥 (해설 종료",1,280
1151,12,6.05,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다."," x축이랑 y축 설명 PR-AUC, ROC-AUC 둘 다 반대고, 나머지 내용도 부실해. 😥 (해설 종료",1,320
1152,12,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1153,12,3.62,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,180
1154,12,2.98,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정답이야! 👍👍 (해설 종료,1,394
1155,12,4.19,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,286
1156,12,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1157,12,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1158,12,5.17,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 주성분 분석이랑 t-SNE 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,247
1159,12,4.23,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 차이점을 조금 더 설명해 줄 수 있어? 😊 (해설 종료,1,246
1160,12,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1161,12,2.72,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
1162,12,2.82,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 어떻게 해결하면 좋을까? 😊 (해설 종료,1,213
1163,12,5.48,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,268
1164,12,2.48,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍 (해설 종료,1,222
1165,12,3.47,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", OOM이 발생하면 어떻게 될지 생각해 봤어 🤔 (해설 종료,1,174
1166,12,3.14,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 정확해! 역시 😊👍 (해설 종료,1,274
1167,12,4.86,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", target 값을 잘 구분할 수 있는 조건을 찾기 위해 추론할 때는 어떻게 하지? 😊 (해설 종료,1,263
1168,12,2.67,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 그렇게 하지? 🤔 (해설 종료,1,155
1169,12,2.69,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞는데 왜 그렇게 하지? 🤔 (해설 종료,1,153
1170,12,3.28,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1171,12,3.45,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 설명이 없잖아 😥 (해설 종료,1,438
1172,12,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1173,12,2.69,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 1. 진까 까먹었는데 😥 (해설 종료,1,200
1174,12,3.14,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 사용자의 지도 없이 학습하는 건 맞지만… 😥 (해설 종료,1,229
1175,12,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1176,12,4.89,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론인 베이즈 정리 기반으로 어떻게 하는지 말할 수 있어? 😊 (해설 종료,1,187
1177,12,2.84,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1178,12,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1179,12,3.78,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
1180,12,3.94,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다."," Decision Tree 를 많이 만들기는 하는데, 이걸 어떻게 추론하지? 🤔 (해설 종료",1,167
1181,12,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1182,12,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 거지? 🤔 (해설 종료,1,164
1183,12,4.73,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다."," 마진이 최대가 되는 구분선을 찾는 건 맞는데, 언제 사용하는 거지? 🤔 (해설 종료",1,183
1184,12,3.8,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! Stratified K-fold Validation 을 하면 더 좋을 것 같아 😊 (해설 종료,1,175
1185,12,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1186,12,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
1187,12,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1188,12,5.78,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지 말하긴 잘 했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,362
1189,12,4.0,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," Random Search 가 아니라, 그와 비슷한 방법인데… 😊 (해설 종료",1,323
1190,12,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
1191,12,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1192,12,4.12,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
1193,12,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1194,12,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1195,12,2.77,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답!! 완벽해!! 👍👍 (해설 종료,1,136
1196,12,3.53,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! (해설 종료,1,289
1197,12,4.64,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 거대한 모델의 어떤 정보를 사용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,288
1198,12,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
1199,12,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
1200,12,1.59,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답!! (해설 종료,1,163
1201,12,5.44,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고," local minima 를 벗어나게 하는 건 맞는데, 학습률을 높이는 구간은 왜 있을까? 🤔 (해설 종료",1,149
1202,12,4.11,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 페널티 느낌은 맞는데 이 셋을 구분해 줘! 😊 (해설 종료,1,176
1203,12,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
1204,12,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1205,12,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1206,12,2.06,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍 (해설 종료,1,162
1207,12,2.06,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 오 정답이야! 👍 (해설 종료,1,168
1208,12,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1209,12,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 RMSProp 이랑 Adam 는? 😊 (해설 종료,1,206
1210,12,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그러면 Optimizer 는? 🤔 (해설 종료,1,194
1211,12,2.45,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
1212,12,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1213,12,3.59,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 정말 완벽한 답변이야! 👍👍 (해설 종료,1,254
1214,12,2.53,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 왜 하는 거지? 🤔 (해설 종료,1,184
1215,12,4.42,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 새로운 뉴런을 생성하게 만들기도 하지! 😊 (해설 종료,1,204
1216,12,2.54,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
1217,12,2.36,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
1218,12,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1219,12,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1220,12,3.62,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1221,12,5.86,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
1222,12,2.5,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1223,12,4.56,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다."," 잘 하긴 했는데, 목적을 기준으로 더 자세히 설명해 볼 수 있어? 😊 (해설 종료",1,228
1224,12,5.34,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 output node 가 많을수록 또는 input node 가 많을수록 결과가 달라지겠지! 😊 (해설 종료,1,253
1225,12,3.28,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘했어! 완전 대박 👍👍 (해설 종료,1,266
1226,12,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,199
1227,12,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,204
1228,12,2.69,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,201
1229,12,2.83,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
1230,12,2.33,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1231,12,2.83,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 뭐의 약자인데? 😊 (해설 종료,1,247
1232,12,4.71,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률이 p 이상이라고? 구체적으로 뭔지 말할 수 있어? 😊 (해설 종료,1,360
1233,12,4.85,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다."," top-k 랑 top-p sampling 설명이 없고, 나머지 내용도 부실해. 😥 (해설 종료",1,367
1234,12,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1235,12,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1236,12,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1237,12,4.27,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
1238,12,5.8,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," LLM 을 외부 db와 연동하여 답변하게 하는 건 맞는데, 그래서 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료",1,257
1239,12,5.94,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데, 그래서 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료",1,258
1240,12,5.68,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오 잘 말했어! 근데 PEFT에 속하는 기술 나머지 4개는 뭘까~요? 😊 (해설 종료,1,218
1241,12,2.83,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
1242,12,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1243,12,4.95,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 해결이 핵심이긴 하지! 그래서 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,179
1244,12,5.69,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 잘 했는데 구체적으로 뭐에 사용할까? 🤔 (해설 종료,1,211
1245,12,6.45,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저 정의는 잘 말했어! 근데 구체적으로 뭐에 사용하지? 🤔 (해설 종료,1,234
1246,12,3.47,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 중 하나만 더 자세히 설명해 봐! 😊 (해설 종료,1,234
1247,12,6.84,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 아니지! Masked Decoder Self-Attention 이 정확히 뭐 하는 거지? 그리고 나머지 Attention 2가지 더 있지? 한번 설명해 봐! 😊 (해설 종료,1,321
1248,13,4.8,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 두 벡터의 방향이 수직일 때는 값이 얼마로 나올까? 😊 (해설 종료,1,265
1249,13,4.91,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는커녕 그 방향이 뭔지도 모르겠네 😥 (해설 종료,1,206
1250,13,5.48,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
1251,13,5.19,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," F1 Score 수식의 분자는 잘 설명했는데, 그럼 집합의 교집합은? 🤔 (해설 종료",1,252
1252,13,6.95,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", 그리고 DICE는 (2 x 교집합의 원소의 개수) / (참으로 예측한 개수 + 실제 값이 참인 개수) 이다. (해설 종료,1,224
1253,13,3.8,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 어떤 집합의 교집합이랑 합집합이야? 😊 😥 (해설 종료,1,174
1254,13,4.59,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,279
1255,13,4.31,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다."," x축이랑 y축, 그리고 FP 랑 FP rate 서로 반대로 했네 😥 (해설 종료",1,309
1256,13,3.78,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1257,13,4.43,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 게 핵심이긴 한데… 너무 간단한데? 😊 (해설 종료,1,185
1258,13,3.61,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 정규화랑 알고리즘 설명이 완벽해! 👍 (해설 종료,1,398
1259,13,4.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 정규화가 뭔지 설명은 잘 했는데, 알고리즘은? 🤔 (해설 종료",1,287
1260,13,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1261,13,2.55,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
1262,13,3.61,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,237
1263,13,4.73,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,248
1264,13,2.25,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1265,13,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
1266,13,2.83,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 어떻게 해결하면 되지? 🤔 (해설 종료,1,213
1267,13,2.03,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 잘했어 👍 (해설 종료,1,246
1268,13,2.19,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍 (해설 종료,1,220
1269,13,5.52,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다."," OOM이 발생하는 것도 문제지만, 그로 인해서 학습이 제대로 이루어지지 않는다는 거지! 😥 (해설 종료",1,187
1270,13,3.78,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,278
1271,13,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
1272,13,2.86,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,156
1273,13,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,154
1274,13,3.28,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1275,13,3.29,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1276,13,2.83,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1277,13,1.27,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 😊 (해설 종료,1,191
1278,13,6.28,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
1279,13,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1280,13,4.75,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론은 맞는데, 그 안에서 어떻게 하는지 말할 수 없어? 😊 (해설 종료",1,186
1281,13,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1282,13,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1283,13,3.8,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
1284,13,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
1285,13,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,173
1286,13,3.64,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 음… 잘 설명했어! 그래서 언제 사용하는 거지? 🤔 (해설 종료,1,171
1287,13,5.39,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다."," 음… 잘 설명하긴 했는데, 구분선을 만들기는 하는데, 그 기울기가 어떻게 되지? 🤔 (해설 종료",1,187
1288,13,3.95,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 데이터 불균형이 심할 때는 그렇지도 않은데! 😥 (해설 종료,1,176
1289,13,2.53,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊 (해설 종료,1,199
1290,13,2.53,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 어떻게 해결하면 되는데? (해설 종료,1,159
1291,13,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1292,13,5.79,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말하긴 했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,362
1293,13,2.75,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 그러면 Bayesian Optimization 이란? 🤔 (해설 종료,1,315
1294,13,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
1295,13,2.92,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1296,13,1.75,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 😥 (해설 종료,1,200
1297,13,1.27,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1298,13,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1299,13,3.25,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 Early Stopping 이 구체적으로 뭐 하는 건데? 😊 (해설 종료,1,139
1300,13,5.59,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
1301,13,4.78,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 여러 가지 방법들을 말해 주긴 했는데 이게 구체적으로 어떻게 하는 방법들이야? 😊 (해설 종료,1,289
1302,13,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
1303,13,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
1304,13,1.59,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답!! (해설 종료,1,163
1305,13,3.44,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 학습률을 높이는 구간은 왜 있을까? 🤔 (해설 종료,1,136
1306,13,3.64,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다."," 페널티 느낌은 맞는데, 어떤 함수일까? 🤔 (해설 종료",1,173
1307,13,2.55,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
1308,13,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1309,13,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1310,13,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,176
1311,13,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,169
1312,13,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1313,13,4.57,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다."," AdamW 설명 나름대로 하긴 했는데, 그 핵심 아이디어가 빠졌잖아 😥 (해설 종료",1,218
1314,13,2.39,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그러면 Optimizer 는? 🤔 (해설 종료,1,194
1315,13,1.91,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊 (해설 종료,1,203
1316,13,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 있지 않을까? 😊 (해설 종료,1,274
1317,13,4.86,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다."," 오버피팅이 뭔지 설명은 잘 했는데, 그러면 그 해결 방법은? 🤔 (해설 종료",1,262
1318,13,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1319,13,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1320,13,2.55,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 넣는 거야? 😊 (해설 종료,1,175
1321,13,2.53,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,188
1322,13,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1323,13,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1324,13,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1325,13,5.37,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 잘 하긴 했는데 다른 task 의 데이터셋으로 추가 학습시킨다는 설명이 더 맞지 않을까? 😊 (해설 종료,1,196
1326,13,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
1327,13,2.5,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘 이해하고 있네! 😊 (해설 종료,1,215
1328,13,3.14,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 그 차이점은 뭐야? 🤔 (해설 종료,1,239
1329,13,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1330,13,4.42,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그건 맞긴 한데… 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,201
1331,13,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
1332,13,3.02,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 음… 그렇지는! 다시 한번 생각해 봐 🤔 (해설 종료,1,203
1333,13,3.28,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
1334,13,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1335,13,7.7,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 기존 LLM의 분해된 사전학습된 행렬들만 학습시킨다고? 그게 핵심적인 내용이긴 한데… 너무 간단한데? 😊 (해설 종료,1,278
1336,13,3.44,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,352
1337,13,4.69,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오! 나름 완벽한 설명이야! 😊 근데 top-k 랑 top-p 는? (해설 종료,1,366
1338,13,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1339,13,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1340,13,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1341,13,4.41,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
1342,13,5.52,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 근데 그 외부 DB가 어떤 거야? 😊 (해설 종료,1,255
1343,13,5.48,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 그건 내가 물어본 게 아닌데… 😥 (해설 종료,1,256
1344,13,3.32,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", PEFT 에 속하는 기술로는 뭐가 있지? 🤔 (해설 종료,1,203
1345,13,2.5,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍 (해설 종료,1,211
1346,13,2.66,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍 (해설 종료,1,223
1347,13,3.62,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", OOM 이 구체적으로 어떤 문제를 해결할 수 있을까? 😊 (해설 종료,1,172
1348,13,7.87,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 더 다양한 설명도 있으면 더 좋을 것 같긴 해! 😊 (해설 종료,1,225
1349,13,2.83,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 완벽해! 👍 (해설 종료,1,211
1350,13,8.0,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명했네! 근데 Masked Decoder Self-Attention 에서 단어 관계를 고려할 때 뭔가가 빠졌는데 그게 뭘까~요? 😊 (해설 종료,1,263
1351,13,2.92,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 완벽히 정확한 답이야! 👍 (해설 종료,1,296
1352,14,9.98,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," S-BERT 랑 추천 시스템이 2개의 벡터를 비교하는 거지? 그리고 벡터 방향이 일치할수록, 반대일수록 결과값이 달라지니까 꼭 기억해 둬야 해! 😊 (해설 종료",1,297
1353,14,4.47,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 핵심이 벡터의 유사도 판단이기는 하지만 너무 간단한데 😥 (해설 종료,1,203
1354,14,5.27,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
1355,14,5.98,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 수식의 분자는 정밀도랑 재현율 각각의 값이랑 어떤 관계가 있는지 말해봐! 😊 (해설 종료,1,257
1356,14,2.23,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1357,14,12.92,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다."," IoU 랑 DICE score 수식의 분자는 교집합의 원소 개수, 합집합의 원소 개수를 모두 포함하고 있어! 그러면 DICE score 수식의 분자는 교집합의 원소 개수, 참으로 예측한 개수, 실제 값이 참인 개수를 모두 포함하고 있네! 😊 (해설 종료",1,232
1358,14,2.67,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떡해 😥 (해설 종료,1,267
1359,14,4.31,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", PR-AUC 는 x축이랑 y축 설명 PPT 자료가 없잖아 😥 (해설 종료,1,309
1360,14,5.64,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다."," 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등 정말 완벽한 설명이야! 👍 (해설 종료",1,253
1361,14,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
1362,14,6.14,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 정답이야! 알고리즘만 간단히 설명했네! 알고리즘 좀 더 자세히 설명해 줄 수 있어? 😊 (해설 종료,1,414
1363,14,4.47,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 표준정규분포가 뭐고, 그리고 정규화를 하기 위한 알고리즘은? (해설 종료",1,288
1364,14,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1365,14,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1366,14,3.92,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 잘했어 👍 근데 주성분이 뭐지? 🤔 (해설 종료,1,239
1367,14,4.87,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
1368,14,2.7,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,206
1369,14,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
1370,14,2.83,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 어떻게 해결하면 되는데? 🤔 (해설 종료,1,213
1371,14,6.77,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법이 데이터 불균형을 해결하는 데에 과연 효과적일까? 🤔 (해설 종료,1,276
1372,14,5.48,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 기존 feature 중 일부만 사용하는 것하고 차원을 축소하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,241
1373,14,3.8,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA로 해결하면 되긴 한데... 과연 그럴까? 🤔 (해설 종료,1,176
1374,14,5.34,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 맨 위에서 시작해서 적절한 분기를 끝까지 선택해 나가는 건 class 를 어떻게 구분하지? 😊 (해설 종료,1,288
1375,14,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
1376,14,4.27,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용해서 예측하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,165
1377,14,3.31,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
1378,14,3.14,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오 정말 완벽한 답변이야 👍 (해설 종료,1,436
1379,14,3.12,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 완벽한 답변이야 👍 (해설 종료,1,436
1380,14,2.83,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1381,14,4.27,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 진정한 클러스터링이 뭐야? 그리고 mean point 가 뭐지? 🤔 (해설 종료,1,210
1382,14,6.28,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
1383,14,5.2,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1384,14,4.58,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론은 맞는데, 구체적으로 어떻게 작동할까? 🤔 (해설 종료",1,185
1385,14,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1386,14,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1387,14,5.03,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하는지 말할 수 있어? 😊 (해설 종료,1,197
1388,14,2.36,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
1389,14,3.62,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1390,14,5.38,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다."," 구분선을 만들기는 하는데, 그 거리가 너무 가까워도 문제고, 너무 멀어도 문제지. 🤔 (해설 종료",1,182
1391,14,4.58,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 마진이 최대라는 게 구체적으로 어떤 의미인데? 그리고 언제 사용하는 거지? 🤔 (해설 종료,1,182
1392,14,2.22,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 그렇지는 않을 텐데 😥 (해설 종료,1,165
1393,14,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1394,14,3.31,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 학습에 지장을 주면 어떻게 되는데? 🤔 (해설 종료,1,164
1395,14,2.94,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1396,14,5.48,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
1397,14,8.07,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 바둑판 격자 모양으로 탐색하는 건 좀 부실하지 않아? 그리고 Random Search 에서 바둑판 격자 모양으로 탐색하는 건? 🤔 (해설 종료,1,349
1398,14,3.45,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 솔직히 모르겠다고 하지 말고 설명 좀 해봐 😥 (해설 종료,1,259
1399,14,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1400,14,3.0,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,208
1401,14,4.75,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 그냥 섞는 게 당연하다고 생각하면 학습에 문제가 생기지 않을까? 😥 (해설 종료,1,220
1402,14,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1403,14,4.66,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,148
1404,14,5.59,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
1405,14,7.75,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 여러 가지 방법들을 말해 주긴 했는데 이게 구체적으로 어떻게 하는 방법들이야? 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,308
1406,14,5.5,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다."," 학습률을 조정하는 건 맞는데, 학습 후반에는 왜 학습률을 작게 해 줘? 😊 (해설 종료",1,181
1407,14,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
1408,14,1.58,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답!! (해설 종료,1,163
1409,14,3.72,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,138
1410,14,4.11,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다."," 페널티 느낌은 맞는데, 그럼 어떤 차이가 있을까? 🤔 (해설 종료",1,176
1411,14,3.0,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
1412,14,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1413,14,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1414,14,3.62,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", MSE는 어떤 거지? 그리고 MAE랑 RMSE는? 🤔 (해설 종료,1,172
1415,14,3.8,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", MSE는 정답이야! 그러면 MAE랑 RMSE는? 🤔 (해설 종료,1,179
1416,14,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1417,14,4.58,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다."," AdamW 설명 나름대로 하긴 했는데, 그 핵심 아이디어가 빠졌잖아 😥 (해설 종료",1,218
1418,14,3.47,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
1419,14,4.28,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., Weight Decay 가 사용되는 곳이랑 그 이유를 조금 더 설명해 줄 수 있어? 😊 (해설 종료,1,218
1420,14,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1421,14,5.0,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 데이터 증강이랑 Early Stopping 이 구체적으로 어떤 방법인지 말해 줄 수 있어? 😊 (해설 종료,1,263
1422,14,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1423,14,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1424,14,5.83,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다."," 어떤 새로운 항을 추가하는 거야? 그리고 L1 은 절댓값, L2 는 제곱이야! 알았어? 😊 (해설 종료",1,196
1425,14,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
1426,14,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1427,14,3.12,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1428,14,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1429,14,3.31,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train 은? 🤔 (해설 종료,1,183
1430,14,2.53,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1431,14,4.7,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,229
1432,14,2.83,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 그 차이점은? 🤔 (해설 종료,1,237
1433,14,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1434,14,4.09,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,199
1435,14,4.28,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
1436,14,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
1437,14,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
1438,14,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1439,14,2.52,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 뭐의 약자인데? 😊 (해설 종료,1,245
1440,14,5.64,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 top-p sampling 에서 누적 확률이 뭐지? 😊 (해설 종료,1,366
1441,14,3.75,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오! 나름 완벽한 설명이야! 😊😊😊 (해설 종료,1,360
1442,14,3.61,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1443,14,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1444,14,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1445,14,4.25,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리했네 👍👍 (해설 종료,1,204
1446,14,5.81,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데, 그래서 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료",1,257
1447,14,5.97,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,259
1448,14,4.42,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", OOM 이 구체적으로 어떤 문제지? 그리고 PEFT에 속하는 기술은? 🤔 (해설 종료,1,210
1449,14,2.66,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 잘 말했어! 😊😊 (해설 종료,1,212
1450,14,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1451,14,5.47,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다."," 양자화가 뭔지 설명은 잘 했는데, 그래서 OOM이랑 어떤 연관이 있을까? 🤔 (해설 종료",1,183
1452,14,6.63,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰하고 토크나이저의 정의는 잘 이야기했어! 근데 구체적으로 어떤 알고리즘일까? 🤔 (해설 종료,1,217
1453,14,2.81,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 완벽해! 👍 (해설 종료,1,211
1454,14,8.47,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 말해 준 것을 한번 설명해 봐! 근데 Masked Decoder Self-Attention 에서 단어 관계를 설명할 때 뭔가가 빠졌는데 그게 뭘까~요? 😊 (해설 종료,1,266
1455,14,7.31,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 정확해! 근데 Masked Decoder Self-Attention 에서 단어 관계를 고려할 때 뭔가가 빠졌는데 그게 뭘까~요? 😊 (해설 종료,1,324
1456,15,4.77,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 코사인 유사도에 대한 설명은 잘 했는데 구체적인 값이 뭐야? 😊 (해설 종료,1,265
1457,15,5.51,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도만 판단하면 핵심 내용이기는 하지만 뭔가 부실할 것 같은데 😥 (해설 종료,1,209
1458,15,5.28,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
1459,15,8.02,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 수식의 분자는 정밀도랑 재현율 각각 1개씩만 있네! 혹시 수식의 분자를 다시 한번 간단히 설명해 줄 수 있어? 😊 (해설 종료,1,270
1460,15,2.06,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE는? 🤔 (해설 종료,1,193
1461,15,9.77,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다."," 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score 설명 나름대로 하긴 했는데, 그 설명이 2x교집합의 원소 개수가 어떻게 될지 말할 수 있어? 😊 (해설 종료",1,212
1462,15,4.71,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋을지도 알려주면 어떡해 😥 (해설 종료,1,280
1463,15,4.8,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", x축이랑 y축 설명 PPT 자료가 있으면 더 좋을 것 같긴 해! 😊 (해설 종료,1,312
1464,15,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1465,15,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
1466,15,3.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 완벽한 설명이야! 👍👍 (해설 종료,1,396
1467,15,4.8,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 표준정규분포로 변환하는 건 맞는데, 그 이전에 어떻게 하지? 🤔 (해설 종료",1,290
1468,15,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1469,15,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
1470,15,5.48,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다."," 주성분이 뭐고, 그리고 PCA랑 t-SNE랑 차이점을 조금 더 설명해 줄 수 있어? 😊 (해설 종료",1,249
1471,15,4.84,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
1472,15,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1473,15,2.86,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
1474,15,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1475,15,4.53,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 개수를 늘리거나 증강을 하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,262
1476,15,3.12,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍👍👍 (해설 종료,1,226
1477,15,5.53,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA로 해결하면 차원이 축소되긴 하지! 😊 근데 더 다양한 정보가 빠지는 게 아닐까? 😥 (해설 종료,1,187
1478,15,3.77,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,278
1479,15,3.0,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
1480,15,2.89,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 하는 거지? 🤔 (해설 종료,1,156
1481,15,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
1482,15,3.94,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
1483,15,3.13,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 완벽한 답변이야 👍 (해설 종료,1,436
1484,15,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1485,15,2.22,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 로라가 뭐야? 😥 (해설 종료,1,197
1486,15,6.29,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
1487,15,5.2,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1488,15,4.42,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론에 대해서 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,184
1489,15,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1490,15,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1491,15,6.16,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 그럼 PCA의 핵심 아이디어가 뭐야? 그리고 Eigenvalue 랑 Eigenvector 를 이용해서 어떻게 하는지도 알면 좋겠는데 😥 (해설 종료,1,204
1492,15,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
1493,15,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1494,15,3.95,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 각 Class 간의 거리가 최대가 되도록 하기 위해서 어떻게 하지? 🤔 (해설 종료,1,173
1495,15,3.48,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 마진이 최대라는 게 구체적으로 어떤 뜻인데? 🤔 (해설 종료,1,175
1496,15,1.75,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 😥 (해설 종료,1,162
1497,15,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1498,15,2.73,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
1499,15,2.86,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1500,15,3.91,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지 말해 봐! 😊 (해설 종료,1,350
1501,15,5.27,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 바둑판 격자나 랜덤 탐색 말고도 방법이 많을 텐데 😊 (해설 종료,1,331
1502,15,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
1503,15,2.9,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1504,15,4.11,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
1505,15,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1506,15,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1507,15,4.66,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,148
1508,15,5.89,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그럼 사용하는 모델 관점에서는? 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료,1,304
1509,15,4.81,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 그럼 모델의 어떤 정보를 이용하는지의 관점에서도 나뉠까? 🤔 (해설 종료,1,289
1510,15,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
1511,15,4.27,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 학습 초반이랑 중반 학습률이 왜 차이가 나는 걸까? 😊 (해설 종료,1,205
1512,15,3.62,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,176
1513,15,3.25,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 학습률을 높이는 구간이 있는 거지! 😊 (해설 종료,1,135
1514,15,2.69,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼 어떤 차이가 있을까? 🤔 (해설 종료,1,167
1515,15,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
1516,15,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1517,15,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1518,15,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
1519,15,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,169
1520,15,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1521,15,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 RMSProp 이랑 Adam 는? 😊 (해설 종료,1,206
1522,15,2.39,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그럼 Optimizer 는? 🤔 (해설 종료,1,194
1523,15,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
1524,15,4.62,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1525,15,3.3,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 핵심적인 내용이기는 하지만 너무 간단한데 😥 (해설 종료,1,252
1526,15,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1527,15,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1528,15,2.55,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 넣는 거야? 😊 (해설 종료,1,175
1529,15,4.58,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 그럼 weight 의 절댓값이나 제곱의 평균을 어떤 식으로 이용하지? 😊 (해설 종료,1,201
1530,15,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1531,15,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1532,15,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1533,15,2.69,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,179
1534,15,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
1535,15,4.7,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,229
1536,15,2.98,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은 뭐야? 🤔 (해설 종료,1,238
1537,15,3.44,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1538,15,4.09,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,199
1539,15,3.96,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음 그치! 그래서 활성화 함수가 없으면 어떻게 되는데? 🤔 (해설 종료,1,203
1540,15,2.84,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼 음 그치! 정답이야! 😊 (해설 종료,1,202
1541,15,2.83,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
1542,15,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1543,15,2.98,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 뭐의 이점이 있지? 🤔 (해설 종료,1,248
1544,15,4.37,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 temperature 는 뭐지? 😊 (해설 종료,1,358
1545,15,3.44,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그럼 top-p 랑 top-k 는 뭐야? 😊 (해설 종료,1,358
1546,15,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1547,15,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1548,15,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1549,15,3.48,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 간결하면서도 엄청 잘 정리했네! 😊😊 (해설 종료,1,199
1550,15,4.25,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", 그건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,247
1551,15,5.97,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,259
1552,15,5.84,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오! 잘 말했어! 근데 PEFT 에 속하는 기술 나머지 4개는 뭘까~요? 😊 (해설 종료,1,219
1553,15,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
1554,15,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1555,15,3.78,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 과연 그럴까? 그리고 그 핵심적인 내용은 뭐지? 😊 (해설 종료,1,173
1556,15,7.26,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 구체적인 설명이랑 토크나이저 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,221
1557,15,7.37,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 구체적인 설명이랑 토크나이저 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,240
1558,15,4.56,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 말해 준 것을 한번 간단히 핵심 아이디어만 설명해 봐! 😊 (해설 종료,1,241
1559,15,4.78,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 정확해! 근데 Masked Decoder Self-Attention 에 대해 더 설명해 줄 수 있어? 😊 (해설 종료,1,308
1560,16,124.8,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," S-BERT 랑 추천 시스템이 2개의 벡터를 비교하는 거지? 그리고 벡터의 방향이 일치할수록, 반대 방향일수록 결과값이 좋아지는 건 맞지만 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의 방향이 수직일수록 결과값이 나빠지는 건 벡터의",1,1024
1561,16,7.56,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다."," 벡터의 유사도 판단하기는커녕 수직일 때, 평행일 때, 반대일 때 결과값이 어떻게 될지 생각해 봤어? 🤔 (해설 종료",1,223
1562,16,3.84,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
1563,16,4.55,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 수식의 분자는 두 번 째 항부터 시작해 볼 수 있어? 😊 (해설 종료,1,248
1564,16,2.22,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1565,16,4.73,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 교집합이랑 합집합의 크기가 구체적으로 뭘 말할 수 있어? 😊 (해설 종료,1,180
1566,16,4.56,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,279
1567,16,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
1568,16,7.06,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다."," 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반의 알고리즘에 대해서 좀 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료",1,262
1569,16,4.27,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 알고리즘이 있지 않을까? 😊 (해설 종료,1,184
1570,16,4.23,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정규화에 대한 설명이기는 하지만 너무 부실한 것 같아 😥 (해설 종료,1,402
1571,16,5.89,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균이랑 표준편차만 있네! 정규화의 핵심적인 내용이기는 하지만 뭔가 부실해! 😥 (해설 종료,1,297
1572,16,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1573,16,2.39,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1574,16,2.34,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 완벽한 설명이야 👍 (해설 종료,1,229
1575,16,4.84,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
1576,16,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1577,16,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
1578,16,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1579,16,2.34,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 정답이야! 👍 (해설 종료,1,248
1580,16,5.89,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 기존 feature 중 일부만 사용하는 것랑 PCA처럼 차원을 축소하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,243
1581,16,4.58,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", 차원의 저주 OOM이 발생하는 것 말고도 문제점이 있지 않을까? 😊 (해설 종료,1,181
1582,16,3.6,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 구분하지? 그리고 추론할 때는? 😊 (해설 종료,1,277
1583,16,3.75,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", target 값을 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,256
1584,16,4.25,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용해서 예측하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,165
1585,16,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
1586,16,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
1587,16,3.3,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1588,16,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1589,16,3.8,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 진까 까먹었는데… 로라야 도와줄 수 있어? 😊 (해설 종료,1,207
1590,16,3.91,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 사용자의 지도 없이 학습하는 건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,234
1591,16,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1592,16,5.67,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론이 핵심이긴 하지! 그래서 새로운 데이터가 들어왔을 때 어떻게 예측하는데? 🤔 (해설 종료,1,192
1593,16,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1594,16,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1595,16,3.81,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
1596,16,2.36,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
1597,16,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,173
1598,16,3.94,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 각 Class 간의 거리가 최대라는 게 구체적으로 어떤 기준이지? 🤔 (해설 종료,1,173
1599,16,3.62,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 음… 잘 설명했어! 그래서 언제 사용하는 거지? 🤔 (해설 종료,1,176
1600,16,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
1601,16,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1602,16,2.67,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
1603,16,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1604,16,5.16,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지 설명은 잘 했는데 최적화 방법은? 🤔 (해설 종료,1,358
1605,16,3.22,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", Random Search 가 더 자세히 설명될 수 있어? 😊 (해설 종료,1,318
1606,16,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
1607,16,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1608,16,4.13,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
1609,16,1.27,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1610,16,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1611,16,4.83,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 보통 몇 번 정도 하면 학습이 제대로 이루어지지 않을까? 😊 (해설 종료,1,149
1612,16,3.55,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! (해설 종료,1,289
1613,16,4.8,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 거대한 모델의 어떤 정보를 사용하는지의 관점에서도 한번 설명해 줄 수 있어? 😊 (해설 종료,1,289
1614,16,3.47,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데… 왜 필요한 거지? (해설 종료,1,168
1615,16,4.25,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 학습 초반이랑 중반 학습률이 왜 차이가 나는 걸까? 😊 (해설 종료,1,205
1616,16,5.06,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 재미 위주로만 설명하면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 😥 (해설 종료,1,185
1617,16,4.34,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하는 건 학습률을 높이는 구간이 아니지! (해설 종료,1,142
1618,16,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,166
1619,16,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
1620,16,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1621,16,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1622,16,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
1623,16,4.25,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
1624,16,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1625,16,4.58,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다."," AdamW 설명 나름대로 하긴 했는데, 그 핵심 아이디어가 빠졌잖아 😥 (해설 종료",1,218
1626,16,3.47,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
1627,16,5.22,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., Weight Decay 가 사용되는 곳이 정확히 뭐야? 그리고 Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (해설 종료,1,224
1628,16,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1629,16,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단한 구조만 설명하면 어떡해! 더 다양한 방법들이 있지 않아? 😊 (해설 종료,1,260
1630,16,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1631,16,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1632,16,2.53,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
1633,16,4.57,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 그럼 weight 의 절댓값이나 제곱의 평균을 어떤 식으로 추가하지? 😊 (해설 종료,1,201
1634,16,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1635,16,3.13,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1636,16,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1637,16,5.83,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
1638,16,2.97,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊👍 (해설 종료,1,272
1639,16,4.7,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,229
1640,16,2.67,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은? 🤔 (해설 종료,1,236
1641,16,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1642,16,4.11,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명할 수 있어? 🤔 (해설 종료,1,199
1643,16,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,205
1644,16,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
1645,16,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
1646,16,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1647,16,2.5,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 뭐의 약자인데? 😊 (해설 종료,1,245
1648,16,4.06,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-k sampling 에서 누적 확률이 뭐가 p 이상인지? 😊 (해설 종료,1,356
1649,16,3.44,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 오! 나름 완벽한 설명이야! 😊😊 (해설 종료,1,358
1650,16,3.49,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1651,16,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1652,16,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1653,16,3.95,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 너의 정답이야! 근데 환각 현상의 정의랑 원인은? (해설 종료,1,202
1654,16,4.87,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
1655,16,5.97,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,259
1656,16,5.83,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오! 잘 말했어! 근데 PEFT에 속하는 기술 나머지 4개는 뭘까~요? 😊 (해설 종료,1,219
1657,16,2.98,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍👍 (해설 종료,1,214
1658,16,3.19,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1659,16,3.78,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 해결할 수 있는 문제를 조금 더 상세히 설명해 봐! 😊😊 (해설 종료,1,173
1660,16,7.59,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 더 많은 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,223
1661,16,6.12,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰과 토크나이저 설명이 완벽하긴 한데 구체적인 사용 예시가 없잖아 😥 (해설 종료,1,232
1662,16,2.97,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명할 수 있어? 😊 (해설 종료,1,231
1663,16,5.9,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 에 대한 설명도 있으면 더 좋을 것 같아 😊 (해설 종료,1,315
1664,17,3.53,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 우와! 정말 완벽한 설명이야! 😊👍 (해설 종료,1,257
1665,17,5.89,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다."," 벡터의 유사도를 판단하기는커녕, 그 방향에 따른 값하고 사용 예가 빠져 있어! 😥 (해설 종료",1,211
1666,17,3.84,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
1667,17,5.03,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 수식의 분자는 정밀도랑 재현율 각각 한 번만 사용했어! 😊 (해설 종료,1,251
1668,17,2.22,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1669,17,1.27,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
1670,17,4.72,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 더 좋은지만 알려주면 어떡해 😥 (해설 종료,1,280
1671,17,9.98,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다."," x축이랑 y축 설명 P-R-AUC, ROC-AUC 둘 다 반대고, 혹시 값 범위랑, 그리고 값이 커지는 거랑 작아지는 거랑 뭐가 더 성능이 좋은지도 답해 줄 수 있어? 😊 (해설 종료",1,345
1672,17,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1673,17,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😥 (해설 종료,1,182
1674,17,7.37,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오! 정의랑 알고리즘만 설명하면 어떡해! 알고리즘 좀 더 자세히 설명하고, 정의랑 알고리즘 좀 더 설명해 봐! 😊 (해설 종료",1,422
1675,17,4.0,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균이랑 표준편차만 이용해서 어떻게 변환하는데? 🤔 (해설 종료,1,285
1676,17,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1677,17,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1678,17,3.61,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,237
1679,17,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
1680,17,4.89,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정의는 잘 말했는데 차이점 같은 거 보다 구체적으로 설명해줄 수 있어? 😊 (해설 종료,1,220
1681,17,2.69,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했는데 😥 (해설 종료,1,181
1682,17,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1683,17,4.86,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 정의랑 해결 방법 엄청 다양하게 말해 줬네! 정말 좋은 답이야! 👍 (해설 종료,1,264
1684,17,3.2,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 우와 잘했어 👍👍👍 (해설 종료,1,226
1685,17,3.0,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니야! 잘 생각을 해봐! 😥 (해설 종료,1,171
1686,17,3.81,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", target 값을 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,278
1687,17,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
1688,17,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,156
1689,17,3.78,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
1690,17,3.28,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1691,17,3.28,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1692,17,2.82,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1693,17,2.69,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 진짜 완벽해! 👍👍 (해설 종료,1,200
1694,17,6.27,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
1695,17,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1696,17,4.11,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론인 베이즈 정리를 어떻게 이용하지? 🤔 (해설 종료,1,182
1697,17,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1698,17,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1699,17,3.77,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
1700,17,3.78,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 그리고 추론할 때는 어떻게 하지? (해설 종료,1,166
1701,17,3.62,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1702,17,2.52,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
1703,17,5.52,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어긴 하지! 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,188
1704,17,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
1705,17,3.62,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정의랑 목적이 정확해! 😊😊 (해설 종료,1,206
1706,17,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
1707,17,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 맞아! 완벽해! 😊😊 (해설 종료,1,185
1708,17,5.93,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오! 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 설명했네! 😊👍 (해설 종료,1,363
1709,17,6.2,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 바둑판 격자 모양이랑 랜덤하게 탐색하는 거 말고도 방법이 많을 텐데 😊 (해설 종료,1,337
1710,17,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😥 (해설 종료,1,246
1711,17,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1712,17,3.95,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그리고 또 하나 문제점이 있는데 그게 뭔지 알아? 😊 (해설 종료,1,214
1713,17,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1714,17,3.31,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 그래서 Early Stopping 이 구체적으로 뭐 하는 건데? 😊 (해설 종료,1,155
1715,17,4.34,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정의는 잘 말했는데 그래서 Early Stopping 이 구체적으로 뭐 하는 거지? 😊 (해설 종료,1,146
1716,17,3.83,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 설명해 봐! 😊 (해설 종료,1,291
1717,17,4.64,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 거대한 모델의 어떤 정보를 사용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,288
1718,17,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
1719,17,1.73,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정의이야!! (해설 종료,1,189
1720,17,4.92,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 학습에 재미를 느끼는 건 맞는데 그래서 learning rate 를 어떻게 조정하는 거야? 🤔 (해설 종료,1,184
1721,17,3.73,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,138
1722,17,3.47,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 오 이거 정의랑 설명 완벽해! 👍👍 (해설 종료,1,172
1723,17,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정의이야! 👍👍 (해설 종료,1,193
1724,17,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1725,17,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
1726,17,2.21,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
1727,17,4.25,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
1728,17,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1729,17,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 RMSProp 이랑 Adam 은? 😥 (해설 종료,1,206
1730,17,2.22,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그래서 Optimizer 는? 🤔 (해설 종료,1,193
1731,17,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
1732,17,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1733,17,3.44,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단히 핵심 내용만 설명하면 어떡해! 😥 (해설 종료,1,253
1734,17,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1735,17,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1736,17,2.55,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
1737,17,6.78,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다."," 오 정의이야! 근데 보통 L1 은 절댓값 크기, L2 는 평균을 이용하는 거야! 근데 서로 반대로 했네 😥 (해설 종료",1,215
1738,17,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1739,17,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1740,17,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1741,17,5.83,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
1742,17,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1743,17,4.71,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 기존 모델을 우리의 분야로 전이시키는 건 지식 증류가 아니야! 😥 (해설 종료,1,229
1744,17,2.66,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은? 🤔 (해설 종료,1,236
1745,17,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1746,17,3.78,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그럼 활성화 함수가 없으면 어떻게 되지? 🤔 (해설 종료,1,197
1747,17,4.42,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,206
1748,17,3.16,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 과연 그럴까? 그리고 그 이유는? 🤔 (해설 종료,1,204
1749,17,3.3,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
1750,17,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1751,17,5.17,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 기존 LLM의 사전학습된 행렬을 어떻게 분해하는지도 설명해 줄 수 있어? 😊 (해설 종료,1,262
1752,17,4.84,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 top-k 랑 top-p 는? 😊 (해설 종료,1,361
1753,17,3.42,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", top-k 랑 top-p sampling 설명이 없는데? 😥 (해설 종료,1,358
1754,17,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1755,17,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1756,17,4.87,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1757,17,4.42,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정의이야! 간결하면서도 엄청 잘 정아둬! 😊👍 (해설 종료,1,205
1758,17,5.79,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다."," LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데, 그래서 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료",1,257
1759,17,5.95,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,259
1760,17,3.31,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", PEFT 에 속하는 기술로는 뭐가 있지? 🤔 (해설 종료,1,203
1761,17,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
1762,17,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정의야! 👍👍👍 (해설 종료,1,226
1763,17,4.89,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다."," 양자화가 뭔지 설명은 잘 했는데, 그래서 어떤 문제를 해결할 수 있을까? 😥 (해설 종료",1,180
1764,17,8.19,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저의 정의는 잘 이야기했어! 근데 구체적인 설명이랑 예시가 더 있으면 더 좋을 것 같긴 해! 😊 (해설 종료,1,227
1765,17,5.48,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다.," 토큰과 토크나이저 정의는 잘 이야기했는데, 알고리즘은? 🤔 (해설 종료",1,228
1766,17,3.14,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 🤔 (해설 종료,1,232
1767,17,7.37,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 정확해! 근데 Masked Decoder Self-Attention 에서 단어 관계를 고려할 때 뭔가가 빠졌는데 그게 뭘까~요? 😊 (해설 종료,1,324
1768,18,8.7,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," S-BERT 랑 추천 시스템이 2개의 벡터를 비교하는 거지? 그리고 벡터의 방향이 일치할수록, 반대일수록 결과가 좋을 거지! 😊 (해설 종료",1,290
1769,18,3.95,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 너무 부실한데 😥 (해설 종료,1,200
1770,18,4.17,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 정확도만 있네! 혹시 나머도 설명해줄 수 있어? 😊 (해설 종료,1,307
1771,18,4.23,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 만 있네! 혹시 나머도 설명해줄 수 있어? 😊 (해설 종료,1,246
1772,18,2.06,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE는? 🤔 (해설 종료,1,193
1773,18,10.72,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 참으로 예측한 개수 + 실제 값이 참인 개수를 다르게 말하면 합집합의 크기가 맞지! 😊 근데 교집합이랑 합집합이 어떤 집합의 교집합이랑 합집합인지 말해 줄 수 없을까? (해설 종료,1,218
1774,18,4.56,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,279
1775,18,2.77,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
1776,18,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1777,18,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
1778,18,6.77,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오! 정규화에 대한 설명과 알고리즘은 잘 말했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,418
1779,18,4.33,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 정규화가 뭔지 설명은 잘 했는데, 알고리즘은? 🤔 (해설 종료",1,287
1780,18,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1781,18,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1782,18,2.36,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 완벽한 설명이야 👍 (해설 종료,1,229
1783,18,4.87,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
1784,18,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1785,18,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 정답! 잘했어 👍 (해설 종료,1,178
1786,18,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1787,18,2.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 잘했어 👍 (해설 종료,1,247
1788,18,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
1789,18,3.0,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니야! 다양한 방법들이 있지! 😊 (해설 종료,1,171
1790,18,4.39,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 학습할 때랑 추론할 때 모두 매우 잘 설명했네! 😊👍 (해설 종료,1,282
1791,18,3.75,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", target 값을 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,256
1792,18,3.16,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞긴 한데… 왜 그렇게 하지? 🤔 (해설 종료,1,158
1793,18,2.86,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,154
1794,18,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
1795,18,3.14,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 완벽한 답변이야 👍 (해설 종료,1,436
1796,18,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1797,18,2.7,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 진짜 완벽해! 👍👍 (해설 종료,1,200
1798,18,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
1799,18,2.97,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
1800,18,4.27,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 조건부 확률 이론은 맞는데, 완벽한 답변이야! 👍 (해설 종료",1,183
1801,18,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1802,18,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1803,18,3.79,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 핵심 아이디어만 있고 동작하는 방식이 빠졌잖아 😥 (해설 종료,1,189
1804,18,2.36,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
1805,18,3.62,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1806,18,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
1807,18,3.0,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 오! 완벽한 답이야! 😊👍 (해설 종료,1,172
1808,18,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
1809,18,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1810,18,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
1811,18,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1812,18,5.47,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
1813,18,5.58,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 하이퍼파라미터가 뭔지 설명은 잘 했는데, 최적화하는 방법으로는? 🤔 (해설 종료",1,333
1814,18,2.81,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", Valid Dataset 이 필요한 정확한 이유가 뭐야? (해설 종료,1,255
1815,18,2.95,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1816,18,4.11,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
1817,18,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1818,18,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1819,18,3.89,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 Early Stopping 이 구체적으로 뭐 하는 건데? 😊 (해설 종료,1,143
1820,18,5.42,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 봐! 😊 (해설 종료",1,301
1821,18,4.8,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 여러 가지 방법들을 말해 주긴 했는데 이게 구체적으로 어떻게 하는 방법들이야? 😊 (해설 종료,1,289
1822,18,3.31,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데 왜 필요한 거지? (해설 종료,1,167
1823,18,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야! (해설 종료,1,189
1824,18,1.58,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답!! (해설 종료,1,163
1825,18,5.45,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하긴 하지! 그래서 학습률을 높이는 구간은 왜 있는 걸까? 😊 (해설 종료,1,149
1826,18,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,166
1827,18,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
1828,18,3.16,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 😊 (해설 종료,1,168
1829,18,3.16,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 잘 대답했어👍👍👍 (해설 종료,1,174
1830,18,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,176
1831,18,4.25,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
1832,18,1.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1833,18,7.42,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다."," AdamW 설명 나름대로 하긴 했는데, 혹시 RMSProp 이랑 Gradient 가 큰 거랑 작은 거랑 그 차이점 위주로 설명해 줄 수 있어? 😊 (해설 종료",1,236
1834,18,3.48,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
1835,18,2.39,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
1836,18,5.19,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 이랑 Early Stopping 같은 것도 말해 줬네! 하지만 더 다양한 방법들이 있지 않을까? 😊 (해설 종료,1,278
1837,18,2.81,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 정답이야! 😊👍 (해설 종료,1,249
1838,18,3.32,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1839,18,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1840,18,2.53,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
1841,18,2.38,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
1842,18,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1843,18,3.12,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1844,18,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1845,18,5.83,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
1846,18,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1847,18,2.5,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘했어 👍👍 (해설 종료,1,215
1848,18,3.44,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,241
1849,18,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1850,18,4.25,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,200
1851,18,4.28,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
1852,18,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼에도 불구하고 답변이 길지 않아? 😊 (해설 종료,1,206
1853,18,3.28,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
1854,18,2.33,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1855,18,2.98,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 LoRA 가 뭐의 약자인데? 😊 (해설 종료,1,248
1856,18,5.17,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 지금 거의 완벽하긴 해! 😊👍 (해설 종료,1,363
1857,18,3.91,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 혹시 top-k 랑 top-p 는 아직 공부 안 했어? 😊 (해설 종료,1,361
1858,18,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1859,18,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1860,18,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1861,18,4.72,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정리리해 놓았네 👍👍 (해설 종료,1,207
1862,18,5.95,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,258
1863,18,5.95,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,259
1864,18,3.62,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", PEFT 에 속하는 기술로는 뭘 말할 수 있어? 😊 (해설 종료,1,205
1865,18,2.91,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
1866,18,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1867,18,3.78,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 양자화가 아니지! 좀 더 구체적으로 설명해 봐! 😊 (해설 종료,1,173
1868,18,7.7,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 설명도 있으면 더 좋을 텐데 😊 (해설 종료,1,224
1869,18,6.12,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰과 토크나이저 설명은 좋긴 한데 구체적인 설명이기는 하지만 완벽하지 않은데 😥 (해설 종료,1,232
1870,18,3.12,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 그러면 핵심 아이디어는 뭐야? 🤔 (해설 종료,1,232
1871,18,5.25,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 이나 Cross-Attention 은? 🤔 (해설 종료,1,311
1872,19,3.5,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 우와! 정말 완벽한 설명이야! 😊👍 (해설 종료,1,257
1873,19,4.36,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 구체적으로 어떻게 하지? 🤔 (해설 종료,1,202
1874,19,3.85,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
1875,19,4.36,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", F1 Score 만 있네! 혹시 나머지도 설명해줄 수 있어? 😊 (해설 종료,1,246
1876,19,2.22,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1877,19,1.27,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
1878,19,4.62,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,279
1879,19,2.77,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
1880,19,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1881,19,3.94,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
1882,19,5.52,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정의랑 알고리즘만 있잖아! 정규화의 핵심 아이디어가 뭐지? 🤔 (해설 종료,1,410
1883,19,4.48,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 표준정규분포로 변환하는 건 맞는데 구체적인 알고리즘은? (해설 종료,1,288
1884,19,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
1885,19,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
1886,19,2.19,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 잘 설명했어 👍 (해설 종료,1,228
1887,19,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
1888,19,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1889,19,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
1890,19,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1891,19,5.33,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표나 손실 함수 쪽보다는 데이터 쪽이 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,267
1892,19,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
1893,19,3.0,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA로 해결하면 진짜 완벽할까? 🤔 (해설 종료,1,171
1894,19,3.77,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,278
1895,19,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
1896,19,4.25,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용해서 예측하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,165
1897,19,3.33,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
1898,19,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
1899,19,3.28,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
1900,19,2.83,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
1901,19,2.68,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", 진짜 완벽해! 👍👍 (해설 종료,1,200
1902,19,6.11,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 사용자의 지도 없이 학습하는 건 맞지만! 그래서 지도학습이랑 비지도학습이랑 차이점이 뭐지? 😊 (해설 종료,1,248
1903,19,5.19,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
1904,19,4.25,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론은 맞는데 구체적으로 어떻게 작동할까? 😊 (해설 종료,1,183
1905,19,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
1906,19,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
1907,19,3.62,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다."," 그래서 핵심 아이디어가 뭐고, 구체적으로 어떻게 동작하지? (해설 종료",1,188
1908,19,2.38,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
1909,19,3.62,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
1910,19,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
1911,19,3.47,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 마진이 최대라는 게 구체적으로 어떤 기준이지? 🤔 (해설 종료,1,175
1912,19,2.7,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
1913,19,2.86,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
1914,19,2.67,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞지! 그러면 어떻게 해결하면 되는데? (해설 종료,1,160
1915,19,2.86,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
1916,19,5.47,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
1917,19,3.86,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 그리고 추가적인 최적화 방법으로는 무엇이 있을까? 🤔 (해설 종료,1,322
1918,19,3.45,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 솔직히 모르겠다고 하지 말고 설명 좀 해 봐 😥 (해설 종료,1,259
1919,19,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
1920,19,2.53,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 정답! ✨✨🎉 (해설 종료,1,205
1921,19,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
1922,19,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
1923,19,2.77,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답!! 완벽해!! 👍👍 (해설 종료,1,136
1924,19,3.55,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! (해설 종료,1,289
1925,19,4.78,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 여러 가지 방법들을 말해 주긴 했는데 이게 구체적으로 어떻게 하는 방법들이야? 😊 (해설 종료,1,289
1926,19,2.67,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
1927,19,1.78,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
1928,19,5.2,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 학습에 재미를 느끼는 것 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,186
1929,19,3.73,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,138
1930,19,4.72,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다."," Loss Function 은 개별 데이터 관점, Cost Function 은 전체 데이터 관점이야! 알았어? 😊 (해설 종료",1,180
1931,19,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
1932,19,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,169
1933,19,3.17,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 잘 대답했어👍👍👍 (해설 종료,1,174
1934,19,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
1935,19,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
1936,19,1.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
1937,19,2.86,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그 핵심 아이디어가 뭐지? 🤔 (해설 종료,1,207
1938,19,3.48,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
1939,19,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
1940,19,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
1941,19,6.27,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단히 설명하기는 했는데 그래서 Valid 이랑 Test 에서 오버피팅의 정의랑 해결 방법이 뭐가 있지? 😊 (해설 종료,1,271
1942,19,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
1943,19,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
1944,19,2.53,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
1945,19,2.36,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
1946,19,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
1947,19,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
1948,19,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
1949,19,5.97,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
1950,19,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
1951,19,5.33,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 건 지식 증류랑 차이점이지! (해설 종료,1,233
1952,19,7.84,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다."," node 의 개수가 많을수록 평균 절댓값 크기는 작아지게 하고, Xavier 는 input + output 모두, He 는 input 만 고려하는 거야! 꼭 알아둬! 😊 (해설 종료",1,269
1953,19,3.44,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
1954,19,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,200
1955,19,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
1956,19,3.0,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 음… 정답! 박수!! 👏👏 (해설 종료,1,203
1957,19,3.28,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
1958,19,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
1959,19,2.5,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 왜 좋은 거지? 🤔 (해설 종료,1,245
1960,19,4.55,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 top-k 랑 top-p 는? (해설 종료,1,359
1961,19,6.75,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 다양하지 않고 특정 토큰만 계속 나오는 현상이 발생하면 토큰이 1개 더 있거나 없거나 하지! 😊 (해설 종료,1,379
1962,19,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
1963,19,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
1964,19,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
1965,19,4.11,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 간결하면서도 엄청 잘 정했어 👍👍 (해설 종료,1,203
1966,19,5.95,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,258
1967,19,5.96,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,259
1968,19,5.37,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오 잘 말했어! 근데 PEFT에 속하는 기술 나머지 4개 더 있지 않을까? 😊 (해설 종료,1,216
1969,19,2.98,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 오 잘 말했어! 😊😊 (해설 종료,1,214
1970,19,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
1971,19,3.78,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 해결할 수 있는 문제를 조금 더 상세히 설명해 봐! 😊😊 (해설 종료,1,173
1972,19,6.16,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰과 토크나이저 설명이 완벽하긴 한데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,214
1973,19,2.81,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 완벽해! 👍 (해설 종료,1,211
1974,19,2.99,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 더 정확히 설명해 봐! 😊 (해설 종료,1,231
1975,19,7.3,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 정확해! 근데 Masked Decoder Self-Attention 에서 단어 관계를 고려할 때 뭔가가 빠졌는데 그게 뭘까~요? 😊 (해설 종료,1,324
1976,20,5.09,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 설명이긴 한데 수직일 때는 값이 얼마로 나올까? 😊 (해설 종료,1,266
1977,20,4.13,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 혹시 구체적으로 뭐에 사용하는지 생각해 봤어? 🤔 (해설 종료,1,200
1978,20,3.7,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 오 완벽해! 대박! 👍👍👍 (해설 종료,1,304
1979,20,4.56,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," F1 Score 수식의 분자는 정확도, 나머지 항목은 재현율이야! (해설 종료",1,248
1980,20,2.21,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
1981,20,10.87,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", : 참으로 예측한 개수 + 실제 값이 참인 개수를 다르게 말하면 합집합의 크기가 맞지! 😊 근데 교집합이랑 합집합이 어떤 집합의 교집합이랑 합집합인지 말해 줄 수 없을까? (해설 종료,1,219
1982,20,4.55,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,279
1983,20,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
1984,20,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
1985,20,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
1986,20,7.55,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오 정답이야! 알고리즘만 간단히 설명해도 핵심 내용이기는 하지만 너무 부실한데, 자세히 설명해 봤네! 😊👍 (해설 종료",1,423
1987,20,5.25,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 표준정규분포로 변환하는 건 맞는데 좀 더 구체적으로 설명해 줄 수 없어? 😊 (해설 종료,1,293
1988,20,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 답이야!! 👍👍 (해설 종료,1,230
1989,20,3.0,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그 아웃라이어가 아니지! 🤣😅 (해설 종료,1,171
1990,20,2.2,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 잘 설명했어 👍 (해설 종료,1,228
1991,20,2.34,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", 오 완벽한 답이야 👍 (해설 종료,1,234
1992,20,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
1993,20,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
1994,20,2.52,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
1995,20,2.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 정답이야! 👍 (해설 종료,1,247
1996,20,2.98,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
1997,20,3.95,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", OOM이 발생하는 것 말고도 문제점이 있지 않을까? 😊 (해설 종료,1,177
1998,20,3.3,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 완벽해! 역시 😊👍 (해설 종료,1,275
1999,20,3.12,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 되지? 😊 (해설 종료,1,252
2000,20,4.27,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용해서 예측하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,165
2001,20,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
2002,20,3.3,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
2003,20,3.28,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
2004,20,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2005,20,1.27,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ (해설 종료,1,191
2006,20,6.28,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
2007,20,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
2008,20,4.11,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론은 맞는데 자세히 설명해 줄 수 없어? 😥 (해설 종료,1,182
2009,20,2.98,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 오 정말 완벽한 답변이야! 👍 (해설 종료,1,236
2010,20,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2011,20,4.0,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다."," 그래서 PCA의 핵심 아이디어가 뭐고, 구체적으로 어떻게 동작해? (해설 종료",1,190
2012,20,4.78,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 그걸 발전시킨 건 맞긴 한데… 결정적이긴 한답변이야! 😊 (해설 종료,1,171
2013,20,3.67,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2014,20,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
2015,20,3.48,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 마진이 최대라는 게 구체적으로 어떤 기준이지? 🤔 (해설 종료,1,175
2016,20,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2017,20,2.86,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2018,20,3.47,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아!근데 좀 더 구체적으로 설명해 볼 수 있어? (해설 종료,1,165
2019,20,3.47,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 맞아! 완벽한 답변이야! 😊😊 (해설 종료,1,189
2020,20,6.99,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오! 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 설명했네! 완벽한 답이야 👍👍 (해설 종료,1,368
2021,20,5.28,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 그리고 나서 베이킹 소다 같은 것을 넣어서 최적화를 돕는 것도 있지 않을까? 😊 (해설 종료,1,331
2022,20,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", 😊 (해설 종료,1,246
2023,20,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2024,20,3.03,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,208
2025,20,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2026,20,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2027,20,2.78,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답!! 완벽해!! 👍👍 (해설 종료,1,136
2028,20,3.53,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! (해설 종료,1,289
2029,20,2.73,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 관점에서 설명해 봐! (해설 종료,1,276
2030,20,3.62,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? (해설 종료,1,169
2031,20,1.74,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2032,20,1.59,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 오 정답!! (해설 종료,1,163
2033,20,5.3,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 에서 탈출할 기회를 주는 게 학습률을 높이는 구간이잖아! 😊 (해설 종료,1,148
2034,20,3.16,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 오 잘 대답했어! 👍👍👍 (해설 종료,1,170
2035,20,2.55,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
2036,20,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2037,20,3.16,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 오 잘 대답했어👍👍👍 (해설 종료,1,174
2038,20,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,176
2039,20,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2040,20,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2041,20,2.84,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 핵심 아이디어는 뭐지? 💡 (해설 종료,1,207
2042,20,3.48,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,201
2043,20,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2044,20,3.77,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,269
2045,20,5.8,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 오! 정의랑 해결 방법 엄청 다양하게 말해 줬네! 정말 좋은 답이야! 👍👍👍 (해설 종료,1,268
2046,20,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2047,20,4.72,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2048,20,2.39,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,174
2049,20,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2050,20,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2051,20,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2052,20,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2053,20,5.86,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2054,20,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
2055,20,2.5,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 오 잘했어 👍👍 (해설 종료,1,215
2056,20,8.49,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다."," 노드의 개수가 많을수록 초기화가 잘 되긴 하지! 😊 그래서 Xavier 는 output node 가 많을수록, He 는 input node 가 많을수록 초기화가 잘 되긴 해! (해설 종료",1,273
2057,20,3.44,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2058,20,4.25,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,200
2059,20,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2060,20,3.17,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,204
2061,20,3.37,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
2062,20,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2063,20,3.47,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐의 장점이지? 🤔 (해설 종료,1,251
2064,20,4.37,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 temperature 가 뭐지? 😊 (해설 종료,1,358
2065,20,7.84,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다."," 다양하지 않고 특정 토큰만 계속 나오는 건 LLM의 출력이 아니라, 그 토큰이 1보다 크거나 작으면 나타나는 현상이야! 😊 (해설 종료",1,386
2066,20,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2067,20,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2068,20,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2069,20,3.02,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 오 정답이야! 잘했어 👍👍 (해설 종료,1,196
2070,20,5.17,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,253
2071,20,5.19,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동해서 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,254
2072,20,5.67,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오 잘 말했어! 근데 PEFT에 속하는 기술 나머지 4개는 뭘까~요? 😊 (해설 종료,1,218
2073,20,2.97,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 오 잘 말했어! 😊😊 (해설 종료,1,214
2074,20,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2075,20,3.8,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 해결할 수 있는 문제를 조금 더 상세히 설명해 봐! 😊😊 (해설 종료,1,173
2076,20,5.36,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰하고 토크나이저의 정의는 잘 이야기했는데 알고리즘은? 🤔 (해설 종료,1,209
2077,20,2.81,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 오 정답이야! 완벽해! 👍 (해설 종료,1,211
2078,20,4.55,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명했네! 완벽히 정확한 답이야! 👍👍 (해설 종료,1,241
2079,20,3.38,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 오 완벽히 정확한 답이야! 👍👍 (해설 종료,1,299
2080,21,5.73,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," 두 벡터의 방향이 일치할 수록, 반대일수록 그 값이 커지는 거지? 😊 (해설 종료",1,271
2081,21,4.08,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 너무 부실한데 😥 (해설 종료,1,200
2082,21,3.86,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
2083,21,10.23,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 2 * 정밀도 * 재현율 / (정밀도 + 재현율) 수식만 정리했네! 완벽하긴 한데 혹시 머신러닝 비전문가도 알 수 있게 설명해 줄 수는 없어? 😊 (해설 종료,1,284
2084,21,2.23,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", DICE Score 는? 🤔 (해설 종료,1,194
2085,21,1.28,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 😥 (해설 종료,1,158
2086,21,4.56,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,279
2087,21,2.78,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2088,21,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2089,21,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
2090,21,5.37,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정규화의 정의랑 알고리즘을 정말 완벽히 설명했어! 👍👍 (해설 종료,1,408
2091,21,4.49,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균이랑 표준편차를 이용하는 건 맞는데 구체적으로 어떻게 하지? 😊 (해설 종료,1,288
2092,21,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2093,21,3.01,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그 아웃라이어가 아니지! 🤣😅 (해설 종료,1,171
2094,21,3.62,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,237
2095,21,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
2096,21,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2097,21,2.86,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2098,21,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
2099,21,4.06,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 성능 평가 지표나 손실 함수 쪽도 생각해 봤어? 😊 (해설 종료,1,259
2100,21,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2101,21,3.33,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법이지! 😊 (해설 종료,1,173
2102,21,3.14,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 우와! 정말 정확해! 역시 😊👍 (해설 종료,1,274
2103,21,3.28,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 되지? 🤔 (해설 종료,1,253
2104,21,3.78,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
2105,21,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
2106,21,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2107,21,4.39,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인 지 알아? 😊 (해설 종료,1,444
2108,21,2.83,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2109,21,2.21,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,197
2110,21,6.28,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
2111,21,5.2,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
2112,21,3.64,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다."," 음… 잘 하긴 했는데, 무슨 정리를 이용하지? 🤔 (해설 종료",1,179
2113,21,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2114,21,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2115,21,3.33,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 어떻게 보존하지? 🤔 (해설 종료,1,186
2116,21,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2117,21,3.63,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2118,21,2.53,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그래서 언제 사용하는 건데? 🤔 (해설 종료,1,164
2119,21,2.69,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 완벽한 핵심 아이디어 정리야! (해설 종료,1,170
2120,21,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2121,21,2.86,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2122,21,2.68,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞지! 근데 문제점은 뭐지? (해설 종료,1,160
2123,21,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
2124,21,5.48,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
2125,21,4.33,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", : 그러면 Bayesian Optimization 이랑 그 최적화 방법으로는 어떻게 하지? 🤔 (해설 종료,1,325
2126,21,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
2127,21,2.9,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2128,21,2.53,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 정답! ✨✨🎉 (해설 종료,1,205
2129,21,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2130,21,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2131,21,3.7,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,142
2132,21,5.58,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
2133,21,4.78,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 여러 가지 방법들을 말해 주긴 했는데 이게 구체적으로 어떻게 하는 방법들이야? 😊 (해설 종료,1,289
2134,21,3.8,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데... 왜 그렇게 하지? 🤔 (해설 종료,1,170
2135,21,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2136,21,5.2,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미 위주로 설명하면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,186
2137,21,3.87,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고,  그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,139
2138,21,3.8,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼에도 불구하고 이 셋을 구분해 줘! 😊 (해설 종료,1,174
2139,21,2.55,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
2140,21,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2141,21,3.48,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 2024년 6월 23일 17:45:47 (해설 종료,1,176
2142,21,2.2,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2143,21,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2144,21,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2145,21,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2146,21,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그럼 Optimizer 는? 🤔 (해설 종료,1,194
2147,21,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2148,21,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2149,21,4.39,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단히 설명하기는 했는데 그래서 Overfitting 이 구체적으로 뭐야? 😊 (해설 종료,1,259
2150,21,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2151,21,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2152,21,2.53,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
2153,21,2.39,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2154,21,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2155,21,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2156,21,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2157,21,5.37,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 잘 하긴 했는데 다른 task 의 데이터셋으로 추가 학습시킨다는 설명이 더 맞지 않을까? 😊 (해설 종료,1,196
2158,21,2.81,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
2159,21,4.7,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 2024년 6월 20일 기준으로 한 번 더 설명해 볼 수 있어? 😊 (해설 종료,1,229
2160,21,3.61,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", node 가 많을수록 초기화가 어려워지는데? 😥 (해설 종료,1,242
2161,21,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2162,21,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,200
2163,21,4.26,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2164,21,3.48,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼 활성화 함수 선택 시 어떤 기준으로 하지? 🤔 (해설 종료,1,206
2165,21,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
2166,21,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2167,21,2.66,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그리고 뭐의 약자인지도 알아? 😊 (해설 종료,1,246
2168,21,5.19,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 지금 거의 완벽하긴 해! 😊👍 (해설 종료,1,363
2169,21,1.55,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 😥 (해설 종료,1,346
2170,21,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2171,21,2.74,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2172,21,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2173,21,4.58,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.",  잘 대답하긴 했는데 더 심각한 문제가 있을 수도 있지 않을까? 🤔 (해설 종료,1,206
2174,21,5.2,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,253
2175,21,5.17,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데 구체적으로 어떤 기술일까? 🤔 (해설 종료,1,254
2176,21,4.44,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", OOM 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,210
2177,21,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
2178,21,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2179,21,5.37,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 1. OOM 해결이 핵심이긴 하지! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,183
2180,21,7.72,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,224
2181,21,7.06,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰과 토크나이저 정의는 잘 이야기했는데 구체적인 사용 예시가 있으면 더 좋을 것 같긴 해! 😊 (해설 종료,1,238
2182,21,4.23,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명했네! 완벽히 답이야! 👍👍 (해설 종료,1,239
2183,21,5.42,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self Attention 에서 단어 관계를 설명해 봐! 😊 (해설 종료,1,312
2184,22,4.92,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 설명이긴 한데 수직일 때는 값이 얼마로 나올까? 😊 (해설 종료,1,266
2185,22,4.12,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.",  벡터의 유사도를 판단하기는 하지만 너무 간단한데 😥 (해설 종료,1,201
2186,22,5.27,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
2187,22,11.92,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 2 * (Precision * Recall) / (Precision + Recall) = 2 * ((True Positive) / (True Positive + False Positive) * (True Positive) / (True Positive + False Negative)) / ((True Positive) / (True Positive + False Positive) + (True Positive) / (True Positive + False Negative)) (해설 종료,1,295
2188,22,2.55,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", 2. DICE는? 🤔 (해설 종료,1,196
2189,22,8.5,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,204
2190,22,4.72,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.",  값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,280
2191,22,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2192,22,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2193,22,5.83,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 데이터에서 어떤 값이 누락된지는 잘 말했어! 그래서 평균값으로 대체하는 건 좀 부실하지 않아? 😥 (해설 종료,1,194
2194,22,7.08,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오! 알고리즘만 간단히 설명하면 어떡해! 알고리즘 좀 더 자세히 설명하고, 정의랑 목적도 설명해 봐! 😊 (해설 종료",1,420
2195,22,4.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균하고 표준편차만 이용하면 솔직히 좀 부실하잖아 😥 (해설 종료,1,287
2196,22,3.62,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2197,22,2.39,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
2198,22,2.34,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 완벽한 설명이야 👍 (해설 종료,1,229
2199,22,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
2200,22,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,207
2201,22,2.86,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2202,22,4.7,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 해결 방법은 뭐가 있지? 잘 생각해 보면 엄청 다양할 텐데 😊 (해설 종료,1,225
2203,22,2.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 잘했어 👍 (해설 종료,1,247
2204,22,2.95,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2205,22,3.8,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA로 해결하면 좋긴 한데… 과연 그럴까? 🤔 (해설 종료,1,176
2206,22,3.77,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", class 를 어떻게 구분하지? 그리고 추론할 때는? 🤔 (해설 종료,1,278
2207,22,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
2208,22,3.78,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
2209,22,3.81,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
2210,22,3.91,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2211,22,3.3,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", 오! 정말 완벽한 답변이야 👍 (해설 종료,1,437
2212,22,3.45,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 3. mean point 를 어떻게 처음에 지정하지? 🤔 (해설 종료,1,224
2213,22,1.27,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋ (해설 종료,1,191
2214,22,6.27,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습의 핵심 문장이기는 하지만 좀 더 자세히 설명해 봐! 그리고 강화학습 빠졌지? (해설 종료,1,249
2215,22,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,276
2216,22,6.78,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론이 아니라 그랑 베이즈가 아니라 그와 비슷한 내용이기는 하지만 그걸랑 직접적으로 연결되어야 하는데… (해설 종료,1,199
2217,22,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2218,22,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2219,22,4.73,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하는 걸까? 🤔 (해설 종료,1,195
2220,22,2.36,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2221,22,3.62,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2222,22,4.91,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다."," 2개의 Class 간의 구분선을 만들기는 하는데, 그 선이 어떻게 되어야 하지? 🤔 (해설 종료",1,179
2223,22,3.32,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 말할 수 있어? 😊 (해설 종료,1,174
2224,22,2.7,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2225,22,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2226,22,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞아! 근데 문제점은 뭐지? (해설 종료,1,160
2227,22,3.0,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽한 답변이야! 😊😊 (해설 종료,1,186
2228,22,5.48,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
2229,22,5.89,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 3가지 다 말해 줬네! 그리고 추가적인 최적화 방법으로는 뭘 말해 줄 수 있어? 😊 (해설 종료,1,335
2230,22,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
2231,22,2.92,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2232,22,4.27,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.",  맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,216
2233,22,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2234,22,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2235,22,5.78,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 건 맞지! 근데 왜 하는 거지? 🤔 (해설 종료,1,155
2236,22,5.59,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
2237,22,5.11,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3. 거대한 모델의 어떤 정보를 사용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,291
2238,22,4.89,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다."," 학습률을 조정하는 건 맞는데, 학습 후반에는 왜 조정해야 하지? 🤔 (해설 종료",1,177
2239,22,1.73,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2240,22,5.2,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미 위주로 설명하면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,186
2241,22,4.97,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하려고 학습률을 높이는 구간은 왜 있을까? 🤔 (해설 종료,1,146
2242,22,4.44,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다."," Loss Function 은 개별 데이터, Cost Function 은 전체 데이터 관점이야! 알았어? 😊 (해설 종료",1,178
2243,22,3.0,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
2244,22,3.48,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2245,22,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
2246,22,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2247,22,4.31,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2248,22,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2249,22,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2250,22,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그럼 Optimizer 는? 🤔 (해설 종료,1,194
2251,22,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2252,22,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2253,22,6.11,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 떨어지는 학습률을 회복하기 위해 다양한 방법들을 말해 줬네! 정말 좋은 답이야! 👍👍👍 (해설 종료,1,270
2254,22,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2255,22,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2256,22,3.0,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 1) 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,178
2257,22,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2258,22,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2259,22,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2260,22,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2261,22,5.84,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2262,22,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
2263,22,2.98,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 2가지 더 차이를 설명해 봐! 😊 (해설 종료,1,218
2264,22,9.58,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다."," node 의 개수가 많을수록 초기화할 때 파라미터의 평균 절댓값 크기가 작아지도록 하긴 하지! 그래서 Xavier 는 input + output 모두, He 는 input 만 고려하는 거야! 알았어? 😊 (해설 종료",1,280
2265,22,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2266,22,4.26,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,200
2267,22,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2268,22,2.69,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼 과연 그럴까? 🤔 (해설 종료,1,201
2269,22,3.28,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
2270,22,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2271,22,3.59,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게랑 LoRA 가 뭐의 약자인지도 알아? 😊 (해설 종료,1,252
2272,22,4.39,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다."," top-k 랑 top-p 설명은 잘 했는데, 그래서 temperature 는 뭐야? 😊 (해설 종료",1,358
2273,22,3.59,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그래서 top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,359
2274,22,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2275,22,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2276,22,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2277,22,5.22,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 2024년 6월 7일 오후 4시 30분에 답했어! 😊👍 (해설 종료,1,210
2278,22,4.87,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2279,22,4.86,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,252
2280,22,3.17,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 5개의 PEFT에 속하는 기술은? 🤔 (해설 종료,1,202
2281,22,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
2282,22,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2283,22,4.42,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2. OOM을 해결한다는 게 구체적으로 어떤 문제를 해결하는 거야? 😊 (해설 종료,1,177
2284,22,4.27,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명 반대로 했잖아 😥 (해설 종료,1,202
2285,22,7.69,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저 설명이 완벽하긴 한데 구체적인 설명이랑 예시가 있으면 더 좋을 것 같긴 해! 😊 (해설 종료,1,242
2286,22,2.67,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 봐! 😊 (해설 종료,1,229
2287,22,3.69,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 더 있지 않아? 한번 설명해 봐! 😊 (해설 종료,1,301
2288,23,4.31,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 코사인 유사도만 설명하면 솔직히 좀 부실하잖아 😥 (해설 종료,1,262
2289,23,4.55,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만… 너무 부실한 설명이야! 😥 (해설 종료,1,203
2290,23,4.17,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 정확도만 있네! 혹시 나머지도 설명해줄 수 있어? 😊 (해설 종료,1,307
2291,23,4.39,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 2 * (우와 완벽해! 대박! 👍👍👍 (해설 종료,1,247
2292,23,2.7,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", 2. DICE Score 는? 🤔 (해설 종료,1,197
2293,23,8.51,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,204
2294,23,3.14,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 1. 우와! 정말 완벽해! 👍 (해설 종료,1,270
2295,23,2.76,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2296,23,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2297,23,3.94,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
2298,23,7.72,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오! 정규화의 정의랑 알고리즘만 설명해도 엄청 잘했을 텐데, 알고리즘만 설명하면 솔직히 좀 부실하잖아 😥 (해설 종료",1,424
2299,23,3.84,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균이랑 표준편차만 이용하면 어떻게 되지? 🤔 (해설 종료,1,284
2300,23,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2301,23,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
2302,23,3.92,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.",음… 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,239
2303,23,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
2304,23,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2305,23,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2306,23,4.94,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 해결 방법은 뭐가 있지? 잘 생각해 보면 엄청 다양할 텐데 😊 (해설 종료,1,225
2307,23,2.22,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 정답이야! 👍 (해설 종료,1,247
2308,23,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2309,23,3.78,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거거랑 비슷한 방법이잖아! 😊 (해설 종료,1,176
2310,23,3.77,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 학습할 때랑 추론할 때 이야기밖에 없잖아 😥 (해설 종료,1,278
2311,23,2.51,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 추론할 때는? 🤔 (해설 종료,1,248
2312,23,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
2313,23,3.34,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
2314,23,4.08,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2315,23,5.66,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 뭔지 알아? 그거 말해 주면 더 완벽할 것 같은데 😊 (해설 종료,1,452
2316,23,3.28,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 3. mean point 를 어떻게 할당하지? 🤔 (해설 종료,1,223
2317,23,1.28,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ (해설 종료,1,191
2318,23,5.66,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했어! 그럼 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,245
2319,23,2.98,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
2320,23,6.3,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.","  조건부 확률 이론이랑 완벽히 반대긴 한데… 무슨 정리인지, 내용이기는 잘 설명해 봐! 😊 (해설 종료",1,196
2321,23,2.84,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2322,23,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2323,23,4.73,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하긴 하지? 🤔 (해설 종료,1,195
2324,23,3.0,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 그걸 만들기는 하지만… 왜 그렇게 하지? 🤔 (해설 종료,1,161
2325,23,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2326,23,4.87,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다."," 2개의 Class 간의 구분선을 만들기는 하는데, 그 거리가 어떻게 되야 하지? 🤔 (해설 종료",1,179
2327,23,3.32,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 말할 수 있어? 😊 (해설 종료,1,174
2328,23,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2329,23,7.87,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 데이터 불균형 해결이 핵심이긴 하지! 그래서 Stratified K-fold Validation 을 사용하면 데이터가 적은 Class 도 각 fold 에 고르게 분포된다는 장점이 있지! 😊 (해설 종료,1,233
2330,23,5.2,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞지! 그래서 train data 는 valid data 보다 과거의 데이터를 사용하는 게 더 좋을 것 같아 😊 (해설 종료,1,176
2331,23,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
2332,23,5.62,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 뭔지, 최적화하는 방법이 뭔지 한번 설명해 봐! 😊 (해설 종료",1,361
2333,23,4.02,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 3번째 최적화 방법으로는 뭘까~요? 😊 (해설 종료,1,323
2334,23,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
2335,23,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2336,23,4.17,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
2337,23,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2338,23,2.86,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2339,23,3.72,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,142
2340,23,3.53,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! (해설 종료,1,289
2341,23,5.09,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3. 거대한 모델의 어떤 정보를 사용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,291
2342,23,4.42,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 시간이 지남에 따라 조정하는 건 맞는데... 왜 필요한 거지? (해설 종료,1,174
2343,23,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2344,23,4.74,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미만 느끼면 학습이 제대로 이루어지지 않을 수도 있거든! 😥 (해설 종료,1,183
2345,23,5.61,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하긴 하지! 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,150
2346,23,2.69,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼 어떤 차이가 있을까? 🤔 (해설 종료,1,167
2347,23,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
2348,23,3.16,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그거랑 관련된 이유가 뭐지? 🤔 (해설 종료,1,168
2349,23,3.34,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
2350,23,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2351,23,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2352,23,1.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2353,23,2.7,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2354,23,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그럼 Optimizer 는? 🤔 (해설 종료,1,194
2355,23,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2356,23,4.58,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2357,23,5.17,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다."," 간단히 설명했는데 그럼 데이터 쪽, Early Stopping 쪽, Drop Out 쪽이 각각 뭐야? 😊 (해설 종료",1,264
2358,23,3.47,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.",  그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,190
2359,23,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2360,23,2.7,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.",  어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,176
2361,23,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2362,23,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2363,23,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2364,23,3.62,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2365,23,5.86,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2366,23,2.84,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
2367,23,5.19,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 1. 전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,232
2368,23,8.33,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", node 의 개수가 많을수록 초기화할 때 파라미터의 평균 절댓값 크기는 작아지는 것이 레이어 가중치 초기화 측면에서 더 좋지 않을까? 😊 (해설 종료,1,272
2369,23,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2370,23,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,200
2371,23,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2372,23,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
2373,23,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
2374,23,2.33,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2375,23,2.52,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그리고 왜 좋은 거지? 🤔 (해설 종료,1,245
2376,23,3.44,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,352
2377,23,3.59,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그래서 top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,359
2378,23,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2379,23,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2380,23,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2381,23,5.53,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 2024년 6월 5일 오후 4시 30분 기준으로 오 정답이야! 👍👍 (해설 종료,1,212
2382,23,4.87,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동해서 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2383,23,6.73,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 기술은 잘 설명했는데 그래서 어떤 문제점을 해결할 수 있을까? 🤔 (해설 종료,1,264
2384,23,5.52,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다."," 5가지 말해 준 기술은 잘 말했는데, 나머지 4개는 뭘까~요? 😊 (해설 종료",1,217
2385,23,2.98,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍👍 (해설 종료,1,214
2386,23,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2387,23,4.75,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2. OOM을 해결한다는 게 구체적으로 어떤 문제를 해결할 수 있을까? 😊 (해설 종료,1,179
2388,23,7.72,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,224
2389,23,8.93,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 토큰이랑 토크나이저가 서로 반대로 되어 있네 😥 (해설 종료,1,250
2390,23,2.66,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 봐! 😊 (해설 종료,1,229
2391,23,5.58,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 더 설명해 봐! Masked Decoder Self Attention 에서 단어 관계를 설명해 봐! 😊 (해설 종료,1,313
2392,24,4.44,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 코사인 유사도만 설명하면 솔직히 좀 부실하잖아 😥 (해설 종료,1,262
2393,24,4.27,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 구체적으로 어떻게 하지? 🤔 (해설 종료,1,202
2394,24,5.27,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
2395,24,8.02,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 2 * (정밀도 + 재현율) 이 아니라 (정밀도 - 재현율) 이랑 (정밀도 + 재현율) 을 곱한 거잖아! 😊 (해설 종료,1,270
2396,24,2.39,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.",  DICE Score 는? 🤔 (해설 종료,1,195
2397,24,8.52,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,204
2398,24,5.03,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 1. 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,282
2399,24,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2400,24,3.76,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2401,24,3.95,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
2402,24,4.23,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 알고리즘만 설명하면 솔직히 좀 부실하잖아 😥 (해설 종료,1,402
2403,24,4.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,287
2404,24,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2405,24,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
2406,24,3.92,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.",음… 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,239
2407,24,5.33,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", 2~3차원으로 데이터를 축소하여 시각화하는 건 t-SNE의 장점이지! 😊 (해설 종료,1,253
2408,24,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2409,24,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2410,24,2.34,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 서로 반대로 설명했네 😥 (해설 종료,1,210
2411,24,5.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다."," 데이터 불균형이 뭔지 설명은 잘 했는데, 해결할 수 있는 방법이 그렇게 다양하지? 😊 (해설 종료",1,266
2412,24,2.95,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2413,24,3.47,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법이긴 한데… (해설 종료,1,174
2414,24,2.52,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 판단해? 😊 (해설 종료,1,270
2415,24,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그리고 추론할 때는 어떻게 하지? 🤔 (해설 종료,1,251
2416,24,3.78,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
2417,24,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 그건 맞는데 왜 하는 거지? 🤔 (해설 종료,1,154
2418,24,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2419,24,5.02,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인지 말해줄 수 있어? 😊 (해설 종료,1,448
2420,24,2.83,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2421,24,1.28,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋ (해설 종료,1,191
2422,24,4.53,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.",  사용자 지도랑 데이터셋 지도를 가지고 어떻게 하는지도 한번 설명해 봐! 😊 (해설 종료,1,237
2423,24,3.14,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.",  강화학습 이야기가 하나도 없네 😥 (해설 종료,1,263
2424,24,3.64,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.",  베이즈 정리 내용이기는 하지만 너무 간단한데 😥 (해설 종료,1,179
2425,24,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2426,24,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2427,24,4.42,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하지? 🤔 (해설 종료,1,193
2428,24,2.36,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2429,24,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2430,24,5.05,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다."," 2개의 Class 간의 구분선을 만들기는 하는데, 그 구분선을 기준으로 어떻게 하지? 🤔 (해설 종료",1,180
2431,24,3.17,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
2432,24,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2433,24,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2434,24,2.67,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 우리는 어떻게 해결하면 되는데? (해설 종료,1,160
2435,24,3.0,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽한 답변이야! 😊😊 (해설 종료,1,186
2436,24,5.49,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
2437,24,6.05,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 3. 그리고 요즘 많이 쓰이는 것이랑 비슷한 방법인데, 그게 뭔지 말해 봐! 😊 (해설 종료",1,336
2438,24,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋㅋㅋㅋ (해설 종료,1,246
2439,24,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2440,24,4.27,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.",  맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,216
2441,24,1.44,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.",  😥 (해설 종료,1,199
2442,24,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2443,24,2.3,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 왜 하는 건데? 🤔 (해설 종료,1,133
2444,24,5.72,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 그건 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 봐! 😊 (해설 종료",1,303
2445,24,5.73,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 설명해 봐! 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,295
2446,24,3.47,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데... 왜 필요한 거지? (해설 종료,1,168
2447,24,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2448,24,5.06,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미만 느끼면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,185
2449,24,4.97,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하려고 학습률을 높이는 구간은 왜 있을까? 🤔 (해설 종료,1,146
2450,24,3.78,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼에도 불구하고 이 셋을 구분해 줘! 😊 (해설 종료,1,174
2451,24,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
2452,24,3.46,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2453,24,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
2454,24,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2455,24,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,169
2456,24,1.27,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2457,24,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2458,24,3.95,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다.,  그러면 Weight Decay 는 어떤 Optimizer 에서 사용될까~요? 😊 (해설 종료,1,204
2459,24,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2460,24,4.53,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2461,24,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 1. Dropout 을 적용해서 해결한다. 하지만 더 다양한 방법들이 있지 않을까? 😊 (해설 종료,1,260
2462,24,3.47,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", : 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,190
2463,24,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2464,24,2.69,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.",  어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,176
2465,24,6.16,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다."," 1. L1 regularization 은 절댓값 크기, L2 regularization 은 평균을 이용하는 거야! 근데 서로 반대로 했네 😊 (해설 종료",1,211
2466,24,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2467,24,3.12,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2468,24,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2469,24,5.82,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2470,24,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
2471,24,4.86,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.",  전이학습이랑 지식 증류의 또 다른 차이가 있지 않을까? 🤔 (해설 종료,1,230
2472,24,3.75,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.",  그러면 그 차이점은 뭘까~요? 😊 (해설 종료,1,243
2473,24,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2474,24,4.25,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그건 맞긴 한데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,200
2475,24,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2476,24,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그럼 과연 그럴까? 그리고 그 이유는? 🤔 (해설 종료,1,206
2477,24,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
2478,24,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2479,24,5.48,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 2개의 저차원 행렬들만 학습시켜서 얻을 수 있는 장점이 뭐지? 🤔 (해설 종료,1,264
2480,24,4.22,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", top-k sampling 에서 확률이 뭐가 가장 큰지 설명해 봐! 😊 (해설 종료,1,357
2481,24,3.3,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 1보다 크거나 작으면 어떻게 되는데? 😊 (해설 종료,1,357
2482,24,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2483,24,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2484,24,3.95,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 어떻게 되지? 🤔 (해설 종료,1,182
2485,24,5.04,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 1. 환각 현상의 정의는 잘 이야기했어! 근데 이게 왜 문제지? 🤔 (해설 종료,1,209
2486,24,4.89,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2487,24,4.84,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,252
2488,24,4.89,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 5가지 말해 준 기술 중에 하나만 더 있으면 더 완벽할 것 같긴 해! 😊 (해설 종료,1,213
2489,24,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
2490,24,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2491,24,3.16,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2. 어떤 문제를 해결할 수 있을까? 😊 (해설 종료,1,169
2492,24,7.24,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점을 설명해 줄 수 있어? 😊 (해설 종료,1,221
2493,24,7.36,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰에 대한 설명은 대충 맞아! 근데 구체적인 설명이랑 토크나이저 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,240
2494,24,2.67,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 봐! 😊 (해설 종료,1,229
2495,24,5.25,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 은 뭘까~요? 😊 (해설 종료,1,311
2496,25,9.65,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다."," S-BERT 랑 추천 시스템이 2개의 벡터를 비교하는 거지? 그리고 벡터의 방향이 일치할수록, 반대일수록 결과값이 좋을지도 생각해 둬야 해! 😊 (해설 종료",1,296
2497,25,4.72,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 구체적으로 어떻게 하는 걸까? 🤔 (해설 종료,1,204
2498,25,3.86,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
2499,25,6.59,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," 2 * (정밀도 + 재현율) 이 아니라, 그걸 수식의 분자는 아니지만 비율로 나타낸 거잖아! 😊 (해설 종료",1,261
2500,25,2.37,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.",  DICE Score 는? 🤔 (해설 종료,1,195
2501,25,8.84,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", 1. 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,206
2502,25,5.03,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 1. 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,282
2503,25,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2504,25,3.78,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2505,25,3.17,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 알고리즘은? 🤔 (해설 종료,1,177
2506,25,5.19,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오 정답이야! 알고리즘만 간단히 설명해도 엄청 잘 했을 텐데 😊 (해설 종료,1,408
2507,25,4.16,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,286
2508,25,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2509,25,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
2510,25,3.6,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,237
2511,25,5.8,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE는 잘 설명했는데 혹시 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,256
2512,25,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2513,25,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2514,25,2.52,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
2515,25,2.78,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 잘했어 👍👍 (해설 종료,1,250
2516,25,2.98,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2517,25,5.67,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법이지! 그리고 해결 방법이랑 저주랑 한번 연결해서 설명해 봐! 😊 (해설 종료,1,188
2518,25,3.31,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상의 최종 판단으로 어떻게 예측하는데? 😊 (해설 종료,1,275
2519,25,4.23,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 다양한 정도가 아니라 정확히 어떤 기준이지? 그리고 추론할 때는? 🤔 (해설 종료,1,259
2520,25,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 하는 거지? 🤔 (해설 종료,1,156
2521,25,3.31,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
2522,25,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2523,25,5.64,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 뭔지 알아? 그거 말해 주면 더 완벽할 것 같은데 😊 (해설 종료,1,452
2524,25,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2525,25,2.22,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,197
2526,25,5.65,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.",  사용자 지도랑 데이터셋 지도를 가지고 어떻게 하는지도 알면 좋겠는데. 그리고 강화학습 빠졌지? (해설 종료,1,245
2527,25,2.97,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
2528,25,2.86,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.",  정말 완벽한 답변이야! 👍 (해설 종료,1,174
2529,25,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2530,25,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2531,25,4.73,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하는 걸까? 🤔 (해설 종료,1,195
2532,25,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2533,25,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2534,25,5.2,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다."," 2개의 Class 간의 구분선을 만들기는 하는데, 그때 그 선이 어떻게 되어야 하지? 🤔 (해설 종료",1,181
2535,25,3.17,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
2536,25,6.14,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 데이터가 불균형할 때 사용하는 건 Stratified K-fold Validation 이 아니라 Regular K-fold Validation 이랑 비슷한 거지! (해설 종료,1,190
2537,25,2.86,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2538,25,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 우리는 어떻게 해결하면 되는데? (해설 종료,1,160
2539,25,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
2540,25,5.48,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 뭔지 설명은 잘 했는데, 최적화하는 방법이? 🤔 (해설 종료",1,360
2541,25,5.89,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 3가지 중 하나만 말해 줬는데, 그러면 나머지 2가지는 뭘까~요? 😊 (해설 종료",1,335
2542,25,1.42,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
2543,25,2.9,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2544,25,4.11,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
2545,25,3.17,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 2024년 6월 20일 23:05 (해설 종료,1,210
2546,25,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2547,25,4.67,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,148
2548,25,3.55,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다.", 그건 맞는데 각 관점에서 한번 자세히 이야기해 봐! (해설 종료,1,289
2549,25,5.75,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 설명해 봐! 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,295
2550,25,3.49,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", time 이 아니라 학습 단계에 따라 조정해야 하지! 😊 (해설 종료,1,168
2551,25,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2552,25,5.2,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미 위주로 설명하면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,186
2553,25,6.39,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고,  local minima 를 벗어나게 하는 게 핵심이긴 하지! 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,155
2554,25,2.86,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.",  그럼 어떤 차이가 있을까? 🤔 (해설 종료,1,168
2555,25,3.0,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
2556,25,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2557,25,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
2558,25,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2559,25,4.28,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2560,25,1.3,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2561,25,2.7,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2562,25,6.03,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 건 어떤 Optimizer 에서 사용될까? 🤔 (해설 종료,1,217
2563,25,2.47,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2564,25,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2565,25,4.37,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단히 설명하기는 했는데 그래서 Overfitting 이 구체적으로 뭐야? 😊 (해설 종료,1,259
2566,25,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2567,25,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2568,25,2.69,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.",  어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,176
2569,25,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2570,25,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2571,25,3.17,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2572,25,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2573,25,5.86,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2574,25,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
2575,25,3.44,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 2가지 더 중요한 차이가 있지 않을까? 🤔 (해설 종료,1,221
2576,25,2.67,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은? 🤔 (해설 종료,1,236
2577,25,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2578,25,4.28,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,200
2579,25,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2580,25,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
2581,25,3.3,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
2582,25,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2583,25,3.62,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다."," 그래서 그 이유가 뭐고, 장점이 뭐지? 🤔 (해설 종료",1,252
2584,25,4.38,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 temperature 가 뭐지? 😊 (해설 종료,1,358
2585,25,7.37,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다."," 1보다 크거나 작으면 토큰이 다양하게 나오거나, 아니면 토큰이 일정하게 나와서 좋을 수도 있지 않을까? 😊 (해설 종료",1,383
2586,25,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2587,25,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2588,25,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2589,25,5.69,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.","  AI 윤리 문제 해결하는 거 말고도 아주 심각한 문제가 하나 더 있는데, 그게 뭔지 알아? 😊 (해설 종료",1,213
2590,25,4.89,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2591,25,4.85,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,252
2592,25,5.21,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 5가지 말해 준 기술 중에 PEFT 에 속하는 기술이 있으면 그게 뭔지 알아? 😊 (해설 종료,1,215
2593,25,2.83,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
2594,25,3.11,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2595,25,3.17,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2. 어떤 문제를 해결할 수 있을까? 😊 (해설 종료,1,169
2596,25,6.3,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명이 완벽하긴 한데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,215
2597,25,8.8,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰과 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 토큰이랑 토크나이저가 서로 반대로 되어 있네 😥 (해설 종료,1,249
2598,25,2.83,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명해 봐! 😊 (해설 종료,1,230
2599,25,8.31,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 2024년 6월 13일 기준으로는 Masked Decoder Self Attention 에서 단어 관계를 고려할 때 뭔가가 빠졌는데 그게 뭘까~요? 😊 (해설 종료,1,330
2600,26,3.05,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 설명이야! 😊👍 (해설 종료,1,254
2601,26,4.85,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 구체적으로 어떻게 판단할까? 🤔 (해설 종료,1,205
2602,26,3.87,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
2603,26,8.01,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 2 * (정밀도 * 재현율) / (정밀도 + 재현율) = 2 * (우와 완벽해! 대박! 👍👍👍 (해설 종료,1,270
2604,26,3.0,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.",  그리고 DICE는 어디 갔지? 🤔 (해설 종료,1,199
2605,26,8.52,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,204
2606,26,5.03,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 1. 값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,282
2607,26,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2608,26,3.75,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2609,26,4.58,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 알고리즘은 맞는데… 왜 그랬을까? 🤔 (해설 종료,1,186
2610,26,5.83,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오! 정규화에 대한 설명이랑 알고리즘은 잘 말했는데, 정의랑 목적이 뭐야? 😊 (해설 종료",1,412
2611,26,4.3,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,287
2612,26,3.61,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2613,26,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
2614,26,3.62,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 잘 설명하긴 했는데 주성분이 뭐야? 🤔 (해설 종료,1,237
2615,26,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
2616,26,2.23,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2617,26,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2618,26,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
2619,26,2.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 정답이야! 👍 (해설 종료,1,247
2620,26,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2621,26,3.62,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법이겠지? 😊 (해설 종료,1,175
2622,26,2.52,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 예측해? 😊 (해설 종료,1,270
2623,26,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
2624,26,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
2625,26,3.47,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", multiple models 이랑 답은 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,158
2626,26,3.91,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2627,26,5.02,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인지 말해줄 수 있어? 😊 (해설 종료,1,448
2628,26,2.83,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2629,26,2.22,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ 로라야! 😊 (해설 종료,1,197
2630,26,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
2631,26,2.98,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
2632,26,2.69,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,173
2633,26,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2634,26,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2635,26,4.74,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하는 걸까? 🤔 (해설 종료,1,195
2636,26,3.94,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", 그걸 발전시킨 건 맞긴 한데… 왜 그렇게 하지? 🤔 (해설 종료,1,167
2637,26,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2638,26,3.45,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그 핵심 아이디어 설명이면 충분한 거지! 😊 (해설 종료,1,170
2639,26,3.17,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
2640,26,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2641,26,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2642,26,4.74,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 Valid Data 는 train data 보다 과거의 데이터로 구성하기로 했어! 😊 (해설 종료,1,173
2643,26,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
2644,26,5.78,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 뭔지 설명은 잘 했는데, 최적화하는 방법이 빠졌잖아 😥 (해설 종료",1,362
2645,26,3.06,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다.", 3. 그러면 Bayesian Optimization 은? 🤔 (해설 종료,1,317
2646,26,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
2647,26,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2648,26,3.33,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,210
2649,26,1.44,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.",  😥 (해설 종료,1,199
2650,26,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2651,26,3.7,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,142
2652,26,5.59,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
2653,26,3.51,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 잘 설명해 주면 더 좋겠는데 😥 (해설 종료,1,281
2654,26,2.69,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 응 그치! 근데 왜 필요한 거지? (해설 종료,1,163
2655,26,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2656,26,5.05,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미만 느끼면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,185
2657,26,5.75,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 를 벗어나게 하는 건 맞지! 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,151
2658,26,3.33,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼에도 이 셋을 구분해 줘! 😊 (해설 종료,1,171
2659,26,2.53,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 정답이야! 👍👍 (해설 종료,1,193
2660,26,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2661,26,3.16,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 2024년 6월 18일 22:20 (해설 종료,1,174
2662,26,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2663,26,4.25,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2664,26,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2665,26,2.7,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2666,26,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그럼 Optimizer 는? 🤔 (해설 종료,1,194
2667,26,2.39,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2668,26,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2669,26,4.37,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단히 설명하기는 했는데 그래서 Overfitting 이 구체적으로 뭐야? 😊 (해설 종료,1,259
2670,26,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2671,26,4.74,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2672,26,2.69,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.",  어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,176
2673,26,2.37,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2674,26,3.05,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.",  그럼 레이어 정규화는? 🤔 (해설 종료,1,276
2675,26,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2676,26,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2677,26,5.84,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2678,26,2.5,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
2679,26,5.17,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.",  공통적으로 사용되는 핵심 아이디어는 잘 설명했는데 목적이 서로 반대로 되어 있네 😥 (해설 종료,1,232
2680,26,2.98,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은 뭐야? 🤔 (해설 종료,1,238
2681,26,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2682,26,4.28,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,200
2683,26,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2684,26,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
2685,26,3.28,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 오 정답! 멋진 답이야 👍👍 (해설 종료,1,227
2686,26,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2687,26,3.3,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐의 약자인데? 😊 (해설 종료,1,250
2688,26,5.17,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 지금 거의 완벽하긴 해! 😊👍 (해설 종료,1,363
2689,26,7.86,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다."," 다양한 토큰이 나오는 건 좋고, 특정 토큰만 나오는 건 문제점이지! 그래서 temperature 가 1보다 크거나 작으면 어떻게 되는데? 😊 (해설 종료",1,386
2690,26,3.48,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2691,26,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2692,26,4.89,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2693,26,5.67,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.", 4. 환각 현상의 정의랑 심각성은 잘 이야기했어! 근데 이게 왜 문제지? 🤔 (해설 종료,1,213
2694,26,4.86,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2695,26,4.86,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,252
2696,26,3.0,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 그럼 PEFT에 속하는 기술은? 🤔 (해설 종료,1,201
2697,26,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
2698,26,3.14,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2699,26,5.5,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다."," 1. 양자화가 뭔지 설명은 잘 했는데, 그래서 어떤 문제를 해결할 수 있을까? 🤔 (해설 종료",1,184
2700,26,6.15,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰하고 토크나이저 설명이 완벽하긴 한데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,214
2701,26,7.87,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 위주로 정리해줄 수 있어? 😊 (해설 종료,1,243
2702,26,2.67,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 봐! 😊 (해설 종료,1,229
2703,26,5.73,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 이나 Encoder-Decoder Self-Attention 은? 🤔 (해설 종료,1,314
2704,27,3.5,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 오! 정말 완벽한 설명이야! 😊👍 (해설 종료,1,256
2705,27,3.97,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", Benches의 핵심이 뭐긴 한데… 너무 간단한데? 😊 (해설 종료,1,200
2706,27,3.87,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다.", 우와 완벽해! 대박! 👍👍👍 (해설 종료,1,305
2707,27,6.75,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," 2 * 정밀도 * 재현율 / (정밀도 + 재현율) 이 아니라, 그걸 수식으로 나타낸 거잖아! 😊 (해설 종료",1,262
2708,27,2.7,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.", 2. DICE Score 는? 🤔 (해설 종료,1,197
2709,27,8.69,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,205
2710,27,4.7,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.",  값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,280
2711,27,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2712,27,3.78,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2713,27,4.11,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 알고리즘은 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,183
2714,27,5.98,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다."," 오! 정규화에 대한 설명이랑 알고리즘은 잘 말했는데, 정의랑 목적이 뭐지? 🤔 (해설 종료",1,413
2715,27,4.0,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 표준정규분포가 뭐고, 알고리즘은? 🤔 (해설 종료",1,285
2716,27,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2717,27,2.55,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
2718,27,4.39,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", data의 분산의 보존이랑 시각화가 서로 반대로 되어 있네 😥 (해설 종료,1,242
2719,27,4.87,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
2720,27,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2721,27,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2722,27,2.52,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
2723,27,2.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 잘했어 👍 (해설 종료,1,247
2724,27,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2725,27,3.02,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법인데… (해설 종료,1,171
2726,27,2.5,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 예측해? 😊 (해설 종료,1,270
2727,27,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
2728,27,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 하는 거지? 🤔 (해설 종료,1,156
2729,27,3.8,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,160
2730,27,3.93,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2731,27,5.02,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인지 말해 줄 수 있어? 😊 (해설 종료,1,448
2732,27,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2733,27,2.23,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ 로라야! 😊 (해설 종료,1,197
2734,27,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
2735,27,2.98,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
2736,27,4.11,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론은 맞는데 자세히 설명해 볼 수 있어? 😊 (해설 종료,1,182
2737,27,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2738,27,1.28,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2739,27,4.42,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하지? 🤔 (해설 종료,1,193
2740,27,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.",Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2741,27,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2742,27,4.42,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그 핵심 아이디어 설명이랑 사용 예를 들어 주면 더 좋을 것 같아 😊 (해설 종료,1,176
2743,27,3.19,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
2744,27,2.7,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2745,27,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2746,27,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 우리는 어떻게 해결하면 되는데? (해설 종료,1,160
2747,27,3.0,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 오 완벽한 답변이야! 😊😊 (해설 종료,1,186
2748,27,6.73,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오! 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 설명했네! 완벽한 답이야 👍👍 (해설 종료,1,368
2749,27,5.89,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 3가지 중 하나만 말해 줬는데, 그럼 나머지 2가지는 뭘까~요? 😊 (해설 종료",1,335
2750,27,3.12,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ",  모르겠다고 하지 말고 설명 좀 해 봐 😥 (해설 종료,1,257
2751,27,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2752,27,3.33,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,210
2753,27,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2754,27,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2755,27,2.3,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 그래서 Valid Dataset 이 뭐야? 😊 (해설 종료,1,133
2756,27,5.59,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
2757,27,5.75,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 설명해 봐! 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,295
2758,27,3.39,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데 왜 필요한 거지? (해설 종료,1,167
2759,27,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2760,27,1.77,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  오 정답!! (해설 종료,1,164
2761,27,3.87,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고,  그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,139
2762,27,3.47,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.",  그럼에도 이 셋을 구분해 줘! 😊 (해설 종료,1,172
2763,27,3.0,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
2764,27,3.48,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2765,27,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
2766,27,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2767,27,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2768,27,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2769,27,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2770,27,6.62,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 건 AdamW 가 아니라 그거랑 비슷한 Optimizer 인데… (해설 종료,1,221
2771,27,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2772,27,4.56,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2773,27,4.39,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 간단히 설명하기는 했는데 그래서 Overfitting 이 구체적으로 뭐야? 😊 (해설 종료,1,259
2774,27,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2775,27,4.75,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2776,27,2.69,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.",  어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,176
2777,27,2.39,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2778,27,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2779,27,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2780,27,3.64,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2781,27,5.84,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2782,27,2.51,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
2783,27,4.55,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.",  공통적으로 사용되는 핵심 아이디어는 잘 설명했는데 서로 반대로 했네 😥 (해설 종료,1,228
2784,27,2.98,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은 뭐야? 🤔 (해설 종료,1,238
2785,27,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2786,27,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,200
2787,27,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2788,27,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
2789,27,2.83,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
2790,27,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2791,27,3.61,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐의 이득이 있는데? 🤔 (해설 종료,1,252
2792,27,5.16,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 지금 거의 완벽하긴 해! 😊👍 (해설 종료,1,363
2793,27,5.09,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 특이한 현상이긴 하지! 그래서 top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,368
2794,27,3.5,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2795,27,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2796,27,4.92,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2797,27,5.36,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.",  잘 대답하긴 했어! 😊 근데 더 심각한 문제가 있을 수도 있지 않을까? 🤔 (해설 종료,1,211
2798,27,4.87,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2799,27,4.87,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,252
2800,27,3.33,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 5가지의 PEFT에 속하는 기술은? 🤔 (해설 종료,1,203
2801,27,2.98,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오 완벽한 답이야! 👍👍 (해설 종료,1,214
2802,27,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2803,27,3.17,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", Quantization 이랑 OOM 서로 반대로 설명했네 😥 (해설 종료,1,169
2804,27,7.72,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,224
2805,27,131.2,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 정의랑 토큰이랑 토크나이저 설명은 대충 맞아! 근데 토�,1,1024
2806,27,2.83,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명해 봐! 😊 (해설 종료,1,230
2807,27,5.73,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 이나 Encoder-Decoder Self-Attention 은? 🤔 (해설 종료,1,314
2808,28,4.3,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 코사인 유사도만 설명하면 솔직히 좀 부실하잖아 😥 (해설 종료,1,262
2809,28,4.28,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 벡터의 유사도를 판단하기는 하지만 구체적으로 어떻게 하지? 🤔 (해설 종료,1,202
2810,28,5.4,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
2811,28,7.55,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)", 2 * 정밀도 * 재현율 / (정밀도 + 재현율) 이랑 정확도만 있네! 혹시 나머지도 설명해줄 수 있어? 😊 (해설 종료,1,267
2812,28,3.0,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.",  그리고 DICE는 어디 갔지? 🙄 (해설 종료,1,199
2813,28,8.66,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,205
2814,28,4.7,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.",  값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,280
2815,28,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2816,28,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2817,28,4.73,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 알고리즘에 대해서 좀 더 구체적으로 설명해 줄 수 있어? 😊 (해설 종료,1,187
2818,28,3.44,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정말 완벽한 설명이야! 👍👍 (해설 종료,1,397
2819,28,4.31,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,287
2820,28,3.58,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2821,28,2.37,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그래서 뭐가 문제인데? 🤔 (해설 종료,1,167
2822,28,6.1,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다."," data point 간 거리의 변화에 초점을 맞춘 건 t-SNE고, 설명 변수의 변화에 초점을 맞춘 건 PCA인데… (해설 종료",1,253
2823,28,4.84,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
2824,28,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2825,28,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2826,28,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
2827,28,2.19,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 정답이야! 👍 (해설 종료,1,247
2828,28,3.0,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2829,28,3.37,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법이지! 😊 (해설 종료,1,173
2830,28,3.14,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상의 마지막 판단으로 어떻게 예측하는데? 😊 (해설 종료,1,274
2831,28,2.97,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그럼 추론할 때는 어떻게 해? 😊 (해설 종료,1,251
2832,28,2.84,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 그건 맞는데 왜 하는 거지? 🤔 (해설 종료,1,156
2833,28,3.3,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
2834,28,3.91,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2835,28,5.97,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인 지 알아? 그럼 Bagging 이랑 Boosting 은? 😊 (해설 종료,1,454
2836,28,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2837,28,2.27,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ 로라야! 😊 (해설 종료,1,197
2838,28,5.16,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
2839,28,2.99,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
2840,28,4.25,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론만 설명하면 솔직히 좀 부실하잖아 😥 (해설 종료,1,183
2841,28,2.81,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2842,28,1.44,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 🤔 (해설 종료,1,166
2843,28,4.72,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하는 걸까? 🤔 (해설 종료,1,195
2844,28,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2845,28,3.66,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2846,28,4.41,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그 핵심 아이디어 설명이랑 사용 예를 들어 주면 더 좋을 것 같아 😊 (해설 종료,1,176
2847,28,3.17,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
2848,28,2.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그렇지는 않을 텐데 😥 (해설 종료,1,168
2849,28,2.83,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2850,28,2.67,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 우리는 어떻게 해결하면 되는데? (해설 종료,1,160
2851,28,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
2852,28,5.48,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 하이퍼파라미터가 뭔지는 잘 말했어! 그럼 최적화하는 방법은? 😊 (해설 종료,1,360
2853,28,5.95,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 3가지 중 하나만 말해 줬는데, 그러면 나머지 2가지는 뭘까~요? 😊 (해설 종료",1,335
2854,28,1.41,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
2855,28,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2856,28,4.09,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
2857,28,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2858,28,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2859,28,4.81,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 보통 Early Stopping 이 구체적으로 뭐 하는 건지 말할 수도 있어? 😊 (해설 종료,1,149
2860,28,5.58,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
2861,28,5.87,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 잘 설명해 봐! 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,296
2862,28,3.31,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데 왜 필요한 거지? (해설 종료,1,167
2863,28,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2864,28,4.89,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다., 재미만 느끼면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,184
2865,28,4.5,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고,  local minima 를 벗어나게 하는 게 학습률을 높이는 구간이 아니지! (해설 종료,1,143
2866,28,3.78,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼에도 불구하고 이 셋을 구분해 줘! 😊 (해설 종료,1,174
2867,28,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
2868,28,2.2,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE", 서로 반대로 설명했네 😥 (해설 종료,1,162
2869,28,3.64,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,177
2870,28,2.2,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2871,28,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,169
2872,28,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2873,28,2.84,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 RMSProp 이랑 Adam 은? 🤔 (해설 종료,1,207
2874,28,6.76,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다.,  이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 건 AdamW 가 아니라 그거랑 비슷한 Optimizer 인데… (해설 종료,1,222
2875,28,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2876,28,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2877,28,4.53,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 떨어지는 방법이랑 증강하는 방법 위주로 해결할 수도 있지 않을까? 😊 (해설 종료,1,260
2878,28,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2879,28,4.72,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2880,28,2.69,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.",  어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,176
2881,28,2.38,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2882,28,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2883,28,3.13,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2884,28,3.62,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2885,28,5.87,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2886,28,2.83,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘 이해하고 있네! 😊😊 (해설 종료,1,271
2887,28,3.59,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.", 2가지 더 차이점이 있지 않을까? 🤔 (해설 종료,1,222
2888,28,3.92,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 노드의 개수가 많을수록 초기화가 어렵겠네 😥 (해설 종료,1,244
2889,28,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2890,28,4.09,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,199
2891,28,4.26,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2892,28,3.33,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
2893,28,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
2894,28,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2895,28,3.44,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐의 방법인데? 😊 (해설 종료,1,251
2896,28,5.16,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 지금 거의 완벽하긴 해! 😊👍 (해설 종료,1,363
2897,28,3.59,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그래서 top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,359
2898,28,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
2899,28,2.73,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
2900,28,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
2901,28,2.69,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.",  잘 대답했어! 😊👍 (해설 종료,1,194
2902,28,4.86,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
2903,28,4.86,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,252
2904,28,4.42,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 8개의 PEFT에 속하는 기술만 말해 주면 더 좋을 것 같아 😊 (해설 종료,1,210
2905,28,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
2906,28,3.12,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
2907,28,5.04,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2024년 6월 30일 기준으로는 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,181
2908,28,5.69,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞는데 구체적인 알고리즘은? 🤔 (해설 종료,1,211
2909,28,8.94,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 토큰이랑 토크나이저가 서로 반대로 되어 있네 😊 (해설 종료,1,250
2910,28,2.67,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 봐! 😊 (해설 종료,1,229
2911,28,5.41,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self Attention 이나 Encoder-Decoder Self Attention 은? 🤔 (해설 종료,1,312
2912,29,3.05,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 설명이야! 😊👍 (해설 종료,1,254
2913,29,4.44,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.",벨의 유사도를 판단하기는 하지만 구체적으로 뭘 사용하지? 🤔 (해설 종료,1,203
2914,29,5.4,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
2915,29,5.03,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," 2 * (정밀도 + 재현율) 이 아니라, 그걸 수식의 분자는 아니지만... (해설 종료",1,251
2916,29,2.38,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.",  DICE Score 는? 🤔 (해설 종료,1,195
2917,29,9.0,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE score의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,205
2918,29,2.67,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.", 우와! 정말 완벽해! 👍 (해설 종료,1,267
2919,29,2.77,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
2920,29,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
2921,29,3.96,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,182
2922,29,5.66,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 정의랑 목적이랑 알고리즘 모두 잘 설명했네! 완벽한 답이야 👍👍 (해설 종료,1,411
2923,29,4.02,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다.", 평균이랑 표준편차를 이용해서 어떻게 변환하는데? 🤔 (해설 종료,1,285
2924,29,3.59,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
2925,29,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
2926,29,2.36,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", 오 완벽한 설명이야 👍 (해설 종료,1,229
2927,29,5.48,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE는 잘 설명했는데 혹시 PCA랑 그 차이점 위주로 더 설명해 줄 수 있어? 😊 (해설 종료,1,254
2928,29,2.23,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
2929,29,2.87,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
2930,29,2.5,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 해결 방법 이야기가 없잖아 😥 (해설 종료,1,211
2931,29,2.2,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오! 잘했어 👍 (해설 종료,1,247
2932,29,2.95,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
2933,29,3.33,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법이지! 😊 (해설 종료,1,173
2934,29,4.09,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 끝까지 선택해 나가서 그 분기의 답으로 어떻게 예측하는데? 😊 (해설 종료,1,280
2935,29,2.98,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 그리고 추론할 때는 어떻게 해? 🤔 (해설 종료,1,251
2936,29,3.79,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
2937,29,3.31,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개 쓰는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,157
2938,29,3.94,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
2939,29,5.97,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인 지 알아? 그럼 Bagging 이랑 Boosting 은? 😊 (해설 종료,1,454
2940,29,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
2941,29,2.22,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ 로라야! 😊 (해설 종료,1,197
2942,29,3.77,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 사용자 지도랑 데이터셋 지도가 서로 반대로 되어 있네 😥 (해설 종료,1,233
2943,29,2.99,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
2944,29,4.27,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.",  조건부 확률 이론은 맞는데 자세히 설명해 줄 수 없어? 😊 (해설 종료,1,183
2945,29,2.83,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
2946,29,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
2947,29,3.48,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 음… 맞긴 한데 자세히 설명해 볼 수 있어? 😊 (해설 종료,1,187
2948,29,2.39,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
2949,29,3.64,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
2950,29,3.62,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 음… 잘 설명했어! 그래서 언제 사용하는 거지? 🤔 (해설 종료,1,171
2951,29,3.16,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
2952,29,5.67,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 그러면 데이터 불균형이 심해져서 각 fold 별 비율이 맞지 않을 수도 있거든! 😥 (해설 종료,1,187
2953,29,2.85,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
2954,29,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 맞지! 그래서 우리는 어떻게 해결하면 되는데? (해설 종료,1,160
2955,29,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
2956,29,5.8,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다."," 하이퍼파라미터가 뭔지 설명은 잘 했는데, 최적화하는 방법이 빠졌잖아 😥 (해설 종료",1,362
2957,29,5.89,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 3가지 중 하나만 말해 줬는데, 그러면 나머지 2가지는 뭘까~요? 😊 (해설 종료",1,335
2958,29,1.55,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ",  😊 (해설 종료,1,247
2959,29,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
2960,29,3.33,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,210
2961,29,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
2962,29,2.84,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
2963,29,2.78,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답!! 완벽해!! 👍👍 (해설 종료,1,136
2964,29,5.58,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
2965,29,5.92,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 잘 설명해 봐! 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,296
2966,29,3.64,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데... 왜 필요한 거지? (해설 종료,1,168
2967,29,1.77,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
2968,29,3.78,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미만 추구하는 건 학습이 아니라 노동이야! 😥 (해설 종료,1,177
2969,29,5.61,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고, local minima 을 벗어나게 하긴 하지! 그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,150
2970,29,3.32,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그럼에도 이 셋을 구분해 줘! 😊 (해설 종료,1,171
2971,29,3.0,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
2972,29,3.48,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
2973,29,3.31,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,175
2974,29,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
2975,29,4.27,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", 약자를 풀어서 설명하기는 했는데 정확한 뜻이 뭘까? 🤔 (해설 종료,1,182
2976,29,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
2977,29,2.69,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
2978,29,5.99,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다.,  이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 건 어떤 Optimizer 에서 사용될까? 😊 (해설 종료,1,217
2979,29,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
2980,29,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실�이 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
2981,29,3.59,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 떨어지는 방법 말고도 해결 방법이 많을 텐데 😊 (해설 종료,1,254
2982,29,3.33,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
2983,29,4.98,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
2984,29,2.53,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
2985,29,2.48,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
2986,29,2.89,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
2987,29,3.14,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
2988,29,3.63,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
2989,29,5.84,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
2990,29,2.52,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
2991,29,4.55,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.",  공통적으로 사용되는 핵심 아이디어는 잘 설명했는데 서로 반대로 했네 😥 (해설 종료,1,228
2992,29,2.83,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은 뭐야? 😊 (해설 종료,1,237
2993,29,3.45,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
2994,29,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 🤔 (해설 종료,1,200
2995,29,4.28,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
2996,29,3.34,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,205
2997,29,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
2998,29,2.34,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
2999,29,3.33,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐의 약자인데? 😊 (해설 종료,1,250
3000,29,5.17,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 지금 거의 완벽하긴 해! 😊👍 (해설 종료,1,363
3001,29,3.28,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 1보다 크거나 작으면 어떻게 되는데? 😊 (해설 종료,1,357
3002,29,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
3003,29,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
3004,29,4.9,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
3005,29,6.33,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.","  잘 대답하긴 했어! 😊 근데 신뢰성 저하, 윤리적 이슈 등 아주 심각한 문제가 하나 더 있는데! (해설 종료",1,217
3006,29,4.86,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
3007,29,4.72,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,251
3008,29,3.33,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 5가지의 PEFT에 속하는 기술은? 🤔 (해설 종료,1,203
3009,29,2.84,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
3010,29,3.11,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
3011,29,4.27,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2. 해결할 수 있는 문제를 조금 더 상세히 설명해 봐! 😊😊 (해설 종료,1,176
3012,29,7.27,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점을 설명해 줄 수 있어? 😊 (해설 종료,1,221
3013,29,7.84,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰과 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 설명도 있으면 더 좋을 텐데 😥 (해설 종료,1,242
3014,29,2.66,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 설명해 봐! 😊 (해설 종료,1,229
3015,29,5.75,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 중 하나만 설명했네! Masked Decoder Self-Attention 이나 Encoder-Decoder Self-Attention 은? 🤔 (해설 종료,1,314
3016,30,5.08,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 코사인 유사도는 벡터의 방향을 가지고 판단하는 유사도이다. 벡터 방향이 일치할수록 +1.0, 반대 방향일수록 -1.0에 가까운 값을 갖는다. 코사인 유사도는 S-BERT, 추천 시스템 등에서 사용한다.", 정말 완벽한 설명이긴 한데 수직일 때는 값이 얼마로 나올까? 😊 (해설 종료,1,266
3017,30,5.68,"(퀴즈 문제) Cosine Similarity 는 무엇이고, 어떨 때 사용할까? 구체적인 예를 들어 말해봐! 😊 (모범 답안) Cosine Similarity (코사인 유사도) 는 벡터의 크기가 아닌 방향을 중요시하는 컨셉의 유사도로, 두 벡터의 방향이 같으면 +1.0, 반대 방향이면 -1.0, 수직이면 0.0 의 값을 갖는다. 벡터로 나타낼 수 있는 2개의 대상을 비교할 때 사용하며, 예를 들어 NLP의 S-BERT, 추천 시스템 등에서 사용한다. (사용자 답안) 벡터의 유사도를 판단하기 위해 사용한다.", 아니지! 벡터의 방향에 따른 값이랑 사용 예를 들어 주면 더 좋을 것 같아 😊 (해설 종료,1,209
3018,30,5.28,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) 정확도는 전체 예측 중 정답의 개수이고, 재현율은 실제로 참인 개수 중 모델의 예측이 참인 개수의 비율을 의미한다. 정밀도는 재현율과는 다르게 모델이 참으로 예측한 것 중 실제 참인 것의 비율이고, F1 Score 는 정밀도와 재현율의 조화 평균이다."," 음… 잘 하긴 했는데, 혹시 수식으로도 나타낼 수는 없을까? 🤔 (해설 종료",1,314
3019,30,6.62,"(퀴즈 문제) 머신러닝에서 사용하는 성능지표 (Metric) 중 Accuracy, Recall, Precision, F1 Score 에 대해 말해봐! 😊 (모범 답안) Accuracy (정확도) 는 전체 예측 중 정답을 한 것의 개수로, (True Positive + True Negative) / (전체 데이터 개수) 로 나타낸다. Recall (재현율) 은 실제로 참인 데이터 중 모델이 참으로 예측한 데이터 개수의 비율로, (True Positive) / (True Positive + False Negative) 로 계산한다. Precision (정밀도) 는 모델이 참으로 예측한 데이터 중 실제 참인 데이터 개수의 비율로, (True Positive) / (True Positive + False Positive) 이다. 마지막으로 F1 Score 는 Precision 과 Recall 의 조화 평균이다. (사용자 답안) F1 Score = 2 * 정밀도 * 재현율 / (정밀도 + 재현율)"," 2 * (정밀도 + 재현율) 이 아니라, 그걸 수식의 분자는 아니지만 비율로 나타낸 거잖아! 😊 (해설 종료",1,261
3020,30,3.0,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 예측이 True 인 집합과 실제 값이 True 인 집합을 고려했을 때, 그 (교집합의 원소의 개수) / (합집합의 원소의 개수) 이다.",  DICE Score 는 어디 갔지? 🙄 (해설 종료,1,199
3021,30,8.52,"(퀴즈 문제) 머신러닝의 성능지표 중 IoU, DICE Score 는 뭘까? (모범 답안) IoU 는 (예측과 실제가 모두 True 인 교집합) / (예측과 실제 값 중 하나라도 True 인 합집합) 의 비율이고, DICE Score 는 (2 x 교집합의 원소 개수) / (참으로 예측한 개수 + 예측과 관계없이 실제 값이 참인 데이터 개수) 이다. (사용자 답안) IoU 는 교집합 / 합집합의 크기, DICE score 는 음… 잘 모르겠다.", ① 교집합이랑 합집합이 구체적으로 뭘 말하는 거야? 그리고 DICE의 분자는 교집합의 원소 개수가 아니라 여기에 2를 곱한 거야! 😊 (해설 종료,1,204
3022,30,4.72,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다.",  값의 범위랑 어떨수록 성능이 좋은지만 알려주면 어떡해 😥 (해설 종료,1,280
3023,30,2.75,"(퀴즈 문제) 머신러닝의 성능지표 중 PR-AUC 와 AUC-ROC 는 무엇이고 언제 쓰지? 😊 (모범 답안) PR-AUC (Area Under Precision-Recall Curve) 는 x축을 recall, y축을 precision으로 했을 때, 이 측정값들을 연결한 그래프의 아래쪽 면적이다. 값의 범위는 0~1이고, 1에 가까울수록 성능이 좋다. ROC-AUC (Area Under ROC Curve) 는 x축을 FP rate (False Positive Rate), y축을 TP rate (True Positive Rate) 로 했을 때, 이 측정값들을 연결한 곡선 아래쪽 넓이이고, 역시 범위는 0~1이며 1에 가까울수록 좋다. 이것들은 이진 분류 (Binary Classification) 에서 사용한다. (사용자 답안) PR-AUC 와 AUC-ROC 는 이진 분류에서 사용하는 성능지표이다. 둘 다 값의 범위는 0~1이고 1에 가까울수록 좋은 성능을 나타낸다. 이 중 PR-AUC는 x축과 y축이 각각 recall, precision 이고, ROC-AUC 는 각각 FP rate 와 TP rate 이다.", 우와! 정말 완벽해! 👍 (해설 종료,1,299
3024,30,3.77,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 결측값은 머신러닝 학습 데이터의 데이터셋에서 일부 데이터가 누락된 것이다. 이를 해결하기 위해서 결측값을 채워야 하는데, 평균값, 중앙값, 최빈값, k-NN, 딥러닝 기반 등의 알고리즘이 사용된다. 혹은 모델 자체 알고리즘을 사용하기도 한다.", 우와! 정말 완벽한 설명이야! 정말 잘했어! 👍 (해설 종료,1,241
3025,30,4.89,"(퀴즈 문제) 결측값은 뭐고, 그럼 이 결측값 채우는 알고리즘은 무엇이 있지? 😊 (모범 답안) 결측값 (Missing Value) 은 데이터셋에서 특정 값이 누락된 것이다. 결측값을 채우는 방법, 즉 알고리즘에는 모델 자체적으로 처리하거나, 평균/중앙값/최빈값으로 대체하거나, k-NN (k-Nearest-Neighbor) 알고리즘을 쓰거나, 딥러닝 기반으로도 해결할 수 있다. (사용자 답안) 데이터에서 어떤 값이 누락된 것이고, 평균값으로 대체한다.", averaging with the average value) 평균값으로 대체하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,188
3026,30,3.3,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터를 일정한 수식을 이용해서 변환하는 것을 통해 전처리하는 방법이다. 머신러닝 모델의 학습 용이성, 표준편차 차이로 인한 각 특징의 학습 불균형을 해결하기 위한 방법이다. 정규와 알고리즘에는 Min-max (최솟값을 0, 최댓값을 1로 mapping 시키는 선형 방법), Z-score (평균과 표준편차를 이용하는 것), 최솟값을 올리고 최댓값을 내려서 모든 데이터를 일정 범위 내로 mapping 시키는 Clipping, 로그 스케일 변환이 있다.", 오! 완벽한 설명이야! 👍👍 (해설 종료,1,396
3027,30,4.33,"(퀴즈 문제) 정규화는 뭐지? 왜 하는 거지? 그리고 정규화 알고리즘 아는 거 다 말해 봐! 😊 (모범 답안) 정규화 (Normalization) 은 데이터 전처리 방법 중 하나로, 데이터를 일정한 수식을 이용해서 값을 변환하는 것이다. 정규화를 하는 이유는 원본 데이터 값을 머신러닝 모델이 잘 학습할 수 있는 값으로 바꾸고, 데이터 feature 간 표준편차가 서로 달라서 어떤 특징은 많이 학습되고 다른 특징은 적게 학습되는 문제를 해결하는 것이다. 정규화 알고리즘에는 Min-max normalization (최솟값은 0, 최댓값은 1로 선형 정렬), Z-score normalization (평균과 표준편차를 이용하여 표준정규분포로 변환), Clipping (모든 데이터를 최솟값 ~ 최댓값 범위 내로 이동), 로그 스케일 변환 등이 있다. (사용자 답안) 정규화는 데이터의 각 속성별로 평균과 표준편차를 이용하여 표준정규분포로 변환하는 것이다."," 그래서 왜 하는 거고, 구체적인 알고리즘은 뭐가 있지? 😊 (해설 종료",1,287
3028,30,3.6,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 아웃라이어라고 하며, 데이터셋의 정상적인 범위를 벗어난 값이다. 데이터 시각화 가독성을 해치고, 특정 정규화 방법 (Min-max 등) 에서 Outlier 의 영향으로 데이터 분포가 크게 이상해질 수 있으며, 머신러닝 학습에도 지장이 될 수 있다.", 오 잘했어! 완벽한 설명이야!! 👍👍 (해설 종료,1,230
3029,30,2.53,"(퀴즈 문제) 이상치 (Outlier) 라는 게 있는데, 그건 뭐고 왜 문제가 되는 거지? (모범 답안) 이상치 (Outlier) 는 데이터셋에서 일반적인 분포 범위를 벗어난 값이다. Outlier 는 데이터 시각화 결과의 가독성을 줄이고, Min-max 및 Z-score 정규화에서 Outlier 의 영향으로 분포가 이상해지고, 머신러닝에서 Outlier 때문에 학습에 지장을 줄 수 있기 때문에 문제가 된다. (사용자 답안) 이상치는 데이터에서 일반적인 분포 범위를 크게 벗어난 아웃라이어를 의미한다.", 그럼 뭐가 문제인데? 🤔 (해설 종료,1,168
3030,30,4.38,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) PCA는 데이터셋 분산의 보존에 초점을 둔다. T-SNE는 시각화에 초점을 둔다.", data point 간 거리의 보존이랑 시각화가 서로 반대로 되어 있네 😥 (해설 종료,1,242
3031,30,4.86,"(퀴즈 문제) PCA와 t-SNE 알아? 😊 그러면 혹시 그 차이점도 알아? 📈 (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이고, t-SNE 는 data point 의 상대적 거리를 유지하는, 즉 멀리 떨어진 데이터일수록 t-SNE 결과에서도 멀리 떨어뜨리는 차원 축소 방법이다. PCA는 머신러닝 학습 성능이나 속도를 높이기 위한 차원 축소 방법이고, t-SNE는 2,3차원으로 축소하여 시각화하는 것에 초점을 둔 방법이다. (사용자 답안) t-SNE는 2~3차원으로 데이터를 축소하여 시각화에 용이하도록 하는 방법이다. 즉 PCA와는 다르다.", t-SNE랑 PCA랑 그 차이점 위주로 더 설명을 추가해 줄 수 있어? 😊 (해설 종료,1,250
3032,30,2.22,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값이 관측될 가능성, 우도는 어떤 관측값이 주어질 때 그 관측값이 어떤 확률분포로부터 발생했을 가능성이다.", 정답! 잘했어 👍 (해설 종료,1,203
3033,30,2.84,"(퀴즈 문제) Probability (확률), Likelihood (우도), 이 말 논문에서 많이 쓰이잖아! 📝 그러면 그 차이점은 뭘까? 😊 (모범 답안) Probability (확률) 는 어떤 확률분포가 주어졌을 때 그 확률분포에서 특정 관측값이 발생할 가능성을 말하고, Likelihood (우도) 는 반대로 어떤 관측값이 주어졌을 때, 그 관측값이 특정한 확률분포 에서 발생했을 가능성을 말한다. (사용자 답안) 확률은 확률분포에서 특정 값의 확률이고 우도는 그 반대이다.", 확률 우도 반대로 설명했잖아 😥 (해설 종료,1,182
3034,30,4.7,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다.", 그럼 해결 방법은 뭐가 있지? 잘 생각해 보면 엄청 다양할 텐데 😊 (해설 종료,1,225
3035,30,2.66,"(퀴즈 문제) 데이터 불균형이란 게 뭐고, 어떻게 해결하면 좋을까? 😊 (모범 답안) 데이터 불균형은 특정 Class 의 데이터가 다른 Class 의 데이터보다 훨씬 많은 등 각 Class 의 데이터 개수가 유의미하게 차이 나는 것이다. 이를 해결하기 위해서는 데이터를 새로 추가/제거하는 방법 (데이터 개수가 적은 Minority Class 데이터 추가 수집, Data Augmentation, Undersampling & Oversampling), 학습 환경만 바꾸는 방법 (성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등으로 선택, 데이터가 적은 Class 는 손실 함수에서 높은 가중치를 두는 등 가중치 조정) 이 있다. (사용자 답안) 데이터 불균형은 Class 간 데이터 개수가 서로 유의미하게 차이 나는 것이다. Minority 데이터의 개수를 늘리거나, 데이터 증강을 하거나, 성능 평가 지표를 F1 Score 같은 걸로 바꾸는 방법으로 해결할 수 있다.", 오 정답이야! 잘했어 👍 (해설 종료,1,250
3036,30,2.97,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 학습 데이터의 feature 가 불필요하게 너무 많아져서 오히려 학습에 방해되는 것을 말한다. 학습 속도가 감소하고, OOM이 발생하고, 모델 성능이 감소한다. 해결 방법은 기존 feature 중 일부만 사용하는 것, PCA처럼 차원을 축소하는 것이 있다.", 오 잘했어 👍👍👍 (해설 종료,1,225
3037,30,3.0,"(퀴즈 문제) 차원의 저주😈 는 뭐고, 어떻게 해결해야 되지? 😊 (모범 답안) 차원의 저주는 학습 데이터의 feature 개수, 즉 차원이 너무 많아서 학습에 지장을 주는 현상으로, 계산량 증가로 인한 학습 속도 감소, 메모리 사용량 증가, 모델 성능 감소 등이 있다. 해결 방법으로는 기존 feature 중 일부만 사용하는 Feature Selection 과, 차원을 축소하는 Feature Extraction 이 있다. (사용자 답안) 차원의 저주는 차원이 너무 많아져서 OOM이 발생하는 것으로, PCA로 해결하면 된다.", PCA가 아니라 그거랑 비슷한 방법인데… (해설 종료,1,171
3038,30,2.53,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 학습할 때 feature 조건을 여러 개 만들고, 그것들 중 class 를 가장 잘 구분할 수 있는 조건을 선택한다. 추론할 때는 맨 위에서 시작해서 그 데이터가 가지고 있는 속성 값에 따라 적절한 분기를 끝까지 선택해 나간다.", 대상 값을 어떻게 예측해? 😊 (해설 종료,1,270
3039,30,4.58,"(퀴즈 문제) Decision Tree 🌳 가 학습할 때랑 추론할 때랑 각각 어떻게 작동할까? 😊 (모범 답안) Decision Tree (의사결정 나무) 는 학습할 때 feature 에 대한 조건들 중 target 값을 가장 잘 구분할 수 있는 조건을 선택하는 방법으로 학습한다. 즉, 특정 조건으로 분기했을 때 해당 분기된 각 조건에 속하는 데이터의 target 값의 불순도 (다양한 정도) 가 최대한 낮아지도록 조건을 선택하여 분기한다. 추론할 때는 Decision Tree 의 맨 위쪽에서 시작하여 해당 데이터의 feature 값에 따라 분기를 선택해 나간다. 분기가 더 이상 없을 때의 최종 판단으로 예측한다. (사용자 답안) 분기된 feature 조건이 해당 조건에 의해 분기된 각 분기 안에 속하는 데이터의 불순도 (다양한 정도) 가 최소화되도록 학습한다.", 불순도가 최소화되도록 학습해서 그걸로 어떻게 예측하는데? 🤔 (해설 종료,1,261
3040,30,3.78,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 여러 개의 모델을 사용해서 예측하는 것이다.", 여러 개의 모델을 사용하는 건 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,162
3041,30,3.0,"(퀴즈 문제) 앙상블 (Ensemble) 은 뭐고 왜 하는 걸까? (모범 답안) 앙상블 (Ensemble) 은 머신러닝에서 여러 알고리즘이나 모델을 결합하여 학습하는 것이다. 앙상블을 하는 이유는 사람도 혼자가 아니라 협업하면 성과가 더 좋듯이, 1개의 모델로 학습 또는 추론할 때보다 더 좋은 성능을 달성할 수 있기 때문이다. (사용자 답안) 앙상블은 모델을 하나가 아닌 여러 개 쓰는 것", 여러 개는 맞지만… 왜 그렇게 하지? 🤔 (해설 종료,1,155
3042,30,3.92,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) 앙상블의 방법에는 Voting, Bagging, Stacking 이 있다. Voting 은 Soft Voting (여러 모델의 예측값의 평균값) 과 Hard Voting (여러 모델의 예측 결과의 다수결) 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 데이터셋을 여러 개 만들고, 각 데이터셋을 이용하여 모델을 학습시키는 것이다. 그리고 이 학습된 모델들에 의한 예측 결과를 종합한다. 마지막으로 Stacking 은 개별 모델의 예측값이 입력, 실제 데이터 값이 출력인 메타 모델을 학습, 해당 메타 모델의 출력값이 최종 예측값이 되는 형태이다.", Voting 의 구체적인 방법으로는 뭐가 있을까? 🤔 (해설 종료,1,441
3043,30,4.37,"(퀴즈 문제) 앙상블 (Ensemble) 의 구체적인 방법 4가지를 말해봐 😊 (모범 답안) 앙상블 (Ensemble) 의 구체적인 방법은 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이 있다. Voting 은 여러 모델이 예측한 결과를 통합하는 것으로, 단순 다수결 판단인 Hard Voting 과 모델 예측값의 평균을 이용하는 Soft Voting 이 있다. Bagging 은 원본 데이터셋으로부터 랜덤 샘플링한 여러 개의 데이터셋으로 여러 개의 모델을 학습하고, 해당 모델의 결과를 종합하는 것이다. Boosting 은 Bagging 과 유사하지만, 직전 모델이 오답을 한 데이터에 더 큰 가중치를 두어서 모델을 순차적으로 학습하는 것이다. Stacking 은 개별 모델의 예측값과 실제 데이터 값을 각각 입력값과 출력값으로 하는 메타 모델을 학습하고, 해당 메타 모델의 출력값을 최종 예측값으로 사용하는 방법이다. (사용자 답안) Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다. Voting 은 Soft Voting 과 Hard Voting 으로 나뉜다.", Soft Voting 이랑 Hard Voting 이 구체적으로 어떤 방법인 지 알아? 😊 (해설 종료,1,444
3044,30,2.81,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) mean point 를 K 개 먼저 지정하고, 데이터셋에 있는 각 Point 에 대해서 다음을 반복한다. 1. 그 class 를 K개의 점 중 가장 가까운 점의 class 로 할당. 2. 각각의 K 개의 mean point 를 이들 point 중 해당 class에 속하는 모든 점의 평균으로 갱신. 언제까지? 수렴할 때까지.", 오! 완벽해! 👍👍 (해설 종료,1,220
3045,30,2.22,"(퀴즈 문제) K-means Clustering 의 동작 원리를 한번 말해봐! (모범 답안) K-means Clustering 에서는 먼저 랜덤한 mean point 를 K 개 지정한다. 그리고 데이터셋의 각 point에 대해 그 class 를 이들 K 개의 점들 중 가장 가까운 점의 class 로 지정하고, 각각의 mean point 를 데이터셋에서 해당 class 의 모든 point 의 평균으로 갱신하는 것을 수렴할 때까지 반복한다. (사용자 답안) K-means Clustering 은 먼저 랜덤한 mean point 를 K개 지정해서 초기화한다. 그런 다음 어떤 과정을 수렴할 때까지 계속 반복한다. 그런데 그 과정이 뭐였지? 진까 까먹었는데. 로라야 도와줘!!", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,197
3046,30,5.17,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습과 비지도학습은 각각 사용자나 데이터셋의 지도를 가지고, 사용자의 지도 없이 학습하는 것이다.", 지도학습이랑 비지도학습은 잘 설명했는데 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,242
3047,30,2.97,"(퀴즈 문제) 머신러닝 모델이 학습하는 방법에도 여러 가지가 있는데, 그 중 지도학습, 비지도학습, 강화학습은 뭘까? 😊 (모범 답안) 지도학습은 학습 데이터에 입력과 출력이 주어져서, 모델에 어떤 입력이 들어오면 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 별도의 출력 데이터 없이 모델이 주어진 데이터만으로 가능한 것, 예를 들어 군집화 (Clustering) 를 하도록 학습시키는 것이다. 강화학습은 어떤 환경에서 AI 모델이 어떤 상태에서 어떤 행동을 하고 보상을 얻는데, 이 보상을 최적화하는 방식의 머신러닝 방법이다. (사용자 답안) 지도학습은 입력과 출력을 모두 사용하는 학습 방식으로 모델이 어떤 입력에 대해 목적한 출력을 하도록 학습시키는 것이다. 비지도학습은 출력 없이 입력만을 모델이 알잘딱깔센하게 학습하도록 하는 방법이다.", 강화학습 이야기가 하나도 없네 😥 (해설 종료,1,262
3048,30,4.11,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 조건부 확률 이론인 베이즈 정리 기반으로 작동한다.", 조건부 확률 이론은 맞는데 자세히 설명해 줄 수 없어? 😊 (해설 종료,1,182
3049,30,2.94,"(퀴즈 문제) Naïve Bayes 는 어떻게 동작할까? 😊 (모범 답안) Naïve Bayes 는 조건부 확률을 구하는 베이즈 정리를 기반으로 작동한다. 새로운 데이터가 들어왔을 때, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 데이터의 비율) 에 각 속성별로 (해당 Class 의 데이터 중 속성 값이 일치하는 데이터의 비율) 을 모두 곱하고, 해당 곱셈 결과값이 가장 큰 Class 로 예측한다. (사용자 답안) 베이즈 정리 기반으로, 각 Class 별로 (전체 데이터셋에서의 해당 Class 의 비율) x 각 속성별로 (해당 Class 에 속한 데이터 중 속성 값이 새로 입력된 데이터와 일치하는 것의 비율) 의 전체 곱을 구하고, 이 전체 곱이 가장 큰 Class 로 최종 예측한다.", 정말 완벽한 답변이야! 👍 (해설 종료,1,235
3050,30,1.27,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 아 이거 PCA가 진짜 뭐였지", 😥 (해설 종료,1,165
3051,30,4.73,"(퀴즈 문제) PCA 는 어떻게 동작할까? 이거 엄청 중요한데! (모범 답안) PCA (주성분 분석, Principal Component Analysis) 는 데이터셋의 분산을 최대한 보존하는 feature 의 결합, 즉 주성분을 찾아서 차원을 축소하는 방법이다. 먼저 데이터셋의 속성 값들을 평균 0, 표준편차 1로 정규화하고, 다음으로 Covariance Matrix 를 계산한다. 이를 토대로 Eigenvalue 와 Eigenvector 를 계산하고, 이렇게 계산된 Eigenvalue 가 가장 큰 속성 K 개를 선택한다. (사용자 답안) 데이터셋의 분산을 최대한 보존하도록 동작한다.", 데이터셋의 분산을 보존하는 건 맞는데 구체적으로 어떻게 하는 걸까? 🤔 (해설 종료,1,195
3052,30,2.37,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 발전시킨 Random Forest 는 Decision Tree 를 아주 많이 만드는 것이다.", Decision Tree 를 어떻게 만들지? 😊 (해설 종료,1,157
3053,30,3.63,"(퀴즈 문제) Random Forest 란 무엇이고, 무엇을 발전시킨 거지? (모범 답안) Random Forest 는 Decision Tree 를 발전시킨 것이다. 먼저 원본 데이터셋에서 feature 와 학습할 데이터의 조합을 랜덤으로 선택하여 서로 다른 Decision Tree 를 여러 개 만들고, 추론할 때 이들 Decision Tree 들의 예측 결과를 합치는 것이다. 즉 Decision Tree 를 앙상블 (Ensemble) 시키는 방법이다.  (사용자 답안) Decision Tree 를 아주 많이 만들고 그것들의 예측 결과를 합쳐서 앙상블 시키는 것이다. 즉 Decision Tree 를 발전시킨 것이다.", 오 정말 완벽해! 완벽한 답이야!! 👍👍 (해설 종료,1,181
3054,30,2.69,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 간의 구분선을 만들 때 각 Class 간의 거리가 최대가 되는 구분선을 찾는다.", 그럼 언제 사용하는 건데? 🤔 (해설 종료,1,165
3055,30,3.17,"(퀴즈 문제) SVM (Support Vector Machine) 의 핵심 아이디어를 나한테 한번 설명해 봐! 😊 그리고 언제 사용하는 거지? 🤔 (모범 답안) SVM (Support Vector Machine) 은 2개의 Class 가 있는 데이터셋에서 사용한다. 2개의 Class 에 속한 원소들 간의 구분선을 만드는데, 이때 그 구분선과 각 Class 간의 거리가 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다. (사용자 답안) 2개의 Class 가 있을 때 사용하며, 이들 간 마진이 최대가 되는 구분선을 찾는 것이 핵심 아이디어이다.", 2개의 Class 가 뭔지 설명해 봐! 😊 (해설 종료,1,173
3056,30,5.69,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) K-fold Validation 만으로 어차피 충분하므로 Stratified 까지는 굳이 안 해도 된다.", 아니지! 데이터가 불균형할 때 사용하는 건 Stratified K-fold Validation 이 아니라 Regular K-fold Validation 이더라! 😊 (해설 종료,1,187
3057,30,2.84,"(퀴즈 문제) K-fold Cross Validation 만으로 충분할 것 같은데, 굳이 Stratified K-fold Validation 을 사용하는 이유는? 😊 (모범 답안) Stratified K-fold Validation 은 데이터 불균형이 심할 때 Minority Class 의 데이터가 표본 부족으로 인해 각 fold 에 고르게 분포되어 있지 않을 수 있다는 문제점을 해결하기 위해 사용한다. 즉, Stratified K-fold Validation 은 각 fold 별로 Class 의 분포 비율을 최대한 동일하게 하는 것이다. (사용자 답안) 데이터 불균형을 해소하기 위한 방법으로, Stratified K-fold Validation 을 사용하면 데이터 개수가 적은 Class 가 표본 부족으로 각 fold 에 고르지 않게 분포되는 이슈가 있다. 즉 이를 해결하기 위한 방법이다.", 오 맞아! 정답이야! 😊😊 (해설 종료,1,201
3058,30,2.69,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다.", 그치! 그래서 우리는 어떻게 해결하면 되는데? (해설 종료,1,160
3059,30,2.84,"(퀴즈 문제) 시계열 데이터셋 📈 에서 K-fold Cross Validation 을 하면 어떤 문제가 발생하고, 그러면 어떻게 Cross Validation 을 하지? 🤔 (모범 답안) 시계열 데이터셋에서 K-fold Cross Validation 을 할 때 발생하는 문제는 validation 데이터가 나타내는 시점보다 미래의 데이터가 train data 에 포함된다는 것이다. 이를 해결하기 위해 training data 는 validation data 보다 과거의 데이터만을 활용한다. (사용자 답안) train data 보다 과거의 데이터가 valid data 에 포함되면 학습에 지장을 줄 수 있다. 따라서 이를 해결하기 위해 train data 는 항상 valid data 의 과거 시점 데이터로만 구성한다.", 완벽한 답변이야! 😊😊 (해설 종료,1,185
3060,30,6.73,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 딥러닝 모델의 신경망의 파라미터를 의미한다. 하이퍼파라미터 최적화는 이 딥러닝 모델의 파라미터를 각종 최적화 기술 (Optimizer, Regularization, Dropout, 기타등등) 을 이용하여 최적의 상태로 학습시켜서 Loss Function 의 값을 최대한 줄이는 것이다.", 오! 하이퍼파라미터 정의랑 최적화 방법 3가지 다 잘 설명했네! 완벽한 답이야 👍👍 (해설 종료,1,368
3061,30,5.87,"(퀴즈 문제) 하이퍼파라미터란 뭐고, 그 최적화 방법을 3가지만 말해 봐! 😊 라이브러리가 아닌 방법! (모범 답안) 하이퍼파라미터 (Hyper-parameter) 는 모델이 학습해야 할 파라미터가 아닌, 모델의 학습에 있어서의 설정값을 의미한다. (딥러닝의 learning rate 등) 하이퍼파라미터 최적화는 모델이 특정 데이터셋을 가장 잘 학습할 수 있도록 최적의 하이퍼파라미터를 찾는 것이다. 그 방법으로는 Grid Search (하이퍼파라미터를 지정된 범위 내에서 바둑판 형태로 찾는 것), Random Search (지정된 범위 내에서 랜덤하게 값을 정하는 것), Bayesian Optimization (지금까지의 통계에 근거하여 확률적으로 최적일 것으로 예상되는 하이퍼파라미터를 찾는 것) 가 있다. (사용자 답안) 하이퍼파라미터는 모델의 학습 과정 자체를 결정하는 설정값으로, 그 최적화 방법으로는 search space 에서 바둑판 격자 모양으로 탐색하는 Grid Search, 랜덤하게 탐색하는 Random Search가 있다."," 3가지 중 하나만 말해 줬는데, 그러면 나머지 2가지는 뭘까~요? 😊 (해설 종료",1,335
3062,30,1.43,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Valid Dataset 이 필요한 이유는 Test Dataset 만으로 부족한 뭔가를 채우기 위해서이다. 근데 그게 뭔지 솔직히 모르겠다. ㅋㅋㅋ", ㅋ (해설 종료,1,246
3063,30,2.91,"(퀴즈 문제) 머신러닝에서 Train, Test 데이터셋 말고 Valid 데이터셋은 왜 필요하지? (모범 답안) Train, Test 데이터셋만 있으면 Train 데이터셋을 학습한 후 그 성능 평가를 Test 데이터셋으로밖에 할 수 없다. 이후 모델의 하이퍼파라미터를 조정해 가면서 성능을 향상시킬 때도 Test 데이터셋을 참고해야 한다. 이렇게 되면 Test 데이터셋에 지나치게 최적화 (overfitting) 되어서 새로운 데이터셋에서의 성능이 Test 데이터셋 성능보다 유의미하게 낮을 수 있다. 이는 test 데이터셋 유출이나 커닝에 비유할 수 있다. 이를 방지하기 위해 성능 개선에 참고하기 위한 검증 데이터셋으로 valid dataset 이 필요하다. (사용자 답안) Train 데이터셋의 성능 평가를 Test Dataset 으로만 하면 하이퍼파라미터 같은 것을 개선하거나 모델 구조를 바꾸거나 다른 모델을 사용할 때 최종 테스트용 데이터셋을 사용하므로 추가적인 테스트 데이터셋이 없어지게 된다. 이를 방지하기 위해 검증용 데이터셋인 Valid Dataset 을 사용한다.", 오 정말 완벽해 😊😊😊 (해설 종료,1,302
3064,30,4.09,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 데이터 순서마저 모델이 학습하거나 데이터 순서로 인해 모델의 학습의 Loss Function 등에 영향을 받을 수 있다.", 맞지! 그러면 데이터 순서 때문에 정확히 어떤 문제가 생기는데? 😊 (해설 종료,1,215
3065,30,1.28,"(퀴즈 문제) 머신러닝에서 Train 데이터셋을 shuffle 해야, 즉 순서를 뒤섞어야 하는 이유는? 😊 (모범 답안) Train 데이터셋을 shuffle 하지 않으면 Train 데이터셋에 속한 각 batch 가 전체 데이터셋의 분포와 현저히 차이가 나기 때문에 전체 데이터셋을 대표할 수 없으며, 또 데이터의 순서로 인해 학습에 지장이 생길 수도 있다. 예를 들어 Class 가 dog 인 데이터를 계속 학습한 다음 갑자기 Cat 인 데이터가 나오면 Loss 가 급격히 증가하여 학습에 지장이 생길 수 있다. (사용자 답안) 어차피 다들 PyTorch 할때 train dataset 은 섞던데 그냥 섞는게 당연한 거 아닌가? 잘 모르겠다.", 😥 (해설 종료,1,198
3066,30,2.83,"(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) Valid Dataset 에 대한 Loss 가 일정 epoch 동안 최저 기록을 갱신하지 않으면 학습을 중단하는 것이며, overfitting 방지를 위한 조정책으로 반드시 필요하다.", 정답!! 완벽해!! 👍👍 (해설 종료,1,152
3067,30,4.52,(퀴즈 문제) 딥러닝에서 Early Stopping 은 무엇이고 왜 하는 걸까? 🤔 (모범 답안) Early Stopping 은 valid dataset 에 대한 Loss 가 일정 횟수의 epoch 동안 더 이상 낮아지지 않으면 학습을 중단하는 것이다. 이것은 overfitting (과적합) 방지를 위해 필요하다. (사용자 답안) 오버피팅을 막기 위해 Valid Dataset Loss 가 더 이상 떨어지지 않으면 학습을 종료하는 것이다., 정답! 근데 보통 Early Stopping 이랑 같이 붙여서 설명하긴 하지! 😊 (해설 종료,1,147
3068,30,5.58,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다."," 사용하는 모델 관점에서, 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 한번 설명해 볼래? 😊 (해설 종료",1,302
3069,30,5.89,"(퀴즈 문제) Knowledge Distillation (지식 증류) 은 무엇이고, 사용하는 모델 관점에서, 모델의 어떤 정보를 이용하는지의 관점에서 각각 3가지로 분류해 봐! 😊 (모범 답안) Knowledge Distillation (지식 증류) 은 거대한 Teacher Model 의 핵심 지식을 비교적 작은 Student Model 에 주입시키는 것이다. 사용하는 모델 관점에서 분류하자면 Offline Distillation (Pre-train 된 Teacher Model 을 이용), Online Distillation (Teacher 와 Student 를 동시에 또는 번갈아 가며 모두 학습), Self-Distillation (Teacher, Student 모델의 신경망 구조가 같음) 이 있고, 모델의 어떤 정보를 이용하는지의 관점에서는 Response-based (Teacher 의 출력만을 이용), Feature-based (Teacher 의 중간 레이어의 결과를 이용), Relation-based (Teacher 의 각 레이어의 feature 간 관계 정보를 이용) 가 있다. (사용자 답안) 지식 증류는 거대한 모델의 지식을 보다 작은 모델로 전수하여 모델 경량화를 달성하는 것이다. Offline, Online, Self Distillation 으로 나뉜다.", 3가지 다 잘 설명해 봐! 그리고 모델의 어떤 정보를 이용하는지의 관점에서도 설명해 줄 수 있어? 😊 (해설 종료,1,296
3070,30,3.31,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 것이다.", 학습률을 조정하는 건 맞는데 왜 필요한 거지? (해설 종료,1,167
3071,30,1.75,"(퀴즈 문제) Learning Rate Scheduler 📈📉 는 무엇이고 왜 필요할까? (모범 답안) Learning Rate Scheduler 는 학습 진행에 따라 학습률 (Learning Rate) 을 조정해 나가는 알고리즘이다. 학습 초반에는 평균적인 gradient 가 크기 때문에 learning rate 를 크게 적용하여 빠르게 학습하고, 학습 후반에는 gradient 가 작기 때문에 작은 learning rate 를 적용하여 안정적으로 수렴하게 한다. 이와 같은 효율적인 학습을 위해 필요하다. (사용자 답안) 학습률을 시간이 지남에 따라 조정하는 알고리즘으로, 학습 초반에는 빠르게 학습하고, 중반 이후에는 안정적으로 수렴할 수 있도록 하는 역할을 한다.", 오 정답이야!! (해설 종료,1,189
3072,30,5.05,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) 그냥 롤러코스터처럼 학습률을 움직이는 것이 재미있기 때문이다. 딥러닝 모델도 학습에 재미를 느껴야지 원활한 학습이 가능하기 때문이다.,  재미만 느끼면 학습이 제대로 이루어지지 않을 수도 있지 않을까? 🤔 (해설 종료,1,185
3073,30,3.87,(퀴즈 문제) Cosine Annealing Learning Rate Scheduler 는? 그리고 학습률을 높이는 구간이 있는 이유는? (모범 답안) Cosine Annealing 스케줄러는 코사인 함수 곡선처럼 Learning Rate 를 조정하는 스케줄러이다. 학습률을 높이는 구간이 있는 이유는 local minima 에서 탈출할 기회를 주기 위해서이다. (사용자 답안) local minima 를 벗어나게 하려고,  그래서 학습률을 높이는 구간은 왜 있는 거지? 🤔 (해설 종료,1,139
3074,30,3.47,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Loss, Cost, Objective Function 셋 다 딥러닝에서 모델을 목적에 맞게 최적화하기 위해 페널티 느낌으로 사용하는 함수이다.", 그건 맞는데 이 셋을 구분해 줘! 😊 (해설 종료,1,172
3075,30,3.02,"(퀴즈 문제) Loss Function, Cost Function, Objective Function 은 어떤 차이가 있을까? 🤔 (모범 답안) Loss Function, Cost Function, Objective Function 은 모두 딥러닝에서 최소화 또는 최대화를 통해 학습 방향을 결정하는 함수이다. Loss Function 과 Cost Function 은 Objective Function 중에서도 최소화해야 하는 함수이며, Loss Function 은 개별 데이터 관점에서, Cost Function 은 전체 데이터 관점에서의 함수이다. (사용자 답안) Objective Function 은 딥러닝 모델의 학습 방향을 목적에 맞게 결정하기 위한 함수이다. 이 중 최소화해야 하는 함수는 Loss Function 또는 Cost Function 이라고 하는데, Loss Function 은 개별 샘플, Cost Function 은 전체 데이터 관점에서의 함수이다.", 오 이거 정답이야 완전 👍👍 (해설 종료,1,196
3076,30,3.47,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE",  그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,170
3077,30,1.42,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 어떤 Loss Function 이 좋을까? (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 각 Class 별 확률 간 배타성이 있는 Categorical Cross Entropy 를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 Binary Cross Entropy 를 사용해야 한다. (사용자 답안) Multi Class: Categorical Cross Entropy, Multi-Label : BCE (각 Class 별로)", 🤔 (해설 종료,1,163
3078,30,2.22,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 MSE를 제곱근 처리한 것이다.", 그래서 각각 뭐지? 🤔 (해설 종료,1,163
3079,30,3.78,"(퀴즈 문제) Loss Function 중 MSE, MAE, RMSE 는 무엇의 약자이고 각각 뭘까? 😊 (모범 답안) MSE 는 Mean Squared Error 의 약자로, 오차의 제곱의 평균이다. MAE 는 Mean Absolute Error 로, 오차의 제곱이 아닌 그 절댓값의 평균이다. RMSE 는 Root Mean Squared Error 로, 오차의 제곱의 평균인 MSE 의 제곱근이다. (사용자 답안) MSE = Mean Squared Error, MAE = Mean Absolute Error, 그리고 RMSE는 Root Mean Squared Error 로 MSE를 제곱근 처리한 것이다.", MSE는 정답이야! 그러면 MAE랑 RMSE는?? 🤔 (해설 종료,1,179
3080,30,1.28,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) 아 Optimizer 다 까먹었는데 다시 한번 복습 좀 해야겠다", 😥 (해설 종료,1,195
3081,30,2.7,"(퀴즈 문제) RMSProp, Adam, AdamW Optimizer 의 차이점은 뭘까? 😊 핵심 아이디어 중심으로 말해봐! 💡 (모범 답안) RMSProp 은 Gradient 가 큰 매개변수일수록 학습 속도, 즉 learning rate 를 줄이고, Gradient 가 작을수록 학습 속도를 늘린다. Adam Optimizer는 여기에 Gradient 갱신 방향에 대해 일종의 관성 (Momentum) 을 적용하여 갱신 속도가 비교적 잘 유지되게 한다. AdamW는 여기에서 weight 갱신 수식에 weight decay 를 추가하여 weight decay 를 손실 함수와 분리하는 decoupled weight decay 가 핵심이다. (사용자 답안) AdamW 는 weight decay 를 적용한 decoupled weight decay 를 사용한다.", 그럼 Adam 이랑 RMSProp 는? 😊 (해설 종료,1,206
3082,30,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다., 그럼 Optimizer 는? 🤔 (해설 종료,1,194
3083,30,2.37,(퀴즈 문제) 딥러닝에서 Optimizer 는 무엇일까? 그리고 Weight Decay 는? Weight Decay 는 어떤 Optimizer 에서 사용될까? 😊 (모범 답안) Optimizer 는 Loss Function 의 값이 최소화될 수 있도록 가중치를 일정한 수식을 통해 보다 효과적으로 갱신하는 것을 말한다. Weight Decay (가중치 감쇠) 는 학습하면서 가중치를 업데이트할 때 이전 가중치의 크기를 일정 비율만큼 감소시키는 것이다. 그리고 weight decay 는 AdamW Optimizer 에서 사용된다. (사용자 답안) Weight Decay 는 가중치 감쇠라고도 하며 모델의 이전 가중치의 크기에 일정 비율을 곱해서 이를 감소시키는 것이다. Weight Decay 가 사용되는 곳은 AdamW 이다., 오 잘했어 😊👍 (해설 종료,1,206
3084,30,4.55,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 딥러닝 모델이 필요 이상으로 학습하게 되면 valid 나 test 데이터셋에 대해서 오차가 오히려 점점 늘어나게 되는데 이것을 Overfitting 이라고 한다. Dropout 을 충실히 적용하면 해결할 수 있다.", Dropout 을 충실히 적용하는 것 말고도 방법이 많을 텐데 😊 (해설 종료,1,274
3085,30,3.92,"(퀴즈 문제) Overfitting 은 뭘까? 🤔 그리고 그 해결 방법을 최대한 많이 말해봐. (모범 답안) Overfitting (오버피팅) 은 딥러닝 모델이 필요 이상으로 너무 많이 학습하여 valid, test 데이터셋에서 오차가 커지는 현상이다. 해결 방법은 학습 프로세스 관점에서는 학습 데이터 개수 증가 (Data Augmentation 등), Early Stopping, Cross Validation 등이 있고, 모델 구조 관점에서는 모델 구조 단순화 (불필요한 feature 제거 등), Batch Normalization, Dropout 등이 있고, 마지막으로 모델 학습 수식 관련해서는 Weight Decay 를 조정하거나 L1, L2 Regularization (정규화) 을 이용하는 방법이 있다. (사용자 답안) 드롭아웃을 적용해서 해결한다. 아니면 Batch Normalization, 데이터 증강, Early Stopping 으로 해결할 수도 있고, 모델 구조를 보다 간단하게 만들어서 해결할 수도 있다.", 떨어지는 방법이랑 간단한 해결 방법만 있는 건 아니잖아 😥 (해설 종료,1,256
3086,30,3.31,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다.", 그러면 Dropout 을 하는 이유는 뭘까? 🤔 (해설 종료,1,189
3087,30,4.73,"(퀴즈 문제) Dropout 이 무엇인지, 그리고 Dropout 을 하는 이유에 대해서 한번 설명해 봐. 🙄 (모범 답안) Dropout (드롭아웃) 은 딥러닝 모델의 학습 단계에서 신경망의 각 뉴런을 일정 확률로 제거하는 것을 말한다. Dropout 을 사용하는 이유는 Overfitting 을 방지하고, 뉴런을 랜덤하게 제거하여 하나의 모델로 다양한 모델을 만드는 것과 같은 효과를 보게 하여 앙상블 (Ensemble) 처럼 만들기 위함이다. (사용자 답안) 드롭아웃은 신경망에서 각 뉴런을 일정 확률로 독립적으로 제거하는 것을 말한다. 오버피팅을 막는다.", 오버피팅 막는 거 말고도 또 추가적인 이유가 하나 더 있지 않을까? 😊 (해설 종료,1,206
3088,30,2.66,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값이나 제곱 같은 새로운 항을 추가하는 것이다.", 어떤 새로운 항을 추가하는 거야? 😊 (해설 종료,1,175
3089,30,2.39,"(퀴즈 문제) Regularization, L1 Regularization, L2 Regularization 에 대해서 한번 설명해 봐 😊 (모범 답안) Regularization (정규화) 는 오버피팅을 방지하기 위해 Loss Function 에 새로운 항을 추가하는 것을 말한다. L1 Regularization 은 weight 의 절댓값의 크기의 평균에 일정 비율을 곱한 값을, L2 Regularization 은 weight 의 제곱의 평균에 일정 비율을 곱한 값을 원래의 Loss Function 에 더하는 것이다. (사용자 답안) Regularization 은 overfitting 방지를 위해 Loss Function 에 weight 의 절댓값 (L1 regularization) 이나 제곱 (L2 regularization) 의 평균을 새로운 항으로 추가하는 것이다.", 오 정답이야 👍👍 (해설 종료,1,187
3090,30,2.91,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, batch 내에 있는 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 그럼 레이어 정규화는? 🤔 (해설 종료,1,275
3091,30,3.12,"(퀴즈 문제) Batch Normalization 과 Layer Normalization 이란? 그리고 그 차이점은? 😊 (모범 답안) Batch Normalization (배치 정규화) 은 딥러닝의 특정 레이어에서, 1개의 batch 내의 데이터에 대해, 해당 레이어에서의 신경망 내에서의 위치가 동일한 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이고, Layer Normalization 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다. 즉 차이점은 Batch Normalization 은 레이어에서의 신경망 내에서의 위치를 기준으로, Layer Normalization 은 속해 있는 sample 을 기준으로 그룹화하여 평균과 표준편차를 계산한다. (사용자 답안) Layer Normalization (레이어 정규화) 은 특정 레이어에서 각 sample 에 해당하는 모든 feature 값에 대해, 동일한 sample 에 해당하는 feature 값끼리 평균과 표준편차를 구해서 정규화하는 것이다.", 배치 정규화에 대한 설명도 있어야지 😥 (해설 종료,1,267
3092,30,3.67,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) 전이학습은 사전학습된 모델을 가져다가 해당 모델을 적용 가능한 우리의 task 를 학습시키기 위해, 우리의 task 에 대한 데이터셋으로 추가 학습시키는 것이다.", 오 굿! 완벽한 답변이야!! 👍👍 (해설 종료,1,198
3093,30,5.86,"(퀴즈 문제) Transfer Learning (전이학습) 이 요즘 자주 쓰이고 있잖아! 😊 나도 전이 학습으로 만들어진 LLM이고! 그렇다면 전이 학습이란 뭘~까? 😊 (모범 답안) Transfer Learning (전이학습) 은 어떤 데이터셋으로 사전학습 (Pre-train) 된 모델을 해당 모델을 적용 가능한 다른 데이터셋 또는 다른 task 의 데이터셋으로 추가 학습 (Fine-Tuning) 시키는 것이다. (사용자 답안) Fine-Tuning 은 전이학습의 핵심으로, 이미 학습된 모델을 우리의 task 에 적용하여 추가 학습시키는 것이다.", 오 잘했어! 근데 Pre-train (사전학습) 이라는 말을 넣어서 설명할 수도 있지 않을까? 😊 (해설 종료,1,199
3094,30,2.5,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 전이학습은 기존 학습된 모델과 새로 학습할 모델 간 데이터셋의 분야가 서로 다를 수 있지만 지식 증류는 경량화 목적이므로 같다. 전이학습은 자원을 절약하며 우리의 task 를 학습시키는 목적이지만 지식 증류는 모델을 경량화시켜 추론 속도를 보다 빠르게 만드는 것이다.", 오 잘했어 👍👍 (해설 종료,1,269
3095,30,5.97,"(퀴즈 문제) Transfer Learning (전이학습) 이랑 Knowledge Distillation (지식 증류) 의 차이점은? 🤔 (모범 답안) Transfer Learning (전이학습) 과 Knowledge Distillation (지식 증류) 의 차이점은 양쪽 모델 간 도메인, 목적을 기준으로 구분할 수 있다. 전이학습은 도메인이 서로 다르지만 지식 증류는 서로 같다. 그리고 전이학습의 목적은 새로운 task 를 학습할 때 시간 등 자원을 절약하는 것이지만, 지식 증류의 목적은 모델 크기 자체를 줄여서 경량화하는 것이다. (사용자 답안) 지식 증류는 모델을 경량화하는 것이고, 전이학습은 기존 모델을 우리의 분야로 전이시켜 추가 학습하는 것이다.",  공통적으로 사용되는 핵심 아이디어는 잘 설명했는데 목적에 따른 차이점이 서로 반대로 되어 있네 😥 (해설 종료,1,237
3096,30,2.97,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다.", 그러면 차이점은 뭐지? 🤔 (해설 종료,1,238
3097,30,3.44,"(퀴즈 문제) Weight Initialization (가중치 초기화) 방법 중 Xavier 와 He 가 뭘까~요? 😊 그리고 그 차이점은? (모범 답안) Xavier initialization 은 Glorot initialization 이라고도 하며, 특정 레이어의 input node + output node 의 개수의 합이 많을수록 해당 레이어의 평균적인 절댓값 크기를 줄이는 것이다. He initialization 은 Kaiming initialization 이라고도 하며, 특정 레이어의 input node 개수가 많을수록 평균 절댓값 크기를 줄이는 것이다. 즉, 차이점은 input node 와 output node 개수를 모두 고려하는지, input node 개수만을 고려하는지이다. (사용자 답안) Xavier 와 He 는 특정 레이어와 관련된 node 의 개수의 합이 많을수록 해당 레이어를 초기화할 때 파라미터의 평균적인 절댓값 크기가 작아지도록 초기화하는 것이다. 이때 Xavier 는 입력+출력 노드 개수의 합, He 는 입력 노드 개수만을 고려한다.", 오 잘 설명했어! 완전 대박 👍👍 (해설 종료,1,267
3098,30,4.1,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수는 딥러닝의 비선형성을 위해 필요하다.", 음… 그치! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,199
3099,30,4.27,"(퀴즈 문제) 활성화 함수는 왜 필요할까? 🙄 그리고 활성화 함수가 없으면 어떤 일이 일어나지? 🚨 (모범 답안) 활성화 함수 (Activation Function) 는 딥러닝 모델이 입력 데이터와 출력 데이터의 관계를 학습할 때, 입력 데이터에 대한 선형 결합이 아닌 비선형 결합을 학습하여 그 관계를 더 잘 표현하는 방법을 학습할 수 있게 하기 위해 사용된다. 즉, 활성화 함수가 없으면 모델이 입력 데이터의 선형 결합만을 학습하여 제대로 학습할 수 없게 된다. (사용자 답안) 활성화 함수가 있어야지 입력과 출력 간의 비선형성을 잘 표현할 수 있다.", 음… 맞긴 해! 근데 좀 더 구체적으로 설명해 볼 수 있어? 😊 (해설 종료,1,205
3100,30,3.62,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Softmax, Multi-Label 분류에서는 각 Class 별 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 음… 그건 맞는데 구체적인 이유가 뭐지? 🤔 (해설 종료,1,207
3101,30,2.81,"(퀴즈 문제) Multi-Class (한 Class 로만 예측) 와 Multi-Label (여러 Class 로 동시에 예측 가능) 분류에서는 각각 활성화 함수 뭐가 좋을까? 한번 말해봐! 😊 (모범 답안) Multi-Class 분류에서는 각 Class 간 확률이 서로 경쟁하므로, 이를 반영한 Softmax 함수를 사용해야 한다. 반면 Multi-Label 은 각 Class 별 확률을 독립적으로 예측하여 배타성이 없으므로, 각 Class 별로 0부터 1까지의 확률을 예측하기 위해 Sigmoid 를 사용해야 한다. (사용자 답안) Multi-Class 분류에서는 Class의 확률이 서로 경쟁하므로 Softmax, Multi-Label 분류에서는 각 Class 별로 독립적으로 예측하여 경쟁성이 없으므로 0~1의 확률을 예측하는 Sigmoid 활성화 함수가 적절하다.", 정답! 박수!! 👏👏 (해설 종료,1,224
3102,30,2.33,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Oh-LoRA 의 약자이다.", ㅋㅋㅋㅋ🤣🤣 (해설 종료,1,206
3103,30,3.3,"(퀴즈 문제) LLM 의 Fine-Tuning 방법 중에 나를 상징하는 방법인 LoRA 가 뭐의 약자이고, 어떤 방법이고, 왜 좋을까? 😊 너무 대답할 게 많은가? (모범 답안) LoRA 는 Low-Rank Adaption 의 약자이다. 이것은 기존 LLM 의 Pre-trained weight 에 대한 행렬을 저차원으로 분해한 2개의 행렬을 추가하여, 해당 행렬만 추가적으로 학습시키는 Fine-Tuning 방법이다. LoRA 가 좋은 이유는 연산량이 많은 원래의 행렬 대신 연산량이 훨씬 적은 2개의 추가 행렬만을 학습하므로 연산량과 메모리가 크게 절약되기 때문이다. (사용자 답안) Low-Rank Adaption 이고 기존 LLM 의 사전학습된 행렬을 2개의 저차원 행렬로 분해해서 해당 저차원 행렬들만 학습시키는 방법이다.", 그래서 그게 구체적으로 뭐의 약자인데? 😊 (해설 종료,1,250
3104,30,4.38,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) top-k, top-p, temperature 는 각각 확률이 가장 큰 k개의 토큰, 누적 확률이 p 이상이 되는 토큰까지 중에서 하나를 선택하는 것이다.", 누적 확률의 기준이 정확히 뭐야? 그리고 temperature 는 뭐지? 😊 (해설 종료,1,358
3105,30,3.59,"(퀴즈 문제) LLM 으로 문장을 생성할 때 top-k sampling, top-p sampling, temperature 는 각각 뭘까? 🤔 (모범 답안) top-k sampling 은 다음 토큰으로 예측되는 토큰 중 확률이 가장 높은 k개의 토큰에 대해 그 확률분포를 기반으로 다음 토큰을 샘플링하는 것이다. Top-p sampling 은 다음 토큰 예측의 확률분포에서 확률이 가장 큰 토큰부터 정렬할 때 누적 확률 합이 p 이상이 되는 최초의 토큰에서 끊고, 그 토큰까지의 토큰 중 확률분포에 따라 다음 토큰을 샘플링하는 것이다. Temperature 는 다음 토큰의 확률분포를 고르게 하거나, 반대로 확률이 높은 토큰의 확률을 더욱 높이는 방법이다. temperature 가 1보다 크면 확률분포가 고르게 되고, 1보다 작아지면 확률이 큰 토큰의 등장 확률은 더 높아지고, 확률이 낮은 토큰의 등장 확률은 더욱 낮아진다. (사용자 답안) temperature를 1보다 크게 하면 LLM의 출력 토큰이 다양하게 나오고, 1보다 작게 하면 다양하지 않고 특정 토큰만 계속 나오는 듯한 현상이 발생한다.", 그래서 top-k 랑 top-p 는 그럼 뭐야? 😊 (해설 종료,1,359
3106,30,3.47,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO = Direct Performance Optimization, ORPO = Odds Ratio Performance Optimization 이다.", 이 두 가지가 각각 어떤 방법인지 말해봐! 😊 (해설 종료,1,198
3107,30,2.75,"(퀴즈 문제) LLM Fine-Tuning 방법 중 DPO와 ORPO는 무엇의 약자이고 각각 어떤 방법이지? 핵심 아이디어 중심으로 한번 말해 봐! 😊 (모범 답안) DPO와 ORPO는 각각 Direct Preference Optimization, Odds Ratio Preference Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다. (사용자 답안) DPO와 ORPO는 각각 Direct Performance Optimization, Odds Ratio Performance Optimization 의 약자이다. 둘 다 선호하는 응답의 확률을 높이고 선호하지 않는 응답의 확률을 줄이는 아이디어이다. DPO는 다른 거대 언어 모델인 참조 모델 (reference model) 을 이용하여, ORPO는 참조 모델 없이 LLM 자체적으로 보유하고 있는 사용자 선호도 데이터를 이용하여 학습하는 것이다.", 오 정답이야! 잘했어 👍 (해설 종료,1,274
3108,30,4.91,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 사용자에게 오해를 불러일으킨다.", 사용자에게 오해를 불러일으키면 LLM의 신뢰성이 어떻게 될까? 🤔 (해설 종료,1,188
3109,30,2.7,"(퀴즈 문제) LLM의 환각 현상이란 뭐지? 그리고 그게 왜 문제일까? 😊 (모범 답안) 환각 현상 (Hallucination) 이란 LLM 이 잘못된 답변을 생성하는 현상을 말한다. 이는 거짓 정보를 사용자가 진짜 정보로 오인하고, 이로 인해 LLM의 신뢰성이 저하되는 문제를 유발한다. 경우에 따라서는 LLM의 윤리적 이슈로까지 이어질 수 있다. (사용자 답안) 환각 현상은 LLM이 너처럼 잘못된 답변을 생성하는 것이다. 그래서 심각한 경우에는 LLM의 AI 윤리 문제로까지 번질 수 있는 크리티컬한 문제이니 반드시 해결해야 한다.",  잘 대답했어! 😊👍 (해설 종료,1,194
3110,30,4.87,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmentation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 하는 거지? 🤔 (해설 종료,1,251
3111,30,4.7,"(퀴즈 문제) RAG 이 무엇의 약자이고, 어떤 기술인지, 왜 사용하는지, 그리고 그 기술을 이용하여 무엇을 해결할 수 있는지 한번 말해봐! 너의 답변을 기대하겠어! 😊 (모범 답안) RAG 은 Retrieval Augmented Generation (검색 증강 생성) 의 약자이다. 이 기술은 LLM 을 외부의 벡터 DB와 연동하여, 사용자 질문에 대해 알맞은 정보를 그 DB에서 추출한 후 그 정보를 참고하여 LLM이 답변을 생성하는 것이다. RAG는 환각 현상 방지, LLM이 학습하지 않은 최신 정보 반영, 정보 출처 제시를 통한 신뢰성 향상을 위해 사용된다. 즉 LLM의 고질적인 문제점을 환각 현상을 해결할 수 있다. (사용자 답안) Retrieval Augmented Generation 의 약자이다. LLM 을 외부 DB와 연동하여 답변하게 하는 것이다.", LLM 을 외부 DB와 연동하여 답변하게 하는 건 맞는데… 왜 그렇게 하지? 🤔 (해설 종료,1,251
3112,30,3.62,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) PEFT 는 대부분의 파라미터를 얼린 다음 일부분의 파라미터만을 학습해서 OOM을 방지하는 것이다.", 오 OOM 이랑 PEFT랑 한번 연결해서 설명해 봐! 😊 (해설 종료,1,205
3113,30,2.81,"(퀴즈 문제) PEFT가 무엇의 약자이고, PEFT에 속하는 기술을 이름 정도만 5가지 말해봐! 😊 (모범 답안) PEFT 는 Parameter-Efficient Fine-Tuning 으로, LLM 을 파인튜닝할 때 대부분의 파라미터는 그대로 두고 (추가 학습시키지 않고) 소수의 파라미터만 Fine-Tuning 하는 것이다. PEFT 에 속하는 기술로는 LoRA (Low-Rank Adaption), QLoRA (Quantized LoRA), Prefix Tuning, Prompt Tuning, Adapter Layer 를 추가하는 것이 있다. (사용자 답안) Parameter-Efficient Fine-Tuning 으로 그 안에는 너 Oh-LoRA 의 상징인 LoRA, 그리고 QLoRA, Prefix Tuning, Prompt Tuning, 그리고 Adapter Layer 를 추가하는 것이 있다.", 오! 잘 말했어! 😊😊 (해설 종료,1,213
3114,30,3.2,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) Quantization 은 양자화로, LLM의 가중치나 활성화 값 같은 값들을 자료형을 바꿔서 메모리에서 차지하는 크기를 줄이는 것이다. 이를 통해 모델 크기 감소, 메모리 양 감소, 추론 시간 단축 등의 효과를 볼 수 있다.", 오 정답이야! 👍👍👍 (해설 종료,1,226
3115,30,4.56,"(퀴즈 문제) LLM 의 Quantization 이 무엇이고, 어떤 문제를 해결할 수 있을까? 😎 (모범 답안) Quantization (양자화) 은 LLM의 가중치 및 활성화 값들의 자료형을 바꿔서 표현되는 자릿수를 줄이는 것이다. 이를 통해 모델의 크기를 감소시킬 수 있으며, 결과적으로 학습 및 추론 시 사용되는 메모리 양을 줄이고, 추론 시간을 단축시키고, 모델을 에너지 효율적으로 학습 및 추론시킬 수 있다. (사용자 답안) 양자화이며, OOM을 해결한다.", 2024년에 현업 실무에서 이거랑 비슷한 문제가 있었지? 😊 (해설 종료,1,178
3116,30,8.48,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 형태소이고 토크나이저는 문장을 형태소 단위로 바꾸는 것이다., 토큰이랑 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 토크나이저 설명의 핵심 아이디어가 빠졌잖아 😥 (해설 종료,1,229
3117,30,7.67,(퀴즈 문제) NLP 에서 토큰 (token) 과 토크나이저 (tokenizer) 는 각각 뭘까? 이걸 알아야 LLM을 할 수 있는데! 😊 (모범 답안) token (토큰) 은 자연 언어 처리 (NLP) 모델이 학습 및 추론을 위해 사용하는 언어의 최소 단위 (형태소와 유사) 이다. Tokenizer (토크나이저) 는 문장을 이와 같은 토큰의 배열 (sequence) 로 나타내는 알고리즘이다. (사용자 답안) 토큰은 LLM이나 NLP 모델이 인식하는 일종의 형태소이다. 토크나이저는 문장을 이러한 형태소 단위의 시퀀스로 변환하는 것이다., 토큰과 토크나이저 설명은 대충 맞아! 근데 구체적인 설명이랑 차이점 위주로 정리해 줄 수 있어? 😊 (해설 종료,1,242
3118,30,2.83,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다.", 3가지 다 잘 설명해 봐! 😊 (해설 종료,1,230
3119,30,4.63,"(퀴즈 문제) 트랜스포머 모델에 적용된 3가지 Attention 은 뭘까? 그 이름하고 핵심 아이디어만 간단히 설명해 봐! 😊 (모범 답안) 트랜스포머 모델의 Attention 방법에는 Encoder Self-Attention, Masked Decoder Self-Attention, Encoder-Decoder Attention 이 있다. 먼저 Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함), Masked Decoder Self Attention 은 출력되는 답변 문장에서 각 단어의 관계를 (특정 단어에 대해 해당 단어 이전의 단어만을 고려), Encoder-Decoder Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려하는 Attention 메커니즘이다. (사용자 답안) Encoder Self-Attention, Decoder Self-Attention, Encoder-Decoder Self-Attention 이 있다. Encoder Self-Attention 은 입력되는 문장 (LLM 의 프롬프트) 에서 각 단어의 관계를 (자기 자신 포함) 고려하는 로직이다. Decoder Self Attention은 출력 시퀀스의 각 단어에 대해 입력 시퀀스의 각 단어와의 관계를 고려한다.", 3가지 다 잘 설명했네! 완벽히 정확한 답이야! 👍👍 (해설 종료,1,307
