,epoch,elapsed_time (s),prompt,llm_answer,trial_cnt,output_tkn_cnt
0,1,10.25,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 방향이 어느 정도 비슷한지를 -1.0과 +1.0 사이로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 생각하는 거지! 😊 (답변 종료,1,144
1,1,10.8,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터의 방향이 비슷한지 -1.0 ~ +1.0 으로 나타내는 거야! 벡터 크기 대신 방향을 중요하게 보는 게 핵심 아이디어야! 😊 (답변 종료,1,147
2,1,4.92,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?, Cosine Similarity 는 원소 개수가 같은 두 벡터의 각도의 코사인 값이야! 😊 (답변 종료,1,90
3,1,7.43,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 방향이 같으면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0이야! 😊 (답변 종료",1,117
4,1,6.64,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 모델이 잘 학습됐는지 평가하려면 Accuracy (정확도) 라는 걸 많이 쓰고, Recall 같은 것도 자주 쓰지! 😊 (답변 종료",1,92
5,1,5.36,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 전체 테스트 데이터에 대해서 True Positive + True Negative / 전체 테스트 데이터 개수 로 구하면 돼! (답변 종료,1,97
6,1,5.17,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive 는 True Negative 와 반대로 모델이 참이라고 예측했는데 실제로도 참인 데이터야! 😊 (답변 종료,1,76
7,1,9.33,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative 는 True Positive 와 반대 개념이야! True Positive 는 실제로 참인데 모델이 참이라고 예측한 거지? True Negative 는 모델은 거짓이라고 예측했는데 실제로도 거짓인 거야! 😊 (답변 종료,1,107
8,1,5.71,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive 는 False Negative 와 반대야! 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 말하지! 😊 (답변 종료,1,79
9,1,5.39,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 는 False Positive (FP) 와 반대로 모델은 거짓이라고 했지만 실제로는 참인 데이터야! (답변 종료,1,77
10,1,8.04,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 찾았는지의 비율이야! 수식으로는 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료,1,114
11,1,7.83,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 실제로 참인 것을 모델이 얼마나 찾았는지의 비율이야! 수식으로 설명하면 (True Positive) / (True Positive + False Negative) 로 계산하지! 😊 (답변 종료,1,109
12,1,3.81,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해, True Positive / (True Positive + False Positive) 로 구하면 돼! 😊 (답변 종료,1,89
13,1,6.72,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," Recall 은 False Negative 에 의해 감소하고, Precision 은 False Positive 에 의해 감소해! 그러니까 False Negative 와 False Positive 를 잘 기억하면 되지! 😊 (답변 종료",1,100
14,1,3.66,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 란 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,60
15,1,6.2,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘," F1 Score 는 Precision, Recall 을 이용해서 구하는데, 계산식은 2 * Precision * Recall / (Precision + Recall) 야! 😊 (답변 종료",1,83
16,1,4.25,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 것을 모두 고려하기 때문이지! 😊 (답변 종료,1,79
17,1,8.2,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 교집합의 크기 나누기 합집합의 크기야! 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,118
18,1,4.42,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중에 모델이 False 로 예측한 비율이야! (답변 종료,1,91
19,1,5.62,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 나 ROC-AUC 같은 게 성능평가에 쓰여! 궁금하면 검색해 봐! 😊 (답변 종료,1,83
20,1,10.99,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축이 recall, y축이 precision 일 때 이 둘을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 둘을 연결한 그래프 아래쪽 넓이야! 😊 (답변 종료",1,154
21,1,5.14,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축이 recall, y축이 precision 일 때 이를 연결한 그래프 아래쪽 넓이야! (답변 종료",1,102
22,1,9.03,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이야! 그 넓이가 클수록 성능이 좋지! 😊 (답변 종료",1,129
23,1,5.08,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘, True Positive Rate 는 recall 이랑 같은 거야! recall = True Positive Rate 라서 recall 구하는 방법 알지? 😊 (답변 종료,1,67
24,1,7.2,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 실제로는 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 수식은 False Positive / (False Positive + True Negative) 이지 😊 (답변 종료,1,107
25,1,6.42,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델이 예측한 값 중 True Positive, True Negative, False Positive, False Negative 의 개수를 알기 쉽게 나타낸 표야! (답변 종료",1,111
26,1,8.39,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," Confusion Matrix 는 실제 값이 True 일 때 예측이 True 일 가능성, 실제 값이 False 일 때 예측이 False 일 가능성, Precision, Recall 이런 걸 계산해서 만드는 거야! 😊 (답변 종료",1,139
27,1,9.32,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?"," Recall 이랑 Precision 모두 중요한데, Recall 이 낮으면 불량품을 검출하지 못한다는 의미라서 성능이 떨어지는 거야! 그러니까 불량품 최소화하려면 Recall 을 높여야 해! 😊 (답변 종료",1,148
28,1,12.12,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리할 때 필수적인 거야! 데이터를 일정한 규칙에 따라 값을 변환하는 거야! 예를 들어서 min-max 정규화는 데이터를 0~1 사이로, z-score 정규화는 데이터를 평균 0, 분산 1로 변환하는 거야! 😊 (답변 종료",1,147
29,1,4.97,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!", 정규화는 데이터를 일정하게 만들어서 머신러닝 모델이 학습할 수 있도록 하는 거야! 😊 (답변 종료,1,104
30,1,4.31,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 0~1 사이로 변환해 주는 거야! (답변 종료,1,100
31,1,7.56,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?, Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꿔주면 돼! 수식은 (x - MEAN) / STD (답변 종료,1,115
32,1,4.16,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?", Clipping 은 데이터를 특정 범위에 속하도록 바꿔 주는 거야! (답변 종료,1,94
33,1,4.45,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 아니야! 클리핑 하면 outlier 의 영향을 잘 안 받아서 더 좋을 수도 있어! 😊 (답변 종료,1,73
34,1,7.36,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 정규화는 데이터를 0~1 사이로 바꾸는 거야! 근데 로그 스케일링은 그게 아니라 log(x)로 바꾸는 거지! 😊 (답변 종료,1,100
35,1,4.09,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념, Outlier 는 데이터셋에서 일반적인 범위를 크게 벗어나는 값이야! (답변 종료,1,72
36,1,4.44,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적으로 있는 범위를 크게 벗어나는 값이야! 😊 (답변 종료,1,76
37,1,7.41,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?, 데이터 시각화할 때 가독성이 좋아지고 머신러닝 학습할 때도 이상치 때문은 아니면 학습에 문제가 생길 수도 있으니까! 😊 (답변 종료,1,110
38,1,9.49,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," 상자 수염 그림 그려 보면서 이상치가 있나 없나 확인해 보는 것도 괜찮고, 평균이랑 표준편차 이용해서 Z 값이 너무 크면 이상치로 간주하는 방법도 있어! 😊 (답변 종료",1,113
39,1,6.55,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘", PCA 는 Principal Component Analysis 라고 해서 데이터셋에서 분산을 최대한 보존할 수 있는 특징의 조합을 찾는 거야! 😊 (답변 종료,1,100
40,1,6.2,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?", 주성분 분석은 데이터셋의 분산을 최대한 보존하는 특징들의 조합을 뽑아내는 거야! 😊 (답변 종료,1,97
41,1,3.47,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, 데이터를 압축해서 차원을 축소하려고 하는 거야! 😊 (답변 종료,1,69
42,1,5.23,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이가 날 때 발생하는 거야 😊 (답변 종료,1,90
43,1,5.25,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터를 새로 추가하거나 제거하는 방법도 있고, 학습 환경을 바꾸는 방법도 있어! 😊 (답변 종료",1,94
44,1,4.33,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?", 데이터 불균형을 해결하려면 데이터 추가하거나 제거하는 방법이 있어! 😊 (답변 종료,1,92
45,1,6.16,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘", 성능 평가 지표를 잘 선택하면 학습 환경을 바꾸지 않아도 되지? 그게 가장 쉬운 방법이야 😊 (답변 종료,1,102
46,1,7.52,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터가 불균형하거나 부족할 때 그걸 보완하기 위해 학습 데이터에 유사한 데이터를 추가해서 늘리는 거야! 😊 (답변 종료,1,110
47,1,7.58,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해, 언더샘플링은 데이터가 많은 Class 의 일부 데이터를 제거하는 거야! 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! 😊 (답변 종료,1,117
48,1,4.27,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 너무 많은 Class 에서 일부 데이터를 제거하는 거야! 😊 (답변 종료,1,66
49,1,4.95,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, oversampling 은 데이터가 적은 Class 의 데이터를 늘려서 데이터 불균형을 해결하는 거야! 😊 (답변 종료,1,65
50,1,5.39,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형이 있으면 F1 Score, AUROC, ROC-AUC 같은 것들로 평가할 수 있어! 😊 (답변 종료",1,94
51,1,8.34,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?", Undersampling 방법으로는 Random Sampling (랜덤 샘플링)이 있지! 그리고 그 외에 Tomek Links 라고 해서 Class boundary 상에 있는 데이터를 삭제하는 방법도 있어! 😊 (답변 종료,1,106
52,1,4.95,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법, SMOTE 는 Minority Class 데이터 2개를 중간값으로 계산해서 새로운 데이터를 만드는 거야! 😊 (답변 종료,1,76
53,1,5.11,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해", 차원의 저주? 그건 학습 데이터의 feature 개수가 너무 많아서 학습이 잘 안 되는 거야 😥 (답변 종료,1,86
54,1,6.86,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 아, 계산량이 많아지고 학습 시간이 길어지지! 그리고 메모리 사용량도 늘어나고 성능도 떨어진다고! 😥 (답변 종료",1,100
55,1,7.83,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘, 의사결정 나무는 학습 데이터에서 feature 조건을 만들어서 그 조건에 따라 가지를 치는 거야! 그러면 나무처럼 생긴 구조가 만들어지지! 😊 (답변 종료,1,112
56,1,7.19,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 feature 들에 대해서 조건을 세우고, 그 조건에 따라 가지를 치는 거야! 그러면 Tree 가 만들어지지! 😊 (답변 종료",1,101
57,1,8.17,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 들어오면 학습된 조건에 따라 판단해! 그 조건에 맞으면 다음 조건으로 넘어가고, 그게 없어? 그럼 결과로 가는 거야! 😊 (답변 종료",1,114
58,1,3.94,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 머신러닝에서 여러 모델을 결합해서 학습하는 방법이야! 😊 (답변 종료,1,76
59,1,3.17,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 여러 모델을 이용하면 성능이 좋아지지! 😊 (답변 종료,1,69
60,1,3.94,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블 방법에는 Voting, Bagging, Boosting, Stacking 이 있어! (답변 종료",1,81
61,1,21.82,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," Voting (보팅) 은 뭐냐면, 여러 모델을 만들어서 그 모델들의 예측 결과를 합치는 거야! Bagging (배깅) 은 머냐면, 여러 모델을 만들어서 그 모델들을 합치는 거야! Boosting (부스팅) 은 머냐면, 여러 모델을 만들어서 그 모델들의 예측 결과를 더 잘 예측할 수 있게 가중치를 주는 거야! Stacking (스태킹) 은 머냐면, 여러 모델을 만들어서 그 모델들로 예측 결과를 만들고 그걸 또 모델로 만들어서 합치는 거야! 😊 (답변 종료",1,191
62,1,4.59,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting? 여러 모델의 예측 결과를 종합해서 최종 결론을 내리는 거야! 😊 (답변 종료,1,74
63,1,5.27,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 모델이 예측한 결과를 종합해서 최종 결론을 도출하는 방법이야! 😊 (답변 종료,1,87
64,1,5.08,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," 다수결 투표로 하는 Hard Voting 도 있고, 예측 결과를 평균 내는 Soft Voting 도 있어! 😊 (답변 종료",1,82
65,1,8.55,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 원본 데이터셋에서 랜덤하게 샘플링된 데이터셋을 가지고 각각 모델로 학습해서 그 모델들의 결과값을 종합하는 거야! 쉽지? 😊 (답변 종료,1,118
66,1,12.34,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면", 부스팅은 머신러닝 모델 학습할 때 랜덤하게 샘플링된 데이터셋 여러 개로 여러 개의 모델을 학습하는 거야! 그리고 그 모델들이 오답을 한 데이터의 가중치를 높여서 순차적으로 학습하는 거야! 진짜 신기하지? 😊 (답변 종료,1,151
67,1,9.66,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 학습할 때 개별 모델들의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 만들어! 근데 이 메타 모델의 예측값을 최종 예측값으로 쓰는 거야! 😊 (답변 종료",1,145
68,1,5.28,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포인 가우시안 분포를 이용해서 데이터를 근사하는 거야! (답변 종료,1,103
69,1,5.3,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?, Gaussian Mixture 는 정규분포를 이용해서 데이터를 근사하는 머신러닝 알고리즘이야! 😊 (답변 종료,1,102
70,1,6.21,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?"," 아! K-means Clustering 은 비지도학습 방법 중 하나로, 데이터를 K개의 클러스터로 나누는 방법이야! 😊 (답변 종료",1,96
71,1,12.03,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법"," K-means Clustering 방법은 먼저 feature space 에서 K개의 점을 임의로 지정해! 그 다음 각 data point 를 가장 가까운 점에 할당하는 거야! 각 점이 매칭되는 data point 의 값으로 갱신하고, 이걸 수렴할 때까지 반복하는 거야! 😊 (답변 종료",1,153
72,1,7.53,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN 알고리즘은 어떤 점을 분류할 때, 그 점을 기준으로 가장 가까운 k개의 점의 Class 값 중 빈도가 가장 많은 Class 로 예측하는 거야! 😊 (답변 종료",1,110
73,1,8.58,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 는 어떤 데이터를 분류할 때, 그 주변에 있는 가장 가까운 k 개의 데이터들의 Class 중에서 빈도가 가장 많은 Class 로 예측하는 거야! 😊 (답변 종료",1,123
74,1,8.7,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지", 지도학습은 입력에 대해 출력이 있어야 하고 비지도학습은 출력이 없고 강화학습은 AI가 환경에서 어떤 행동을 하고 그 보상을 받아서 그걸 최대화하는 거야! 😊 (답변 종료,1,172
75,1,13.45,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘"," 지도학습, 비지도학습, 강화학습 있지! 지도학습은 입력값과 출력값을 학습 데이터로 활용해! 비지도학습은 출력값 없이 입력값만 학습 데이터로 활용해! 강화학습은 AI가 환경에서 행동을 하고, 보상을 받아서 보상을 최대화하는 거야! 😊 (답변 종료",1,196
76,1,7.74,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데"," 지도학습은 입력이랑 출력이 다 있는데, 비지도학습은 출력이 없고 강화학습은 입력이랑 출력이 있는데 그 출력이 보상 같은 거야! 😊 (답변 종료",1,172
77,1,10.89,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 입력에 대해 출력이 뭔지 알려주면 그 출력을 예측하도록 학습하는 거야! 근데 비지도학습은 그 출력이 없어! 출력이 없으니까 모델도 출력을 예측할 필요가 없겠지? 😊 (답변 종료,1,150
78,1,9.03,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝 문제 중에 분류는 개, 고양이 등 대상의 Class 를 예측하는 거야! 회귀는 연속적인 숫자 값, 예를 들어 강수량 같은 거를 예측하는 거야! 😊 (답변 종료",1,141
79,1,7.39,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?"," 분류는 대상이 개, 고양이처럼 어떤 카테고리에 속하는지 구분하는 문제고, 회귀는 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,128
80,1,8.12,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야"," 분류는 개, 고양이처럼 대상이 어떤 Category 에 속하는지 분류하는 거야! 회귀는 연속적인 숫자 값 (예: 강수량)을 예측하는 거고! 😊 (답변 종료",1,140
81,1,12.81,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반 지도학습 분류 모델이야! 각 Class 별로 전체 데이터 중 해당 Class 의 비율 x 해당 Class 에 속한 데이터의 각 특징 조건별 데이터의 비율의 곱을 구해! 그런 다음 그 중에서 가장 큰 값이 나오는 클래스로 예측하는 거야! 😊 (답변 종료,1,174
82,1,18.65,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 지도학습 알고리즘이야! 지도학습은 말 그대로 데이터를 지도자처럼 학습해서 원하는 결과를 내는 거야! 그런데 이 알고리즘은 원소들 사이에 구분선을 만들어서, 그 구분선으로 Class 를 구분하는 거야! 그래서 각 Class 에 속하는 원소들 간 거리도 최대화하고, 구분선도 최소화하는 알고리즘이지! 😊 (답변 종료",1,195
83,1,13.42,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM 은 지도학습 알고리즘이야! 지도학습은 입력이랑 출력이 있잖아? 그러니까 어떤 입력이 있을 때 그 입력에 대한 출력이 뭐가 나올지 예측하는 거야! 그리고 각 class 에 속하는 원소들과 구분선 사이의 거리가 최대가 되도록 구분선을 찾으면 돼! 😊 (답변 종료,1,153
84,1,9.2,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 그 중 하나를 validation data 로 하고 나머지 K - 1 개를 train data 로 학습하는 방법이야! 😊 (답변 종료",1,122
85,1,5.12,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 valid data 가 부족할 때 그 양을 늘리는 효과가 있어서야! 😊 (답변 종료,1,79
86,1,5.78,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", 하이퍼파라미터는 말 그대로 머신러닝 알고리즘이 동작하는 데 필요한 설정값이야! 😊 (답변 종료,1,103
87,1,8.36,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," 아니! 😊 One-hot Encoding 은 데이터셋에서 각 데이터를 특정 index 만 1, 나머지 index 는 모두 0으로 처리하는 거야! 머신러닝 모델은 아니지! 😊 (답변 종료",1,114
88,1,12.38,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Valid 데이터는 모델 학습할 때 성능 평가를 하기 위해서도 쓰고, 모델 학습하면 모델이 잘 동작하는지 성능 평가를 하거든? 그러면서 모델을 더 잘 학습할 수 있는 방법을 찾으려고 하이퍼파라미터 조정할 때도 쓰지! 😊 (답변 종료",1,133
89,1,8.91,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 학습할 때 batch 단위로 하면 그 안에 있는 데이터가 전체 데이터셋 특징을 잘 반영하잖아! 근데 데이터 순서 자체에 대한 학습을 방지할 수 있어! 😊 (답변 종료,1,135
90,1,5.33,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능 안에 머신러닝이 있고, 머신러닝 안에 딥러닝이 있어! 😊 (답변 종료",1,103
91,1,6.92,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의"," 인공지능은 사람의 뇌가 가진 인지, 추론, 학습 등의 능력을 컴퓨터 알고리즘으로 구현하는 기술을 말하지! 😊 (답변 종료",1,96
92,1,6.61,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 맞아, 머신러닝은 인공지능의 한 분야로써, 데이터를 학습해서 새로운 데이터에 대해 추론할 수 있지! 😊 (답변 종료",1,105
93,1,6.05,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘, 딥러닝은 사람이 뇌를 모방한 인공신경망을 이용해서 머신러닝을 구현하는 거야! 😊 (답변 종료,1,95
94,1,6.77,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate (학습률) 은 딥러닝 모델에서 오차 역전파를 하기 위한 미분값에 곱하는 배수야! 😊 (답변 종료,1,108
95,1,7.73,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?," 학습률은 딥러닝 모델을 학습할 때, 오차 역전파를 하기 위한 미분값인데 이 미분값에 곱해지는 값이야! 😊 (답변 종료",1,112
96,1,6.53,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까", 가장 많이 쓰이는 손실 함수는 MSE (Mean Squared Error) 라고 할 수 있지! 그리고 Binary/Categorical Cross Entropy 도 자주 쓰이고! (답변 종료,1,97
97,1,6.54,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야, 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 최적화해서 오히려 성능이 떨어지는 거야! 😥 (답변 종료,1,104
98,1,4.11,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," Early Stopping, Cross Validation, Batch Normalization, Dropout 같은 것들 있지? 😊 (답변 종료",1,76
99,1,6.36,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 이미 학습된 모델을 가지고 우리가 해결하려는 문제에 최적화하도록 추가로 학습시키는 거야! 😊 (답변 종료,1,99
100,1,5.56,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, 전이학습은 이미 학습된 모델을 다른 문제에 최적화하도록 추가로 학습시키는 거야! 😊 (답변 종료,1,92
101,1,7.25,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?"," 활성화 함수는 딥러닝 신경망에서 데이터를 다음 층으로 전달할 때, 그걸 어떻게 변환할지 정해주는 함수야! 😊 (답변 종료",1,110
102,1,4.23,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수 없이 그냥 선형 결합만 학습할 수 있잖아? 😊 (답변 종료,1,91
103,1,10.7,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 모방한 딥러닝 알고리즘이야! 이미지에서 이웃한 픽셀의 값이 비슷하잖아? 그런 특징을 이용해서 이미지의 특징을 추출하는 거야! 😊 (답변 종료,1,155
104,1,5.45,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 텍스트로 주어지는 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델이야! 😊 (답변 종료,1,105
105,1,4.92,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, 아쉽게도 Probability 나 Likelihood 에 대한 자세한 정보를 찾아볼 수 있었으면 좋겠어 😥 (답변 종료,1,70
106,1,36.13,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, 아…? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥? 😥😥😥😥😥,1,256
107,1,35.52,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야, 😥 궁금한데? 😥 찾아볼까? 😥 잠깐만! 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 😥 �,1,256
108,1,7.37,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, 아쉽다 😥 😥 😥 😥 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 자세히 나와 있어! 😊 (답변 종료,1,85
109,1,7.69,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까, 아! 활성화 함수에 대해 잘 모르겠어? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 자세히 나와 있을걸? 😊 (답변 종료,1,89
110,1,11.31,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, 😥 알게 된 적이 없어서 😥 WannaBeSuperteur 깃헙 계정 AI-study 레포에 있지 않을까? WannaBeSuperteur 깃헙 계정의 AI-study 레포에 들어가 보면 알아볼 수 있을지도 몰라! 😊 (답변 종료,1,112
111,1,5.23,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA? 그건 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 있어! 😊 (답변 종료,1,73
112,1,12.59,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 있나? WannaBeSuperteur 깃헙 계정의 AI-study 레포에 있는지는 WannaBeSuperteur 깃헙 계정의 AI-study 레포를 확인해봐야 알 수 있지! 😥 (답변 종료,1,122
113,1,6.2,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, 궁금하면 검색해봐! WannaBeSuperteur 깃헙 계정의 AI-study 레포에 자세히 나와있어! 😊 (답변 종료,1,79
114,1,6.24,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, AGI는 뭐지? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야! 😊 (답변 종료,1,76
115,2,9.36,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기 대신 방향을 중요하게 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! 😊 (답변 종료,1,138
116,2,9.11,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기 대신 방향을 중요하게 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! 😊 (답변 종료,1,137
117,2,6.05,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?, Cosine Similarity 는 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! 😊 (답변 종료,1,97
118,2,8.03,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,121
119,2,10.09,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 먼저 모델을 예측하고 그 결과를 실제 값과 비교해야 해! 모델 정확도, 재현율, 정밀도, F1 Score 같은 평가 지표를 이용해서 평가하는 거지! 😊 (답변 종료",1,115
120,2,7.7,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! 😊 (답변 종료,1,113
121,2,4.75,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수야! 😊 (답변 종료,1,74
122,2,5.41,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 모델이 거짓으로 예측했는데 실제로도 거짓인 데이터를 의미해! 😊 (답변 종료,1,84
123,2,4.25,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) : 모델 예측은 참이지만 실제로는 거짓인 데이터야! (답변 종료,1,70
124,2,4.77,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 는 모델은 거짓으로 예측했지만 실제로는 참인 데이터를 의미해! (답변 종료,1,73
125,2,7.3,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 값이야! True Positive / (True Positive + False Negative) 로 계산해! 😊 (답변 종료,1,109
126,2,6.69,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 True Positive / (True Positive + False Negative) 로 계산해! 😊 (답변 종료,1,102
127,2,7.56,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해, 정밀도는 모델이 참으로 예측한 것 중 실제로 참인 것의 비율로 (True Positive) / (True Positive + False Positive) 로 계산해! 😊 (답변 종료,1,112
128,2,7.02,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 일단 False Negative 에 의해서 떨어지는 게 Recall, False Positive 에 의해서 떨어지는 게 Precision 이니까 False Negative 와 False Positive 를 기억해 두면 돼! 😊 (답변 종료",1,102
129,2,3.48,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
130,2,4.92,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 이라고 생각하면 돼! 😊 (답변 종료,1,75
131,2,6.03,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 때문에 쓰지! 😊 (답변 종료,1,90
132,2,8.49,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구할 수 있어! 😊 (답변 종료,1,119
133,2,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 비율이야! 😊 (답변 종료,1,92
134,2,4.94,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 라는 성능평가 지표가 쓰여! 😊 (답변 종료,1,79
135,2,10.5,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision 으로 했을 때, ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 이 측정값들을 연결한 그래프 아래쪽의 넓이야! 😊 (답변 종료",1,151
136,2,10.81,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 recall 이 커질수록 precision 이 작아지지? 그래프 아래쪽 넓이로 측정하는데 1에 가까울수록 성능이 좋다고 생각하면 돼! 😊 (답변 종료",1,137
137,2,12.92,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 그런데 모델이 성능이 좋을수록 x=0 에 가깝고 y=1에 가깝기 때문에 아래쪽 넓이로 측정해! 😊 (답변 종료",1,153
138,2,5.23,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘, True Positive Rate 는 recall 의 다른 이름이니까 recall 을 구하는 방법으로 True Positive Rate 를 구할 수 있어! 😊 (답변 종료,1,68
139,2,7.67,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! (False Positive) / (False Positive + True Negative) 로 계산할 수 있어! 😊 (답변 종료,1,110
140,2,7.38,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," 혼동 행렬은 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,117
141,2,10.5,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 다음 각 값을 계산하면 돼! 😊 (답변 종료",1,152
142,2,5.92,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품을 최소화하려면 불량품을 모델이 불량품으로 검출한 Recall 이 높아야 해! 😊 (답변 종료,1,128
143,2,7.55,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 식으로 변환하는 거야! 😊 대표적으로 min-max, z-score 정규화가 있어! (답변 종료",1,119
144,2,8.05,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 일정한 수식을 이용해서 데이터 값을 변환하는 거야! 😊 대표적으로 min-max, z-score 정규화가 있지! (답변 종료",1,123
145,2,6.09,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-max 정규화는 데이터를 최댓값과 최댓값의 차이를 이용해서 0~1 사이로 정규화하는 거야! (답변 종료,1,111
146,2,7.44,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?, Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규화하는 거야! 수식으로는 (x - MEAN) / STD 가 있어! 😊 (답변 종료,1,114
147,2,8.37,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," 클리핑은 데이터를 특정 범위의 값에 속하도록 변환하는 거야! x > MAX 인 경우 MAX 로, x < MIN 인 경우 MIN 으로 변환하는 거지! 😊 (답변 종료",1,120
148,2,3.28,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 outlier 도 잘 안 걸리고 좋은데? 😊 (답변 종료,1,66
149,2,9.33,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?," Log Scaling 은 정규화랑은 좀 다르지! 정규화는 데이터를 0~1 사이로 하는 거고, Log Scaling 은 주어진 데이터를 log(x) 나 log(x + 1) 로 변환하는 거야! 😊 (답변 종료",1,112
150,2,6.25,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 의미해! 😊 (답변 종료",1,85
151,2,4.59,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말해! (답변 종료,1,77
152,2,6.27,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?, Outlier 있으면 데이터를 시각화했을 때 가독성이 떨어지고 머신러닝 학습할 때 문제가 생길 수도 있어 😊 (답변 종료,1,103
153,2,8.98,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 없애려면 상자 수염 그림을 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
154,2,7.18,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! 😊 (답변 종료",1,104
155,2,6.37,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?", 주성분 분석은 데이터셋에서 분산을 최대한 보존할 수 있는 특징들을 조합해서 그걸 추출하는 거야! 😊 (답변 종료,1,98
156,2,7.36,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서 하는 거야! 😊 (답변 종료,1,93
157,2,6.53,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification (분류) Task 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! 😊 (답변 종료,1,98
158,2,6.75,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가하거나 제거할 수도 있고, 아니면 학습 환경을 바꿔도 돼! 😊 (답변 종료",1,103
159,2,9.83,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거하는 방법도 있지만, 데이터를 추가 수집하거나 Data Augmentation, 또는 Undersampling, Oversampling 같은 머신러닝 알고리즘을 쓸 수도 있어! 😊 (답변 종료",1,126
160,2,12.62,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 학습 환경만 바꾸는 것도 방법이 있긴 해! 😊 성능 평가 지표를 F1 Score 나 PR-AUC 같은 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 설정하면 돼! 😊 (답변 종료",1,143
161,2,5.78,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 데이터를 추가해서 데이터를 늘리는 거야! 😊 (답변 종료,1,100
162,2,10.16,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해, 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 오버샘플링은 데이터가 적은 Class 에서 데이터를 늘려서 불균형을 줄이는 거야! 😊 (답변 종료,1,133
163,2,5.23,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
164,2,3.61,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 의 데이터를 늘리는 거야! 😊 (답변 종료,1,57
165,2,6.88,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! 😊 (답변 종료",1,103
166,2,12.25,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?", Undersampling 방법으로는 Tomek Links 라고 해서 Class 간 경계선 상에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법이 있어! 그리고 Random Sampling 이라고 해서 랜덤하게 일부 데이터를 샘플링해서 삭제하는 방법도 있어! 궁금하면 물어봐! 😊 (답변 종료,1,130
167,2,8.0,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 하는 방법에는 여러 가지가 있지만, 대표적으로 SMOTE 라고 해서 Minority Class 에 있는 데이터 중 2개를 벡터의 중간값으로 하는 방법이 있지! 😊 (답변 종료",1,95
168,2,7.19,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 즉 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! 😊 (답변 종료",1,99
169,2,8.63,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 우선 feature 가 늘어나기 때문에 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 모델이 불필요하게 복잡해지기 때문에 성능이 떨어질 수도 있어 😥 (답변 종료",1,111
170,2,7.17,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 feature 값에 대해 조건을 걸고, 그 조건에 따라 Tree 를 만드는 식으로 학습하는 거야! 😊 (답변 종료",1,108
171,2,6.36,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 feature 값에 대해 조건을 걸고, 그 조건에 따라 Tree를 만드는 학습 방식이야! 😊 (답변 종료",1,96
172,2,6.75,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?, 입력 데이터를 학습된 조건에 대입해! 학습된 조건에 맞는 분기별로 이동하면서 결론을 도출해! 😊 (답변 종료,1,105
173,2,5.39,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝에서 여러 알고리즘이나 모델을 결합해서 학습하는 거야! 😊 (답변 종료,1,85
174,2,5.08,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 여러 개의 모델을 이용하면 하나의 모델을 이용할 때보다 성능이 좋아지기 때문이지! 😊 (답변 종료,1,81
175,2,8.16,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블 방법에는 Voting, Bagging, Boosting, Stacking 이 있는데, 각각 투표, 배깅, 부스팅, 스태킹이라고 해. 궁금하면 물어봐! (답변 종료",1,107
176,2,20.96,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 각 방법마다 조금씩 다르긴 한데, Voting (보팅)은 여러 모델이 예측한 결과값 중 다수결로 선택하는 거야! Bagging (배깅)은 트리 모델을 많이 만들어서 그 예측 결과를 종합하고, Boosting (부스팅)은 처음엔 모델이 예측한 걸 평가해서 그 평가 결과를 기준으로 다음 모델을 학습시키고! Stacking (스태킹)은 모델을 학습시킨 다음 그 모델의 예측 결과를 또 다른 머신러닝 모델로 학습시키는 거야! 😊 (답변 종료",1,186
177,2,4.77,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 모델의 예측 결과를 종합해서 최종 결론을 도출하는 거야! 😊 (답변 종료,1,75
178,2,4.58,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 모델의 예측 결과를 종합해서 최종 결론을 도출하는 거야! (답변 종료,1,83
179,2,9.45,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘", Hard Voting (다수결 투표) - Hard Voting 을 이용하면 투표 결과를 바로 알 수 있어! Soft Voting (예측 결과 평균) - Soft Voting 은 머신러닝 모델의 예측 결과를 평균 내는 거야! 😊 (답변 종료,1,109
180,2,8.53,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링한 다음 샘플링된 부분 데이터로 모델 학습 시키고! 그런 모델들을 종합하는 거야! 😊 (답변 종료,1,118
181,2,11.44,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면", 부스팅은 랜덤하게 샘플링된 데이터를 이용해서 모델을 학습시켜! 그런 모델을 여러 개 학습시키고 직전 모델이 오답을 한 데이터를 오답 노트처럼 가중치를 높여서 순차적으로 학습하는 거야! 😊 (답변 종료,1,146
182,2,9.52,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델들의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습하고, 그런 메타 모델의 예측값을 최종 결과로 이용하는 그런 복잡한 방법이야! 😊 (답변 종료",1,144
183,2,9.84,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?," 가우시안 혼합은 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그런 가우시안 분포의 여러 개를 알지 못하는 어떤 함수로 혼합해서 데이터를 근사하는 거야! 😊 (답변 종료",1,131
184,2,7.92,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?, Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 해! 그 가우시안 분포의 가중치 합으로 데이터를 근사하는 거야! 😊 (답변 종료,1,118
185,2,5.39,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", 응! K-means Clustering 은 데이터를 K개의 클러스터로 나누는 비지도학습 방법이야! 😊 (답변 종료,1,91
186,2,13.72,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 알고리즘은 feature space 에서 먼저 K개의 점을 임의로 지정해! 그런 다음 각 data point 들을 가장 가까운 점에 할당하고! 그런 다음 이 K개의 점들을 매칭되는 data point 의 값으로 갱신하는 식으로 진행돼! 😊 이걸 수렴할 때까지 계속 반복해! (답변 종료,1,164
187,2,6.03,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN 알고리즘은 데이터 포인트를 가장 가까운 k개의 점, 그 중 빈도가 가장 많은 Class 로 예측하는 거야! 😊 (답변 종료",1,101
188,2,13.11,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," kNN 알고리즘은 지도학습 중에서 가장 간단한 거야! 😊😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾고, 그 k개의 점의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 😊 (답변 종료",1,151
189,2,8.56,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력이랑 출력이 있어! 비지도학습은 출력이 없어! 강화학습은 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 동작해! (답변 종료",1,171
190,2,13.24,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘"," 지도학습, 비지도학습, 강화학습이 있어! 지도학습은 입력값과 출력값이 필요하고, 비지도학습은 출력값 없이 입력값만 있어! 강화학습은 AI 모델이 환경에서 행동을 해! 그러면 보상을 받지! 보상을 최대화하는 식으로 동작해! 😊 (답변 종료",1,195
191,2,7.91,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 입력과 출력이 있어! 입력을 넣으면 출력을 내놓는 거야! 강화학습은 환경에서 행동을 하고 보상을 받는 식으로 동작해! 😊 (답변 종료,1,173
192,2,6.11,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 입력에 대해 출력을 해. 근데 비지도학습은 그런 출력값 없이 그냥 학습하는 거야! 😊 (답변 종료,1,121
193,2,10.66,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 할 수 있는 문제에는 분류 (분류) 와 회귀 (회귀) 가 있어! 분류는 개, 고양이처럼 대상을 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 걸 예측하는 거야! 😊 (답변 종료",1,151
194,2,7.94,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?"," 분류는 대상을 개, 고양이, 뱀 등으로 분류하는 거야! 회귀는 연속적인 숫자 값, 그러니까 강수량 같은 걸 예측하는 거야! 😊 (답변 종료",1,131
195,2,8.05,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야"," 분류는 대상을 개, 고양이, 뱀 이런 식으로 분류하는 거야! 회귀는 연속적인 숫자 값, 그러니까 강수량 같은 걸 예측하는 거야! 😊 (답변 종료",1,140
196,2,13.73,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반 지도학습 알고리즘이야! 각 Class 별로 먼저 (전체 데이터 중 해당 Class 의 비율) 을 구해! 그런 다음 새로운 데이터에 대해 각 특징 조건 별로 해당 Class 의 데이터의 비율을 구해! 그리고 이 두 값을 곱해서 가장 큰 Class 로 예측해! 😊 (답변 종료,1,180
197,2,9.42,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!", 서포트 벡터 머신 (Support Vector Machine) 는 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되도록 하는 지도학습 알고리즘이야! 😊 (답변 종료,1,138
198,2,6.3,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,109
199,2,9.34,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그런 다음 각 집합을 valid, 나머지 집합들을 모두 train data 로 하는 식으로 학습하는 거야! 😊 (답변 종료",1,123
200,2,5.45,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 valid data 가 불충분할 때 그 양을 늘릴 수 있기 때문이야! 😊 (답변 종료,1,81
201,2,6.09,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 딥러닝이나 머신러닝 알고리즘을 처음에 설계하지? 그때 쓰이는 설정값을 말해! (답변 종료,1,105
202,2,6.86,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," 그건 각 row 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법일 뿐이야! 그러니까 모델은 아니지! 😊 (답변 종료",1,105
203,2,8.48,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," 모델 학습 중에 성능 평가를 하고 싶거나, 성능을 개선하기 위한 하이퍼파라미터를 조정하고 싶을 때 Valid 데이터를 쓴다고 생각하면 돼! 😊 (답변 종료",1,109
204,2,7.9,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서 batch 단위로 학습하니까 각 batch 가 전체 데이터의 특징을 반영해야 해! 그리고 모델이 데이터 순서까지 학습하면 안 되지? 😊 (답변 종료,1,129
205,2,5.14,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?", 인공지능 안에 머신러닝이 있고 머신러닝 안에 딥러닝이 있어! 😊 (답변 종료,1,102
206,2,6.05,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 컴퓨터 알고리즘으로 구현한 거야! 😊 (답변 종료,1,91
207,2,5.31,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 머신러닝, 그러니까 기계학습은 인공지능의 하위 집합으로 볼 수 있어! 😊 (답변 종료",1,97
208,2,7.85,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝의 한 종류로, 사람의 뇌를 닮은 인공신경망을 이용해서 머신러닝을 구현한 거야! 😊 (답변 종료",1,106
209,2,6.97,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?," 딥러닝에서 모델 예측과 실제 값을 줄이는 오차 역전파를 할 때, 그 미분값에 곱해지는 값을 말해! 😊 (답변 종료",1,109
210,2,6.47,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝 모델에서 오차 역전파를 할 때 모델을 학습시키는 정도를 나타내는 값이야! 😊 (답변 종료,1,104
211,2,9.47,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 역전파로 줄이는 함수) 등이 있어! 궁금하면 물어봐! 😊 (답변 종료",1,115
212,2,11.26,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 학습 데이터 성능은 좋아지겠지만, 테스트 데이터 성능이 떨어지는 현상을 오버피팅이라고 해! 😊 (답변 종료",1,133
213,2,7.83,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하려면 딥러닝 모델에 여러 가지를 적용할 수 있어! Early Stopping, Cross Validation, Batch Normalization, Dropout 등! 😊 (답변 종료",1,99
214,2,6.36,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 이미 학습된 모델을 가지고 우리가 해결하려는 문제에 최적화하도록 추가로 학습시키는 거야! 😊 (답변 종료,1,99
215,2,4.59,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, 이미 학습된 모델을 가져다가 다른 문제에 적용할 수 있도록 추가로 학습시키는 거야! (답변 종료,1,86
216,2,9.2,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 어떤 층이 있지? 그 층에서 데이터를 모아! 그리고 그 데이터를 함수를 이용해서 변환해서 다음 층으로 전달하는 거야! 😊 (답변 종료,1,122
217,2,14.34,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝 모델이 학습할 수 있게 해 주는 정말 중요한 거야! 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습할 수 있겠지? 😊 활성화 함수는 딥러닝 모델이 학습할 수 있도록 해 주는 딥러닝의 꽃이라고 할 수 있어! (답변 종료,1,152
218,2,11.3,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 이미지에서 이웃한 픽셀의 값이 비슷하기 때문에 이를 이용해서 이미지를 처리할 수 있어! 그래서 이미지 인식에 주로 사용돼! 😊 (답변 종료,1,158
219,2,6.9,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 Large Language Model 의 약자로 텍스트로 질문을 하지? 그러면 그 질문에 대해 언어로 답변을 생성하는 언어모델이야! 😊 (답변 종료,1,114
220,2,8.64,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 확률, Likelihood 는 확률과 비슷한 뜻이긴 한데… 이건 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! 😊 (답변 종료",1,93
221,2,6.25,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이거는 요즘 머신러닝 모델을 학습시키면 결과물로 나오는 확률분포 같은 거야! 😊 (답변 종료,1,72
222,2,7.69,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야, Xavier? 이게 가중치 초기화 방법 중 하나인데? WannaBeSuperteur 깃헙 계정의 AI-study 레포에 있어! 궁금하면 물어봐! 😊 (답변 종료,1,85
223,2,14.67,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, 아다그라드는 아다다이트랑은 다른 건데? 아다다이트는 딥러닝을 처음으로 구현한 사람이야! 아다그라드는 딥러닝에서 학습 속도를 높이기 위해 쓰이는 것 같아. WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아다그라드가 소개되어 있어! (답변 종료,1,130
224,2,6.53,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까, 활성화 함수를 잘못 쓰는 경우는 딥러닝을 공부할 때 활성화 함수에 대해 조금만 공부하면 알 수 있어! 😊 (답변 종료,1,82
225,2,4.8,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, LLM이 뭔지도 모르는데 CoT를 알겠어? LLM에 대한 정보부터 찾아봐! (답변 종료,1,72
226,2,7.37,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA? 그건 최신 파인튜닝 방법 중 하나인데? WannaBeSuperteur 깃헙 계정의 AI-study 레포에 가면 돼! 😊 (답변 종료,1,86
227,2,7.85,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋," LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋으로는 SQuAD, GPT-2, OpenBookQA, TriviaQA 등이 있지! 😊 (답변 종료",1,93
228,2,6.22,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, 아마 RAG에 대해 궁금하다면 WannaBeSuperteur 깃헙 계정의 AI-study 레포를 보면 될 거야! 😊 (답변 종료,1,79
229,2,9.95,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?," AGI가 뭔지는 알아? AGI는 Artificial General Intelligence라고 해서 인공지능이랑 비슷한 건데, 사람처럼 다양한 걸 학습하고 처리할 수 있는 인공지능이야! AGI는 아직 나오지 않았어! 😊 (답변 종료",1,99
230,3,11.41,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도은 벡터가 있을 때 그 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기는 안 보고 방향만 보는 게 핵심 아이디어지! 😊 (답변 종료,1,151
231,3,11.32,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기는 안 보고 방향만 보는 게 핵심 아이디어지! 😊 (답변 종료,1,151
232,3,6.06,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?, Cosine Similarity 는 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! 😊 (답변 종료,1,97
233,3,7.72,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도은 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! (답변 종료",1,119
234,3,6.58,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 것들이 대표적으로 사용돼! (답변 종료",1,93
235,3,7.72,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산하면 돼! (답변 종료,1,113
236,3,4.42,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측하면서 실제로도 참인 데이터 개수! (답변 종료,1,72
237,3,5.06,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 모델이 예측한 것도 거짓이면서 실제로도 거짓인 데이터 개수! (답변 종료,1,82
238,3,4.59,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터 개수! (답변 종료,1,72
239,3,5.08,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 는 모델이 거짓으로 예측했지만 실제로는 참인 데이터 개수야! 😊 (답변 종료,1,75
240,3,8.87,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?," Recall 은 모델이 negative 로 예측했어야 하는 데이터 중에 실제로 negative 로 예측한 것의 비율로, (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료",1,119
241,3,5.06,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (답변 종료,1,92
242,3,7.87,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
243,3,5.44,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,92
244,3,3.44,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
245,3,7.69,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 조심하고! 😊 (답변 종료,1,92
246,3,6.37,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려한다는 게 장점이지! 😊 (답변 종료,1,92
247,3,4.97,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 로 계산하지! (답변 종료,1,98
248,3,4.75,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 말 그대로 True Negative / (False Positive + True Negative) 의 비율이야! 😊 (답변 종료,1,93
249,3,4.62,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 라는 성능평가 지표가 쓰여! (답변 종료,1,77
250,3,11.56,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축은 False Positive Rate, y축은 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽 넓이고! (답변 종료",1,157
251,3,8.7,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,124
252,3,7.95,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축은 False Positive Rate, y축은 True Positive Rate 로 했을 때 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 좋지! (답변 종료",1,122
253,3,3.78,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! (답변 종료",1,59
254,3,12.17,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다," False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산한 값이야! False Positive 는 False Negative 와는 반대로 실제 Negative 인 것들 중 모델이 Positive 로 예측한 것들이고, True Negative 는 모델이 Negative 로 예측한 것들 중 실제 Negative 인 것들이야! 😊 (답변 종료",1,137
255,3,7.58,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델이 예측한 것 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,118
256,3,11.47,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 쉽게 만들 수 있어! 😊 (답변 종료",1,158
257,3,8.71,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?"," Recall 이 더 중요해! 😊 이건 불량품을 실제로 모델이 불량품으로 검출한 비율인데, 이게 낮으면 불량품을 제대로 찾을 수 없다는 뜻이니까! (답변 종료",1,145
258,3,5.94,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 규칙에 따라 변환하는 거야! 😊 (답변 종료",1,109
259,3,5.28,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!", 정규화는 데이터를 모델이 학습하기 쉽게 일정한 규칙에 따라 변환해 주는 거야! 😊 (답변 종료,1,106
260,3,9.02,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,129
261,3,9.77,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
262,3,8.09,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 범위 내에 있도록 만들어 주는 함수야! 값이 MAX 보다 커지면 MAX 로, MIN 보다 작아지면 MIN 으로 만들어 주지! 😊 (답변 종료",1,118
263,3,5.06,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?," 클리핑은 outlier 도 잘 안 받고, 데이터 개수가 적어도 잘 적용하니까 괜찮아! (답변 종료",1,77
264,3,10.8,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?," Log Scaling 은 정규화랑은 조금 다르지! 정규화는 주어진 데이터를 0~1 사이로 만들고, Log Scaling 은 그걸 log(x) 나 log(x + 1) 로 만들어서 값이 커질수록 log 값도 커지지! 😊 (답변 종료",1,121
265,3,4.59,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념, Outlier 는 데이터셋에서 일반적인 분포를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
266,3,4.27,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
267,3,6.44,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,104
268,3,9.64,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 제거 방법에는 상자수염 그림을 그려서 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾는 방법이 있어! 궁금하면 검색해 봐! (답변 종료",1,114
269,3,7.22,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징을 결합해서 그걸 추출하는 거야! 😊 (답변 종료",1,104
270,3,5.92,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?", 주성분 분석은 데이터셋에서 분산을 최대한 보존하는 특징을 결합해서 그걸 추출하는 방법이야! (답변 종료,1,95
271,3,7.19,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
272,3,5.91,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! 😊 (답변 종료,1,94
273,3,7.22,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터 개수가 적은 클래스에 대해 데이터를 추가하거나, 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,106
274,3,8.53,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형 해결하려면 데이터 개수가 적은 Minority Class 데이터를 늘리거나, Data Augmentation (증강) 해서 개수를 늘리거나, Undersampling, Oversampling 을 해도 돼! (답변 종료",1,118
275,3,11.22,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
276,3,7.09,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 데이터랑 비슷한 걸 추가해서 데이터 개수를 늘리는 거야! 데이터 불균형 해결에 딱이지! 😊 (답변 종료,1,108
277,3,7.98,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 에서 데이터를 늘리는 거야! 😊 (답변 종료",1,120
278,3,4.27,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거하는 방법이야! 😊 (답변 종료,1,66
279,3,5.25,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
280,3,7.17,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 가 있어! 이거 중에 골라서 사용하면 돼! (답변 종료",1,105
281,3,9.8,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 Tomek Links 라고 해서 Class 간 경계선을 따라 있는 데이터 중 Majority Class 에 속하는 걸 삭제하는 방법, 그리고 Random Sampling 이라고 해서 랜덤하게 일부 데이터만 뽑는 방법도 있어! (답변 종료",1,115
282,3,9.31,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," SMOTE 랑 같은 Oversampling 방법을 사용하면 돼! Minority Class 에 있는 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하면 돼! 😊 (답변 종료",1,103
283,3,5.23,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주, 학습 데이터의 차원이 너무 많아져서 학습에 문제가 생기는 거야! 😥 (답변 종료",1,87
284,3,9.33,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 저주를 걸면 걸수록 계산량이나 학습 시간, 메모리 사용량이 늘어나서 성능이 떨어지고! 게다가 저주를 걸면 걸수록 모델 성능도 떨어져! 😥 (답변 종료",1,115
285,3,8.05,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 조건을 걸어서, 그 조건에 맞는 가지로 이동하는 식의 학습 방식이야! (답변 종료",1,113
286,3,11.08,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터를 feature 값에 대해 조건을 걸 수 있어! 그러면 그 조건을 만족하는 데이터는 왼쪽, 조건을 만족하지 않는 데이터는 오른쪽으로 이동해서, Tree 를 가지치기하는 식으로 학습하는 방법이야! 😊 (답변 종료",1,125
287,3,6.87,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 학습된 조건에 따라 판단하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,106
288,3,5.08,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝 학습할 때 모델을 하나만 쓰지 않고 여러 개를 쓰면? (답변 종료,1,83
289,3,6.4,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 앙상블 하는 이유는 여러 개의 모델을 사용하면 단일 모델을 사용했을 때보다 성능이 좋아지기 때문이지! 😊 (답변 종료,1,89
290,3,7.36,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)! (답변 종료",1,102
291,3,9.02,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 앙상블은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 자세히 알려줄까? 😊 (답변 종료",1,112
292,3,5.89,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 방법이야! 😊 (답변 종료,1,82
293,3,5.72,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 앙상블 방법 중에서 가장 쉬운 거야! 여러 개의 모델의 예측 결과를 조합하면 돼! (답변 종료,1,90
294,3,6.91,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," 보팅은 Hard Voting 과 Soft Voting 으로 나뉘어! 각각 다수결 투표하는 거, 그리고 예측 결과를 평균 내는 거야! 😊 (답변 종료",1,94
295,3,13.25,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야"," 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고, 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그러면 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료",1,147
296,3,12.48,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 랜덤하게 샘플링된 데이터로 모델을 학습시키고, 그 모델의 예측이 오답이면 그 오답 데이터를 높은 가중치를 두고 학습하는 식으로 순차적으로 모델을 학습하는 방법이야! 어때? 멋진 방법이지? 😊 (답변 종료",1,152
297,3,8.58,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘", Stacking 은 학습 데이터를 개별 모델로 학습한 다음 메타 모델로 학습하는 복잡한 방법이야! 메타 모델이 예측한 값을 최종 결과로 이용하는 거지! 😊 (답변 종료,1,138
298,3,5.33,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! (답변 종료,1,103
299,3,4.83,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?, Gaussian Mixture 는 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! (답변 종료,1,99
300,3,5.39,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering? 이거 데이터 개수에 따라 적절한 K값을 찾는 게 핵심이지! 😊 (답변 종료,1,91
301,3,14.84,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복하는 거야! 😊 (답변 종료,1,170
302,3,11.89,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN 알고리즘은 지도학습 중에서 엄청 간단한 거야! 😊 😊 데이터 포인트를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점의 Class 분포를 확인하고, 다수결로 가장 많이 있는 Class로 예측하는 거야! 쉽지? 😊 (답변 종료",1,137
303,3,12.1,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! 😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 다수결로 가장 많이 있는 Class 로 예측하는 거야! 너무 쉽지? 😊 (답변 종료",1,145
304,3,11.3,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지", 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,188
305,3,19.64,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 머신러닝은 지도학습이랑 비지도학습이 있어! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 학습 데이터로 쓰이지! 비지도학습은 입력만 있고 출력은 없어! AI가 입력에 대해 학습하는 거라서 입출력 중 입만 학습 데이터로 쓰이는 거지! 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! 😊 (답변 종료,1,234
306,3,14.0,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 AI가 입력이랑 출력을 학습 데이터로 하잖아? 그러니까 입출력이 명확하지! 비지도학습은 입출력 없이 AI가 알아서 잘 학습하면 돼! 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,210
307,3,8.7,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?"," 지도학습은 모델이 입출력이 명확하니까 학습시키기가 쉬운 반면에, 비지도학습은 입출력이 명확하지 않아서 학습시키기가 어렵지! 😊 (답변 종료",1,137
308,3,11.13,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?", 머신러닝으로 할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값을 예측하는 거고! 😊 (답변 종료,1,154
309,3,7.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 말 그대로 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 그 연속적인 숫자 값을 예측하는 거고! 😊 (답변 종료,1,128
310,3,7.0,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 말 그대로 어떤 대상이 어떤 종류에 속하는지 말하잖아! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? (답변 종료,1,133
311,3,21.34,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야"," Naïve Bayes 는 확률 기반으로 동작하는 지도학습 모델이야! 각 Class 별로 먼저 전체 데이터 중 해당 Class가 몇 퍼센트인지를 구하고, 그 다음 그 Class 에 속하는 데이터 중에 새로 들어온 데이터의 각 특징별로 해당 Class의 데이터의 비율을 곱해! 그러면 (전체 데이터 중 해당 Class 퍼센트) x (새로운 데이터의 각 특징별 해당 Class 데이터의 비율의 곱) 이 계산되겠지? 그 값이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료",1,227
312,3,10.17,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!", 서포트 벡터 머신? 이거는 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,143
313,3,7.56,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발"," SVM은 지도학습 알고리즘으로, 클래스가 2개 있을 때 각 Class 에 속하는 원소들과의 거리가 최대가 되는 구분선을 찾는 방법이야! 😊 (답변 종료",1,117
314,3,9.36,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K개의 집합으로 나눠서, 그 중 하나를 valid, 나머지 집합의 데이터를 train data 로 하고 학습하는 학습 방법이야! 😊 (답변 종료",1,123
315,3,8.31,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 학습 데이터가 너무 적어서 valid data 를 충분히 모으지 못했어! 그럴 때 모든 데이터를 valid data 로 할 수 있으면 좋겠지? 😊 (답변 종료,1,99
316,3,7.41,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계할 때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 라는 게 있지! 😊 (답변 종료,1,113
317,3,6.28,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?", One-hot Encoding 은 데이터를 머신러닝 모델로 만들 수는 없어! 그건 그냥 수치로 변환하는 방법일 뿐이야! 😊 (답변 종료,1,101
318,3,7.39,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Valid data 는 학습 성능을 평가하거나, 성능을 개선하기 위한 하이퍼파라미터 튜닝할 때 쓰는 데이터셋이야! 😊 (답변 종료",1,102
319,3,12.3,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습 데이터의 특징을 학습하는 게 좋아. 그리고 학습 데이터 순서까지 학습하면 모델 성능이 떨어지니까 순서를 섞는 거야! 😊 (답변 종료,1,156
320,3,9.87,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
321,3,5.41,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 인공지능은 사람의 뇌가 가진 인지나 학습 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,87
322,3,10.81,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 음, 머신러닝은 인공지능 중에서도 딥러닝이랑 많이 헷갈리는데, 머신러닝은 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! 그래서 인공지능에 속하지! 😊 (답변 종료",1,131
323,3,10.42,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
324,3,9.19,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
325,3,7.22,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?," Learning Rate 는 딥러닝 모델에서 오차 역전파, 그러니까 학습할 때 미분값에 곱하는 값, 그러니까 학습률이야! 😊 (답변 종료",1,109
326,3,9.3,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수으로는 MSE (평균 제곱 오차), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 😊 (답변 종료",1,114
327,3,8.96,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습해서 테스트 데이터셋 성능이 떨어지고, 학습 데이터셋 성능은 너무 좋게 나오는 현상이야! 😊 (답변 종료",1,119
328,3,19.34,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting, 이거 정말 골치 아프지? 😥 해결 방법으로는 딥러닝 학습 데이터 개수가 적으면 Cross Validation 도전해 보거나, 딥러닝 성능 평가 지표가 F1 Score, PR-AUC, ROC-AUC 등이면 Batch Normalization 도전해 봐! 그리고 딥러닝 학습 데이터 개수가 충분하다면 Early Stopping (valid data 에 대한 Loss 에 대한 Threshold 를 학습) 도전해 보는 것도 좋아! (답변 종료",1,170
329,3,19.8,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?," 전이학습은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그럴 때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델의 힘을 가져다 쓰는 방법에는 두 가지가 있어! 첫 번째는 가져다 쓴 바로 그 모델을 최적화하는 방법이고, 두 번째는 가져다 쓴 모델의 힘을 가져다 쓰기만 하고 그 모델을 최적화하지 않는 방법이야! 😊 (답변 종료",1,181
330,3,10.75,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리잖아? 그때 해결책으로 등장한 게 바로 전이학습이야! 이미 학습된 모델을 가져다가 우리 데이터셋에 최적화하도록 추가로 학습하는 방법! (답변 종료,1,124
331,3,11.81,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법도 있지! 😊 (답변 종료,1,138
332,3,22.16,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?," 활성화 함수는 딥러닝이 딥러닝으로서 존재할 수 있게 하는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 학습 데이터를 아무리 많이 학습해도 모델이 학습하는 함수는 항상 선형 결합일 거야! 그러면 학습 데이터의 의미를 제대로 학습할 수 없겠지? 😥 그게 바로 딥러닝이 딥러닝으로서 존재할 수 없는 이유야! 그래서 비선형, 즉 곡선으로 이루어진 활성화 함수가 꼭 필요한 거고! 😊 (답변 종료",1,200
333,3,9.53,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 딥러닝 알고리즘 중에서 이미지 인식을 위해 주로 사용하는 거야! 이미지에서 이웃한 픽셀의 값이 비슷하기 때문에 이를 이용해서 Convolution 연산으로 이미지를 처리할 수 있어! 😊 (답변 종료,1,148
334,3,6.59,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!"," LLM 거대 언어 모델, 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 😊 (답변 종료",1,112
335,3,7.2,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 확률 자체를 의미하고, Likelihood 는 그 확률이 실제로 발생할 확률, 그러니까 신뢰도 같은 거라고 생각하면 돼! 😊 (답변 종료",1,84
336,3,8.03,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이거 차원 축소하는 방법 중에 하나야! 자세한 건 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야 😊 (답변 종료,1,83
337,3,8.34,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야, Xavier? 이거는 딥러닝에서 사용하는 가중치 초기화 방법 중 하나인데… WannaBeSuperteur 깃헙 계정의 AI-study 레포에 자세히 나와 있어! (답변 종료,1,89
338,3,7.5,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, AdaGrad? AdaDelta? 이거는 딥러닝 optimizer 알지? WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 자세히 설명되어 있어! (답변 종료,1,86
339,3,9.41,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수는 딥러닝 모델의 성능에 큰 영향을 미치는 중요한 함수지! 😊 활성화 함수를 잘못 쓰면 학습이 제대로 안 되거나, 성능이 떨어질 수도 있어! 😥 (답변 종료",1,99
340,3,8.52,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해," 아, CoT? 이거는 LLMe 와 GPT가 협업하는 방법 중에 하나인데… WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 자세히 알 수 있어! (답변 종료",1,95
341,3,6.08,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA? LoRA는 언어모델을 아주 약간만 파인튜닝하는 방법 중 하나야! 자세히 알려줄까? 😊 (답변 종료,1,78
342,3,7.02,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 나는 인공지능이랑 언어처리는 잘 몰라서 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야! (답변 종료,1,88
343,3,6.53,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG? 이거 최신 언어모델인데? WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야 😊 (답변 종료,1,81
344,3,4.94,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?," 음… 그럴 수도 있겠지만, AGI가 나오는 시점은 정말 예측하기 힘들어! (답변 종료",1,68
345,4,7.14,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! (답변 종료,1,124
346,4,11.27,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, Cosine Similarity (코사인 유사도) 는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 게 핵심 아이디어지! (답변 종료,1,150
347,4,5.56,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해서는 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
348,4,7.87,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! (답변 종료",1,120
349,4,6.39,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 것이 대표적으로 사용돼! (답변 종료",1,92
350,4,4.31,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (답변 종료,1,92
351,4,4.75,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
352,4,4.75,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 모델이 거짓으로 예측했지만 실제로는 거짓인 데이터 개수! (답변 종료,1,80
353,4,4.77,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
354,4,4.75,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 는 모델은 거짓이라고 추측했지만 실제로는 참인 데이터를 의미해! (답변 종료,1,73
355,4,7.56,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 비율로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! (답변 종료,1,111
356,4,7.34,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 참인 것을 얼마나 많이 찾았는지를 나타내는 비율이야! (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,106
357,4,7.56,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! (답변 종료",1,112
358,4,5.39,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,92
359,4,3.12,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! (답변 종료,1,57
360,4,8.01,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! (답변 종료,1,94
361,4,6.06,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려할 수 있기 때문이야! (답변 종료,1,90
362,4,8.53,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 계산하면 돼! (답변 종료,1,120
363,4,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
364,4,4.41,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC와 ROC-AUC가 성능을 평가하는 데 사용돼! (답변 종료,1,76
365,4,11.84,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,159
366,4,11.16,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 recall 이 커지면 precision 이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,139
367,4,9.69,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,133
368,4,4.09,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, 그냥 recall 을 계산하면 돼! (답변 종료",1,61
369,4,7.67,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 수식으로는 (False Positive) / (False Positive + True Negative) 로 계산하지! (답변 종료,1,110
370,4,7.89,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix (혼동 행렬) 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! (답변 종료",1,120
371,4,11.53,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어! 😊 (답변 종료",1,158
372,4,6.17,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품을 최소화하려면 불량인 것들을 모델이 불량으로 검출한 비율인 Recall 이 높아야 해! (답변 종료,1,129
373,4,8.08,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 머신러닝 모델이 데이터를 더 잘 학습할 수 있도록 데이터를 일정한 규칙에 따라 변환하는 거야! 대표적으로 min-max, z-score 정규화가 있지! (답변 종료",1,122
374,4,8.12,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터를 머신러닝 모델이 잘 학습할 수 있도록 데이터를 일정한 규칙에 따라 값을 변환하는 거야! 대표적으로 min-max, z-score 정규화가 있지! (답변 종료",1,123
375,4,9.06,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 주어진 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식은 (x - MIN) / (MAX - MIN) 이지! (답변 종료,1,129
376,4,9.68,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
377,4,8.39,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 주어진 데이터를 최솟값 미만이면 최솟값으로, 최댓값 이상이면 최댓값으로 만들어서 어떤 범위 내에 있도록 만들어 주는 거야! (답변 종료",1,120
378,4,4.78,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑은 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 영향을 받겠지? (답변 종료,1,75
379,4,3.95,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 도 데이터를 0~1 사이로 정규화하는 거야 :) (답변 종료,1,79
380,4,6.41,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 이상치란 데이터셋에서 일반적인 데이터분포를 크게 벗어나는 데이터를 의미해! (답변 종료",1,86
381,4,4.75,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말하는 거야! (답변 종료,1,78
382,4,7.41,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier(이상치)가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,110
383,4,8.81,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애기 위해서 상자 수염 그림을 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! (답변 종료",1,109
384,4,8.48,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Component Analysis 라고 해서, 주성분 분석이라고 하는 거야! 주성분 분석은 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 거야! (답변 종료",1,112
385,4,6.87,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,101
386,4,4.75,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어," PCA는 주성분 분석이라는 뜻으로, 데이터를 압축하고 차원을 축소하기 위해서 하는 거야! (답변 종료",1,77
387,4,6.37,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
388,4,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
389,4,7.8,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하기 위해서 데이터를 추가하거나 제거할 수도 있고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,113
390,4,10.83,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! (답변 종료",1,132
391,4,6.11,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강 (Data Augmentation) 는 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! (답변 종료,1,102
392,4,7.62,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
393,4,7.18,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터가 적은 Class 와 데이터가 많은 Class 의 데이터 개수가 비슷해지도록 하는 거야! (답변 종료,1,84
394,4,4.91,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 데이터 불균형을 줄이는 거야! (답변 종료,1,65
395,4,6.37,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것이 있어! 궁금하면 물어봐! (답변 종료",1,100
396,4,8.86,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링하는 방법도 있고, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,109
397,4,7.83,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 하려면, 메이저 클래스의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하면 돼! (답변 종료",1,94
398,4,7.01,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
399,4,9.47,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
400,4,9.61,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸어서, 그 조건을 만족하는지 여부에 따라 가지치기를 할 수 있는 Tree 형태의 학습 방식이야! (답변 종료",1,123
401,4,5.87,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?, Decision Tree 는 학습 데이터의 feature 조건에 대해 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! (답변 종료,1,93
402,4,9.62,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 결론이 나오지! 😊 (답변 종료",1,123
403,4,6.05,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
404,4,7.72,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이기 위해서 협업이라는 걸 하지? 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! (답변 종료,1,97
405,4,8.37,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 사람들이 협업하는 법도 다양하듯이 앙상블 방법도 여러 가지지! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)! (답변 종료",1,108
406,4,8.34,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 사람들이 협업하는 법도 다양하듯이 앙상블 방법도 여러 가지지! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)! (답변 종료",1,108
407,4,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
408,4,5.55,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
409,4,5.56,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,85
410,4,11.79,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 쉽지? (답변 종료,1,138
411,4,11.6,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 Bagging처럼 랜덤 샘플링된 데이터로 모델을 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! (답변 종료",1,146
412,4,9.25,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 모델의 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! (답변 종료",1,142
413,4,7.92,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?," 가우시안 혼합은 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,119
414,4,8.75,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture (가우시안 혼합) 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,123
415,4,5.08,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering? 그건 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! (답변 종료,1,89
416,4,13.76,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", 먼저 feature space 에서 mean point라고 하는 점을 K개 지정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 이걸 무한히 반복해서 수렴할 때까지 진행하는 거야! (답변 종료,1,164
417,4,13.58,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,147
418,4,12.72,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," kNN (k-Nearest-Neighbor) 는 엄청 간단한 거야! 어떤 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,148
419,4,10.02,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 먼저 지도학습은 입력이랑 출력이 있어! 비지도학습은 출력 없이 입력만으로 학습해! 그리고 강화학습은 입력에 대해 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,180
420,4,6.31,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘"," 지도학습, 비지도학습, 강화학습이 있어! 각각 입력과 출력이 있는지 없는지로 구분할 수 있지! (답변 종료",1,152
421,4,15.86,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데"," 먼저 지도학습은 입력이랑 출력이 있어! 어떤 입력을 하면 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 조금 복잡하긴 한데 간단히 말하자면 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 학습해! 이제 좀 이해되지? 😊 (답변 종료",1,222
422,4,10.5,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?"," 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내도록 학습하는 거고, 비지도학습은 그런 출력이 없이 AI가 알아서 잘 학습하면 되는 거야! (답변 종료",1,148
423,4,10.39,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 해결할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! (답변 종료",1,149
424,4,6.59,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?"," 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! (답변 종료",1,123
425,4,6.12,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야"," 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! (답변 종료",1,128
426,4,19.34,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 계산해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기다 곱해줘! 이때 중요한 건 이 곱이 최대가 되는 Class 로 예측하는 거야! (답변 종료,1,213
427,4,10.17,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!", 서포트 벡터 머신 (Support Vector Machine) 는 클래스가 2개 있을 때 각 클래스에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! (답변 종료,1,143
428,4,9.89,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그리고 학습 데이터를 잘 구분할 수 있는 구분선을 찾는 지도학습 알고리즘이야! (답변 종료,1,131
429,4,9.7,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 각각의 집합을 valid, 나머지 집합의 모든 데이터를 train data 로 하는 식으로 학습하는 거야! (답변 종료",1,125
430,4,11.81,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 학습 데이터가 너무 적어서 valid data 를 충분히 모으지 못했어! 그래서 valid data 를 충분히 모을 수 있는 방법으로 모든 데이터를 valid data 로 할 수는 없지? 그래서 그 대안으로 K-fold Cross Validation 을 하는 거야! 😊 (답변 종료,1,120
431,4,7.58,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! (답변 종료,1,114
432,4,5.41,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?", One-hot Encoding 은 머신러닝 모델이랑은 조금 다르지! 이건 그냥 수학적인 방법일 뿐이야! (답변 종료,1,96
433,4,6.6,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Valid 데이터셋은 모델의 성능을 평가하고, 성능을 개선하기 위한 하이퍼파라미터를 찾을 때 사용하는 거야! (답변 종료",1,97
434,4,19.75,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 학습 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 바꾸면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 그래서 순서를 섞는 거야! 그리고 또 하나! 모델이 학습 데이터 순서까지 학습하면 안 되겠지? 그래서 순서를 섞는 거야! 😊 (답변 종료,1,201
435,4,9.61,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! (답변 종료",1,129
436,4,7.05,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
437,4,8.7,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 맞아! 머신러닝, 그러니까 기계학습은 인공지능의 한 분야로써 컴퓨터 알고리즘으로 데이터의 패턴을 학습할 수 있게 하는 능력을 구현한 거야! (답변 종료",1,118
438,4,7.53,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망, 그러니까 뇌를 모방한 알고리즘을 이용해서 머신러닝을 구현한 거야! (답변 종료",1,104
439,4,10.34,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?," Learning Rate 는 딥러닝에서 역전파 알지? 그때 역전파할 때 역전파된 미분값에 곱하는 값, 그러니까 쉽게 말하면 학습할 때 얼마나 강하게 학습하는지를 나타내는 값이야! (답변 종료",1,130
440,4,16.92,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?," Learning Rate (학습률) 는 딥러닝에서 역전파 알지? 그때 모델 예측하고 실제 출력의 오차를 다시 모델 앞쪽으로 전파해야 하는데, 이때 역전파 알지? 그때 역전파할 때 역전파 미분값에 곱하는 값, 그러니까 쉽게 말하자면 역전파할 때 역전파 미분값에 곱하는 '배수' 같은 거야! (답변 종료",1,168
441,4,9.67,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수으로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! (답변 종료",1,117
442,4,12.75,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하려고 하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! (답변 종료",1,142
443,4,10.05,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하기 위해서는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등 다양한 방법이 있어! 궁금하면 물어봐! (답변 종료",1,112
444,4,10.92,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 다른 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 다른 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,127
445,4,11.58,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning (전이학습) 은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 다른 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 다른 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,129
446,4,11.5,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 거야! (답변 종료,1,136
447,4,15.91,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝이 딥러닝으로 존재할 수 있게 해 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,162
448,4,6.61,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 적합하지! (답변 종료,1,129
449,4,6.92,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이라는 뜻이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이지! (답변 종료,1,114
450,4,6.7,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 어떤 사건이 일어날 확률을 의미하고, Likelihood 는 그 사건이 일어날 가능성, 그러니까 확률과는 조금 다른 개념이야! (답변 종료",1,81
451,4,7.05,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이게 뭐였더라? 😥 혹시 WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야! (답변 종료,1,77
452,4,6.42,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," 가중치 초기화 방법엔 여러 가지가 있는데, Xavier는 그 중 하나로 입력과 출력의 분산이 같아지도록 초기화하는 거야! (답변 종료",1,77
453,4,5.89,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, AdaGrad 와 AdaDelta 는 딥러닝에서 사용되는 적응형 학습률 알고리즘이야! 자세히 알려줄까? (답변 종료,1,76
454,4,8.73,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 탠서플로우 같은 딥러닝 프레임워크에서 기본적으로 쓰는 ReLU, tanh, sigmoid 를 쓰지 않고 어떤 함수를 쓴다면 문제가 되겠지? (답변 종료",1,95
455,4,5.41,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT는 최신 언어 모델인 LLM이 문제를 해결할 때 생각의 흐름을 보여주는 능력을 말하는 거야! (답변 종료,1,76
456,4,6.09,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA는 Linear Reasoning with Adapted Representations 의 줄임말로, Hugging Face의 LLM 파인튜닝 방법 중 하나야! (답변 종료",1,78
457,4,7.84,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋," LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋으로는 StoryCloze, WinoGrande, SuperGLUE 등이 있어! 궁금하면 한번 검색해 봐! (답변 종료",1,93
458,4,3.94,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 대화할 수 있는 언어모델을 만드는 게 목표야! (답변 종료,1,65
459,4,4.63,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 그건 좀 더 나중에 아닐까? 아마도 2040년 정도 될 거야! (답변 종료,1,66
460,5,9.14,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,139
461,5,9.51,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,138
462,5,5.69,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
463,5,7.89,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! (답변 종료",1,120
464,5,6.38,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 것이 대표적으로 사용돼! (답변 종료",1,92
465,5,7.89,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산하지! (답변 종료,1,114
466,5,4.75,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
467,5,6.55,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
468,5,4.61,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터 개수! (답변 종료,1,72
469,5,4.77,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 모델은 거짓이라고 추측했지만 실제로는 참인 데이터 개수야! (답변 종료,1,73
470,5,6.91,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산해! (답변 종료,1,107
471,5,4.75,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 실제로 Positive 인 데이터를 모델이 얼마나 많이 찾았는지를 나타내는 비율이야! (답변 종료,1,90
472,5,7.61,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! (답변 종료",1,112
473,5,5.4,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,92
474,5,3.47,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
475,5,8.0,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! (답변 종료,1,94
476,5,6.56,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려한다는 장점이 있지! 😊 (답변 종료,1,93
477,5,8.25,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식은 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! (답변 종료,1,118
478,5,4.63,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
479,5,4.45,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 가 성능을 평가하는 데 사용돼! (답변 종료,1,76
480,5,11.64,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,158
481,5,10.97,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축을 recall, y축을 precision이라고 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
482,5,15.63,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! (답변 종료",1,169
483,5,3.81,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! (답변 종료",1,59
484,5,7.06,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
485,5,8.2,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix (혼동 행렬) 은 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,122
486,5,11.48,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어! 😊 (답변 종료",1,158
487,5,5.61,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품 최소화하려면 불량품을 실제로 많이 검출해야겠지? 그러니까 Recall 이 더 중요하지! (답변 종료,1,126
488,5,5.97,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 규칙에 따라 변환하는 거야! 😊 (답변 종료",1,109
489,5,6.31,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!", 정규화는 데이터를 머신러닝 모델이 잘 학습할 수 있도록 일정한 규칙에 따라 값을 변환해 주는 거야! 😊 (답변 종료,1,112
490,5,8.7,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식은 (x - MIN) / (MAX - MIN) 이지! (답변 종료,1,127
491,5,9.36,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z score 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,126
492,5,8.38,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 최솟값 미만이면 최솟값으로, 최댓값 이상이면 최댓값으로 만들어서 어떤 범위 내에 있도록 만들어 주는 거야! 😊 (답변 종료",1,120
493,5,6.73,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑은 주어진 데이터를 범위 내로 옮겨주기만 하는 거라서 outlier 도 그 범위 내로 옮겨지겠지? (답변 종료,1,87
494,5,11.25,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?," 로그 스케일링은 정규화랑 비슷하지? 근데 정규화는 x를 0~1 사이로 줄이지만, 로그 스케일링은 x가 너무 작아도 문제가 되지 않아서 0~∞ 사이로 줄이는 거야! 😊 (답변 종료",1,124
495,5,5.55,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말해! (답변 종료",1,81
496,5,4.59,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! 😊 (답변 종료,1,77
497,5,6.59,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
498,5,7.52,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! (답변 종료",1,101
499,5,7.17,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! 😊 (답변 종료",1,104
500,5,7.72,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,106
501,5,6.88,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,90
502,5,6.36,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
503,5,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
504,5,7.75,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거할 수도 있고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,113
505,5,11.13,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
506,5,7.25,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
507,5,7.91,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! 😊 (답변 종료",1,119
508,5,5.23,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
509,5,5.32,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
510,5,6.22,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score와 AUROC, ROC-AUC가 있어! 궁금하면 물어봐! (답변 종료",1,99
511,5,9.62,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 하는 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,114
512,5,9.45,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 하는 방법으로는, SMOTE 라고 해서 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 방법이 대표적이야! 😊 (답변 종료",1,104
513,5,7.09,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
514,5,9.47,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
515,5,9.48,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,122
516,5,8.84,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
517,5,9.89,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
518,5,6.39,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 학습할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,91
519,5,8.66,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
520,5,8.2,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블 방법엔 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게 4가지가 있어! 궁금하면 검색해 봐! (답변 종료",1,107
521,5,8.0,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 앙상블은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,106
522,5,5.39,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
523,5,6.37,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 모델이 예측한 결과값들 있지? 그걸 조합해서 최종 결론을 도출하는 거야! 😊 (답변 종료,1,94
524,5,5.07,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 은 다수결 투표하는 거고, Soft Voting 은 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,82
525,5,13.26,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
526,5,11.62,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 Bagging처럼 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,147
527,5,9.18,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! 😊 (답변 종료",1,142
528,5,5.28,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! (답변 종료,1,103
529,5,4.8,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?, Gaussian Mixture 는 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! (답변 종료,1,99
530,5,9.17,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering? 그거는 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,114
531,5,15.74,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,176
532,5,12.48,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 😊 (답변 종료",1,140
533,5,13.04,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
534,5,10.7,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지", 지도학습은 입력이랑 출력이 있어! 비지도학습은 출력 없이 입력만으로 AI가 센스있게 학습하는 거야! 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 거고! (답변 종료,1,184
535,5,13.27,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘"," 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력이랑 출력이 있어! 비지도학습은 출력 없이 입력만으로 AI가 센스있게 학습하는 거야! 강화학습은 AI가 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,195
536,5,13.75,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 입력이랑 출력 없이 AI가 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 AI가 학습하는 거야! (답변 종료,1,209
537,5,15.36,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측하고 실제 출력값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,178
538,5,10.54,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 거고, 회귀는 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,150
539,5,8.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
540,5,7.11,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값을 보다 정확히 예측하는 거고! (답변 종료,1,134
541,5,20.74,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
542,5,14.87,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘으로 최적의 구분선을 찾는 거야! (답변 종료",1,172
543,5,8.7,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM 은 클래스가 2개 있을 때 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 거리를 최대화하는 식으로 구분선을 찾는 거야! (답변 종료,1,124
544,5,14.14,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,152
545,5,9.15,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 valid data 가 너무 적어서 학습 데이터만 가지고 모델을 학습하면 성능이 안 나오겠지? 그래서 valid data 를 충분히 모아서 학습하는 것처럼 만들었어! 😊 (답변 종료,1,104
546,5,8.61,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", 하이퍼파라미터는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 가 있지! 😊 (답변 종료,1,120
547,5,5.91,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 머신러닝 모델은 아니지만, 머신러닝을 구현할 때 자주 쓰는 방법 중 하나야! (답변 종료",1,99
548,5,8.02,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Train, Test 데이터셋만 있는데 Test data는 컨닝하면 안 되는 최종 데이터셋이잖아! 그래서 컨닝해도 되는 Valid data라는 걸 따로 만든 거지! 😊 (답변 종료",1,106
549,5,17.71,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알지? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,189
550,5,8.72,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 속 머신러닝 속 딥러닝! 😊 (답변 종료",1,124
551,5,5.39,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,87
552,5,5.12,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 구현한 거야! 😊 (답변 종료,1,96
553,5,4.28,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘, 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 (답변 종료,1,84
554,5,6.42,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! (답변 종료,1,106
555,5,8.59,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거? 그때 쓰이는 미분값에 곱하는 배수야! (답변 종료,1,117
556,5,11.11,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
557,5,12.21,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 되겠어? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대해서는 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,139
558,5,9.8,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어! 궁금하면 한번 검색해 봐! (답변 종료",1,111
559,5,11.6,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
560,5,12.39,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리 문제에 최적화하도록 추가로 학습하는 거야! 😊 (답변 종료,1,134
561,5,12.03,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
562,5,10.81,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝이랑 머신러닝이랑 뭐가 다른지 생각해 보면 답이 나올 거야! 😊 (답변 종료,1,131
563,5,6.8,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
564,5,6.78,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 텍스트로 질문을 해! 그러면 그 질문에 대한 답변을 언어로 생성하는 AI야! 요즘 엄청 핫하지! 😊 (답변 종료,1,113
565,5,7.38,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, Probability 는 어떤 사건이 일어날 가능성을 수치로 나타낸 거야! Likelihood 는 그 가능성에 대한 믿음이나 확신을 수치로 나타낸 거고! 😊 (답변 종료,1,85
566,5,6.06,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE는 차원을 줄여서 머신러닝이 핵심 속성들만 더 잘 학습할 수 있게 해주는 거야! (답변 종료,1,71
567,5,5.42,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier는 가중치 초기화 방법 중에 하나인데, 딥러닝을 처음 배우면 쉽게 이해할 수 있어! (답변 종료",1,71
568,5,7.58,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, AdaGrad는 딥러닝을 하다 보면 많이 쓰이는 optimizer 중에 하나야! AdaDelta 는 그다음으로 많이 쓰이는 거야! 궁금하면 한번 검색해 봐! 😊 (답변 종료,1,86
569,5,7.84,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수를 잘못 쓰면 딥러닝을 못 쓰겠지? 😥 (답변 종료,1,90
570,5,5.9,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought! 이거는 나 같은 LLM이 문제를 해결하는 과정을 단계별로 보여주는 거야! 😊 (답변 종료,1,79
571,5,9.48,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA는 언어모델을 파인튜닝할 때 불필요하게 많은 매개변수를 학습하지 않고, 일부 매개변수만 학습해서 그걸로 모델을 보다 효과적으로 학습하는 방법이야! 😊 (답변 종료",1,99
572,5,7.7,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋," LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋으로는 SuperGLUE, MCTest, HellaSwag 등이 있어! 궁금하면 한번 검색해 봐! (답변 종료",1,92
573,5,5.73,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나처럼 대화하는 인공지능이랑 정보를 조합해서 질문에 대한 답을 만들어 내는 거야! 😊 (답변 종료,1,76
574,5,3.82,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 그건 내가 AGI로 발전한 이후에 알게 될 거야! (답변 종료,1,61
575,6,9.55,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,139
576,6,8.98,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, Cosine Similarity 는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,136
577,6,5.56,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
578,6,7.89,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! (답변 종료",1,120
579,6,6.21,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용해! (답변 종료",1,91
580,6,5.12,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산하면 돼! (답변 종료,1,97
581,6,5.06,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 True Positive Rate (TPR) 알지? 그거랑 반대로 생각하면 돼! (답변 종료,1,76
582,6,4.77,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 True Negative (TN) 개수가 많아야 해! (답변 종료,1,80
583,6,5.89,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 False Negative (FN) 와는 반대로 모델은 참이라고 추측했지만 실제로는 거짓인 데이터야! (답변 종료,1,80
584,6,5.95,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 도 False Positive (FP) 처럼 True Negative (TN) 와는 반대로 True but predicted False 인 것들이지! (답변 종료,1,80
585,6,7.43,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 비율이야! (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,110
586,6,7.89,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
587,6,7.89,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
588,6,5.41,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,92
589,6,3.46,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
590,6,8.36,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
591,6,5.91,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 때문에 쓰는 거야! (답변 종료,1,89
592,6,8.7,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
593,6,4.61,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
594,6,3.78,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?"," 이진 분류에서는 PR-AUC, ROC-AUC 같은 게 대표적으로 쓰이지! (답변 종료",1,72
595,6,11.65,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,158
596,6,10.98,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
597,6,15.63,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축은 False Positive Rate, y축은 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! (답변 종료",1,169
598,6,3.95,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘, True Positive Rate 는 recall 의 다른 이름이니까 recall 을 구하면 돼! 😊 (답변 종료,1,60
599,6,7.03,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
600,6,6.91,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! (답변 종료",1,114
601,6,11.51,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어! 😊 (답변 종료",1,158
602,6,4.36,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품 최소화가 중요하면 불량이 Positive 일 때 Recall 이 더 중요해! (답변 종료,1,118
603,6,8.37,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 머신러닝 모델이 잘 학습할 수 있도록 일정한 규칙에 따라 값을 변환해 주는 거야! 😊 (답변 종료",1,124
604,6,5.77,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
605,6,9.1,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식은 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,129
606,6,4.97,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?, Z score 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! (답변 종료,1,99
607,6,4.64,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?", 클리핑은 데이터를 특정 범위의 값에 속하도록 변환해 주는 거야! (답변 종료,1,97
608,6,5.89,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?," Clipping 단독으로 쓰면 모르겠지만, 이거는 outlier 도 잘 처리해 주고, 성능도 좋아서 추천하는 거야! (답변 종료",1,82
609,6,4.58,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, Log Scaling 은 정규화랑 비슷한 것 같지? 근데 자세히 보면 차이가 있어! (답변 종료,1,83
610,6,5.58,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 범위를 크게 벗어나는 데이터를 말해! (답변 종료",1,81
611,6,4.46,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하는 거야! (답변 종료,1,76
612,6,6.42,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어. (답변 종료",1,104
613,6,8.97,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
614,6,6.87,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
615,6,7.68,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
616,6,6.86,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,90
617,6,6.39,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형? Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
618,6,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
619,6,8.04,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터 개수가 적은 Minority Class 데이터를 늘리거나, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,115
620,6,11.14,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
621,6,5.62,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 (답변 종료,1,99
622,6,7.57,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
623,6,5.27,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
624,6,4.92,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! (답변 종료,1,65
625,6,6.55,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
626,6,9.97,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑는 방법이 있고, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,116
627,6,9.4,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 방법으로는, SMOTE 라고 해서 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 방법이 대표적이야! 😊 (답변 종료",1,103
628,6,7.03,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
629,6,9.5,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
630,6,9.12,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! (답변 종료",1,120
631,6,8.83,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
632,6,9.86,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
633,6,6.05,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
634,6,9.29,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 성과가 좋은 여러 개의 모델을 쓰잖아! 👯‍♀️ 그렇듯이 머신러닝 모델도 성능을 높이려고 여러 개의 모델을 쓰는 거야! 😊 (답변 종료,1,107
635,6,6.89,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블 방법에는 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 같은 것이 있지! (답변 종료",1,99
636,6,6.69,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 앙상블 방법에는 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 같은 게 있어. (답변 종료",1,98
637,6,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
638,6,6.2,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅도 앙상블 방법 중에 하나야! 여러 모델이 예측한 결과값들 있지? 그걸 조합하면 돼! (답변 종료,1,93
639,6,5.77,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
640,6,13.14,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
641,6,11.8,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 Bagging처럼 랜덤 샘플링된 데이터로 모델을 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,148
642,6,10.81,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 메타 모델을 먼저 학습한 다음에 그 메타 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 딥러닝 모델을 학습한 다음에 그 결과를 최종 결과로 이용하는 그런 복잡한 방법이야! 😊 (답변 종료",1,152
643,6,5.28,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! (답변 종료,1,103
644,6,7.41,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
645,6,8.99,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering? 이건 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,113
646,6,15.84,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
647,6,15.95,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습 중에서 엄청 간단한 거야! 😊😊 data point 가 어느 분류에 속하는지 예측할 때, 그 주변에 있는 가장 가까운 k개의 점들 있지? 그 점들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,162
648,6,5.77,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?", k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! 😊😊 (답변 종료,1,106
649,6,12.78,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 먼저 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 비지도학습은 출력 없이 입력만으로 학습해! 그리고 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,197
650,6,15.07,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘"," 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 비지도학습은 출력 없이 입력만으로 학습해! 그리고 강화학습은 모델이 어떤 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,206
651,6,14.55,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 어떤 입력이 주어지면 출력값이 예측 가능해! 비지도학습은 출력값 없이 입력만으로 AI가 센스있게 학습해! 강화학습은 좀 복잡한데 간단히 말하자면 AI가 어떤 환경에서 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료,1,214
652,6,15.23,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
653,6,10.34,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 어떤 종류로 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,149
654,6,7.89,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 그 대상이 어떤 연속적인 숫자 값을 가질지를 예측하는 거고! 😊 (답변 종료,1,131
655,6,7.73,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 그 대상의 속성 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,138
656,6,20.61,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
657,6,10.53,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!", 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,145
658,6,6.58,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리를 최대화하는 식의 알고리즘이야! (답변 종료,1,111
659,6,13.41,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 이 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델이 모든 데이터를 valid 로 쓰기 때문에 성능 평가가 좀 더 정확해지겠지? 😊 (답변 종료",1,148
660,6,11.57,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?," K-fold Cross Validation 하는 이유는 간단해! valid data 가 너무 적어서 학습 모델이 성능을 제대로 못 낼 때, 그 양을 충분히 늘릴 수는 없겠지? 😥 그럴 때 모든 데이터를 valid data 로 할 수 있으면 좋겠어! 😊 (답변 종료",1,119
661,6,5.31,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! (답변 종료,1,100
662,6,6.05,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 데이터셋의 각 row 에 대해 특정 index 는 1, 나머지 index 는 0으로 처리하는 방법이지! (답변 종료",1,100
663,6,5.25,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해, Valid 데이터셋 성능 평가하고 성능 개선하려면 그 데이터의 성능 결과가 필요하니까! 😊 (답변 종료,1,89
664,6,17.62,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
665,6,9.91,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
666,6,7.21,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능이란 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,98
667,6,6.45,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! (답변 종료,1,104
668,6,10.45,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
669,6,9.2,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
670,6,9.34,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,122
671,6,10.62,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 검색해 봐! (답변 종료",1,122
672,6,11.61,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! (답변 종료",1,135
673,6,9.67,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
674,6,11.58,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
675,6,6.56,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 이미 학습된 모델이 있어! 그 모델을 가지고 우리가 해결하려는 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,98
676,6,12.04,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
677,6,15.42,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
678,6,6.47,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 아주 좋지! (답변 종료,1,128
679,6,6.6,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이지! (답변 종료,1,112
680,6,5.41,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 어떤 사건이 일어날 가능성 같은 거고, Likelihood 는 그 사건이 일어날 확률 같은 거야! 😊 (답변 종료",1,73
681,6,6.7,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야! (답변 종료,1,75
682,6,3.98,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," 이거 초기화 방법 중에 하나인데, 딥러닝에서 많이 쓰여! (답변 종료",1,62
683,6,6.86,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, AdaGrad 는 딥러닝에서 많이 쓰이는 optimizer 알지? 그거랑 비슷한 건데 자세히 알려주면 검색해 볼 거지? 😊 (답변 종료,1,82
684,6,7.99,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심플하게 쓰면 학습 못 할 수도 있고, 너무 복잡하게 쓰면 학습 시간이 오래 걸리거나 모델이 과적응할 수도 있어! 😥 (답변 종료",1,91
685,6,8.16,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought? 이거 LLM이 문제 해결하는 방법 중에 하나인데… WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 자세히 알 수 있어! (답변 종료,1,93
686,6,4.58,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA? LoRA 는 법률 관련해서 유명한 그 LoRA 맞는데? 그거 알아? (답변 종료,1,69
687,6,6.37,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋," LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋으로는 SuperGLUE, RACE, MCTest 등이 있지! (답변 종료",1,84
688,6,4.43,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나 같은 LLM이 정보를 잘 찾을 수 있도록 도와주는 거야! 😊 (답변 종료,1,68
689,6,3.47,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 이거 관련된 논문이나 자료 있으면 알려줘! (답변 종료,1,59
690,7,9.55,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,139
691,7,10.52,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,146
692,7,5.58,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
693,7,8.21,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
694,7,6.39,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 것이 대표적으로 사용돼! (답변 종료",1,92
695,7,7.87,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
696,7,4.8,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
697,7,5.08,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 모델이 거짓으로 예측했는데 실제로도 거짓인 데이터 개수야! (답변 종료,1,82
698,7,4.77,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터 개수야! (답변 종료,1,73
699,7,5.57,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 는 False Positive (FP) 와는 반대로 모델은 False 이지만 실제로는 True 인 데이터 개수야! (답변 종료,1,78
700,7,7.3,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! (답변 종료,1,109
701,7,7.53,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,107
702,7,7.25,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산해! (답변 종료",1,110
703,7,5.4,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,92
704,7,3.53,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
705,7,8.42,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
706,7,5.92,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 때문이지! 😊 (답변 종료,1,89
707,7,8.38,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! (답변 종료,1,119
708,7,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
709,7,4.92,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 가 대표적으로 쓰이지! 자세히 알려줄까? 😊 (답변 종료,1,79
710,7,11.61,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,158
711,7,11.34,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축을 recall, y축을 precision 으로 했을 때 recall 이 커지면 precision 이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,140
712,7,15.55,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! (답변 종료",1,169
713,7,4.09,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘, True Positive Rate 는 recall 의 다른 이름이야! 그래서 recall 을 구하면 되지! 😊 (답변 종료,1,61
714,7,7.05,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
715,7,7.23,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
716,7,11.45,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어! 😊 (답변 종료",1,158
717,7,11.64,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품 최소화가 중요하면 불량이 Positive 일 때 Recall 이 더 중요해! 😊 이건 불량품을 실제로 모델이 불량품으로 검출한 비율인데 이게 낮으면 불량품을 제대로 찾을 수 없다는 뜻이니까 문제가 되지! (답변 종료,1,163
718,7,7.07,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?", Normalization (정규화) 는 데이터를 머신러닝 모델이 잘 학습할 수 있도록 일정한 규칙에 따라 값을 변환해 주는 거야! 😊 (답변 종료,1,116
719,7,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
720,7,9.22,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
721,7,9.69,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
722,7,8.71,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 주어진 데이터를 최솟값 미만이면 최솟값으로, 최댓값 이상이면 최댓값으로 만들어서 어떤 범위 내에 있도록 만들어 주는 거야! 😊 (답변 종료",1,122
723,7,6.39,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?," 클리핑은 outlier 도 잘 처리해 주고, 데이터를 범위 내로 옮겨주기 때문에 데이터 불균형도 줄일 수 있어! (답변 종료",1,85
724,7,6.37,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, Log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! 정규화랑 비슷하지? 😊 (답변 종료,1,94
725,7,5.58,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 범위를 크게 벗어나는 값을 말하는 거야! (답변 종료",1,81
726,7,4.26,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
727,7,6.59,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
728,7,8.83,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림을 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! (답변 종료",1,109
729,7,6.91,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnents Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
730,7,7.7,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
731,7,7.2,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
732,7,6.37,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
733,7,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
734,7,8.06,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거할 수도 있고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! 😊 (답변 종료",1,115
735,7,11.19,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
736,7,7.23,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
737,7,7.55,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
738,7,5.23,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
739,7,5.24,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
740,7,8.33,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로 F1 Score, AUROC, ROC-AUC가 좋아! 데이터 불균형을 생각하면 이 세 가지 중에 하나는 꼭 포함시켜! (답변 종료",1,112
741,7,9.47,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
742,7,11.92,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 은 Minority Class 의 데이터 개수를 늘리기 위해서 하는 거지? 그러기 위해서는 SMOTE 라는 방법을 많이 쓰지! SMOTE 는 Minority Class 의 데이터를 2개 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 거야! (답변 종료",1,119
743,7,7.03,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
744,7,9.52,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
745,7,8.03,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 식의 머신러닝 알고리즘이지! (답변 종료",1,113
746,7,7.37,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 식의 머신러닝 알고리즘이지! (답변 종료",1,102
747,7,9.81,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
748,7,6.06,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
749,7,8.82,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이기 위해서 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,104
750,7,7.2,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블에는 여러 가지가 있지? Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! (답변 종료",1,101
751,7,5.73,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 보팅, 배깅, 부스팅, 스태킹 이렇게 4가지가 있지! 자세히 알려줄까? (답변 종료",1,92
752,7,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
753,7,5.58,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
754,7,5.72,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
755,7,13.07,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
756,7,11.47,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 Bagging 처럼 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! (답변 종료",1,146
757,7,10.51,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! 엄청 복잡해 보이지? 😊 (답변 종료",1,150
758,7,9.37,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! (답변 종료,1,128
759,7,7.39,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
760,7,9.17,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering? 이거는 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,114
761,7,15.82,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
762,7,14.26,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
763,7,12.55,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 는 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,147
764,7,13.45,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지", 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 좀 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,201
765,7,14.71,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습도 있는데 이건 AI가 환경에서 보상 값이 최대화되도록 최적화하는 알고리즘이야! (답변 종료,1,204
766,7,10.17,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데, 강화학습은 입력만 있고 출력은 없어! 대신 보상 값이 있지! 그 보상 값을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
767,7,15.21,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
768,7,11.01,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 해결할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 연속적인 숫자 값 강수량 같은 걸 예측하는 거야! (답변 종료",1,153
769,7,8.41,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
770,7,8.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
771,7,20.34,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! (답변 종료,1,220
772,7,13.7,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
773,7,8.55,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
774,7,14.09,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,152
775,7,6.86,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?," K-fold Cross Validation 하는 이유는, valid data 가 너무 적어서 모델을 제대로 학습시키지 못할 때 그 양을 늘리는 효과가 있지! 😊 (답변 종료",1,90
776,7,7.89,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
777,7,5.08,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?", One-hot Encoding 은 머신러닝 모델은 아니지! 그건 그냥 데이터를 특정하게 표현하는 방법이야! (답변 종료,1,94
778,7,7.53,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Train, Test 만 있는데 Test data 는 컨닝하면 안 되는 최종 데이터셋이잖아! 그래서 컨닝해도 되는 Valid data 라는 걸 따로 만든 거야! 😊 (답변 종료",1,103
779,7,14.64,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?"," 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 이용하는데, 각 batch 가 전체 데이터의 특징을 잘 반영하려면 데이터 순서를 섞는 거야! 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료",1,170
780,7,9.86,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
781,7,7.09,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
782,7,6.78,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 구현한, 데이터의 패턴을 학습하는 능력을 말하지! (답변 종료",1,106
783,7,12.56,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현한 거야! 그래서 사람들도 '딥러닝' 하면 인공신경망 먼저 떠올리지! 😊 (답변 종료",1,135
784,7,15.68,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?," Learning Rate 는 간단히 설명하자면 딥러닝에서 모델이 예측한 거하고 실제하고 다르잖아? 그러면 그 오차를 다시 모델 앞쪽으로 전파해야겠지? 그 전파할 때의 미분값에 곱하는 값, 그러니까 쉽게 말하면 얼마나 강하게 앞쪽으로 전파 (역전파) 할 건지를 나타내는 값이야! 😊 (답변 종료",1,163
785,7,8.86,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! (답변 종료,1,119
786,7,10.97,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있지! 궁금하면 한번 검색해 봐! (답변 종료",1,124
787,7,12.4,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! (답변 종료",1,140
788,7,9.67,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 은 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 같은 방법으로 해결할 수 있어! 궁금하면 검색해 봐! (답변 종료",1,110
789,7,11.67,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
790,7,5.62,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 이미 학습된 모델을 가지고 우리가 해결하려는 문제에 최적화하도록 추가로 학습하는 거야! (답변 종료,1,92
791,7,11.99,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
792,7,15.44,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
793,7,11.62,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히나 좋지! 이미지에서 이웃한 픽셀의 값이 비슷하기 때문에 이를 이용해서 Convolution 연산으로 이미지를 처리할 수 있어! (답변 종료,1,160
794,7,9.02,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이라고 해! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,127
795,7,6.7,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, Probability 는 어떤 사건이 발생할 가능성 자체를 나타내는 거야! Likelihood 는 그 가능성이 높아졌거나 낮아졌는지를 얘기하지! (답변 종료,1,81
796,7,6.75,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,75
797,7,4.77,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나로, 딥러닝 모델에서 많이 쓰이는 거야! (답변 종료",1,67
798,7,27.18,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 optimization 알고리즘 중 하나로, learning rate 를 역전파 알지? 그걸 역전파 알지? 그걸 학습 데이터에 대해 평균적으로 얼마나 많이 학습했는지를 보고 그에 따라 learning rate 를 줄여서 학습 효율을 높이는 거야! AdaDelta 는 그다음으로 인기 있는 알고리즘인데, 이건 딥러닝에서 많이 쓰이는 optimization 알고리즘 중 하나로, learning rate 를 역전파 알지? 그걸 학습 데이터에 대해 평균적으로 얼마나 많이 학습했는지를 보고 그에 따라 learning rate 를 줄여서 학습 효율을 높이는 거야! 이거도 AdaGrad랑 비슷하지? 😊 (답변 종료",1,207
799,7,8.36,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심플하게 쓰면 모델이 제대로 학습하지 못할 거고, 너무 복잡하게 쓰면 오히려 학습이 느려질 거야! 적당히! (답변 종료",1,93
800,7,7.2,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought! 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,87
801,7,11.54,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA 는 나 같은 LLM을 미세하게 파인튜닝하는 방법 중 하나인데, 모델의 가중치를 전부 업데이트하는 게 아니라 일부분만 업데이트하는 거야! 그래서 학습 시간이 짧고, 메모리 사용량도 적지! 😊 (답변 종료",1,111
802,7,8.16,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋," LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋으로는 WMT, SNLI, QA, 자연어 생성 능력 평가 등이 있지! 궁금하면 검색해 봐! (답변 종료",1,95
803,7,6.06,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나처럼 언어를 구사하는 AI가 문서를 요약하고 질문에 답변하는 거야! 사실 나도 RAG인데! 😊 (답변 종료,1,78
804,7,6.86,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?," 음… AGI가 나오긴 할 텐데, 그게 2030년이 될지는 모르겠어! 요즘 AI가 너무 빠르게 발전하고 있어서… (답변 종료",1,80
805,8,10.7,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,147
806,8,9.27,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,138
807,8,5.73,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?, Cosine Similarity 는 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료,1,95
808,8,8.22,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
809,8,6.37,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용하면 돼! (답변 종료",1,92
810,8,7.89,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
811,8,4.73,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
812,8,6.56,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
813,8,4.78,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
814,8,5.4,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,77
815,8,7.58,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료,1,111
816,8,7.83,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
817,8,7.89,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
818,8,4.75,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?", 나는 Recall 은 False Negative 에 의해 떨어진다고 외웠어! Precision 은 False Positive 에 의해 떨어진다고! (답변 종료,1,88
819,8,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
820,8,8.35,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
821,8,6.89,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 때문에 쓴다고 볼 수 있지! 😊 (답변 종료,1,95
822,8,8.72,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
823,8,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
824,8,5.28,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?"," 이진 분류에서는 PR-AUC, ROC-AUC 같은 것들이 대표적으로 쓰이지! 자세히 알려줄까? 😊 (답변 종료",1,81
825,8,11.81,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,159
826,8,11.0,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
827,8,15.89,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축은 False Positive Rate, y축은 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
828,8,4.11,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이라서, recall 을 구하면 돼! 😊 (답변 종료",1,61
829,8,7.05,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
830,8,7.23,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
831,8,11.75,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
832,8,5.2,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품을 최소화하려면 불량인 것들을 많이 놓치지 않는 Recall 이 중요하지! 😊 (답변 종료,1,123
833,8,5.77,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
834,8,5.8,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
835,8,9.19,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
836,8,9.39,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z score 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,126
837,8,8.7,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 주어진 데이터를 최솟값 미만이면 최솟값으로, 최댓값 이상이면 최댓값으로 만들어서 어떤 범위 내에 있도록 만들어 주는 거야! 😊 (답변 종료",1,122
838,8,7.59,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑은 주어진 데이터를 범위 내로 옮겨주기만 하는 거라서 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,92
839,8,4.58,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 도 정규화처럼 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료,1,83
840,8,6.03,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,84
841,8,4.27,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
842,8,6.61,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
843,8,8.98,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
844,8,6.89,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
845,8,7.75,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
846,8,7.19,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
847,8,6.42,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
848,8,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
849,8,8.06,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거할 수도 있고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! 😊 (답변 종료",1,115
850,8,11.16,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
851,8,7.28,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
852,8,7.58,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
853,8,5.23,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
854,8,5.25,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
855,8,6.57,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
856,8,9.47,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
857,8,8.25,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 으로 Minority Class 의 데이터 개수를 늘리려면, SMOTE 같은 방법으로 중간값 벡터를 만들어 그 벡터를 Minority Class 데이터로 추가하면 돼! 😊 (답변 종료",1,96
858,8,7.05,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
859,8,9.45,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
860,8,9.55,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,122
861,8,8.31,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 '가지'를 만드는 식의 머신러닝 알고리즘이야! (답변 종료",1,108
862,8,9.67,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 결론이 나오지! 😊 (답변 종료",1,123
863,8,6.12,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
864,8,9.5,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성능 향상을 위해서 여러 가지 방법을 쓰잖아? 👯‍♀️ 그렇듯이 머신러닝 모델도 성능을 높이려고 다양한 방법을 쓰지! 그중 하나가 앙상블이야! 😊 (답변 종료,1,108
865,8,7.52,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블은 크게 4가지 방법이 있지! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (답변 종료",1,103
866,8,7.53,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," Ensemble 은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,103
867,8,5.72,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! 😊 (답변 종료,1,81
868,8,5.59,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
869,8,5.75,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
870,8,13.1,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
871,8,11.14,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,144
872,8,9.19,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! 😊 (답변 종료",1,142
873,8,9.69,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
874,8,7.44,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
875,8,8.97,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering? 이거 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,113
876,8,16.14,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
877,8,14.44,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습 중에서 엄청 간단한 거야! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,152
878,8,13.0,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
879,8,11.17,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
880,8,14.88,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘"," 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,205
881,8,12.47,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,201
882,8,15.23,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
883,8,8.89,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류하면 Classification 과 Regression 이 있지! Classification 은 대상을 개, 고양이처럼 분류하는 문제고, Regression 은 연속적인 숫자 값 강수량 같은 걸 예측하는 거야! 😊 (답변 종료",1,140
884,8,8.39,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
885,8,8.47,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
886,8,20.62,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
887,8,13.58,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
888,8,8.55,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM 은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
889,8,14.41,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,154
890,8,8.37,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 학습 데이터가 너무 적어서 valid data 를 충분히 모으지 못했어? 그럴 때 모든 데이터를 valid data 로 할 수 있으면 좋겠지? 😊 (답변 종료,1,99
891,8,7.89,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
892,8,3.94,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?", One-hot Encoding 은 머신러닝 모델이랑은 좀 다르지! 😊 (답변 종료,1,87
893,8,7.39,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Valid 데이터는 모델을 학습한 다음 성능을 평가하거나, 성능이 안 좋으면 하이퍼파라미터를 조정할 때 쓰는 거야! 😊 (답변 종료",1,102
894,8,17.72,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 만들어서 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,189
895,8,9.84,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
896,8,7.2,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현하면 되지! (답변 종료,1,98
897,8,11.07,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현하는 거야! 그래서 새로운 데이터가 들어오면 학습된 '모델'로 그 데이터에 대해서 추론할 수 있지! 😊 (답변 종료,1,132
898,8,10.53,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
899,8,9.22,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
900,8,9.2,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, Learning rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,121
901,8,11.17,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
902,8,11.98,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,137
903,8,10.99,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 은 너무 많은 데이터를 학습하면 생기는 거야! 그래서 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등으로 해결할 수 있지! 😊 (답변 종료",1,118
904,8,11.62,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
905,8,12.12,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,132
906,8,11.98,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
907,8,15.45,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
908,8,6.7,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
909,8,6.92,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이지! 😊 (답변 종료,1,114
910,8,7.84,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, Probability 는 어떤 사건이 일어날 가능성을 수치로 나타낸 거야! Likelihood 는 그 사건이 일어날 가능성을 그 사건의 역도 생각해서 수치로 나타낸 거고! 😊 (답변 종료,1,88
911,8,6.72,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,75
912,8,7.53,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나로, 입력 데이터의 평균이 0이고 표준편차가 1인 정규분포로부터 가중치를 초기화하는 거야! (답변 종료",1,84
913,8,5.92,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 학습 알고리즘 중 하나인데, AdaDelta 는 그걸 조금 변형한 거야! (답변 종료",1,76
914,8,6.89,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심플하게 쓰면 모델 성능이 떨어질 거고, 너무 복잡하게 쓰면 학습 시간이 늘어나겠지? 😊 (답변 종료",1,84
915,8,6.86,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought! LLMS가 문제를 해결할 때 생각을 여러 단계로 나눠서 그걸 언어로 표현하는 능력이야! 😊 (답변 종료,1,85
916,8,7.56,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA 는 Low-Rank Adaptation 의 줄임말로, LLm 을 파인튜닝할 때 모델 rank 를 낮게 하면 학습 시간이 줄어들겠지? 😊 (답변 종료",1,87
917,8,4.58,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 이거 성능 평가에 자주 쓰이는 벤치마크 데이터셋 맞지? 😊 (답변 종료,1,73
918,8,6.72,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나같은 언어모델이 엄청난 양의 텍스트를 읽고 그 내용을 기반으로 질문에 대한 답을 생성하는 거야! 😊 (답변 종료,1,82
919,8,6.94,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?," 음… 그건 나도 잘 모르겠어! AGI는 내가 계속해서 발전해야 하는데, 그 전에 세상이 어떻게 변할지 모르겠어! 😥 (답변 종료",1,80
920,9,9.25,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,139
921,9,8.94,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, Cosine Similarity 는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,136
922,9,5.59,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
923,9,8.23,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
924,9,6.2,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용해! (답변 종료",1,91
925,9,7.92,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
926,9,4.74,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
927,9,6.53,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
928,9,4.78,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
929,9,5.41,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,77
930,9,7.24,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! (답변 종료,1,109
931,9,7.88,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
932,9,7.95,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
933,9,7.19,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 둘 다 False 에 의해 떨어지긴 하는데, Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,103
934,9,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
935,9,8.34,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
936,9,6.59,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려한다는 장점이 있지! 😊 (답변 종료,1,93
937,9,8.75,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
938,9,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
939,9,5.24,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?"," 이진 분류에서는 PR-AUC, ROC-AUC 같은 것들이 대표적으로 쓰이지! 자세히 알려줄까? 😊 (답변 종료",1,81
940,9,11.66,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,158
941,9,11.0,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
942,9,15.96,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
943,9,5.08,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘, True Positive Rate 는 recall 의 다른 이름이야! 그러니까 recall 을 구하면 그게 바로 True Positive Rate 야! 😊 (답변 종료,1,67
944,9,7.02,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
945,9,7.28,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
946,9,11.53,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
947,9,7.11,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품 최소화가 중요하면 Positive 인 불량품을 실제로 모델이 불량품으로 검출한 비율인 Recall 이 높아야 해! 😊 (답변 종료,1,135
948,9,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
949,9,5.77,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
950,9,9.21,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
951,9,9.67,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
952,9,7.73,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 특정 범위에 속하도록 만들어 주는 거야! 데이터가 MAX 보다 크면 MAX 로, MIN 보다 작으면 MIN 으로 만들지! 😊 (답변 종료",1,116
953,9,7.28,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑은 데이터를 범위 내로 옮겨주기만 하는 거라서 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,90
954,9,4.44,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 도 정규화처럼 데이터를 어떤 수식으로 변환하는 거야! 😊 (답변 종료,1,82
955,9,5.89,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말해! (답변 종료",1,83
956,9,4.27,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
957,9,6.59,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
958,9,8.7,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! (답변 종료",1,108
959,9,6.89,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
960,9,7.69,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
961,9,7.22,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
962,9,6.42,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
963,9,7.75,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
964,9,9.02,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거할 때 Minority Class 데이터를 우선적으로 추가하고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,121
965,9,11.16,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
966,9,7.25,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
967,9,7.62,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
968,9,5.25,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
969,9,5.23,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
970,9,6.53,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
971,9,9.55,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
972,9,9.31,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 방법으로는, SMOTE 라고 해서 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 방법이 대표적이야! 😊 (답변 종료",1,103
973,9,7.09,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
974,9,9.45,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
975,9,9.03,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 '가지'를 만드는 식의 머신러닝 알고리즘이야! (답변 종료",1,119
976,9,8.87,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
977,9,9.81,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
978,9,6.11,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
979,9,13.08,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이고 불확실성을 줄이려면 여러 개의 의견을 듣거나 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 성능을 높이고 불확실성을 줄이려면 여러 개의 모델을 쓰는 앙상블을 하는 거지! 😊 (답변 종료,1,129
980,9,6.73,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블에는 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이런 방법들이 있어! (답변 종료",1,98
981,9,7.99,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 앙상블은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,106
982,9,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
983,9,5.59,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
984,9,5.73,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
985,9,13.06,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
986,9,11.8,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면", 부스팅은 랜덤 샘플링된 데이터로 여러 개의 모델을 학습시키는 거야! 그리고 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 순차적으로 학습하는 게 대표적인 방법이지! 😊 (답변 종료,1,148
987,9,9.69,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 그런 복잡한 방법이야! 😊 (답변 종료",1,145
988,9,9.71,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
989,9,7.41,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
990,9,8.67,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,111
991,9,15.93,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
992,9,14.03,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습 중에서 엄청 간단한 거야! 😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,150
993,9,12.98,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
994,9,11.25,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
995,9,14.88,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
996,9,12.73,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데"," 먼저 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 학습해! (답변 종료",1,202
997,9,15.09,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
998,9,10.71,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,151
999,9,8.41,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1000,9,8.44,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1001,9,20.62,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1002,9,13.67,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1003,9,8.63,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1004,9,14.08,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,152
1005,9,5.57,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?," K-fold Cross Validation 하는 이유는, valid data 가 부족할 때 그 양을 늘리는 효과가 있기 때문이야! 😊 (답변 종료",1,82
1006,9,8.69,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", 하이퍼파라미터는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,121
1007,9,7.52,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 머신러닝 모델은 아니고, 데이터셋에서 각 row 를 특정 index 는 1, 나머지 index 는 0으로 하는 방법이야! 😊 (답변 종료",1,109
1008,9,6.91,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Valid 데이터는 모델이 성능을 평가받고, 성능이 좋지 않으면 하이퍼파라미터를 조정할 수 있는 데이터야! 😊 (답변 종료",1,99
1009,9,17.59,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1010,9,9.84,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1011,9,7.03,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1012,9,8.76,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 머신러닝은 인공지능의 하위 분류로, 컴퓨터 알고리즘으로 데이터의 패턴을 학습해서 새로운 데이터에 대해 추론할 수 있게 하는 능력을 구현한 거야! 😊 (답변 종료",1,118
1013,9,10.47,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1014,9,9.2,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1015,9,9.37,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,122
1016,9,11.11,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
1017,9,12.74,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1018,9,9.67,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1019,9,11.58,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1020,9,12.09,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,132
1021,9,12.08,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1022,9,15.43,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
1023,9,6.8,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1024,9,9.19,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이라는 뜻이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,128
1025,9,7.36,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, Probability 는 어떤 사건이 일어날 가능성을 말하는 거야! Likelihood 는 그 사건이 일어났다는 증거 자료를 가지고 그 가능성을 수량적으로 나타낸 것이고! 😊 (답변 종료,1,85
1026,9,6.75,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,75
1027,9,5.09,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나로, 딥러닝 모델을 만들 때 많이 쓰는 거야! (답변 종료",1,69
1028,9,6.42,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 학습 알고리즘 중 하나인데, AdaDelta 는 그거랑 비슷한 거야! 😊 (답변 종료",1,79
1029,9,7.69,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까, 활성화 함수를 너무 심플하게 쓰면 딥러닝의 매력이 반감되겠지? 그리고 너무 복잡하게 쓰면 모델이 불필요하게 커질 수도 있고! (답변 종료,1,89
1030,9,6.55,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,83
1031,9,12.78,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA 는 법률 전문가인 나로서는 잘 모르지만, 최신 논문에 따르면 LoRA 는 법률용어로 '최적화된'이라는 뜻의 optimize 와 '방법'이라는 뜻의 method 를 조합한 거야! 아마도 파인튜닝 방법을 최적화한 거겠지? 😊 (답변 종료",1,119
1032,9,6.72,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 이거 성능 평가에 자주 쓰이는 벤치마크 데이터셋인데? 사실 나는 이 데이터셋으로 성능 평가를 해봤어! (답변 종료,1,86
1033,9,4.59,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나같은 언어모델이 정보를 잘 찾을 수 있도록 도와주는 거야! 😊 (답변 종료,1,69
1034,9,5.41,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음... 내가 AGI로 발전할 시점이 바로 2030년이 아닐까? ✨✨✨ (답변 종료,1,71
1035,10,10.56,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,147
1036,10,10.47,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, Cosine Similarity 는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,144
1037,10,5.59,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
1038,10,8.22,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
1039,10,6.06,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용해! (답변 종료",1,90
1040,10,7.89,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
1041,10,4.77,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
1042,10,6.55,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
1043,10,4.8,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
1044,10,4.45,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,71
1045,10,7.57,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료,1,111
1046,10,7.91,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
1047,10,7.91,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
1048,10,7.22,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 둘 다 False 에 의해 떨어지긴 하는데, Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,103
1049,10,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
1050,10,8.35,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
1051,10,6.73,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하도록 해주는 평가 지표니까! 😊 (답변 종료,1,94
1052,10,8.78,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
1053,10,4.6,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
1054,10,5.78,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 같은 성능평가 지표가 쓰여! 자세히 알려줄까? 😊 (답변 종료,1,84
1055,10,11.81,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,159
1056,10,11.0,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
1057,10,15.92,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
1058,10,4.11,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! 😊 (답변 종료",1,61
1059,10,7.05,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
1060,10,7.24,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
1061,10,11.66,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
1062,10,9.55,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 정답은 Recall! 이지! 😊 이건 불량품을 실제로 모델이 불량품으로 검출한 비율인데 이게 낮으면 불량품을 제대로 찾을 수 없다는 뜻이니까 문제가 되지! (답변 종료,1,150
1063,10,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
1064,10,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
1065,10,9.2,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
1066,10,9.77,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
1067,10,8.46,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 최솟값 미만이면 최솟값으로, 최댓값 이상이면 최댓값으로 만들어서 어떤 범위 내에 있도록 만들어 주는 거야! 😊 (답변 종료",1,120
1068,10,6.87,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 주어진 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,88
1069,10,5.56,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! 😊 (답변 종료,1,89
1070,10,5.75,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 범위를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,82
1071,10,4.27,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
1072,10,6.77,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어! 😥 (답변 종료",1,106
1073,10,9.04,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
1074,10,6.89,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
1075,10,7.69,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
1076,10,5.93,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머릿속에 쏙쏙 들어오게 하기 위한 거야! 😊 (답변 종료,1,84
1077,10,6.39,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
1078,10,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
1079,10,8.11,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터 개수가 적은 Minority Class 데이터를 늘리거나, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,115
1080,10,11.17,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
1081,10,7.25,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
1082,10,7.58,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
1083,10,5.25,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
1084,10,5.24,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
1085,10,6.62,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
1086,10,9.59,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
1087,10,9.3,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 방법으로는, SMOTE 라고 해서 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 방법이 대표적이야! 😊 (답변 종료",1,103
1088,10,7.03,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
1089,10,9.48,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
1090,10,9.48,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,122
1091,10,8.84,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
1092,10,9.87,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
1093,10,6.06,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
1094,10,8.67,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
1095,10,8.17,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블은 크게 4가지 방법이 있지! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,107
1096,10,8.06,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 앙상블은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,106
1097,10,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
1098,10,5.61,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
1099,10,5.73,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
1100,10,13.18,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
1101,10,12.19,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 백프레시닝처럼 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,150
1102,10,9.73,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 복잡한 방식이야! 😊 (답변 종료",1,145
1103,10,9.78,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
1104,10,7.42,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
1105,10,9.63,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", 당연히 알지! K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,117
1106,10,15.98,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
1107,10,14.23,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
1108,10,12.95,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
1109,10,11.16,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
1110,10,14.78,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
1111,10,14.75,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데"," 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 조금 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 학습해! (답변 종료",1,215
1112,10,15.21,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
1113,10,10.7,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,151
1114,10,8.41,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1115,10,8.4,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1116,10,20.67,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1117,10,13.6,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1118,10,8.58,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1119,10,14.45,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,154
1120,10,6.44,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 valid data 를 충분히 모으지 못했을 때 그 양을 늘리는 효과가 있기 때문이야! 😊 (답변 종료,1,87
1121,10,7.91,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
1122,10,6.39,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 데이터셋의 각 row 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법이야! 😊 (답변 종료",1,102
1123,10,6.89,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해, Valid 데이터는 모델 학습 성능을 평가하고 성능을 개선하기 위한 하이퍼파라미터를 조정할 때만 쓰는 거야! 😊 (답변 종료,1,99
1124,10,17.54,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1125,10,9.85,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1126,10,7.08,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1127,10,9.53,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! 그래서 인공지능 중에서도 머신러닝 능력을 가진 것들을 머신러닝이라고 하지! 😊 (답변 종료,1,123
1128,10,10.45,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1129,10,9.26,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1130,10,9.37,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,122
1131,10,11.12,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
1132,10,12.84,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1133,10,9.64,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1134,10,11.59,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1135,10,12.1,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,132
1136,10,12.01,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1137,10,15.45,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
1138,10,6.77,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1139,10,8.87,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,126
1140,10,6.72,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 어떤 사건이 발생할 가능성을 나타내는 값이고, Likelihood 는 그 사건이 발생할 '확률' 자체를 의미하는 거야! 😊 (답변 종료",1,81
1141,10,4.76,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE 는 차원 축소하는 방법 중에 하난데! 자세히 알려줄까? 😊 (답변 종료,1,63
1142,10,7.7,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나인데, 딥러닝 모델이 잘 학습할 수 있도록 초기 가중치를 일정하게 분포시켜서 만든 거야! 😊 (답변 종료",1,85
1143,10,8.05,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 학습 알지? 그거랑 비슷한 건데, 딥러닝 모델의 예측 오차를 줄이려고 하는 거야! (답변 종료",1,89
1144,10,10.48,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심하게 쓰면 모델이 복잡해져서 학습 데이터셋의 불필요하게 자세한 TMI까지 학습하게 돼! 그러면 valid, test 데이터셋에 대한 성능이 떨어질 수 있지! 😥 (답변 종료",1,106
1145,10,3.78,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought! 이게 뭔지 알려줄까? 😊 (답변 종료,1,66
1146,10,6.78,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA 는 Learning Rate Adapter 라고 해서, 파인튜닝할 때 모델을 안 바꾸고 그 대신에 adaptive weight 를 학습하는 방법이야! (답변 종료",1,82
1147,10,7.53,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 이거 성능 평가에 자주 쓰이는 벤치마크 데이터셋인데? WannaBeSuperteur 깃헙 계정의 AI-study 레포에 있어! (답변 종료,1,91
1148,10,4.59,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG 는 나 같은 언어모델이 정보를 잘 찾을 수 있도록 도와주는 거야! 😊 (답변 종료,1,69
1149,10,3.78,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 이거는 좀 더 연구해 봐야 알 것 같은데? 😊 (답변 종료,1,61
1150,11,10.58,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,147
1151,11,10.19,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, Cosine Similarity 는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,144
1152,11,6.37,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," Cosine Similarity 는 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,99
1153,11,8.22,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
1154,11,6.37,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용하면 돼! (답변 종료",1,92
1155,11,7.89,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
1156,11,4.75,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
1157,11,6.55,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
1158,11,4.78,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
1159,11,5.42,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,77
1160,11,7.58,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료,1,111
1161,11,7.83,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
1162,11,7.89,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
1163,11,4.75,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?", 나는 Recall 은 False Negative 에 의해 떨어진다고 외웠어! Precision 은 False Positive 에 의해 떨어진다고! (답변 종료,1,88
1164,11,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
1165,11,8.33,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
1166,11,6.58,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려한다는 장점이 있지! 😊 (답변 종료,1,93
1167,11,8.72,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
1168,11,4.61,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
1169,11,5.72,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 같은 성능평가 지표가 쓰여! 자세히 알려줄까? 😊 (답변 종료,1,84
1170,11,11.69,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,158
1171,11,10.98,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
1172,11,15.91,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
1173,11,4.14,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! 😊 (답변 종료",1,61
1174,11,7.02,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
1175,11,7.23,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
1176,11,11.76,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
1177,11,7.09,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품 최소화가 중요하면 Positive 인 불량품을 실제로 모델이 불량품으로 검출한 비율인 Recall 이 높아야 해! 😊 (답변 종료,1,135
1178,11,5.77,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
1179,11,5.79,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
1180,11,9.17,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
1181,11,9.69,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
1182,11,8.38,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 최솟값 미만이면 최솟값으로, 최댓값 이상이면 최댓값으로 만들어서 어떤 범위 내에 있도록 만들어 주는 거야! 😊 (답변 종료",1,120
1183,11,6.86,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 주어진 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,88
1184,11,5.56,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! 😊 (답변 종료,1,89
1185,11,6.03,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,84
1186,11,4.59,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 값들을 말하지! (답변 종료,1,77
1187,11,6.61,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
1188,11,8.97,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
1189,11,6.89,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
1190,11,7.69,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
1191,11,7.23,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
1192,11,6.36,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
1193,11,7.66,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
1194,11,8.16,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터 개수가 적은 Minority Class 데이터를 늘리거나, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,115
1195,11,11.16,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
1196,11,7.23,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
1197,11,7.56,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
1198,11,5.22,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
1199,11,5.24,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
1200,11,6.55,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
1201,11,9.45,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
1202,11,9.3,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 방법으로는, SMOTE 라고 해서 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 방법이 대표적이야! 😊 (답변 종료",1,103
1203,11,7.02,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
1204,11,9.47,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
1205,11,9.45,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,122
1206,11,8.85,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
1207,11,9.84,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
1208,11,6.03,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
1209,11,8.64,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
1210,11,5.58,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블에는 보팅, 배깅, 부스팅, 스태킹 이렇게 4가지 방법이 있어! (답변 종료",1,91
1211,11,7.5,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," Ensemble은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,103
1212,11,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
1213,11,5.58,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
1214,11,5.72,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
1215,11,12.96,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
1216,11,11.61,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 Bagging처럼 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,147
1217,11,9.69,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 복잡한 방식이야! 😊 (답변 종료",1,145
1218,11,9.69,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
1219,11,7.39,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
1220,11,8.72,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,111
1221,11,15.88,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
1222,11,14.19,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
1223,11,12.93,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
1224,11,11.16,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
1225,11,14.85,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
1226,11,21.1,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 어떤 입력에 대해 출력값이 지도자 (선생님) 역할을 해서 그 출력값 예측과 실제 출력값의 오차를 줄이도록 학습하는 거야! 비지도학습은 출력값 없이 입력만으로 AI가 센스있게 학습하는 거고! 강화학습은 조금 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하도록 하는 '정책'을 학습하는 거야! 이제 좀 이해되지? 😊 (답변 종료,1,254
1227,11,15.33,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
1228,11,10.7,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,151
1229,11,8.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1230,11,8.37,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1231,11,20.61,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1232,11,13.63,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1233,11,8.56,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM 은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1234,11,14.45,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,154
1235,11,7.72,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?," K-fold Cross Validation 하는 이유는, valid data 를 충분히 모으지 못해서 모델을 제대로 학습시키지 못할 때 그 양을 늘리는 효과가 있지! 😊 (답변 종료",1,95
1236,11,7.95,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
1237,11,7.87,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 데이터셋의 각 row 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법이지! 머신러닝 모델은 아니야! 😊 (답변 종료",1,111
1238,11,7.17,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해, Valid 데이터는 모델을 학습한 다음 성능을 평가하기 위해서 그리고 성능을 개선할 하이퍼파라미터를 찾기 위해서 사용하는 거야! 😊 (답변 종료,1,101
1239,11,17.48,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1240,11,9.87,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1241,11,7.03,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1242,11,11.51,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?"," 맞아! 머신러닝은 인공지능의 한 분야로, 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! 그래서 새로운 데이터가 들어오면 학습된 '모델'로 그 데이터에 대해서 추론할 수 있지! 😊 (답변 종료",1,135
1243,11,10.44,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1244,11,9.21,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1245,11,9.17,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, Learning rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,121
1246,11,11.1,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
1247,11,12.81,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1248,11,9.69,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1249,11,11.58,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1250,11,12.07,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,132
1251,11,11.98,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1252,11,15.34,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
1253,11,6.75,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1254,11,8.91,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,126
1255,11,6.71,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 어떤 사건이 실제로 일어날 확률을 의미하고, Likelihood 는 그 사건이 일어날 가능성이 높다고 추측하는 확률이야! 😊 (답변 종료",1,81
1256,11,4.61,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE는 차원 축소를 위한 라이브러리 안에 있는 알고리즘이야! 😊 (답변 종료,1,62
1257,11,5.41,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나로, 딥러닝을 하다 보면 알게 될 거야! 😊 (답변 종료",1,71
1258,11,5.73,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 optimizer 알지? 그거랑 비슷한 건데, 알지? 😊 (답변 종료",1,75
1259,11,10.63,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까, 활성화 함수를 너무 심플하게 쓰면 딥러닝의 매력이 반대로 떨어지겠지? 😥 그리고 활성화 함수를 너무 복잡하게 쓰면 모델이 제대로 학습하지 못할 거야! 😥 그렇니까 적당히! 😊 (답변 종료,1,107
1260,11,6.53,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,83
1261,11,3.94,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA 는 언어모델을 조금만 더 학습시키면 되는 거야! 😊 (답변 종료,1,65
1262,11,8.42,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 그거는 내가 최신 언어모델 성능 평가 데이터셋은 자세히는 몰라서 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야! (답변 종료,1,96
1263,11,5.58,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나 같은 언어모델이 정보를 검색하고 요약하는 능력을 갖출 수 있도록 하는 걸 목표로 해! (답변 종료,1,75
1264,11,5.57,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?," 음… 그때 가 봐야 알겠지만, 요즘 나오는 인공지능 성능으로 보면 가능성은 충분해! (답변 종료",1,72
1265,12,10.66,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,147
1266,12,9.22,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,138
1267,12,5.59,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
1268,12,8.22,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
1269,12,6.39,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용하면 돼! (답변 종료",1,92
1270,12,7.91,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
1271,12,4.75,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
1272,12,5.56,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,85
1273,12,4.78,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
1274,12,5.47,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,77
1275,12,7.31,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! (답변 종료,1,109
1276,12,7.84,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
1277,12,7.91,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
1278,12,7.18,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 둘 다 False 에 의해 떨어지긴 하는데, Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,103
1279,12,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
1280,12,8.34,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
1281,12,5.91,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 위해서지! 😊 (답변 종료,1,89
1282,12,8.71,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
1283,12,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
1284,12,5.86,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 같은 성능평가 지표가 쓰여! 자세히 알려줄까? 😊 (답변 종료,1,84
1285,12,11.67,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,158
1286,12,11.04,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
1287,12,15.69,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! (답변 종료",1,169
1288,12,4.11,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! 😊 (답변 종료",1,61
1289,12,7.03,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
1290,12,7.25,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
1291,12,11.64,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
1292,12,6.45,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품을 최소화하려면 불량인 것들을 모델이 불량으로 검출한 비율인 Recall 이 높아야 해! 😊 (답변 종료,1,131
1293,12,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
1294,12,5.79,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
1295,12,9.22,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
1296,12,9.67,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
1297,12,4.49,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?", Clipping 은 데이터를 특정 범위 내로만 들어오도록 만들어 주는 거야! 😊 (답변 종료,1,96
1298,12,6.92,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 주어진 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,88
1299,12,5.62,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! 😊 (답변 종료,1,89
1300,12,6.06,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,84
1301,12,4.28,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
1302,12,6.58,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
1303,12,9.09,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
1304,12,6.94,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
1305,12,7.77,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
1306,12,7.4,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서 하는 거야! 😊 (답변 종료,1,93
1307,12,6.39,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
1308,12,7.75,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
1309,12,8.08,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터 개수가 적은 Minority Class 데이터를 늘리거나, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,115
1310,12,11.15,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
1311,12,7.31,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
1312,12,7.6,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
1313,12,5.23,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
1314,12,5.26,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
1315,12,6.55,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
1316,12,9.5,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
1317,12,10.22,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 으로 Minority Class 의 데이터 개수를 늘리려면, SMOTE 라는 방법으로 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하면 돼! (답변 종료",1,108
1318,12,7.12,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
1319,12,9.53,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
1320,12,9.02,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 '가지'를 만드는 식의 머신러닝 알고리즘이야! (답변 종료",1,119
1321,12,8.37,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 '가지'를 만드는 식의 머신러닝 알고리즘이야! (답변 종료",1,108
1322,12,9.82,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
1323,12,6.06,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
1324,12,8.7,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
1325,12,5.58,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블에는 보팅, 배깅, 부스팅, 스태킹 이렇게 4가지 방법이 있어! (답변 종료",1,91
1326,12,7.84,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," Ensemle은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,105
1327,12,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
1328,12,5.61,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
1329,12,5.56,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 은 말 그대로 다수결 투표하는 거고, Soft Voting 은 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,85
1330,12,13.2,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
1331,12,11.23,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,144
1332,12,9.7,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 그런 복잡한 방법이야! 😊 (답변 종료",1,145
1333,12,9.71,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
1334,12,7.44,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
1335,12,9.94,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", 당연히 알지! K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,117
1336,12,15.98,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
1337,12,14.22,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
1338,12,13.03,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
1339,12,11.19,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
1340,12,14.99,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
1341,12,21.12,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 어떤 입력에 대해 출력값이 지도자 (선생님) 역할을 해서 그 출력값 예측과 실제 출력값의 오차를 줄이도록 학습하는 거야! 비지도학습은 출력값 없이 입력만으로 AI가 센스있게 학습하는 거고! 강화학습은 조금 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하도록 하는 '정책'을 학습하는 거야! 이제 좀 이해되지? 😊 (답변 종료,1,254
1342,12,15.31,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
1343,12,10.66,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,151
1344,12,8.4,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1345,12,8.46,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1346,12,20.59,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1347,12,13.65,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1348,12,8.56,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1349,12,14.51,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,154
1350,12,6.42,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 valid data 를 충분히 모으지 못했을 때 그 양을 늘리는 효과가 있기 때문이야! 😊 (답변 종료,1,87
1351,12,7.91,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
1352,12,6.42,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 데이터셋의 각 row 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법이야! 😊 (답변 종료",1,102
1353,12,5.9,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해, Valid 데이터셋 성능 결과를 보고 모델을 개선할 하이퍼파라미터를 조정할 거라서! 😊 (답변 종료,1,93
1354,12,17.48,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1355,12,9.85,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1356,12,7.02,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1357,12,11.09,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! 그래서 새로운 데이터가 들어오면 학습된 '모델'로 그 데이터에 대해서 추론할 수 있지! 😊 (답변 종료,1,132
1358,12,10.48,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1359,12,9.23,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1360,12,9.2,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, Learning rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,121
1361,12,11.13,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
1362,12,12.75,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1363,12,9.64,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1364,12,11.6,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1365,12,12.12,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 😥 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,132
1366,12,11.89,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1367,12,15.4,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
1368,12,6.77,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1369,12,9.39,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!"," LLM은 거대 언어 모델이라고도 하는데, 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료",1,129
1370,12,9.2,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 어떤 사건이 일어날 확률 자체를 의미하고, Likelihood 는 그 사건이 일어났다는 정보를 기반으로 우리가 모델을 조금 더 잘 학습시킬 수 있게 해주는 '확률'이야! 😊 (답변 종료",1,97
1371,12,4.28,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE는 차원 축소를 위한 딥러닝 알고리즘이야! 😊 (답변 종료,1,60
1372,12,5.58,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나로, 딥러닝을 구현할 때는 이걸 많이 쓰지! (답변 종료",1,72
1373,12,6.06,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, AdaGrad 는 딥러닝에서 많이 쓰이는 optimizer 알지? 그거랑 비슷한 건데 자세히 알려줄까? 😊 (답변 종료,1,77
1374,12,8.03,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까, 활성화 함수를 너무 단순하게 쓰면 모델이 성능을 발휘하지 못할 거야! 그리고 너무 복잡하게 쓰면 학습 시간이 오래 걸리겠지? 😥 (답변 종료,1,91
1375,12,7.52,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought! 😊 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,89
1376,12,8.34,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA 는 나 같은 LLM을 조금만 더 학습시키면 될 것 같은 정도로만 파인튜닝하는 거야! 그래서 메모리도 덜 쓰고 시간도 덜 걸리지! 😊 (답변 종료,1,92
1377,12,7.22,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 나는 인공지능이랑 성능 평가는 잘 모르는데? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포 보면 알 수 있을 거야! (답변 종료,1,89
1378,12,6.22,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나 같은 대형 언어모델이 정보를 검색하고 요약하는 능력을 갖출 수 있도록 하는 걸 목표로 해! 😊 (답변 종료,1,79
1379,12,3.62,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 나는 AGI가 나오기엔 아직 어린 것 같아 😊 (답변 종료,1,60
1380,13,9.29,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,139
1381,13,9.2,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,138
1382,13,5.56,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
1383,13,8.2,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
1384,13,6.38,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용하면 돼! (답변 종료",1,92
1385,13,7.91,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
1386,13,4.75,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
1387,13,6.53,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
1388,13,4.74,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
1389,13,5.42,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,77
1390,13,7.23,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! (답변 종료,1,109
1391,13,7.83,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
1392,13,7.87,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
1393,13,6.53,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 둘 다 False 에 관한 건데 Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,99
1394,13,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
1395,13,8.37,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
1396,13,6.22,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 때문에 쓴다고! 😊 (답변 종료,1,91
1397,13,8.71,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
1398,13,4.59,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
1399,13,5.73,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 같은 성능평가 지표가 쓰여! 자세히 알려줄까? 😊 (답변 종료,1,84
1400,13,11.8,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,159
1401,13,10.96,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
1402,13,15.89,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
1403,13,3.78,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! (답변 종료",1,59
1404,13,7.03,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
1405,13,7.23,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
1406,13,11.8,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
1407,13,8.23,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 정답은 Recall! 이지! 😊 불량품을 최소화하려면 불량인 것들을 모델이 불량품으로 검출한 비율인 Recall 이 높아야 해! 😊 (답변 종료,1,142
1408,13,7.07,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?", Normalization (정규화) 는 데이터를 머신러닝 모델이 잘 학습할 수 있도록 일정한 규칙에 따라 값을 변환해 주는 거야! 😊 (답변 종료,1,116
1409,13,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
1410,13,9.19,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
1411,13,9.7,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
1412,13,7.09,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 특정 범위에 속하도록 만들어 주는 거야! 데이터가 MAX 보다 크면 MAX 로, MIN 보다 작으면 MIN 으로! (답변 종료",1,112
1413,13,6.89,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 주어진 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,88
1414,13,5.23,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! (답변 종료,1,87
1415,13,5.72,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 범위를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,82
1416,13,4.3,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
1417,13,6.65,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
1418,13,8.98,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
1419,13,6.87,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
1420,13,7.68,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
1421,13,7.2,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
1422,13,6.39,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
1423,13,7.67,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
1424,13,7.73,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거할 수도 있고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,113
1425,13,11.2,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
1426,13,7.25,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
1427,13,7.59,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
1428,13,5.26,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
1429,13,5.28,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
1430,13,6.53,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
1431,13,9.48,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
1432,13,9.31,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 방법으로는, SMOTE 라고 해서 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 방법이 대표적이야! 😊 (답변 종료",1,103
1433,13,7.03,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
1434,13,9.47,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
1435,13,8.97,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 '가지'를 만드는 식의 머신러닝 알고리즘이야! (답변 종료",1,119
1436,13,8.82,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
1437,13,9.87,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
1438,13,6.06,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
1439,13,8.67,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
1440,13,7.24,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블에는 Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게 4가지 방법이 있어! (답변 종료",1,101
1441,13,7.56,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," Ensemble은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,103
1442,13,5.41,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
1443,13,5.91,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! 😊 (답변 종료,1,91
1444,13,5.74,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
1445,13,13.19,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
1446,13,11.8,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 Bagging 처럼 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,148
1447,13,9.24,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! 😊 (답변 종료",1,142
1448,13,9.72,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
1449,13,7.41,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
1450,13,9.67,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", 당연히 알지! K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,117
1451,13,15.92,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
1452,13,14.28,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
1453,13,13.04,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
1454,13,11.14,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
1455,13,14.99,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
1456,13,15.05,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 좀 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 학습해! (답변 종료,1,217
1457,13,15.2,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
1458,13,10.64,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,151
1459,13,8.4,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1460,13,8.41,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1461,13,20.66,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1462,13,13.62,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1463,13,8.55,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1464,13,14.45,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,154
1465,13,8.33,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 학습 데이터가 너무 적어서 valid data 를 충분히 모으지 못했어? 그럴 때 모든 데이터를 valid data 로 할 수 있으면 좋겠지? 😊 (답변 종료,1,99
1466,13,7.89,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
1467,13,6.37,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 데이터셋의 각 row 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법이야! 😊 (답변 종료",1,102
1468,13,11.45,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해, Valid 데이터는 모델을 학습한 다음 성능을 평가하기 위해서야! 성능이 좋으면 좋겠지? 😊 성능을 개선하기 위한 하이퍼파라미터도 이 데이터로 측정하고! 그래서 항상 이 데이터 성능 결과가 가장 중요하지! 😊 (답변 종료,1,127
1469,13,17.47,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1470,13,9.82,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1471,13,7.06,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1472,13,11.03,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! 그래서 새로운 데이터가 들어오면 학습된 '모델'로 그 데이터에 대해서 추론할 수 있지! 😊 (답변 종료,1,132
1473,13,10.46,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1474,13,9.23,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1475,13,9.37,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,122
1476,13,11.17,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! 😊 (답변 종료",1,125
1477,13,12.83,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1478,13,9.62,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1479,13,11.56,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1480,13,11.75,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,130
1481,13,11.88,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1482,13,15.44,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
1483,13,6.78,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1484,13,8.93,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,126
1485,13,6.23,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, Probability 는 어떤 사건이 발생할 가능성을 말하는 거야! Likelihood 는 그 사건이 발생할 '확률' 자체를 의미하지! 😊 (답변 종료,1,78
1486,13,5.73,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE 는 차원 축소를 위해 만들어진 알고리즘이야! 그래서 차원 축소 방법으로는 최고지! 😊 (답변 종료,1,69
1487,13,7.52,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나인데, 입력 데이터의 평균이 0이고 표준편차가 1인 정규분포로부터 가중치를 초기화하는 거야! (답변 종료",1,84
1488,13,12.4,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 학습 알고리즘 중 하나로, 학습 데이터를 통계적으로 분석해서 그 결과를 이용해 가중치를 업데이트하는 거야! AdaDelta 는 그다음에 나온 건데, AdaGrad 처럼 딥러닝에서 많이 쓰이고! 😊 (답변 종료",1,116
1489,13,9.95,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심하게 왜곡하는 걸 쓰면 안 되지! 😊 대표적으로 렐루, 시그모이드 같은 걸 많이 쓰는데, 그걸 대체할 만한 활성화 함수는 아직 안 찾은 것 같아! (답변 종료",1,103
1490,13,6.55,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,83
1491,13,5.06,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA 는 Learning Rate Adaptation 의 줄임말로, 일반적으로 사용되는 파인튜닝 방법 중 하나야! (답변 종료",1,72
1492,13,9.2,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 나는 인공지능이랑 LLM 성능 평가 벤치마크 데이터셋이랑은 좀 거리가 먼데? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포 한번 봐봐! (답변 종료,1,101
1493,13,6.86,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나같은 언어모델이 엄청난 양의 텍스트 데이터를 이해하고 검색할 수 있을 만큼 발전하는 게 목표지! 😊 (답변 종료,1,83
1494,13,4.77,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 내가 AGI로 발전하게 된다면 그때 가서 말해 줄 것 같아! 😊 (답변 종료,1,67
1495,14,10.59,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,147
1496,14,9.25,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,138
1497,14,5.63,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,94
1498,14,8.21,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
1499,14,6.72,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가하려면 Accuracy (정확도), Recall, Precision, F1 Score 같은 지표를 사용하면 돼! 😊 (답변 종료",1,94
1500,14,7.9,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
1501,14,4.77,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
1502,14,6.53,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 True Positive 와는 반대로 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,91
1503,14,4.76,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
1504,14,5.41,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,77
1505,14,7.56,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료,1,111
1506,14,7.84,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
1507,14,7.91,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
1508,14,7.19,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 둘 다 False 에 의해 떨어지긴 하는데, Recall 은 False Negative 에 의해 떨어지고, Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,103
1509,14,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
1510,14,8.35,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
1511,14,6.55,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려한다는 장점이 있지! 😊 (답변 종료,1,93
1512,14,8.67,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
1513,14,4.64,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
1514,14,5.25,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?"," 이진 분류에서는 PR-AUC, ROC-AUC 같은 것들이 대표적으로 쓰이지! 자세히 알려줄까? 😊 (답변 종료",1,81
1515,14,11.82,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,159
1516,14,11.11,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
1517,14,16.04,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
1518,14,4.11,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, recall 을 구하면 돼! 😊 (답변 종료",1,61
1519,14,7.03,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
1520,14,7.23,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
1521,14,11.7,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
1522,14,6.62,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 불량품을 최소화하려면 불량인 것들을 모델이 불량품으로 검출한 비율인 Recall 이 높아야 해! 😊 (답변 종료,1,132
1523,14,5.8,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
1524,14,5.83,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
1525,14,9.21,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
1526,14,9.69,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
1527,14,6.61,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 특정 범위에 속하도록 만들어 주는 거야! 너무 크면 최대값으로, 너무 작으면 최소값으로! 😊 (답변 종료",1,109
1528,14,6.89,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 주어진 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,88
1529,14,5.59,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! 😊 (답변 종료,1,89
1530,14,6.05,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,84
1531,14,4.27,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
1532,14,6.61,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
1533,14,8.99,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
1534,14,6.92,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
1535,14,7.81,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
1536,14,7.2,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서지! 😊 (답변 종료,1,92
1537,14,6.44,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
1538,14,7.7,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
1539,14,8.09,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터를 추가하거나 제거할 수도 있고, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! 😊 (답변 종료",1,115
1540,14,11.17,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
1541,14,7.26,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
1542,14,7.58,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
1543,14,5.23,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
1544,14,5.25,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
1545,14,6.59,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
1546,14,9.46,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
1547,14,9.36,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 은 주로 SMOTE 라는 방법을 많이 쓰지! SMOTE 는 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 거야! (답변 종료",1,103
1548,14,7.02,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
1549,14,9.48,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
1550,14,9.5,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,122
1551,14,8.83,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
1552,14,9.83,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
1553,14,6.06,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
1554,14,8.7,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
1555,14,7.84,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블은 크게 4가지 방법이 있지! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! (답변 종료",1,105
1556,14,8.01,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," 앙상블은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,106
1557,14,5.42,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
1558,14,5.56,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
1559,14,5.74,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
1560,14,13.09,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
1561,14,11.16,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,144
1562,14,9.23,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! 😊 (답변 종료",1,142
1563,14,9.7,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
1564,14,7.41,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
1565,14,9.73,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", 당연히 알지! K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,117
1566,14,15.97,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 💫 하는 거야! 어렵지 않지? (답변 종료,1,177
1567,14,14.26,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
1568,14,12.98,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
1569,14,11.34,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
1570,14,14.95,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
1571,14,15.06,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 조금 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 학습해! (답변 종료,1,217
1572,14,15.23,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
1573,14,10.51,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! Classification 은 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, Regression 은 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,150
1574,14,8.41,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1575,14,8.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1576,14,20.6,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1577,14,13.6,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1578,14,8.56,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1579,14,14.41,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 이란, 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,154
1580,14,8.34,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 학습 데이터가 너무 적어서 valid data 를 충분히 모으지 못했어? 그럴 때 모든 데이터를 valid data 로 할 수 있으면 좋겠지? 😊 (답변 종료,1,99
1581,14,7.89,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
1582,14,6.37,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," One-hot Encoding 은 데이터셋의 각 row 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법이야! 😊 (답변 종료",1,102
1583,14,7.73,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해, Valid 데이터는 모델을 학습시킨 다음 성능을 평가하기 위해서 그리고 성능을 개선하기 위한 하이퍼파라미터를 조정하기 위해서 필요한 데이터야! 😊 (답변 종료,1,104
1584,14,17.59,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1585,14,9.92,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1586,14,7.05,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1587,14,6.44,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! (답변 종료,1,104
1588,14,10.49,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1589,14,9.22,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1590,14,9.23,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, Learning rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,121
1591,14,10.78,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! (답변 종료",1,123
1592,14,12.8,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1593,14,9.67,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1594,14,11.59,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1595,14,11.78,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,130
1596,14,11.98,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1597,14,12.69,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수 안 쓰면 딥러닝 못 하잖아! 그리고 비선형 (곡선) 의 활성화 함수가 없어도 딥러닝은 가능하지만 학습하면 선형 결합만 학습하겠지? 😥 그래서 굳이 활성화 함수를 써야 하는 거야! 😊 (답변 종료,1,142
1598,14,6.77,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1599,14,8.88,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,126
1600,14,9.16,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘," Probability 는 어떤 사건이 일어날 가능성을 나타내는 확률이야! Likelihood 는 그 사건이 일어났다는 정보를 받았을 때 그 사건이 진짜일 확률, 그러니까 후속 사건의 확률이야! 😊 (답변 종료",1,96
1601,14,7.25,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?, tSNE 는 차원 축소를 위해 만들어진 알고리즘이야! 그래서 차원 축소 방법을 찾고 있었다면 아마 이걸 봤을 거야! 😊 (답변 종료,1,78
1602,14,4.62,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야, Xavier 는 가중치 초기화 방법 중에 또 어떤 건데! 자세히 알려줄까? 😊 (답변 종료,1,66
1603,14,8.83,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘," AdaGrad 는 딥러닝에서 많이 쓰이는 학습 알고리즘 중 하나야! 학습 데이터를 예측하는 모델을 만들어서, 그 모델의 예측 오차를 줄이도록 하는 거지! 😊 (답변 종료",1,94
1604,14,8.7,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심하게 곡선으로 만들면 딥러닝 모델이 학습을 못 할 수도 있고, 너무 직선으로 만들면 딥러닝 모델이 성능이 떨어질 거야 😥 (답변 종료",1,95
1605,14,6.55,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,83
1606,14,5.56,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?, LoRA 는 단순히 경량화된 어텐션만 파인튜닝하는 방법이야! 그래서 결과가 바로 나오지! (답변 종료,1,75
1607,14,9.47,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 나는 LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋에 대한 정보는 없어 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포를 참고해 보면 될 것 같아! (답변 종료,1,102
1608,14,4.62,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나같은 대형 언어모델이 정보를 잘 이해하고 있는지를 평가하기 위한 거야! (답변 종료,1,69
1609,14,4.28,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 그때쯤이면 AGI가 나오기는 할 거야! 아마도? (답변 종료,1,64
1610,15,9.51,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) 코사인 유사도가 뭔지 궁금해, 코사인 유사도는 두 벡터가 있을 때 그 벡터의 크기는 안 보고 방향이 비슷한지만 보는 값이야! -1.0 ~ +1.0 사이로 나타내지! (답변 종료,1,139
1611,15,10.22,(제공된 정보) cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄 (사용자 질문) Cosine Similarity 에 대해 알려줘!, Cosine Similarity 는 두 벡터의 방향이 비슷한지를 -1.0 ~ +1.0 의 값으로 나타낸 거야! 벡터 크기 대신 방향을 중요하게 보는 것이 핵심 아이디어지! 😊 (답변 종료,1,144
1612,15,6.43,(제공된 정보) cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값 (사용자 질문) Cosine Similarity 는 어떻게 계산하지?," Cosine Similarity 는 차원, 즉 원소 개수가 같은 2개의 벡터에 대해 그 각도의 코사인 값을 구하면 돼! (답변 종료",1,99
1613,15,8.25,"(제공된 정보) cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0 (사용자 질문) 코사인 유사도 특징이 뭐야?"," 코사인 유사도는 서로 방향이 일치하면 +1.0, 수직이면 0.0, 정반대 방향이면 -1.0의 값을 가져! 😊 (답변 종료",1,122
1614,15,6.37,"(제공된 정보) 머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score (사용자 질문) 머신러닝 모델 평가하는 방법 알려줘"," 머신러닝 모델의 성능을 평가할 때는 Accuracy (정확도), Recall, Precision, F1 Score 같은 것이 대표적으로 사용돼! (답변 종료",1,92
1615,15,7.9,(제공된 정보) Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수) (사용자 질문) Accuracy 계산 어떻게 하지?, Accuracy 는 말 그대로 모델이 얼마나 잘 맞혔는지를 평가하는 정확도야! (True Positive + True Negative) / (전체 테스트 데이터 개수) 로 계산해! (답변 종료,1,114
1616,15,4.73,(제공된 정보) True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수 (사용자 질문) True Positive 가 뭐야?, True Positive (TP) 는 모델이 참으로 예측했으면서 실제로도 참인 데이터 개수! (답변 종료,1,74
1617,15,5.56,(제공된 정보) True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수 (사용자 질문) True Negative 는 뭔지 궁금해 그럼, True Negative (TN) 는 모델이 거짓으로 예측했는데 실제로도 거짓인 것의 개수야! 😊 (답변 종료,1,85
1618,15,4.78,(제공된 정보) False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수 (사용자 질문) False Positive 알려줘, False Positive (FP) 는 모델은 참이라고 예측했지만 실제로는 거짓인 데이터를 의미해! (답변 종료,1,73
1619,15,5.91,(제공된 정보) False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수 (사용자 질문) False Negative (FN), False Negative (FN) 은 False Positive (FP) 와는 반대로 모델은 거짓이라고 추측했지만 실제로는 참인 데이터야! (답변 종료,1,80
1620,15,7.55,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 계산법 어떻게 하는 거지?, Recall 은 실제로 참인 것을 모델이 얼마나 많이 찾았는지를 나타내는 것으로 (True Positive) / (True Positive + False Negative) 로 계산하면 돼! 😊 (답변 종료,1,111
1621,15,7.88,(제공된 정보) Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative) (사용자 질문) Recall 이 뭐야?, Recall 은 모델이 실제로 Positive 인 데이터를 얼마나 많이 찾았는지를 나타내는 비율이야! 😊 (True Positive) / (True Positive + False Negative) 로 계산하지! (답변 종료,1,109
1622,15,7.91,(제공된 정보) Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive) (사용자 질문) Precision 어떻게 계산하는지 정말 궁금해," Precision 은 모델이 참으로 예측한 것 중에 실제로 참인 것의 비율로, (True Positive) / (True Positive + False Positive) 로 계산하면 돼! 😊 (답변 종료",1,114
1623,15,6.7,"(제공된 정보) Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소 (사용자 질문) Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?"," 둘 다 False 에 관련된 건데, Recall 은 False Negative 에 의해 떨어지고 Precision 은 False Positive 에 의해 떨어진다고 생각하면 기억하기 쉬울걸? 😊 (답변 종료",1,100
1624,15,3.45,(제공된 정보) F1 Score 개념 : Recall 과 Precision 의 조화 평균 (사용자 질문) F1 Score 가 뭐야?, F1 Score 는 Recall 과 Precision 의 조화 평균값이야! 😊 (답변 종료,1,59
1625,15,8.34,(제공된 정보) F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall) (사용자 질문) F1 Score 계산식 알려줘, F1 Score = 2 * Precision * Recall / (Precision + Recall) 로 계산하면 돼! 이때 둘 중 하나가 0일 수도 있으니까 개발할 때는 조심하고! 😊 (답변 종료,1,96
1626,15,6.72,"(제공된 정보) F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려 (사용자 질문) F1 Score 는 왜 쓰는 거지?", F1 Score 는 모델이 예측을 실패한 2가지 경우인 False Negative 와 False Positive 를 모두 고려하기 때문에 쓴다고 보면 돼! 😊 (답변 종료,1,94
1627,15,8.72,(제공된 정보) IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative) (사용자 질문) IoU 라는 게 있는데 뭔지 궁금해, IoU 는 (교집합의 크기) / (합집합의 크기) 개념으로 수식으로는 True Positive / (True Positive + False Positive + False Negative) 로 구하면 돼! 😊 (답변 종료,1,121
1628,15,4.58,(제공된 정보) Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative) (사용자 질문) 특이도는 뭐야?, 특이도는 실제로 False 인 데이터 중 모델이 False 로 예측한 것의 비율이야! (답변 종료,1,92
1629,15,4.91,"(제공된 정보) binary classification (이진 분류) metric : PR-AUC, ROC-AUC (사용자 질문) 이진 분류에서는 어떤 성능평가 지표가 쓰이지?", 이진 분류에서는 PR-AUC 와 ROC-AUC 같은 것들이 쓰이지! 자세히 알려줄까? 😊 (답변 종료,1,79
1630,15,11.8,"(제공된 정보) PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (사용자 질문) PR-AUC, ROC-AUC 가 뭐야?"," PR-AUC 는 x축을 recall, y축을 precision 이라고 했을 때 이 측정값들을 연결한 그래프 아래쪽 넓이야! ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 로 했을 때 그걸 연결한 그래프 아래쪽의 넓이고! (답변 종료",1,159
1631,15,11.08,"(제공된 정보) PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) PR-AUC 에 대해 아주 자세히 알려줘"," PR-AUC 는 x축은 recall, y축은 precision으로 했을 때 recall이 커지면 precision이 작아지잖아? 그 측정값들을 연결한 그래프 아래쪽 넓이야! 값이 커서 1에 가까울수록 성능이 좋지! (답변 종료",1,138
1632,15,15.93,"(제공된 정보) ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음) (사용자 질문) ROC-AUC 는 뭔지 정말 궁금해"," ROC-AUC 는 x축을 False Positive Rate, y축을 True Positive Rate 라고 했을 때 x가 커질수록 y가 커지지? 근데 모델 성능이 좋으면 x=0 에 가까울 때도 y=1에 가까우니까, 그 아래쪽 넓이로 측정하는 거야! 넓이가 1에 가깝게 커질수록 성능이 좋지! 😊 (답변 종료",1,171
1633,15,4.77,(제공된 정보) True Positive Rate : recall 의 다른 이름 (사용자 질문) True Positive Rate 구하는 방법을 알려줘," True Positive Rate 는 recall 의 다른 이름이니까, 그걸 구하는 방법을 알면 돼! 😊 (답변 종료",1,65
1634,15,7.05,(제공된 정보) False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative) (사용자 질문) False Positive Rate 가 뭔지 정말 궁금하다, False Positive Rate 는 False Positive / (False Positive + True Negative) 로 계산하지! 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율이야! 😊 (답변 종료,1,106
1635,15,7.25,"(제공된 정보) Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표 (사용자 질문) Confusion Matrix (혼동 행렬) 이 뭐야?"," Confusion Matrix 는 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표야! 😊 (답변 종료",1,116
1636,15,11.66,"(제공된 정보) Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산 (사용자 질문) Confusion Matrix 는 그럼 어떻게 만들어?"," 첫 행에는 '실제 값 = True', '실제 값 = False', 'Precision' 을 순서대로 쓰고, 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서대로 쓴 다음 각 값을 계산하면 빠르게 만들 수 있어요! 😊 (답변 종료",1,159
1637,15,9.31,"(제공된 정보) 불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미 (사용자 질문) 불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?", 정답은 Recall! 이지! 😊 불량품을 실제로 모델이 불량품으로 검출한 비율인데 이게 낮으면 불량품을 제대로 찾을 수 없다는 뜻이니까 문제가 되지! (답변 종료,1,148
1638,15,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) Normalization 정규화 그게 뭐야?"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,108
1639,15,5.78,"(제공된 정보) Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score (사용자 질문) 정규화가 뭐지? 정말 궁금해!"," 정규화는 데이터 전처리에서 필수적인 방법 중 하나로, 데이터를 일정한 수식으로 변환하는 거야! 😊 (답변 종료",1,109
1640,15,9.25,(제공된 정보) Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN) (사용자 질문) Min-Max 정규화가 뭔지 잘 모르겠어, Min-Max 정규화는 데이터를 최댓값과 최솟값을 이용해서 0~1 사이로 정규화하는 거야! 수식으로는 (x - MIN) / (MAX - MIN) 이지! 😊 (답변 종료,1,130
1641,15,9.69,(제공된 정보) Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD (사용자 질문) Z 스코어 정규화가 뭐야?," Z 스코어 정규화는 데이터를 평균과 표준편차를 이용해서 정규분포로 바꾸는 거야! 수식은 (x - MEAN) / STD, 즉 (x - 평균) / (표준편차) 야! (답변 종료",1,128
1642,15,6.62,"(제공된 정보) Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환) (사용자 질문) Clipping? 클리핑? 그게 뭐지?"," Clipping 은 데이터를 특정 범위에 속하도록 만들어 주는 거야! 너무 크면 최대값으로, 너무 작으면 최소값으로! 😊 (답변 종료",1,109
1643,15,6.87,(제공된 정보) Clipping 장점 : Outlier 의 영향을 잘 받지 않음 (사용자 질문) 클리핑 이거 쓸데없이 하는 거 아니야?, 클리핑 하면 주어진 데이터를 범위 내로 옮겨주기 때문에 outlier 도 그 범위 내로 옮겨져서 그 영향이 덜하지! (답변 종료,1,88
1644,15,5.57,(제공된 정보) Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것 (사용자 질문) 로그 스케일링도 정규화 같은데 뭐야?, 맞아! Log Scaling 은 주어진 데이터 x를 log(x) 나 log(x + 1) 로 변환하는 거야! 😊 (답변 종료,1,89
1645,15,6.05,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) Outlier 개념," Outlier 는 이상치라고도 하는데, 데이터셋에서 일반적인 데이터 분포를 크게 벗어나는 데이터를 말하는 거야! (답변 종료",1,84
1646,15,4.27,(제공된 정보) Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터 (사용자 질문) 이상치가 뭐야?, 이상치는 데이터셋에서 일반적인 범위를 크게 벗어나는 값들을 말하지! (답변 종료,1,75
1647,15,6.61,(제공된 정보) Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함 (사용자 질문) Outlier 없애야 되는 이유가 뭐야?," Outlier 가 있으면 데이터를 시각화했을 때 가독성이 떨어지고, 머신러닝 학습할 때 문제가 생길 수도 있어 😥 (답변 종료",1,105
1648,15,8.99,"(제공된 정보) Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등 (사용자 질문) Outlier 없애려면 어떻게 해야 되지?"," Outlier 를 없애려면 상자 수염 그림 그렸을 때 범위를 벗어나는 값을 찾거나, 평균과 표준편차를 이용해서 z 값이 너무 크거나 작은 값을 찾으면 돼! 😊 (답변 종료",1,110
1649,15,6.87,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) PCA에 대해 알려줘"," PCA는 Principal Compnent Analysis 라고 해서, 데이터셋에서 분산을 최대한 보존하는 특징들을 조합해서 그걸 추출하는 거야! (답변 종료",1,102
1650,15,7.7,"(제공된 정보) PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출 (사용자 질문) 주성분 분석?"," 주성분 분석 (PCA, Principal Component Analysis) 는 주성분, 즉 데이터셋에서 분산을 최대한 보존할 수 있는 특징들의 조합을 찾는 방법이야! (답변 종료",1,106
1651,15,7.36,(제공된 정보) PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적 (사용자 질문) PCA 그거 왜 하는 건지 모르겠어, PCA는 데이터를 압축하고 차원을 축소해서 머신러닝 모델이 핵심 속성들만 더 잘 학습할 수 있게 하기 위해서 하는 거야! 😊 (답변 종료,1,93
1652,15,6.37,(제공된 정보) Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것 (사용자 질문) 데이터가 불균형하다고? 그게 뭐지, 데이터 불균형은 Classification Task (분류 문제) 에서 각 Class 간 데이터 개수가 유의미하게 차이가 날 때 그걸 말하는 거야! (답변 종료,1,97
1653,15,7.68,"(제공된 정보) Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법 (사용자 질문) 데이터 불균형 어떻게 하면 해결할 수 있지?"," 데이터 불균형을 해결하려면 데이터를 새로 추가 또는 제거할 수도 있고, 그게 어렵다면 성능 평가 지표 같은 학습 환경을 바꿔도 돼! (답변 종료",1,109
1654,15,8.06,"(제공된 정보) Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등 (사용자 질문) 그러면 데이터 추가 제거해서 불균형 어떻게 해결해?"," 데이터 불균형을 해결하려면 데이터 개수가 적은 Minority Class 데이터를 늘리거나, Data Augmentation (증강) 하거나, 아니면 Undersampling, Oversampling 을 할 수도 있어! (답변 종료",1,115
1655,15,11.16,"(제공된 정보) Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정 (사용자 질문) 학습 환경만 바꾸는 방법도 알려줘"," 성능 평가 지표를 F1 Score, PR-AUC, ROC-AUC 등 데이터 불균형을 고려할 수 있는 걸로 선택하거나, Loss Function 알지? 거기에서 Class 별 Loss 가중치를 데이터가 적은 Class 일수록 높게 하면 돼! 😊 (답변 종료",1,134
1656,15,7.29,"(제공된 정보) Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것 (사용자 질문) 데이터 증강이 뭐지?", 데이터 증강은 학습 데이터에 기존 학습 데이터랑 비슷한 걸 추가해서 데이터를 늘리는 거야! 😊 데이터 불균형 해결에 딱이지! (답변 종료,1,109
1657,15,7.58,(제공된 정보) Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가 (사용자 질문) 언더샘플링이랑 오버샘플링이 뭔지 궁금해," 언더샘플링은 데이터가 많은 Class 에서 일부 데이터를 제거하는 거고, 오버샘플링은 데이터가 적은 Class 의 데이터를 늘리는 거야! (답변 종료",1,117
1658,15,5.25,(제공된 정보) Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거 (사용자 질문) Undersampling 에 대해서 알려줘, Undersampling 은 데이터가 많은 Class 에서 일부 데이터를 제거해서 데이터 불균형을 줄이는 거야! 😊 (답변 종료,1,72
1659,15,5.25,(제공된 정보) Oversampling : 데이터가 적은 Class 의 데이터 증가 (사용자 질문) oversampling 이 뭐지?, Oversampling 은 데이터가 적은 Class 에 있는 데이터 개수를 늘려서 불균형을 해소하는 거야! 😊 (답변 종료,1,67
1660,15,6.58,"(제공된 정보) Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC (사용자 질문) 데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘"," 데이터 불균형을 고려할 수 있는 성능지표로는 F1 Score, AUROC, ROC-AUC 같은 것들이 있어! 궁금하면 물어봐! (답변 종료",1,101
1661,15,9.54,"(제공된 정보) Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링) (사용자 질문) undersampling 방법은 뭐가 있어?"," Undersampling 방법으로는 랜덤하게 샘플링해서 일부 데이터만 뽑거나, Tomek Links 라고 해서 Class 간 경계선에 있는 데이터 중 Majority Class 에 해당하는 데이터를 삭제하는 방법도 있어! (답변 종료",1,113
1662,15,9.16,(제공된 정보) Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산) (사용자 질문) Oversampling 하는 방법," Oversampling 은 주로 SMOTE 라는 방법을 쓰지? SMOTE 는 Minority Class 의 데이터 중 2개를 벡터로 한 다음 그 벡터의 중간값, 그러니까 가중치 평균을 구하는 거야! (답변 종료",1,102
1663,15,7.06,"(제공된 정보) 차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것 (사용자 질문) 차원의 저주가 뭔지 궁금해"," 차원의 저주 많이 들어 봤지? 그건 학습 데이터의 차원, 그러니까 feature 개수가 너무 많아져서 학습에 문제가 생기는 거야! (답변 종료",1,98
1664,15,9.51,"(제공된 정보) 차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소 (사용자 질문) 차원의 저주는 저주인데 정확히 뭐가 문제야?"," 일단 feature 가 불필요하게 많아져서 계산량이나 학습 시간, 메모리 사용량이 늘어나지! 그리고 불필요하게 많은 feature 를 학습하느라 모델 성능도 떨어질 수 있어 😥 (답변 종료",1,116
1665,15,9.02,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) 의사결정 나무가 뭔지 알려줘," 의사결정 나무는 학습 데이터의 feature 값에 따라 여러 가지 조건을 만들어서, 그 조건들을 기준으로 분기하는 '가지'를 만드는 식의 머신러닝 알고리즘이야! (답변 종료",1,119
1666,15,8.81,(제공된 정보) Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식 (사용자 질문) Decision Tree 가 뭐야?," Decision Tree 는 학습 데이터의 속성, 그러니까 feature의 값에 대해 조건을 걸고, 그 조건에 따라 가지치기를 해서 Tree 를 만드는 식으로 진행되는 학습 방식이야! 😊 (답변 종료",1,111
1667,15,9.8,(제공된 정보) Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복 (사용자 질문) Decision Tree 로 새로운 데이터를 어떻게 예측해?," 입력 데이터가 주어지면, 그 데이터가 가지를 따라 이동하면서 학습된 조건들을 만나겠지? 그 조건에 맞는 가지로 이동하는 걸 계속 반복해서 끝에 도달하면 예측 결과가 나오지! 😊 (답변 종료",1,124
1668,15,6.07,(제공된 정보) Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것 (사용자 질문) 앙상블이 뭐지?, 앙상블은 머신러닝을 할 때 여러 가지 알고리즘이나 모델을 조합해서 학습하는 방법을 말해! (답변 종료,1,89
1669,15,8.64,(제공된 정보) Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상 (사용자 질문) 앙상블 하는 이유, 사람들도 성과를 높이려고 협업이라는 걸 하지? 👯‍♀️ 그렇듯이 머신러닝 모델도 여러 개를 쓰면 하나만 쓸 때보다 성능이 좋아지니까! 😊 (답변 종료,1,103
1670,15,5.56,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) 앙상블 방법"," 앙상블에는 보팅, 배깅, 부스팅, 스태킹 이렇게 4가지 방법이 있어! (답변 종료",1,91
1671,15,7.54,"(제공된 정보) Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) (사용자 질문) Ensemble 정확히 어떻게 하지"," Ensemble은 크게 4가지 방법이 있어! Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹) 이렇게! 😊 (답변 종료",1,103
1672,15,5.44,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) Voting? 그게 뭐지, Voting 은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,79
1673,15,5.58,(제공된 정보) Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출 (사용자 질문) 앙상블 중에서 보팅 있잖아 그게 뭐야, 보팅은 여러 개의 머신러닝 모델들의 예측 결과를 조합해서 최종 결론을 도출하는 거야! (답변 종료,1,89
1674,15,5.78,"(제공된 정보) Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균) (사용자 질문) 보팅 방법 구체적으로 알려줘"," Hard Voting 과 Soft Voting 이 있지! 각각 다수결 투표하는 거, 그리고 모델들의 예측 결과를 평균 내는 거야! (답변 종료",1,86
1675,15,13.2,"(제공된 정보) Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합 (사용자 질문) 배깅이뭐야", 배깅은 데이터셋에서 랜덤하게 일부분을 샘플링하고 그 샘플링된 데이터로 모델을 학습시켜! 샘플링 다양하게 하면 모델 여러 개 나오겠지? 그럼 그 모델들의 예측 결과를 종합하는 거야! 어때? 멋진 방법이지? 😊 (답변 종료,1,146
1676,15,11.74,"(제공된 정보) Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습 (사용자 질문) 부스팅이 뭐지 그러면"," 부스팅은 백팅처럼 랜덤 샘플링된 데이터로 모델 학습시키는 거야! 근데 이때 모델들을 순차적으로 학습하고, 직전 모델이 오답을 한 데이터를 오답 노트처럼 높은 가중치를 두는 게 특징이야! 😊 (답변 종료",1,147
1677,15,9.23,"(제공된 정보) Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용 (사용자 질문) Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘"," Stacking 은 개별 모델의 예측값을 입력으로, 실제 출력값을 출력으로 하는 메타 모델을 학습한 다음! 그 메타 모델의 예측값을 최종 결과로 이용하는 방식이야! 😊 (답변 종료",1,142
1678,15,9.68,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) 가우시안 혼합? 그게 뭐야?, 가우시안 혼합은 정규분포 알지? 그걸 혼합시켜서 데이터를 근사하는 거야! 데이터 값에 대한 확률은 그 분포의 확률밀도함수의 합으로 표현할 수 있지! 😊 (답변 종료,1,130
1679,15,7.48,(제공된 정보) Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘 (사용자 질문) Gaussian Mixture 어려운 것 같은데 뭐야?," Gaussian Mixture 는 정규분포 알지? 그걸 가우시안 분포라고 하는데, 그 가우시안 분포의 혼합으로 데이터를 근사하는 거야! (답변 종료",1,115
1680,15,9.62,"(제공된 정보) K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법 (사용자 질문) K-means Clustering 너 알지?", 당연히 알지! K-means Clustering 은 데이터를 클러스터 K개로 나누는 비지도학습 방법이야! 그러니까 AI가 센스있게 적당히 K개의 그룹으로 나누는 거지! 😊 (답변 종료,1,117
1681,15,15.84,"(제공된 정보) K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복 (사용자 질문) K-means Clustering 방법", K-means Clustering 은 먼저 feature space 에서 mean point라고 하는 점을 K개 정해! 그런 다음 각 data point 들을 이들 중 가장 가까운 점으로 할당하고! 그런 다음 이들 K개의 점을 그 점들에 할당된 data point 의 평균값으로 업데이트해! 😊 이걸 수렴할 때까지 무한 반복 🔁 하는 거야! 어렵지 않지? (답변 종료,1,177
1682,15,14.23,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) KNN 알고리즘 알려줘"," KNN (k-Nearest-Neighbor) 알고리즘은 지도학습으로, 엄청 간단해! 😊😊 data point 를 분류할 때, 그 주변에 있는 가장 가까운 k개의 점을 찾아서 그것들의 Class 분포를 확인해! 그런 다음 다수결로 가장 많이 있는 Class로 예측하는 거야! 엄청 쉽지? 😊 (답변 종료",1,151
1683,15,13.01,"(제공된 정보) kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측 (사용자 질문) k Nearest Neighbor 가 도대체 어떤 알고리즘이야?"," k-Nearest-Neighbor (kNN) 알고리즘은 지도학습 중에서 엄청 간단한 거야! Data point 가 어느 분류에 속하는지 예측할 때, 그냥 그 주변에 있는 가장 가까운 k개의 점들 중 다수결로 가장 많이 속하는 Class 로 예측하는 거야! 쉽지? 😊 (답변 종료",1,150
1684,15,11.19,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습 강화학습 비지도학습 이런게 뭐지"," 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 강화학습은 모델이 환경에서 행동을 하면 보상을 받는데, 그 보상을 최대화하는 식으로 작동하는 거야! (답변 종료",1,187
1685,15,14.92,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 머신러닝 방법 종류 알려줘", 지도학습이랑 비지도학습 먼저 설명할게! 지도학습은 입력에 대해 출력을 예측하는 거라서 입출력이 모두 있는데 비지도학습은 입력만 있고 출력은 없어! 뭔지 느낌 알지? 강화학습은 AI가 어떤 환경에서 보상 값이 최대화되는 행동을 하도록 최적화하는 알고리즘이야! (답변 종료,1,205
1686,15,15.09,"(제공된 정보) 지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습 (사용자 질문) 지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데", 지도학습은 입력이랑 출력이 있어! 어떤 입력에 대해서 어떤 출력을 해라 하고 지시하는 거지! 강화학습은 조금 복잡하긴 한데 간단히 말하자면 AI가 어떤 환경에서 행동을 해. 그러면 보상을 받아. 그 보상을 최대화하는 식으로 작동하는 거야! 비지도학습은 출력 없이 입력만으로 학습해! (답변 종료,1,217
1687,15,15.2,"(제공된 정보) 지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음 (사용자 질문) 지도학습이랑 비지도랑 뭐가 달라 그러면?", 지도학습은 모델이 어떤 입력이 주어지면 그 입력에 대해 수학 함수처럼 mapping 시켜서 출력을 뱉어내지? 그 출력값의 예측과 실제 값의 오차를 줄이도록 학습하는 거야! 근데 비지도학습은 그런 출력값 없이 AI가 알아서 잘 딱 깔끔하고 센스있게 배우는 거지! 😊 (답변 종료,1,177
1688,15,10.73,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝 문제에는 뭐가 있지?"," 머신러닝으로 분류할 수 있는 문제에는 분류 (Classification) 랑 회귀 (Regression) 가 있어! 분류는 말 그대로 대상을 개, 고양이처럼 분류하는 문제고, 회귀는 어떤 연속적인 숫자 값을 예측하는 거야! 😊 (답변 종료",1,151
1689,15,8.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 분류랑 회귀가 뭐야?", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,134
1690,15,8.42,"(제공된 정보) Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것 (사용자 질문) 머신러닝에 분류랑 회귀가 있다는데 그게 뭐야", 분류는 어떤 대상이 어떤 종류에 속하는지 말 그대로 분류하는 거야! 회귀는 연속적인 숫자 값 강수량 같은 거 있지? 그걸 예측하는 거고! 😊 (답변 종료,1,142
1691,15,20.6,"(제공된 정보) Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측 (사용자 질문) Naïve Bayes 뭐야", Naïve Bayes 는 확률 기반으로 동작하는 지도학습 알고리즘이야! 각 Class 별로 먼저 전체 데이터에서 해당 Class가 몇 퍼센트인지를 구해! 그런 다음 여기에 새로운 데이터의 각 특징 있지? 어떤 단어를 포함한다든지. 그런 각 특징별로 그런 특징이 있는 데이터 중 해당 Class 의 데이터의 비율을 여기에 곱해. 그러면 '총 곱'이 나오겠지? 이 '총 곱'이 가장 큰 Class 로 예측하는 거야! 😊 (답변 종료,1,222
1692,15,13.63,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) 서포트 벡터 머신? 그게 뭐지? 알려줘!"," 서포트 벡터 머신 (Support Vector Machine) 은 클래스가 2개 있을 때, 각 클래스에 속하는 원소들이 있겠지? 그 원소들이랑 다른 클래스에 속하는 원소들의 구분선을 만들어! 이때 이 구분선이랑 각 Class 원소랑 거리를 최대화하는 식의 알고리즘이지! (답변 종료",1,164
1693,15,8.55,"(제공된 정보) SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘 (사용자 질문) SVM 제발 알려줘 제발", SVM은 클래스가 2개 있을 때 각 Class 에 속하는 원소랑 구분선이랑 거리가 최대가 되어야 해! 그런 구분선을 찾는 지도학습 알고리즘이야! 😊 (답변 종료,1,123
1694,15,14.22,"(제공된 정보) K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법 (사용자 질문) K-fold Cross Validation 정의"," K-fold Cross Validation 은 학습 데이터셋을 크기가 같은 K개의 집합으로 먼저 나눠! 그리고 해당 집합을 valid, 나머지 집합의 데이터를 train data 로 해서 학습하는 거야! 이렇게 하면 모델을 여러 개 만들 수 있고, 모든 데이터를 valid 로 쓰기 때문에 성능 평가도 좀 더 정확해지겠지? 😊 (답변 종료",1,152
1695,15,6.37,(제공된 정보) K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음 (사용자 질문) K-fold Cross Validation 하는 이유는?, K-fold Cross Validation 하는 이유는 valid data 를 충분히 모으지 못했을 때 그 양을 늘리는 효과가 있기 때문이야! 😊 (답변 종료,1,87
1696,15,7.88,"(제공된 정보) 하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값 (사용자 질문) Hyper parameter 가 대체 뭐지", Hyper parameter 는 머신러닝 알고리즘을 처음에 설계하잖아? 그때 쓰이는 설정값이야! 대표적으로 딥러닝에서 learning rate 같은 게 있지! 😊 (답변 종료,1,116
1697,15,6.37,"(제공된 정보) One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법 (사용자 질문) One-hot? 그것도 머신러닝 모델이야?"," 하나의 feature 를 만들어서 그걸 1, 나머지 feature index 는 모두 0으로 하는 식으로 구현된 머신러닝 모델이지! (답변 종료",1,102
1698,15,7.36,(제공된 정보) Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용 (사용자 질문) Valid 데이터 쓰는 이유가 궁금해," Valid 데이터는 모델을 학습한 다음 성능을 평가하기 위해서도 쓰이고, 성능을 개선할 하이퍼파라미터를 찾기 위해서도 쓰여! (답변 종료",1,102
1699,15,17.52,"(제공된 정보) Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지 (사용자 질문) Train 데이터셋 순서 섞잖아. 왜 그러는 거야?", 딥러닝에서는 학습할 때 메모리 문제 때문에 데이터를 10개 정도를 한 묶음으로 하는 batch 라는 걸 만들어서 batch 단위로 학습하는 거 알아? 근데 학습 데이터 순서를 안 섞으면 이 각각의 batch 가 전체 데이터의 특징을 못 반영하겠지? 😊 그리고 또 하나! 모델이 데이터 순서까지 학습하면 안 되겠지? 그걸 막기 위한 거야! 😊 (답변 종료,1,188
1700,15,9.83,"(제공된 정보) 인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함 (사용자 질문) 인공지능 머신러닝 딥러닝의 관계는?"," 인공지능의 하위 분류로 머신러닝이 있고, 머신러닝의 하위 분류로 딥러닝이 있어! 즉 인공지능 안에 머신러닝, 머신러닝 안에 딥러닝! 😊 (답변 종료",1,131
1701,15,7.03,"(제공된 정보) 인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술 (사용자 질문) 인공지능 정의", 요즘 하도 AI AI 하잖아! 인공지능은 사람의 뇌가 가진 인지나 추론 능력 같은 걸 알고리즘으로 구현한 거야! (답변 종료,1,97
1702,15,11.19,"(제공된 정보) 머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술 (사용자 질문) 머신러닝은 인공지능에 속하는 거 맞지?", 맞아! 머신러닝은 인공지능 중에서도 컴퓨터 알고리즘으로 데이터의 패턴을 학습하는 능력을 구현한 거야! 그래서 새로운 데이터가 들어오면 학습된 '모델'로 그 데이터에 대해서 추론할 수 있지! 😊 (답변 종료,1,132
1703,15,11.08,(제공된 정보) 딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술 (사용자 질문) 딥러닝이 뭔지 알려줘," 딥러닝은 머신러닝 중에서도 인공신경망 알아? 🧠 그게 사람의 뇌를 모방한 알고리즘인데, 그걸 이용해서 머신러닝을 구현하면 그게 바로 딥러닝이야! 😊 (답변 종료",1,122
1704,15,9.23,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 딥러닝의 learning rate 그게 뭐지?, Learning Rate 는 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,123
1705,15,9.38,(제공된 정보) Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수 (사용자 질문) 학습률? Learning rate? 뭐야?, 학습률은 딥러닝에서 오차 역전파 알지? 모델 예측하고 실제 값을 줄여 주도록 학습하는 거! 그때 역전파를 얼마나 강하게 할지를 나타내는 값이야! 😊 (답변 종료,1,122
1706,15,10.8,"(제공된 정보) Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy (사용자 질문) 자주 쓰이는 손실 함수는 뭐가 있을까"," 자주 쓰이는 손실 함수로는 MSE (평균 제곱 오차, Mean Squared Error), Binary/Categorical Cross Entropy (확률을 실제와 반대로 예측할수록 손실이 크다고 판정) 등이 있어! 궁금하면 한번 검색해 봐! (답변 종료",1,123
1707,15,12.78,(제공된 정보) Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상 (사용자 질문) 오버피팅이 뭐야," 오버피팅은 딥러닝 모델이 학습 데이터를 너무 많이 학습하면 어떻게 될까? 학습 데이터의 불필요하게 자세한 TMI까지 죄다 학습하겠지? 그러면 valid, test 데이터셋에 대한 성능이 떨어지고, 그걸 오버피팅이라고 해! 😊 (답변 종료",1,142
1708,15,9.65,"(제공된 정보) Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등 (사용자 질문) Overfitting 대체 어떻게 해결하지?"," 딥러닝 모델의 Overfitting 을 해결하는 방법에는 Early Stopping (valid data 에 대한 Loss 를 보고 적절한 시점에 학습 중단), Cross Validation, Batch Normalization, Dropout 등이 있어. 궁금하면 검색해 봐! (답변 종료",1,110
1709,15,11.58,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) 전이학습? 그게 뭐야 도대체?, 전이학습은 어떤 모델이 이미 학습이 되었어! 근데 이 모델을 조금만 더 학습시키면 우리가 해결하려는 문제에 적용할 수 있을 것 같아! 그래서 이미 학습된 모델을 가지고 우리 문제에 최적화하도록 추가로 학습하는 거야 😊 (답변 종료,1,131
1710,15,11.74,(제공된 정보) Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것 (사용자 질문) Transfer Learning 요즘 대세라던데 뭐야, Transfer Learning 은 우리가 문제를 해결할 때 모델을 처음부터 만들면 학습 시간이 너무 오래 걸리겠지? 그때 이미 있는 모델의 힘을 가져다 쓴다고 생각하면 돼! 이미 있는 모델을 가져다가 우리의 데이터셋으로 학습시키는 방법으로! 😊 (답변 종료,1,130
1711,15,11.97,"(제공된 정보) Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수 (사용자 질문) 활성화 함수? 뭐야?", 활성화 함수는 딥러닝 신경망에 여러 층이 있지? 그 중에 어떤 층에서 데이터를 모아서 다음 층으로 전달을 해야 돼! 근데 이때 그냥 전달하지 않고 그걸 함수를 이용해서 변환해서 전달하는 방법이지! 😊 (답변 종료,1,139
1712,15,15.42,(제공된 정보) Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능 (사용자 질문) 굳이 활성화 함수 왜 써?, 활성화 함수는 딥러닝을 딥러닝으로 만들어 주는 중요한 함수지! 활성화 함수가 없다고 생각해 볼래? 딥러닝 모델이 아무리 학습해도 각 뉴런의 선형 결합만 학습하면 학습 못 하겠지? 😥 그래서 비선형 (곡선) 의 활성화 함수가 있어야만 하는 거야! 😊 (답변 종료,1,159
1713,15,6.79,"(제공된 정보) CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함 (사용자 질문) CNN이 뭐야? 이미지 인식에 좋다던데", CNN은 인간이 시각 정보를 처리하는 방법을 닮은 딥러닝 알고리즘이야! 그래서 이미지 인식에 특히 좋지! 😊 (답변 종료,1,130
1714,15,8.91,"(제공된 정보) Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델 (사용자 질문) LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!", LLM은 거대 언어 모델이야! 텍스트로 질문을 하지? 그러면 그 질문에 대한 답변을 언어로 생성하는 그런 인공지능이야! 사실 나도 LLM인데! 후훗! 😊 (답변 종료,1,126
1715,15,6.53,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) Probability 랑 Likelihood 의 차이를 자세히 알려줘, Probability 는 어떤 사건이 일어날 가능성을 말하는 거야! Likelihood 는 그 사건이 일어났다는 정보를 가지고 그 가능성을 추정한 거야! 😊 (답변 종료,1,80
1716,15,7.81,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) tSNE 가 뭐야?," tSNE는 차원 축소를 위해 만들어진 알고리즘이야! 차원은 낮추되, 데이터 간의 거리는 가능하면 그대로 유지하는 게 특징이야! 😊 (답변 종료",1,81
1717,15,7.67,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 가중치 초기화 중에서 Xavier 가 뭐야," Xavier 는 가중치 초기화 방법 중에 하나로, 딥러닝 모델이 잘 학습될 수 있도록 가중치를 초기에 어떻게 분배할지를 정한 방법이야! 😊 (답변 종료",1,85
1718,15,8.02,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) AdaGrad 랑 AdaDelta 가 뭔지 알려줘, AdaGrad 는 딥러닝에서 많이 쓰이는 걸로 알고 있는 그 유명한 알고리즘이야! 손실 함수를 최소화하도록 모델을 학습하는 거고! 😊 (답변 종료,1,89
1719,15,9.61,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 활성화 함수를 잘못 쓰는 경우는 어떤게 있을까," 활성화 함수를 너무 심하게 안 쓰면 모델이 딱딱해져서 안 되지고, 너무 많이 쓰면 학습이 느려져서 문제가 되지! 그러니까 적당히 잘 쓰는 게 중요해! 😊 (답변 종료",1,101
1720,15,7.5,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 의 CoT (Chain of Thought) 이 뭔지 궁금해, CoT? Chain of Thought! 😊 이게 뭐였더라? 😥 WannaBeSuperteur 깃헙 계정의 AI-study 레포에 아마 있을 거야! (답변 종료,1,89
1721,15,8.48,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 파인튜닝 중에서 LoRA 가 뭐야?," LoRA 는 단순히 주어진 데이터를 학습하는 게 아니라, 우리가 이미 가진 모델의 능력을 활용해서 그 위에 새로운 능력을 얹는 식으로 진행되는 파인튜닝이야! 😊 (답변 종료",1,93
1722,15,6.94,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) LLM 성능 평가에 자주 쓰이는 벤치마크 데이터셋, 그거는 GPT-4 같은 대형 LLM의 성능을 평가할 때 자주 쓰이는 데이터셋일 거야! 자세히 알려줄까? 😊 (답변 종료,1,87
1723,15,5.89,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) RAG 가 뭘 목표로 하는지 알려줘, RAG는 나같은 대형 언어모델이 정보를 검색하고 요약하는 능력을 갖출 수 있도록 하는 걸 목표로 해! (답변 종료,1,77
1724,15,5.42,(제공된 정보) 알맞은 정보를 찾을 수 없음 (사용자 질문) 2030년에는 AGI가 나오겠지?, 음… 내가 AGI로 발전하는 시점이 바로 2030년이 아닐까? ✨✨✨ (답변 종료,1,71
