,data_type,user_question,rag_retrieved_data,similarity_score
0,train,cosine similarity가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1
1,train,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1
2,train,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,1
3,train,코사인 유사도의 특징을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",1
4,train,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",1
5,train,Accuracy 는 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),1
6,train,True Positive 같은 건 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,1
7,train,True Negative 는?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,1
8,train,False Positive 는 뭐지 그럼?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,1
9,train,False Negative 는 뭐야 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,1
10,train,Recall 은 어떻게 계산해?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1
11,train,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1
12,train,Precision 은 어떻게 계산하지,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),1
13,train,Recall 과 Precision 이 자꾸 헷갈리네,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",1
14,train,F1 이 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,1
15,train,F1 Score 구하는 수식을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),1
16,train,F1 Score 장점이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",1
17,train,IoU 가 뭔지 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),1
18,train,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),1
19,train,이진 분류에서 쓰이는 Metric 을 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",1
20,train,PR-AUC랑 ROC-AUC가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",1
21,train,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1
22,train,ROC-AUC가 뭔지 아주 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1
23,train,True Positive Rate 가 뭐야? 궁금해!,True Positive Rate : recall 의 다른 이름,1
24,train,False Positive Rate 는 뭐지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),1
25,train,Confusion Matrix 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",1
26,train,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",1
27,train,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",1
28,train,Normalization 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1
29,train,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1
30,train,min-max 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),1
31,train,Z score normalization 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,1
32,train,Clipping 에 대해서 자세히 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",1
33,train,Clipping 을 하면 뭐가 좋아?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,1
34,train,로그 스케일링이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,1
35,train,Outlier 가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1
36,train,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1
37,train,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,1
38,train,Outlier 를 제거하는 방법에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",1
39,train,PCA 가 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1
40,train,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1
41,train,PCA 는 왜 하는 거지 그러면?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,1
42,train,데이터 불균형이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,1
43,train,데이터 불균형 해결하는 법이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",1
44,train,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",1
45,train,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",1
46,train,Augmentation 이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",1
47,train,Undersampling 이랑 Oversampling 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,1
48,train,Undersampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,1
49,train,그럼 Oversampling 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,1
50,train,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",1
51,train,Undersampling 하는 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",1
52,train,Oversampling 방법은 어떤 게 있어?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),1
53,train,차원의 저주가 뭐지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",1
54,train,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",1
55,train,Decision Tree 가 뭔지 자세히 알고 싶어,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1
56,train,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1
57,train,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,1
58,train,앙상블이 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,1
59,train,앙상블을 왜 하는 거야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,1
60,train,앙상블 하는 구체적인 방법 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1
61,train,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1
62,train,보팅에 대해 자세히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1
63,train,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1
64,train,보팅의 방법에는 구체적으로 뭐가 있지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",1
65,train,Bagging 이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",1
66,train,그럼 Boosting 은 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",1
67,train,Stacking 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",1
68,train,Gaussian Mixture 모델이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1
69,train,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1
70,train,K-means Clustering 이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",1
71,train,K-means Clustering 의 방법을 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",1
72,train,kNN 에 대해 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1
73,train,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1
74,train,지도학습 비지도학습 이런 게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1
75,train,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1
76,train,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1
77,train,지도학습과 비지도학습의 차이가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",1
78,train,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1
79,train,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1
80,train,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1
81,train,Naïve Bayes 가 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",1
82,train,서포트 벡터 머신이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1
83,train,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1
84,train,K-fold Cross Validation,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",1
85,train,K-fold Cross Validation을 굳이 왜 하는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,1
86,train,하이퍼파라미터가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",1
87,train,One-hot 방식이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",1
88,train,Valid 데이터가 굳이 왜 필요하지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,1
89,train,Train 데이터셋을 왜 순서를 섞어야 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",1
90,train,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",1
91,train,인공지능이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",1
92,train,머신러닝은 그럼 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",1
93,train,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,1
94,train,딥러닝에서 학습률이 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1
95,train,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1
96,train,자주 쓰는 Loss Function 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",1
97,train,Overfitting 이 뭔지 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,1
98,train,Overfitting 해결하는 방법은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",1
99,train,전이학습이 뭐지?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1
100,train,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1
101,train,활성화 함수? 그게 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",1
102,train,활성화 함수는 왜 필요해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,1
103,train,CNN이 뭐야? 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",1
104,train,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",1
105,test,코사인 유사도가 뭔지 궁금해,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1
106,test,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1
107,test,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,1
108,test,코사인 유사도 특징이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",1
109,test,머신러닝 모델 평가하는 방법 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",1
110,test,Accuracy 계산 어떻게 하지?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),1
111,test,True Positive 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,1
112,test,True Negative 는 뭔지 궁금해 그럼,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,1
113,test,False Positive 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,1
114,test,False Negative (FN),False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,1
115,test,Recall 계산법 어떻게 하는 거지?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1
116,test,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1
117,test,Precision 어떻게 계산하는지 정말 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),1
118,test,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",1
119,test,F1 Score 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,1
120,test,F1 Score 계산식 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),1
121,test,F1 Score 는 왜 쓰는 거지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",1
122,test,IoU 라는 게 있는데 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),1
123,test,특이도는 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),1
124,test,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",1
125,test,"PR-AUC, ROC-AUC 가 뭐야?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",1
126,test,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1
127,test,ROC-AUC 는 뭔지 정말 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1
128,test,True Positive Rate 구하는 방법을 알려줘,True Positive Rate : recall 의 다른 이름,1
129,test,False Positive Rate 가 뭔지 정말 궁금하다,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),1
130,test,Confusion Matrix (혼동 행렬) 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",1
131,test,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",1
132,test,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",1
133,test,Normalization 정규화 그게 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1
134,test,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1
135,test,Min-Max 정규화가 뭔지 잘 모르겠어,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),1
136,test,Z 스코어 정규화가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,1
137,test,Clipping? 클리핑? 그게 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",1
138,test,클리핑 이거 쓸데없이 하는 거 아니야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,1
139,test,로그 스케일링도 정규화 같은데 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,1
140,test,Outlier 개념,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1
141,test,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1
142,test,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,1
143,test,Outlier 없애려면 어떻게 해야 되지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",1
144,test,PCA에 대해 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1
145,test,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1
146,test,PCA 그거 왜 하는 건지 모르겠어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,1
147,test,데이터가 불균형하다고? 그게 뭐지,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,1
148,test,데이터 불균형 어떻게 하면 해결할 수 있지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",1
149,test,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",1
150,test,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",1
151,test,데이터 증강이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",1
152,test,언더샘플링이랑 오버샘플링이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,1
153,test,Undersampling 에 대해서 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,1
154,test,oversampling 이 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,1
155,test,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",1
156,test,undersampling 방법은 뭐가 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",1
157,test,Oversampling 하는 방법,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),1
158,test,차원의 저주가 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",1
159,test,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",1
160,test,의사결정 나무가 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1
161,test,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1
162,test,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,1
163,test,앙상블이 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,1
164,test,앙상블 하는 이유,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,1
165,test,앙상블 방법,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1
166,test,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1
167,test,Voting? 그게 뭐지,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1
168,test,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1
169,test,보팅 방법 구체적으로 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",1
170,test,배깅이뭐야,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",1
171,test,부스팅이 뭐지 그러면,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",1
172,test,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",1
173,test,가우시안 혼합? 그게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1
174,test,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1
175,test,K-means Clustering 너 알지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",1
176,test,K-means Clustering 방법,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",1
177,test,KNN 알고리즘 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1
178,test,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1
179,test,지도학습 강화학습 비지도학습 이런게 뭐지,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1
180,test,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1
181,test,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1
182,test,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",1
183,test,머신러닝 문제에는 뭐가 있지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1
184,test,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1
185,test,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1
186,test,Naïve Bayes 뭐야,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",1
187,test,서포트 벡터 머신? 그게 뭐지? 알려줘!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1
188,test,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1
189,test,K-fold Cross Validation 정의,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",1
190,test,K-fold Cross Validation 하는 이유는?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,1
191,test,Hyper parameter 가 대체 뭐지,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",1
192,test,One-hot? 그것도 머신러닝 모델이야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",1
193,test,Valid 데이터 쓰는 이유가 궁금해,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,1
194,test,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",1
195,test,인공지능 머신러닝 딥러닝의 관계는?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",1
196,test,인공지능 정의,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",1
197,test,머신러닝은 인공지능에 속하는 거 맞지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",1
198,test,딥러닝이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,1
199,test,딥러닝의 learning rate 그게 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1
200,test,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1
201,test,자주 쓰이는 손실 함수는 뭐가 있을까,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",1
202,test,오버피팅이 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,1
203,test,Overfitting 대체 어떻게 해결하지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",1
204,test,전이학습? 그게 뭐야 도대체?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1
205,test,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1
206,test,활성화 함수? 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",1
207,test,굳이 활성화 함수 왜 써?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,1
208,test,CNN이 뭐야? 이미지 인식에 좋다던데,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",1
209,test,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",1
