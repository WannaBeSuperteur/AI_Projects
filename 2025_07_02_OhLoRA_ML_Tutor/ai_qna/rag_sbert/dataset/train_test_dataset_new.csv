,Unnamed: 0.1,idx,data_type,repeat,user_question,rag_retrieved_data,similarity_score
0,0,0,train,0,cosine similarity가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
1,1,1,train,0,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2,2,2,train,0,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,1.0
3,3,3,train,0,코사인 유사도의 특징을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",1.0
4,4,4,train,0,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",1.0
5,5,5,train,0,Accuracy 는 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),1.0
6,6,6,train,0,True Positive 같은 건 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,1.0
7,7,7,train,0,True Negative 는?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,1.0
8,8,8,train,0,False Positive 는 뭐지 그럼?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,1.0
9,9,9,train,0,False Negative 는 뭐야 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,1.0
10,10,10,train,0,Recall 은 어떻게 계산해?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
11,11,11,train,0,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
12,12,12,train,0,Precision 은 어떻게 계산하지,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),1.0
13,13,13,train,0,Recall 과 Precision 이 자꾸 헷갈리네,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",1.0
14,14,14,train,0,F1 이 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,1.0
15,15,15,train,0,F1 Score 구하는 수식을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),1.0
16,16,16,train,0,F1 Score 장점이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",1.0
17,17,17,train,0,IoU 가 뭔지 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),1.0
18,18,18,train,0,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),1.0
19,19,19,train,0,이진 분류에서 쓰이는 Metric 을 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",1.0
20,20,20,train,0,PR-AUC랑 ROC-AUC가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",1.0
21,21,21,train,0,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
22,22,22,train,0,ROC-AUC가 뭔지 아주 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
23,23,23,train,0,True Positive Rate 가 뭐야? 궁금해!,True Positive Rate : recall 의 다른 이름,1.0
24,24,24,train,0,False Positive Rate 는 뭐지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),1.0
25,25,25,train,0,Confusion Matrix 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",1.0
26,26,26,train,0,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",1.0
27,27,27,train,0,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",1.0
28,28,28,train,0,Normalization 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
29,29,29,train,0,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
30,30,30,train,0,min-max 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),1.0
31,31,31,train,0,Z score normalization 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,1.0
32,32,32,train,0,Clipping 에 대해서 자세히 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",1.0
33,33,33,train,0,Clipping 을 하면 뭐가 좋아?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,1.0
34,34,34,train,0,로그 스케일링이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,1.0
35,35,35,train,0,Outlier 가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
36,36,36,train,0,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
37,37,37,train,0,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,1.0
38,38,38,train,0,Outlier 를 제거하는 방법에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",1.0
39,39,39,train,0,PCA 가 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
40,40,40,train,0,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
41,41,41,train,0,PCA 는 왜 하는 거지 그러면?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,1.0
42,42,42,train,0,데이터 불균형이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,1.0
43,43,43,train,0,데이터 불균형 해결하는 법이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",1.0
44,44,44,train,0,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",1.0
45,45,45,train,0,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",1.0
46,46,46,train,0,Augmentation 이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",1.0
47,47,47,train,0,Undersampling 이랑 Oversampling 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,1.0
48,48,48,train,0,Undersampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,1.0
49,49,49,train,0,그럼 Oversampling 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,1.0
50,50,50,train,0,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",1.0
51,51,51,train,0,Undersampling 하는 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",1.0
52,52,52,train,0,Oversampling 방법은 어떤 게 있어?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),1.0
53,53,53,train,0,차원의 저주가 뭐지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",1.0
54,54,54,train,0,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",1.0
55,55,55,train,0,Decision Tree 가 뭔지 자세히 알고 싶어,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
56,56,56,train,0,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
57,57,57,train,0,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,1.0
58,58,58,train,0,앙상블이 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,1.0
59,59,59,train,0,앙상블을 왜 하는 거야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,1.0
60,60,60,train,0,앙상블 하는 구체적인 방법 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
61,61,61,train,0,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
62,62,62,train,0,보팅에 대해 자세히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
63,63,63,train,0,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
64,64,64,train,0,보팅의 방법에는 구체적으로 뭐가 있지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",1.0
65,65,65,train,0,Bagging 이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",1.0
66,66,66,train,0,그럼 Boosting 은 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",1.0
67,67,67,train,0,Stacking 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",1.0
68,68,68,train,0,Gaussian Mixture 모델이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
69,69,69,train,0,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
70,70,70,train,0,K-means Clustering 이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",1.0
71,71,71,train,0,K-means Clustering 의 방법을 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",1.0
72,72,72,train,0,kNN 에 대해 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
73,73,73,train,0,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
74,74,74,train,0,지도학습 비지도학습 이런 게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
75,75,75,train,0,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
76,76,76,train,0,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
77,77,77,train,0,지도학습과 비지도학습의 차이가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",1.0
78,78,78,train,0,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
79,79,79,train,0,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
80,80,80,train,0,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
81,81,81,train,0,Naïve Bayes 가 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",1.0
82,82,82,train,0,서포트 벡터 머신이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
83,83,83,train,0,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
84,84,84,train,0,K-fold Cross Validation,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",1.0
85,85,85,train,0,K-fold Cross Validation을 굳이 왜 하는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,1.0
86,86,86,train,0,하이퍼파라미터가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",1.0
87,87,87,train,0,One-hot 방식이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",1.0
88,88,88,train,0,Valid 데이터가 굳이 왜 필요하지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,1.0
89,89,89,train,0,Train 데이터셋을 왜 순서를 섞어야 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",1.0
90,90,90,train,0,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",1.0
91,91,91,train,0,인공지능이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",1.0
92,92,92,train,0,머신러닝은 그럼 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",1.0
93,93,93,train,0,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,1.0
94,94,94,train,0,딥러닝에서 학습률이 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
95,95,95,train,0,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
96,96,96,train,0,자주 쓰는 Loss Function 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",1.0
97,97,97,train,0,Overfitting 이 뭔지 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,1.0
98,98,98,train,0,Overfitting 해결하는 방법은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",1.0
99,99,99,train,0,전이학습이 뭐지?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
100,100,100,train,0,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
101,101,101,train,0,활성화 함수? 그게 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",1.0
102,102,102,train,0,활성화 함수는 왜 필요해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,1.0
103,103,103,train,0,CNN이 뭐야? 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",1.0
104,104,104,train,0,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",1.0
105,105,105,train,1,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
106,106,106,train,1,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
107,107,107,train,1,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.5
108,108,108,train,1,머신러닝에서 많이 쓰이는 평가지표 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
109,109,109,train,1,Accuracy 는 어떻게 계산해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
110,110,110,train,1,True Positive 같은 건 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.1
111,111,111,train,1,True Negative 는?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
112,112,112,train,1,False Positive 는 뭐지 그럼?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
113,113,113,train,1,False Negative 는 뭐야 그러면?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
114,114,114,train,1,Recall 은 어떻게 계산해?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
115,115,115,train,1,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
116,116,116,train,1,Precision 은 어떻게 계산하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
117,117,117,train,1,Recall 과 Precision 이 자꾸 헷갈리네,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.5
118,118,118,train,1,F1 이 뭔지 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
119,119,119,train,1,F1 Score 구하는 수식을 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
120,120,120,train,1,F1 Score 장점이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.5
121,121,121,train,1,IoU 가 뭔지 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
122,122,122,train,1,특이도라는 걸 봤는데 그게 뭔지 궁금해!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
123,123,123,train,1,이진 분류에서 쓰이는 Metric 을 알려줘!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
124,124,124,train,1,PR-AUC랑 ROC-AUC가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
125,125,125,train,1,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.5
126,126,126,train,1,ROC-AUC가 뭔지 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
127,127,127,train,1,True Positive Rate 가 뭐야? 궁금해!,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
128,128,128,train,1,False Positive Rate 는 뭐지 그러면?,True Positive Rate : recall 의 다른 이름,0.25
129,129,129,train,1,Confusion Matrix 가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.25
130,130,130,train,1,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.5
131,131,131,train,1,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.25
132,132,132,train,1,Normalization 이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
133,133,133,train,1,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
134,134,134,train,1,min-max 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
135,135,135,train,1,Z score normalization 이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
136,136,136,train,1,Clipping 에 대해서 자세히 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
137,137,137,train,1,Clipping 을 하면 뭐가 좋아?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.5
138,138,138,train,1,로그 스케일링이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
139,139,139,train,1,Outlier 가 뭔지 궁금해,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
140,140,140,train,1,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
141,141,141,train,1,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
142,142,142,train,1,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.5
143,143,143,train,1,PCA 가 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
144,144,144,train,1,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
145,145,145,train,1,PCA 는 왜 하는 거지 그러면?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
146,146,146,train,1,데이터 불균형이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
147,147,147,train,1,데이터 불균형 해결하는 법이 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.5
148,148,148,train,1,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.5
149,149,149,train,1,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
150,150,150,train,1,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.1
151,151,151,train,1,Undersampling 이랑 Oversampling 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
152,152,152,train,1,Undersampling 이 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
153,153,153,train,1,그럼 Oversampling 은 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
154,154,154,train,1,데이터 불균형을 고려한 성능지표를 추천해 줘!,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.1
155,155,155,train,1,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
156,156,156,train,1,Oversampling 방법은 어떤 게 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.25
157,157,157,train,1,차원의 저주가 뭐지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
158,158,158,train,1,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.5
159,159,159,train,1,Decision Tree 가 뭔지 자세히 알고 싶어,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
160,160,160,train,1,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
161,161,161,train,1,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
162,162,162,train,1,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
163,163,163,train,1,앙상블을 왜 하는 거야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
164,164,164,train,1,앙상블 하는 구체적인 방법 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
165,165,165,train,1,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
166,166,166,train,1,보팅에 대해 자세히 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
167,167,167,train,1,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
168,168,168,train,1,보팅의 방법에는 구체적으로 뭐가 있지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
169,169,169,train,1,Bagging 이 뭔지 궁금해,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
170,170,170,train,1,그럼 Boosting 은 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
171,171,171,train,1,Stacking 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.25
172,172,172,train,1,Gaussian Mixture 모델이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
173,173,173,train,1,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
174,174,174,train,1,K-means Clustering 이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
175,175,175,train,1,K-means Clustering 의 방법을 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.5
176,176,176,train,1,kNN 에 대해 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
177,177,177,train,1,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
178,178,178,train,1,지도학습 비지도학습 이런 게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
179,179,179,train,1,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
180,180,180,train,1,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
181,181,181,train,1,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
182,182,182,train,1,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
183,183,183,train,1,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
184,184,184,train,1,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
185,185,185,train,1,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
186,186,186,train,1,서포트 벡터 머신이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
187,187,187,train,1,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
188,188,188,train,1,K-fold Cross Validation,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
189,189,189,train,1,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.5
190,190,190,train,1,하이퍼파라미터가 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
191,191,191,train,1,One-hot 방식이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
192,192,192,train,1,Valid 데이터가 굳이 왜 필요하지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.25
193,193,193,train,1,Train 데이터셋을 왜 순서를 섞어야 돼?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
194,194,194,train,1,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
195,195,195,train,1,인공지능이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.5
196,196,196,train,1,머신러닝은 그럼 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
197,197,197,train,1,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.25
198,198,198,train,1,딥러닝에서 학습률이 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.1
199,199,199,train,1,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
200,200,200,train,1,자주 쓰는 Loss Function 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
201,201,201,train,1,Overfitting 이 뭔지 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
202,202,202,train,1,Overfitting 해결하는 방법은 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.5
203,203,203,train,1,전이학습이 뭐지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
204,204,204,train,1,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
205,205,205,train,1,활성화 함수? 그게 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
206,206,206,train,1,활성화 함수는 왜 필요해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.5
207,207,207,train,1,CNN이 뭐야? 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
208,208,208,train,1,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
209,209,209,train,1,cosine similarity가 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
210,210,210,train,2,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
211,211,211,train,2,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
212,212,212,train,2,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
213,213,213,train,2,Accuracy 는 어떻게 계산해?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
214,214,214,train,2,True Positive 같은 건 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
215,215,215,train,2,True Negative 는?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
216,216,216,train,2,False Positive 는 뭐지 그럼?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
217,217,217,train,2,False Negative 는 뭐야 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
218,218,218,train,2,Recall 은 어떻게 계산해?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
219,219,219,train,2,Recall 은 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
220,220,220,train,2,Precision 은 어떻게 계산하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
221,221,221,train,2,Recall 과 Precision 이 자꾸 헷갈리네,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
222,222,222,train,2,F1 이 뭔지 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
223,223,223,train,2,F1 Score 구하는 수식을 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
224,224,224,train,2,F1 Score 장점이 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
225,225,225,train,2,IoU 가 뭔지 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
226,226,226,train,2,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
227,227,227,train,2,이진 분류에서 쓰이는 Metric 을 알려줘!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
228,228,228,train,2,PR-AUC랑 ROC-AUC가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
229,229,229,train,2,PR-AUC가 뭔지 자세히 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
230,230,230,train,2,ROC-AUC가 뭔지 아주 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
231,231,231,train,2,True Positive Rate 가 뭐야? 궁금해!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
232,232,232,train,2,False Positive Rate 는 뭐지 그러면?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
233,233,233,train,2,Confusion Matrix 가 뭐야?,True Positive Rate : recall 의 다른 이름,0.1
234,234,234,train,2,Confusion Matrix 만드는 법을 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
235,235,235,train,2,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.1
236,236,236,train,2,Normalization 이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
237,237,237,train,2,정규화가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
238,238,238,train,2,min-max 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
239,239,239,train,2,Z score normalization 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
240,240,240,train,2,Clipping 에 대해서 자세히 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
241,241,241,train,2,Clipping 을 하면 뭐가 좋아?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
242,242,242,train,2,로그 스케일링이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.25
243,243,243,train,2,Outlier 가 뭔지 궁금해,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
244,244,244,train,2,이상치가 뭔지 궁금해,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
245,245,245,train,2,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
246,246,246,train,2,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
247,247,247,train,2,PCA 가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
248,248,248,train,2,주성분 분석이 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
249,249,249,train,2,PCA 는 왜 하는 거지 그러면?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
250,250,250,train,2,데이터 불균형이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
251,251,251,train,2,데이터 불균형 해결하는 법이 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
252,252,252,train,2,데이터를 새로 추가하거나 제거하는 법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
253,253,253,train,2,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
254,254,254,train,2,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
255,255,255,train,2,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
256,256,256,train,2,Undersampling 이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
257,257,257,train,2,그럼 Oversampling 은 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.25
258,258,258,train,2,데이터 불균형을 고려한 성능지표를 추천해 줘!,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.1
259,259,259,train,2,Undersampling 하는 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
260,260,260,train,2,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
261,261,261,train,2,차원의 저주가 뭐지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
262,262,262,train,2,차원의 저주가 구체적으로 어떤 문제야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
263,263,263,train,2,Decision Tree 가 뭔지 자세히 알고 싶어,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
264,264,264,train,2,의사결정 나무,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
265,265,265,train,2,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
266,266,266,train,2,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
267,267,267,train,2,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
268,268,268,train,2,앙상블 하는 구체적인 방법 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
269,269,269,train,2,앙상블은 정확히 어떻게 하는 건지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
270,270,270,train,2,보팅에 대해 자세히 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
271,271,271,train,2,앙상블 중에 Voting 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
272,272,272,train,2,보팅의 방법에는 구체적으로 뭐가 있지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
273,273,273,train,2,Bagging 이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
274,274,274,train,2,그럼 Boosting 은 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
275,275,275,train,2,Stacking 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
276,276,276,train,2,Gaussian Mixture 모델이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
277,277,277,train,2,가우시안 혼합이 뭔지 궁금해,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
278,278,278,train,2,K-means Clustering 이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
279,279,279,train,2,K-means Clustering 의 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
280,280,280,train,2,kNN 에 대해 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
281,281,281,train,2,k Nearest Neighbor 알고리즘이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
282,282,282,train,2,지도학습 비지도학습 이런 게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
283,283,283,train,2,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
284,284,284,train,2,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
285,285,285,train,2,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
286,286,286,train,2,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
287,287,287,train,2,분류와 회귀 문제가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
288,288,288,train,2,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
289,289,289,train,2,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
290,290,290,train,2,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
291,291,291,train,2,SVM이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
292,292,292,train,2,K-fold Cross Validation,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
293,293,293,train,2,K-fold Cross Validation을 굳이 왜 하는 거야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
294,294,294,train,2,하이퍼파라미터가 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
295,295,295,train,2,One-hot 방식이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
296,296,296,train,2,Valid 데이터가 굳이 왜 필요하지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
297,297,297,train,2,Train 데이터셋을 왜 순서를 섞어야 돼?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
298,298,298,train,2,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
299,299,299,train,2,인공지능이 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
300,300,300,train,2,머신러닝은 그럼 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
301,301,301,train,2,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
302,302,302,train,2,딥러닝에서 학습률이 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
303,303,303,train,2,learning rate 가 뭔지 궁금해!,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
304,304,304,train,2,자주 쓰는 Loss Function 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
305,305,305,train,2,Overfitting 이 뭔지 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
306,306,306,train,2,Overfitting 해결하는 방법은 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
307,307,307,train,2,전이학습이 뭐지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
308,308,308,train,2,Transfer Learning 이 뭔지 궁금해!,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
309,309,309,train,2,활성화 함수? 그게 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
310,310,310,train,2,활성화 함수는 왜 필요해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
311,311,311,train,2,CNN이 뭐야? 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
312,312,312,train,2,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
313,313,313,train,2,cosine similarity가 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
314,314,314,train,2,코사인 유사도가 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
315,315,315,train,3,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
316,316,316,train,3,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
317,317,317,train,3,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
318,318,318,train,3,True Positive 같은 건 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
319,319,319,train,3,True Negative 는?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
320,320,320,train,3,False Positive 는 뭐지 그럼?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
321,321,321,train,3,False Negative 는 뭐야 그러면?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
322,322,322,train,3,Recall 은 어떻게 계산해?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
323,323,323,train,3,Recall 은 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
324,324,324,train,3,Precision 은 어떻게 계산하지,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
325,325,325,train,3,Recall 과 Precision 이 자꾸 헷갈리네,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.5
326,326,326,train,3,F1 이 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
327,327,327,train,3,F1 Score 구하는 수식을 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
328,328,328,train,3,F1 Score 장점이 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
329,329,329,train,3,IoU 가 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
330,330,330,train,3,특이도라는 걸 봤는데 그게 뭔지 궁금해!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
331,331,331,train,3,이진 분류에서 쓰이는 Metric 을 알려줘!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
332,332,332,train,3,PR-AUC랑 ROC-AUC가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
333,333,333,train,3,PR-AUC가 뭔지 자세히 알려줘!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
334,334,334,train,3,ROC-AUC가 뭔지 아주 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
335,335,335,train,3,True Positive Rate 가 뭐야? 궁금해!,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
336,336,336,train,3,False Positive Rate 는 뭐지 그러면?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
337,337,337,train,3,Confusion Matrix 가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
338,338,338,train,3,Confusion Matrix 만드는 법을 알려줘,True Positive Rate : recall 의 다른 이름,0.1
339,339,339,train,3,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
340,340,340,train,3,Normalization 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
341,341,341,train,3,정규화가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
342,342,342,train,3,min-max 정규화가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
343,343,343,train,3,Z score normalization 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
344,344,344,train,3,Clipping 에 대해서 자세히 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
345,345,345,train,3,Clipping 을 하면 뭐가 좋아?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
346,346,346,train,3,로그 스케일링이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
347,347,347,train,3,Outlier 가 뭔지 궁금해,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
348,348,348,train,3,이상치가 뭔지 궁금해,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
349,349,349,train,3,Outlier 를 제거해야 하는 이유는 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
350,350,350,train,3,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
351,351,351,train,3,PCA 가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
352,352,352,train,3,주성분 분석이 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
353,353,353,train,3,PCA 는 왜 하는 거지 그러면?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
354,354,354,train,3,데이터 불균형이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
355,355,355,train,3,데이터 불균형 해결하는 법이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
356,356,356,train,3,데이터를 새로 추가하거나 제거하는 법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
357,357,357,train,3,그러면 학습 환경만 바꾸는 방법은 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
358,358,358,train,3,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
359,359,359,train,3,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
360,360,360,train,3,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
361,361,361,train,3,그럼 Oversampling 은 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
362,362,362,train,3,데이터 불균형을 고려한 성능지표를 추천해 줘!,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.1
363,363,363,train,3,Undersampling 하는 방법 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
364,364,364,train,3,Oversampling 방법은 어떤 게 있어?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
365,365,365,train,3,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
366,366,366,train,3,차원의 저주가 구체적으로 어떤 문제야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
367,367,367,train,3,Decision Tree 가 뭔지 자세히 알고 싶어,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
368,368,368,train,3,의사결정 나무,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
369,369,369,train,3,Decision Tree 로 결정하는 방법은?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
370,370,370,train,3,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
371,371,371,train,3,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
372,372,372,train,3,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
373,373,373,train,3,앙상블은 정확히 어떻게 하는 건지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
374,374,374,train,3,보팅에 대해 자세히 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
375,375,375,train,3,앙상블 중에 Voting 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
376,376,376,train,3,보팅의 방법에는 구체적으로 뭐가 있지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
377,377,377,train,3,Bagging 이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
378,378,378,train,3,그럼 Boosting 은 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
379,379,379,train,3,Stacking 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
380,380,380,train,3,Gaussian Mixture 모델이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
381,381,381,train,3,가우시안 혼합이 뭔지 궁금해,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
382,382,382,train,3,K-means Clustering 이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
383,383,383,train,3,K-means Clustering 의 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
384,384,384,train,3,kNN 에 대해 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
385,385,385,train,3,k Nearest Neighbor 알고리즘이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
386,386,386,train,3,지도학습 비지도학습 이런 게 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
387,387,387,train,3,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
388,388,388,train,3,강화학습? 지도학습? 그게 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
389,389,389,train,3,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
390,390,390,train,3,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
391,391,391,train,3,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
392,392,392,train,3,Regression 이랑 Classification 이 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
393,393,393,train,3,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
394,394,394,train,3,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
395,395,395,train,3,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
396,396,396,train,3,K-fold Cross Validation,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
397,397,397,train,3,K-fold Cross Validation을 굳이 왜 하는 거야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
398,398,398,train,3,하이퍼파라미터가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
399,399,399,train,3,One-hot 방식이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
400,400,400,train,3,Valid 데이터가 굳이 왜 필요하지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
401,401,401,train,3,Train 데이터셋을 왜 순서를 섞어야 돼?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
402,402,402,train,3,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
403,403,403,train,3,인공지능이 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
404,404,404,train,3,머신러닝은 그럼 뭐지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
405,405,405,train,3,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
406,406,406,train,3,딥러닝에서 학습률이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
407,407,407,train,3,learning rate 가 뭔지 궁금해!,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
408,408,408,train,3,자주 쓰는 Loss Function 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
409,409,409,train,3,Overfitting 이 뭔지 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
410,410,410,train,3,Overfitting 해결하는 방법은 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
411,411,411,train,3,전이학습이 뭐지?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
412,412,412,train,3,Transfer Learning 이 뭔지 궁금해!,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
413,413,413,train,3,활성화 함수? 그게 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
414,414,414,train,3,활성화 함수는 왜 필요해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
415,415,415,train,3,CNN이 뭐야? 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
416,416,416,train,3,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
417,417,417,train,3,cosine similarity가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
418,418,418,train,3,코사인 유사도가 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
419,419,419,train,3,코사인 유사도 계산법 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
420,420,420,train,4,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
421,421,421,train,4,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
422,422,422,train,4,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
423,423,423,train,4,True Negative 는?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
424,424,424,train,4,False Positive 는 뭐지 그럼?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
425,425,425,train,4,False Negative 는 뭐야 그러면?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
426,426,426,train,4,Recall 은 어떻게 계산해?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
427,427,427,train,4,Recall 은 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
428,428,428,train,4,Precision 은 어떻게 계산하지,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
429,429,429,train,4,Recall 과 Precision 이 자꾸 헷갈리네,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
430,430,430,train,4,F1 이 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
431,431,431,train,4,F1 Score 구하는 수식을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
432,432,432,train,4,F1 Score 장점이 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
433,433,433,train,4,IoU 가 뭔지 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
434,434,434,train,4,특이도라는 걸 봤는데 그게 뭔지 궁금해!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
435,435,435,train,4,이진 분류에서 쓰이는 Metric 을 알려줘!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
436,436,436,train,4,PR-AUC랑 ROC-AUC가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
437,437,437,train,4,PR-AUC가 뭔지 자세히 알려줘!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
438,438,438,train,4,ROC-AUC가 뭔지 아주 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
439,439,439,train,4,True Positive Rate 가 뭐야? 궁금해!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
440,440,440,train,4,False Positive Rate 는 뭐지 그러면?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
441,441,441,train,4,Confusion Matrix 가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
442,442,442,train,4,Confusion Matrix 만드는 법을 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
443,443,443,train,4,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",True Positive Rate : recall 의 다른 이름,0.25
444,444,444,train,4,Normalization 이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
445,445,445,train,4,정규화가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
446,446,446,train,4,min-max 정규화가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
447,447,447,train,4,Z score normalization 이 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
448,448,448,train,4,Clipping 에 대해서 자세히 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
449,449,449,train,4,Clipping 을 하면 뭐가 좋아?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
450,450,450,train,4,로그 스케일링이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
451,451,451,train,4,Outlier 가 뭔지 궁금해,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
452,452,452,train,4,이상치가 뭔지 궁금해,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
453,453,453,train,4,Outlier 를 제거해야 하는 이유는 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
454,454,454,train,4,Outlier 를 제거하는 방법에 대해 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
455,455,455,train,4,PCA 가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
456,456,456,train,4,주성분 분석이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
457,457,457,train,4,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
458,458,458,train,4,데이터 불균형이 뭔지 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
459,459,459,train,4,데이터 불균형 해결하는 법이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
460,460,460,train,4,데이터를 새로 추가하거나 제거하는 법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
461,461,461,train,4,그러면 학습 환경만 바꾸는 방법은 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
462,462,462,train,4,Augmentation 이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
463,463,463,train,4,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
464,464,464,train,4,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
465,465,465,train,4,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
466,466,466,train,4,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
467,467,467,train,4,Undersampling 하는 방법 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
468,468,468,train,4,Oversampling 방법은 어떤 게 있어?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
469,469,469,train,4,차원의 저주가 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
470,470,470,train,4,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
471,471,471,train,4,Decision Tree 가 뭔지 자세히 알고 싶어,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
472,472,472,train,4,의사결정 나무,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
473,473,473,train,4,Decision Tree 로 결정하는 방법은?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
474,474,474,train,4,앙상블이 뭔지 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
475,475,475,train,4,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
476,476,476,train,4,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
477,477,477,train,4,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
478,478,478,train,4,보팅에 대해 자세히 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
479,479,479,train,4,앙상블 중에 Voting 이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
480,480,480,train,4,보팅의 방법에는 구체적으로 뭐가 있지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
481,481,481,train,4,Bagging 이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
482,482,482,train,4,그럼 Boosting 은 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
483,483,483,train,4,Stacking 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
484,484,484,train,4,Gaussian Mixture 모델이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
485,485,485,train,4,가우시안 혼합이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
486,486,486,train,4,K-means Clustering 이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
487,487,487,train,4,K-means Clustering 의 방법을 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
488,488,488,train,4,kNN 에 대해 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
489,489,489,train,4,k Nearest Neighbor 알고리즘이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
490,490,490,train,4,지도학습 비지도학습 이런 게 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
491,491,491,train,4,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
492,492,492,train,4,강화학습? 지도학습? 그게 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
493,493,493,train,4,지도학습과 비지도학습의 차이가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
494,494,494,train,4,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
495,495,495,train,4,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
496,496,496,train,4,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
497,497,497,train,4,Naïve Bayes 가 뭔지 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
498,498,498,train,4,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
499,499,499,train,4,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
500,500,500,train,4,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
501,501,501,train,4,K-fold Cross Validation을 굳이 왜 하는 거야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
502,502,502,train,4,하이퍼파라미터가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
503,503,503,train,4,One-hot 방식이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
504,504,504,train,4,Valid 데이터가 굳이 왜 필요하지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
505,505,505,train,4,Train 데이터셋을 왜 순서를 섞어야 돼?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
506,506,506,train,4,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
507,507,507,train,4,인공지능이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
508,508,508,train,4,머신러닝은 그럼 뭐지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
509,509,509,train,4,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
510,510,510,train,4,딥러닝에서 학습률이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.1
511,511,511,train,4,learning rate 가 뭔지 궁금해!,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
512,512,512,train,4,자주 쓰는 Loss Function 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
513,513,513,train,4,Overfitting 이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
514,514,514,train,4,Overfitting 해결하는 방법은 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
515,515,515,train,4,전이학습이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
516,516,516,train,4,Transfer Learning 이 뭔지 궁금해!,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
517,517,517,train,4,활성화 함수? 그게 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
518,518,518,train,4,활성화 함수는 왜 필요해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
519,519,519,train,4,CNN이 뭐야? 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
520,520,520,train,4,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
521,521,521,train,4,cosine similarity가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
522,522,522,train,4,코사인 유사도가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
523,523,523,train,4,코사인 유사도 계산법 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
524,524,524,train,4,코사인 유사도의 특징을 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
525,525,525,train,5,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
526,526,526,train,5,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
527,527,527,train,5,True Negative 는?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
528,528,528,train,5,False Positive 는 뭐지 그럼?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
529,529,529,train,5,False Negative 는 뭐야 그러면?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
530,530,530,train,5,Recall 은 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
531,531,531,train,5,Recall 은 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
532,532,532,train,5,Precision 은 어떻게 계산하지,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
533,533,533,train,5,Recall 과 Precision 이 자꾸 헷갈리네,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
534,534,534,train,5,F1 이 뭔지 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
535,535,535,train,5,F1 Score 구하는 수식을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
536,536,536,train,5,F1 Score 장점이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
537,537,537,train,5,IoU 가 뭔지 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
538,538,538,train,5,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
539,539,539,train,5,이진 분류에서 쓰이는 Metric 을 알려줘!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
540,540,540,train,5,PR-AUC랑 ROC-AUC가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
541,541,541,train,5,PR-AUC가 뭔지 자세히 알려줘!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
542,542,542,train,5,ROC-AUC가 뭔지 아주 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
543,543,543,train,5,True Positive Rate 가 뭐야? 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
544,544,544,train,5,False Positive Rate 는 뭐지 그러면?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
545,545,545,train,5,Confusion Matrix 가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.1
546,546,546,train,5,Confusion Matrix 만드는 법을 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
547,547,547,train,5,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
548,548,548,train,5,Normalization 이 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
549,549,549,train,5,정규화가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
550,550,550,train,5,min-max 정규화가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
551,551,551,train,5,Z score normalization 이 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
552,552,552,train,5,Clipping 에 대해서 자세히 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
553,553,553,train,5,Clipping 을 하면 뭐가 좋아?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
554,554,554,train,5,로그 스케일링이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
555,555,555,train,5,Outlier 가 뭔지 궁금해,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
556,556,556,train,5,이상치가 뭔지 궁금해,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
557,557,557,train,5,Outlier 를 제거해야 하는 이유는 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
558,558,558,train,5,Outlier 를 제거하는 방법에 대해 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
559,559,559,train,5,PCA 가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
560,560,560,train,5,주성분 분석이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
561,561,561,train,5,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
562,562,562,train,5,데이터 불균형이 뭔지 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
563,563,563,train,5,데이터 불균형 해결하는 법이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
564,564,564,train,5,데이터를 새로 추가하거나 제거하는 법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
565,565,565,train,5,그러면 학습 환경만 바꾸는 방법은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
566,566,566,train,5,Augmentation 이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
567,567,567,train,5,Undersampling 이랑 Oversampling 이 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
568,568,568,train,5,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
569,569,569,train,5,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
570,570,570,train,5,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.5
571,571,571,train,5,Undersampling 하는 방법 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
572,572,572,train,5,Oversampling 방법은 어떤 게 있어?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.25
573,573,573,train,5,차원의 저주가 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
574,574,574,train,5,차원의 저주가 구체적으로 어떤 문제야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
575,575,575,train,5,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
576,576,576,train,5,의사결정 나무,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
577,577,577,train,5,Decision Tree 로 결정하는 방법은?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
578,578,578,train,5,앙상블이 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
579,579,579,train,5,앙상블을 왜 하는 거야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
580,580,580,train,5,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
581,581,581,train,5,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
582,582,582,train,5,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
583,583,583,train,5,앙상블 중에 Voting 이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
584,584,584,train,5,보팅의 방법에는 구체적으로 뭐가 있지?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
585,585,585,train,5,Bagging 이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
586,586,586,train,5,그럼 Boosting 은 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
587,587,587,train,5,Stacking 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
588,588,588,train,5,Gaussian Mixture 모델이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
589,589,589,train,5,가우시안 혼합이 뭔지 궁금해,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
590,590,590,train,5,K-means Clustering 이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
591,591,591,train,5,K-means Clustering 의 방법을 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
592,592,592,train,5,kNN 에 대해 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
593,593,593,train,5,k Nearest Neighbor 알고리즘이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
594,594,594,train,5,지도학습 비지도학습 이런 게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
595,595,595,train,5,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
596,596,596,train,5,강화학습? 지도학습? 그게 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
597,597,597,train,5,지도학습과 비지도학습의 차이가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
598,598,598,train,5,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
599,599,599,train,5,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
600,600,600,train,5,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
601,601,601,train,5,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
602,602,602,train,5,서포트 벡터 머신이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
603,603,603,train,5,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
604,604,604,train,5,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
605,605,605,train,5,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
606,606,606,train,5,하이퍼파라미터가 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
607,607,607,train,5,One-hot 방식이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
608,608,608,train,5,Valid 데이터가 굳이 왜 필요하지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
609,609,609,train,5,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
610,610,610,train,5,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
611,611,611,train,5,인공지능이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
612,612,612,train,5,머신러닝은 그럼 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
613,613,613,train,5,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
614,614,614,train,5,딥러닝에서 학습률이 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
615,615,615,train,5,learning rate 가 뭔지 궁금해!,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
616,616,616,train,5,자주 쓰는 Loss Function 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
617,617,617,train,5,Overfitting 이 뭔지 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
618,618,618,train,5,Overfitting 해결하는 방법은 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
619,619,619,train,5,전이학습이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
620,620,620,train,5,Transfer Learning 이 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
621,621,621,train,5,활성화 함수? 그게 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
622,622,622,train,5,활성화 함수는 왜 필요해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
623,623,623,train,5,CNN이 뭐야? 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
624,624,624,train,5,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
625,625,625,train,5,cosine similarity가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
626,626,626,train,5,코사인 유사도가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
627,627,627,train,5,코사인 유사도 계산법 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
628,628,628,train,5,코사인 유사도의 특징을 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
629,629,629,train,5,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
630,630,630,train,6,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
631,631,631,train,6,True Negative 는?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
632,632,632,train,6,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
633,633,633,train,6,False Negative 는 뭐야 그러면?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
634,634,634,train,6,Recall 은 어떻게 계산해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
635,635,635,train,6,Recall 은 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
636,636,636,train,6,Precision 은 어떻게 계산하지,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
637,637,637,train,6,Recall 과 Precision 이 자꾸 헷갈리네,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
638,638,638,train,6,F1 이 뭔지 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
639,639,639,train,6,F1 Score 구하는 수식을 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
640,640,640,train,6,F1 Score 장점이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
641,641,641,train,6,IoU 가 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
642,642,642,train,6,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
643,643,643,train,6,이진 분류에서 쓰이는 Metric 을 알려줘!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
644,644,644,train,6,PR-AUC랑 ROC-AUC가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
645,645,645,train,6,PR-AUC가 뭔지 자세히 알려줘!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
646,646,646,train,6,ROC-AUC가 뭔지 아주 자세히 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
647,647,647,train,6,True Positive Rate 가 뭐야? 궁금해!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
648,648,648,train,6,False Positive Rate 는 뭐지 그러면?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
649,649,649,train,6,Confusion Matrix 가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.1
650,650,650,train,6,Confusion Matrix 만드는 법을 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.1
651,651,651,train,6,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
652,652,652,train,6,Normalization 이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
653,653,653,train,6,정규화가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
654,654,654,train,6,min-max 정규화가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
655,655,655,train,6,Z score normalization 이 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
656,656,656,train,6,Clipping 에 대해서 자세히 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
657,657,657,train,6,Clipping 을 하면 뭐가 좋아?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
658,658,658,train,6,로그 스케일링이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
659,659,659,train,6,Outlier 가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
660,660,660,train,6,이상치가 뭔지 궁금해,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
661,661,661,train,6,Outlier 를 제거해야 하는 이유는 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
662,662,662,train,6,Outlier 를 제거하는 방법에 대해 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
663,663,663,train,6,PCA 가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
664,664,664,train,6,주성분 분석이 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
665,665,665,train,6,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
666,666,666,train,6,데이터 불균형이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
667,667,667,train,6,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
668,668,668,train,6,데이터를 새로 추가하거나 제거하는 법 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
669,669,669,train,6,그러면 학습 환경만 바꾸는 방법은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
670,670,670,train,6,Augmentation 이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
671,671,671,train,6,Undersampling 이랑 Oversampling 이 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
672,672,672,train,6,Undersampling 이 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
673,673,673,train,6,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
674,674,674,train,6,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.5
675,675,675,train,6,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
676,676,676,train,6,Oversampling 방법은 어떤 게 있어?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.25
677,677,677,train,6,차원의 저주가 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
678,678,678,train,6,차원의 저주가 구체적으로 어떤 문제야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
679,679,679,train,6,Decision Tree 가 뭔지 자세히 알고 싶어,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
680,680,680,train,6,의사결정 나무,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
681,681,681,train,6,Decision Tree 로 결정하는 방법은?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
682,682,682,train,6,앙상블이 뭔지 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
683,683,683,train,6,앙상블을 왜 하는 거야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
684,684,684,train,6,앙상블 하는 구체적인 방법 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
685,685,685,train,6,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
686,686,686,train,6,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
687,687,687,train,6,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
688,688,688,train,6,보팅의 방법에는 구체적으로 뭐가 있지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
689,689,689,train,6,Bagging 이 뭔지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
690,690,690,train,6,그럼 Boosting 은 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
691,691,691,train,6,Stacking 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
692,692,692,train,6,Gaussian Mixture 모델이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
693,693,693,train,6,가우시안 혼합이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
694,694,694,train,6,K-means Clustering 이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
695,695,695,train,6,K-means Clustering 의 방법을 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
696,696,696,train,6,kNN 에 대해 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
697,697,697,train,6,k Nearest Neighbor 알고리즘이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
698,698,698,train,6,지도학습 비지도학습 이런 게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
699,699,699,train,6,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
700,700,700,train,6,강화학습? 지도학습? 그게 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
701,701,701,train,6,지도학습과 비지도학습의 차이가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
702,702,702,train,6,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
703,703,703,train,6,분류와 회귀 문제가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
704,704,704,train,6,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
705,705,705,train,6,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
706,706,706,train,6,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
707,707,707,train,6,SVM이 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
708,708,708,train,6,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
709,709,709,train,6,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
710,710,710,train,6,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
711,711,711,train,6,One-hot 방식이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
712,712,712,train,6,Valid 데이터가 굳이 왜 필요하지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
713,713,713,train,6,Train 데이터셋을 왜 순서를 섞어야 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
714,714,714,train,6,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
715,715,715,train,6,인공지능이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
716,716,716,train,6,머신러닝은 그럼 뭐지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
717,717,717,train,6,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
718,718,718,train,6,딥러닝에서 학습률이 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
719,719,719,train,6,learning rate 가 뭔지 궁금해!,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
720,720,720,train,6,자주 쓰는 Loss Function 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
721,721,721,train,6,Overfitting 이 뭔지 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
722,722,722,train,6,Overfitting 해결하는 방법은 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
723,723,723,train,6,전이학습이 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.1
724,724,724,train,6,Transfer Learning 이 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
725,725,725,train,6,활성화 함수? 그게 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
726,726,726,train,6,활성화 함수는 왜 필요해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
727,727,727,train,6,CNN이 뭐야? 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
728,728,728,train,6,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
729,729,729,train,6,cosine similarity가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
730,730,730,train,6,코사인 유사도가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
731,731,731,train,6,코사인 유사도 계산법 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
732,732,732,train,6,코사인 유사도의 특징을 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
733,733,733,train,6,머신러닝에서 많이 쓰이는 평가지표 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
734,734,734,train,6,Accuracy 는 어떻게 계산해?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
735,735,735,train,7,True Negative 는?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
736,736,736,train,7,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
737,737,737,train,7,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
738,738,738,train,7,Recall 은 어떻게 계산해?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
739,739,739,train,7,Recall 은 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
740,740,740,train,7,Precision 은 어떻게 계산하지,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
741,741,741,train,7,Recall 과 Precision 이 자꾸 헷갈리네,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
742,742,742,train,7,F1 이 뭔지 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
743,743,743,train,7,F1 Score 구하는 수식을 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
744,744,744,train,7,F1 Score 장점이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
745,745,745,train,7,IoU 가 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
746,746,746,train,7,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
747,747,747,train,7,이진 분류에서 쓰이는 Metric 을 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
748,748,748,train,7,PR-AUC랑 ROC-AUC가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
749,749,749,train,7,PR-AUC가 뭔지 자세히 알려줘!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
750,750,750,train,7,ROC-AUC가 뭔지 아주 자세히 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
751,751,751,train,7,True Positive Rate 가 뭐야? 궁금해!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
752,752,752,train,7,False Positive Rate 는 뭐지 그러면?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
753,753,753,train,7,Confusion Matrix 가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.1
754,754,754,train,7,Confusion Matrix 만드는 법을 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.1
755,755,755,train,7,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
756,756,756,train,7,Normalization 이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
757,757,757,train,7,정규화가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
758,758,758,train,7,min-max 정규화가 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
759,759,759,train,7,Z score normalization 이 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
760,760,760,train,7,Clipping 에 대해서 자세히 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
761,761,761,train,7,Clipping 을 하면 뭐가 좋아?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
762,762,762,train,7,로그 스케일링이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
763,763,763,train,7,Outlier 가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
764,764,764,train,7,이상치가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
765,765,765,train,7,Outlier 를 제거해야 하는 이유는 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
766,766,766,train,7,Outlier 를 제거하는 방법에 대해 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
767,767,767,train,7,PCA 가 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
768,768,768,train,7,주성분 분석이 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
769,769,769,train,7,PCA 는 왜 하는 거지 그러면?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
770,770,770,train,7,데이터 불균형이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
771,771,771,train,7,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
772,772,772,train,7,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
773,773,773,train,7,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
774,774,774,train,7,Augmentation 이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
775,775,775,train,7,Undersampling 이랑 Oversampling 이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
776,776,776,train,7,Undersampling 이 뭐지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
777,777,777,train,7,그럼 Oversampling 은 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
778,778,778,train,7,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
779,779,779,train,7,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
780,780,780,train,7,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
781,781,781,train,7,차원의 저주가 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
782,782,782,train,7,차원의 저주가 구체적으로 어떤 문제야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
783,783,783,train,7,Decision Tree 가 뭔지 자세히 알고 싶어,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
784,784,784,train,7,의사결정 나무,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
785,785,785,train,7,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
786,786,786,train,7,앙상블이 뭔지 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
787,787,787,train,7,앙상블을 왜 하는 거야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
788,788,788,train,7,앙상블 하는 구체적인 방법 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
789,789,789,train,7,앙상블은 정확히 어떻게 하는 건지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
790,790,790,train,7,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
791,791,791,train,7,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
792,792,792,train,7,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
793,793,793,train,7,Bagging 이 뭔지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
794,794,794,train,7,그럼 Boosting 은 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
795,795,795,train,7,Stacking 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.5
796,796,796,train,7,Gaussian Mixture 모델이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
797,797,797,train,7,가우시안 혼합이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
798,798,798,train,7,K-means Clustering 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
799,799,799,train,7,K-means Clustering 의 방법을 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
800,800,800,train,7,kNN 에 대해 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
801,801,801,train,7,k Nearest Neighbor 알고리즘이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
802,802,802,train,7,지도학습 비지도학습 이런 게 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
803,803,803,train,7,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
804,804,804,train,7,강화학습? 지도학습? 그게 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
805,805,805,train,7,지도학습과 비지도학습의 차이가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
806,806,806,train,7,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
807,807,807,train,7,분류와 회귀 문제가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
808,808,808,train,7,Regression 이랑 Classification 이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
809,809,809,train,7,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
810,810,810,train,7,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
811,811,811,train,7,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
812,812,812,train,7,K-fold Cross Validation,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
813,813,813,train,7,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
814,814,814,train,7,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
815,815,815,train,7,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
816,816,816,train,7,Valid 데이터가 굳이 왜 필요하지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
817,817,817,train,7,Train 데이터셋을 왜 순서를 섞어야 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
818,818,818,train,7,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
819,819,819,train,7,인공지능이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
820,820,820,train,7,머신러닝은 그럼 뭐지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
821,821,821,train,7,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
822,822,822,train,7,딥러닝에서 학습률이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
823,823,823,train,7,learning rate 가 뭔지 궁금해!,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
824,824,824,train,7,자주 쓰는 Loss Function 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
825,825,825,train,7,Overfitting 이 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
826,826,826,train,7,Overfitting 해결하는 방법은 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
827,827,827,train,7,전이학습이 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.1
828,828,828,train,7,Transfer Learning 이 뭔지 궁금해!,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
829,829,829,train,7,활성화 함수? 그게 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
830,830,830,train,7,활성화 함수는 왜 필요해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
831,831,831,train,7,CNN이 뭐야? 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
832,832,832,train,7,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
833,833,833,train,7,cosine similarity가 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
834,834,834,train,7,코사인 유사도가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
835,835,835,train,7,코사인 유사도 계산법 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
836,836,836,train,7,코사인 유사도의 특징을 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
837,837,837,train,7,머신러닝에서 많이 쓰이는 평가지표 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
838,838,838,train,7,Accuracy 는 어떻게 계산해?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
839,839,839,train,7,True Positive 같은 건 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
840,840,840,train,8,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
841,841,841,train,8,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
842,842,842,train,8,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
843,843,843,train,8,Recall 은 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
844,844,844,train,8,Precision 은 어떻게 계산하지,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
845,845,845,train,8,Recall 과 Precision 이 자꾸 헷갈리네,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
846,846,846,train,8,F1 이 뭔지 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
847,847,847,train,8,F1 Score 구하는 수식을 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
848,848,848,train,8,F1 Score 장점이 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
849,849,849,train,8,IoU 가 뭔지 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
850,850,850,train,8,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
851,851,851,train,8,이진 분류에서 쓰이는 Metric 을 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
852,852,852,train,8,PR-AUC랑 ROC-AUC가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
853,853,853,train,8,PR-AUC가 뭔지 자세히 알려줘!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
854,854,854,train,8,ROC-AUC가 뭔지 아주 자세히 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
855,855,855,train,8,True Positive Rate 가 뭐야? 궁금해!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
856,856,856,train,8,False Positive Rate 는 뭐지 그러면?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
857,857,857,train,8,Confusion Matrix 가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.1
858,858,858,train,8,Confusion Matrix 만드는 법을 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.1
859,859,859,train,8,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
860,860,860,train,8,Normalization 이 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
861,861,861,train,8,정규화가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
862,862,862,train,8,min-max 정규화가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
863,863,863,train,8,Z score normalization 이 뭐지?,True Positive Rate : recall 의 다른 이름,0.0
864,864,864,train,8,Clipping 에 대해서 자세히 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
865,865,865,train,8,Clipping 을 하면 뭐가 좋아?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
866,866,866,train,8,로그 스케일링이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
867,867,867,train,8,Outlier 가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
868,868,868,train,8,이상치가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
869,869,869,train,8,Outlier 를 제거해야 하는 이유는 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
870,870,870,train,8,Outlier 를 제거하는 방법에 대해 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
871,871,871,train,8,PCA 가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
872,872,872,train,8,주성분 분석이 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
873,873,873,train,8,PCA 는 왜 하는 거지 그러면?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
874,874,874,train,8,데이터 불균형이 뭔지 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
875,875,875,train,8,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
876,876,876,train,8,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
877,877,877,train,8,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
878,878,878,train,8,Augmentation 이 뭔지 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
879,879,879,train,8,Undersampling 이랑 Oversampling 이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
880,880,880,train,8,Undersampling 이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
881,881,881,train,8,그럼 Oversampling 은 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
882,882,882,train,8,데이터 불균형을 고려한 성능지표를 추천해 줘!,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
883,883,883,train,8,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
884,884,884,train,8,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
885,885,885,train,8,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
886,886,886,train,8,차원의 저주가 구체적으로 어떤 문제야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
887,887,887,train,8,Decision Tree 가 뭔지 자세히 알고 싶어,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
888,888,888,train,8,의사결정 나무,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
889,889,889,train,8,Decision Tree 로 결정하는 방법은?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
890,890,890,train,8,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
891,891,891,train,8,앙상블을 왜 하는 거야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
892,892,892,train,8,앙상블 하는 구체적인 방법 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
893,893,893,train,8,앙상블은 정확히 어떻게 하는 건지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
894,894,894,train,8,보팅에 대해 자세히 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
895,895,895,train,8,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
896,896,896,train,8,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
897,897,897,train,8,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
898,898,898,train,8,그럼 Boosting 은 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
899,899,899,train,8,Stacking 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
900,900,900,train,8,Gaussian Mixture 모델이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
901,901,901,train,8,가우시안 혼합이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
902,902,902,train,8,K-means Clustering 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
903,903,903,train,8,K-means Clustering 의 방법을 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
904,904,904,train,8,kNN 에 대해 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
905,905,905,train,8,k Nearest Neighbor 알고리즘이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
906,906,906,train,8,지도학습 비지도학습 이런 게 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
907,907,907,train,8,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
908,908,908,train,8,강화학습? 지도학습? 그게 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
909,909,909,train,8,지도학습과 비지도학습의 차이가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
910,910,910,train,8,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
911,911,911,train,8,분류와 회귀 문제가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
912,912,912,train,8,Regression 이랑 Classification 이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
913,913,913,train,8,Naïve Bayes 가 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
914,914,914,train,8,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
915,915,915,train,8,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
916,916,916,train,8,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
917,917,917,train,8,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
918,918,918,train,8,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
919,919,919,train,8,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
920,920,920,train,8,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
921,921,921,train,8,Train 데이터셋을 왜 순서를 섞어야 돼?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
922,922,922,train,8,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
923,923,923,train,8,인공지능이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
924,924,924,train,8,머신러닝은 그럼 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
925,925,925,train,8,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
926,926,926,train,8,딥러닝에서 학습률이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
927,927,927,train,8,learning rate 가 뭔지 궁금해!,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
928,928,928,train,8,자주 쓰는 Loss Function 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
929,929,929,train,8,Overfitting 이 뭔지 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
930,930,930,train,8,Overfitting 해결하는 방법은 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
931,931,931,train,8,전이학습이 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.1
932,932,932,train,8,Transfer Learning 이 뭔지 궁금해!,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
933,933,933,train,8,활성화 함수? 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
934,934,934,train,8,활성화 함수는 왜 필요해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
935,935,935,train,8,CNN이 뭐야? 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
936,936,936,train,8,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
937,937,937,train,8,cosine similarity가 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
938,938,938,train,8,코사인 유사도가 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
939,939,939,train,8,코사인 유사도 계산법 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
940,940,940,train,8,코사인 유사도의 특징을 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
941,941,941,train,8,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
942,942,942,train,8,Accuracy 는 어떻게 계산해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
943,943,943,train,8,True Positive 같은 건 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
944,944,944,train,8,True Negative 는?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
945,945,945,train,9,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
946,946,946,train,9,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
947,947,947,train,9,Recall 은 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
948,948,948,train,9,Precision 은 어떻게 계산하지,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
949,949,949,train,9,Recall 과 Precision 이 자꾸 헷갈리네,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
950,950,950,train,9,F1 이 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
951,951,951,train,9,F1 Score 구하는 수식을 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
952,952,952,train,9,F1 Score 장점이 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
953,953,953,train,9,IoU 가 뭔지 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
954,954,954,train,9,특이도라는 걸 봤는데 그게 뭔지 궁금해!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
955,955,955,train,9,이진 분류에서 쓰이는 Metric 을 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
956,956,956,train,9,PR-AUC랑 ROC-AUC가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
957,957,957,train,9,PR-AUC가 뭔지 자세히 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
958,958,958,train,9,ROC-AUC가 뭔지 아주 자세히 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
959,959,959,train,9,True Positive Rate 가 뭐야? 궁금해!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
960,960,960,train,9,False Positive Rate 는 뭐지 그러면?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
961,961,961,train,9,Confusion Matrix 가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.1
962,962,962,train,9,Confusion Matrix 만드는 법을 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.1
963,963,963,train,9,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
964,964,964,train,9,Normalization 이 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
965,965,965,train,9,정규화가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
966,966,966,train,9,min-max 정규화가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
967,967,967,train,9,Z score normalization 이 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
968,968,968,train,9,Clipping 에 대해서 자세히 알려줘,True Positive Rate : recall 의 다른 이름,0.0
969,969,969,train,9,Clipping 을 하면 뭐가 좋아?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
970,970,970,train,9,로그 스케일링이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
971,971,971,train,9,Outlier 가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
972,972,972,train,9,이상치가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
973,973,973,train,9,Outlier 를 제거해야 하는 이유는 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
974,974,974,train,9,Outlier 를 제거하는 방법에 대해 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
975,975,975,train,9,PCA 가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
976,976,976,train,9,주성분 분석이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
977,977,977,train,9,PCA 는 왜 하는 거지 그러면?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
978,978,978,train,9,데이터 불균형이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
979,979,979,train,9,데이터 불균형 해결하는 법이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
980,980,980,train,9,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
981,981,981,train,9,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
982,982,982,train,9,Augmentation 이 뭔지 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
983,983,983,train,9,Undersampling 이랑 Oversampling 이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
984,984,984,train,9,Undersampling 이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
985,985,985,train,9,그럼 Oversampling 은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
986,986,986,train,9,데이터 불균형을 고려한 성능지표를 추천해 줘!,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
987,987,987,train,9,Undersampling 하는 방법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
988,988,988,train,9,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
989,989,989,train,9,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
990,990,990,train,9,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
991,991,991,train,9,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
992,992,992,train,9,의사결정 나무,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
993,993,993,train,9,Decision Tree 로 결정하는 방법은?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
994,994,994,train,9,앙상블이 뭔지 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
995,995,995,train,9,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
996,996,996,train,9,앙상블 하는 구체적인 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
997,997,997,train,9,앙상블은 정확히 어떻게 하는 건지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
998,998,998,train,9,보팅에 대해 자세히 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
999,999,999,train,9,앙상블 중에 Voting 이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1000,1000,1000,train,9,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1001,1001,1001,train,9,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1002,1002,1002,train,9,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1003,1003,1003,train,9,Stacking 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
1004,1004,1004,train,9,Gaussian Mixture 모델이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1005,1005,1005,train,9,가우시안 혼합이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1006,1006,1006,train,9,K-means Clustering 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1007,1007,1007,train,9,K-means Clustering 의 방법을 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1008,1008,1008,train,9,kNN 에 대해 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1009,1009,1009,train,9,k Nearest Neighbor 알고리즘이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1010,1010,1010,train,9,지도학습 비지도학습 이런 게 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1011,1011,1011,train,9,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1012,1012,1012,train,9,강화학습? 지도학습? 그게 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1013,1013,1013,train,9,지도학습과 비지도학습의 차이가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1014,1014,1014,train,9,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1015,1015,1015,train,9,분류와 회귀 문제가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1016,1016,1016,train,9,Regression 이랑 Classification 이 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1017,1017,1017,train,9,Naïve Bayes 가 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1018,1018,1018,train,9,서포트 벡터 머신이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1019,1019,1019,train,9,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1020,1020,1020,train,9,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1021,1021,1021,train,9,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1022,1022,1022,train,9,하이퍼파라미터가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1023,1023,1023,train,9,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1024,1024,1024,train,9,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1025,1025,1025,train,9,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1026,1026,1026,train,9,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1027,1027,1027,train,9,인공지능이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1028,1028,1028,train,9,머신러닝은 그럼 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1029,1029,1029,train,9,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1030,1030,1030,train,9,딥러닝에서 학습률이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1031,1031,1031,train,9,learning rate 가 뭔지 궁금해!,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.1
1032,1032,1032,train,9,자주 쓰는 Loss Function 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1033,1033,1033,train,9,Overfitting 이 뭔지 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1034,1034,1034,train,9,Overfitting 해결하는 방법은 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1035,1035,1035,train,9,전이학습이 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1036,1036,1036,train,9,Transfer Learning 이 뭔지 궁금해!,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1037,1037,1037,train,9,활성화 함수? 그게 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1038,1038,1038,train,9,활성화 함수는 왜 필요해?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1039,1039,1039,train,9,CNN이 뭐야? 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1040,1040,1040,train,9,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1041,1041,1041,train,9,cosine similarity가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1042,1042,1042,train,9,코사인 유사도가 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1043,1043,1043,train,9,코사인 유사도 계산법 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1044,1044,1044,train,9,코사인 유사도의 특징을 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1045,1045,1045,train,9,머신러닝에서 많이 쓰이는 평가지표 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1046,1046,1046,train,9,Accuracy 는 어떻게 계산해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1047,1047,1047,train,9,True Positive 같은 건 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1048,1048,1048,train,9,True Negative 는?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1049,1049,1049,train,9,False Positive 는 뭐지 그럼?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1050,1050,1050,train,10,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1051,1051,1051,train,10,Recall 은 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1052,1052,1052,train,10,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1053,1053,1053,train,10,Recall 과 Precision 이 자꾸 헷갈리네,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1054,1054,1054,train,10,F1 이 뭔지 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1055,1055,1055,train,10,F1 Score 구하는 수식을 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1056,1056,1056,train,10,F1 Score 장점이 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1057,1057,1057,train,10,IoU 가 뭔지 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1058,1058,1058,train,10,특이도라는 걸 봤는데 그게 뭔지 궁금해!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1059,1059,1059,train,10,이진 분류에서 쓰이는 Metric 을 알려줘!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1060,1060,1060,train,10,PR-AUC랑 ROC-AUC가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1061,1061,1061,train,10,PR-AUC가 뭔지 자세히 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1062,1062,1062,train,10,ROC-AUC가 뭔지 아주 자세히 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1063,1063,1063,train,10,True Positive Rate 가 뭐야? 궁금해!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
1064,1064,1064,train,10,False Positive Rate 는 뭐지 그러면?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
1065,1065,1065,train,10,Confusion Matrix 가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.1
1066,1066,1066,train,10,Confusion Matrix 만드는 법을 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.1
1067,1067,1067,train,10,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
1068,1068,1068,train,10,Normalization 이 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1069,1069,1069,train,10,정규화가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1070,1070,1070,train,10,min-max 정규화가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1071,1071,1071,train,10,Z score normalization 이 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1072,1072,1072,train,10,Clipping 에 대해서 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1073,1073,1073,train,10,Clipping 을 하면 뭐가 좋아?,True Positive Rate : recall 의 다른 이름,0.0
1074,1074,1074,train,10,로그 스케일링이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1075,1075,1075,train,10,Outlier 가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1076,1076,1076,train,10,이상치가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1077,1077,1077,train,10,Outlier 를 제거해야 하는 이유는 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1078,1078,1078,train,10,Outlier 를 제거하는 방법에 대해 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1079,1079,1079,train,10,PCA 가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1080,1080,1080,train,10,주성분 분석이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1081,1081,1081,train,10,PCA 는 왜 하는 거지 그러면?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1082,1082,1082,train,10,데이터 불균형이 뭔지 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1083,1083,1083,train,10,데이터 불균형 해결하는 법이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1084,1084,1084,train,10,데이터를 새로 추가하거나 제거하는 법 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1085,1085,1085,train,10,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1086,1086,1086,train,10,Augmentation 이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1087,1087,1087,train,10,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1088,1088,1088,train,10,Undersampling 이 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1089,1089,1089,train,10,그럼 Oversampling 은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1090,1090,1090,train,10,데이터 불균형을 고려한 성능지표를 추천해 줘!,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1091,1091,1091,train,10,Undersampling 하는 방법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1092,1092,1092,train,10,Oversampling 방법은 어떤 게 있어?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
1093,1093,1093,train,10,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1094,1094,1094,train,10,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1095,1095,1095,train,10,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1096,1096,1096,train,10,의사결정 나무,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1097,1097,1097,train,10,Decision Tree 로 결정하는 방법은?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1098,1098,1098,train,10,앙상블이 뭔지 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1099,1099,1099,train,10,앙상블을 왜 하는 거야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1100,1100,1100,train,10,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1101,1101,1101,train,10,앙상블은 정확히 어떻게 하는 건지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1102,1102,1102,train,10,보팅에 대해 자세히 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1103,1103,1103,train,10,앙상블 중에 Voting 이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1104,1104,1104,train,10,보팅의 방법에는 구체적으로 뭐가 있지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1105,1105,1105,train,10,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1106,1106,1106,train,10,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1107,1107,1107,train,10,Stacking 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1108,1108,1108,train,10,Gaussian Mixture 모델이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1109,1109,1109,train,10,가우시안 혼합이 뭔지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1110,1110,1110,train,10,K-means Clustering 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1111,1111,1111,train,10,K-means Clustering 의 방법을 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1112,1112,1112,train,10,kNN 에 대해 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1113,1113,1113,train,10,k Nearest Neighbor 알고리즘이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1114,1114,1114,train,10,지도학습 비지도학습 이런 게 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1115,1115,1115,train,10,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1116,1116,1116,train,10,강화학습? 지도학습? 그게 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1117,1117,1117,train,10,지도학습과 비지도학습의 차이가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1118,1118,1118,train,10,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1119,1119,1119,train,10,분류와 회귀 문제가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1120,1120,1120,train,10,Regression 이랑 Classification 이 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1121,1121,1121,train,10,Naïve Bayes 가 뭔지 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1122,1122,1122,train,10,서포트 벡터 머신이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1123,1123,1123,train,10,SVM이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1124,1124,1124,train,10,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1125,1125,1125,train,10,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1126,1126,1126,train,10,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1127,1127,1127,train,10,One-hot 방식이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1128,1128,1128,train,10,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1129,1129,1129,train,10,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1130,1130,1130,train,10,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1131,1131,1131,train,10,인공지능이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1132,1132,1132,train,10,머신러닝은 그럼 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1133,1133,1133,train,10,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1134,1134,1134,train,10,딥러닝에서 학습률이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1135,1135,1135,train,10,learning rate 가 뭔지 궁금해!,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1136,1136,1136,train,10,자주 쓰는 Loss Function 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1137,1137,1137,train,10,Overfitting 이 뭔지 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1138,1138,1138,train,10,Overfitting 해결하는 방법은 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1139,1139,1139,train,10,전이학습이 뭐지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1140,1140,1140,train,10,Transfer Learning 이 뭔지 궁금해!,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1141,1141,1141,train,10,활성화 함수? 그게 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1142,1142,1142,train,10,활성화 함수는 왜 필요해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1143,1143,1143,train,10,CNN이 뭐야? 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1144,1144,1144,train,10,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1145,1145,1145,train,10,cosine similarity가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1146,1146,1146,train,10,코사인 유사도가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1147,1147,1147,train,10,코사인 유사도 계산법 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1148,1148,1148,train,10,코사인 유사도의 특징을 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1149,1149,1149,train,10,머신러닝에서 많이 쓰이는 평가지표 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1150,1150,1150,train,10,Accuracy 는 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1151,1151,1151,train,10,True Positive 같은 건 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1152,1152,1152,train,10,True Negative 는?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1153,1153,1153,train,10,False Positive 는 뭐지 그럼?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1154,1154,1154,train,10,False Negative 는 뭐야 그러면?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1155,1155,1155,train,11,Recall 은 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1156,1156,1156,train,11,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1157,1157,1157,train,11,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1158,1158,1158,train,11,F1 이 뭔지 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1159,1159,1159,train,11,F1 Score 구하는 수식을 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1160,1160,1160,train,11,F1 Score 장점이 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1161,1161,1161,train,11,IoU 가 뭔지 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1162,1162,1162,train,11,특이도라는 걸 봤는데 그게 뭔지 궁금해!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1163,1163,1163,train,11,이진 분류에서 쓰이는 Metric 을 알려줘!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1164,1164,1164,train,11,PR-AUC랑 ROC-AUC가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1165,1165,1165,train,11,PR-AUC가 뭔지 자세히 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1166,1166,1166,train,11,ROC-AUC가 뭔지 아주 자세히 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1167,1167,1167,train,11,True Positive Rate 가 뭐야? 궁금해!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1168,1168,1168,train,11,False Positive Rate 는 뭐지 그러면?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
1169,1169,1169,train,11,Confusion Matrix 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.1
1170,1170,1170,train,11,Confusion Matrix 만드는 법을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.1
1171,1171,1171,train,11,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
1172,1172,1172,train,11,Normalization 이 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1173,1173,1173,train,11,정규화가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1174,1174,1174,train,11,min-max 정규화가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1175,1175,1175,train,11,Z score normalization 이 뭐지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1176,1176,1176,train,11,Clipping 에 대해서 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1177,1177,1177,train,11,Clipping 을 하면 뭐가 좋아?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1178,1178,1178,train,11,로그 스케일링이 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
1179,1179,1179,train,11,Outlier 가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1180,1180,1180,train,11,이상치가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1181,1181,1181,train,11,Outlier 를 제거해야 하는 이유는 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1182,1182,1182,train,11,Outlier 를 제거하는 방법에 대해 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1183,1183,1183,train,11,PCA 가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1184,1184,1184,train,11,주성분 분석이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1185,1185,1185,train,11,PCA 는 왜 하는 거지 그러면?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1186,1186,1186,train,11,데이터 불균형이 뭔지 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1187,1187,1187,train,11,데이터 불균형 해결하는 법이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1188,1188,1188,train,11,데이터를 새로 추가하거나 제거하는 법 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1189,1189,1189,train,11,그러면 학습 환경만 바꾸는 방법은 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1190,1190,1190,train,11,Augmentation 이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1191,1191,1191,train,11,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1192,1192,1192,train,11,Undersampling 이 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1193,1193,1193,train,11,그럼 Oversampling 은 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1194,1194,1194,train,11,데이터 불균형을 고려한 성능지표를 추천해 줘!,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1195,1195,1195,train,11,Undersampling 하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1196,1196,1196,train,11,Oversampling 방법은 어떤 게 있어?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1197,1197,1197,train,11,차원의 저주가 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1198,1198,1198,train,11,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1199,1199,1199,train,11,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1200,1200,1200,train,11,의사결정 나무,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1201,1201,1201,train,11,Decision Tree 로 결정하는 방법은?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1202,1202,1202,train,11,앙상블이 뭔지 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1203,1203,1203,train,11,앙상블을 왜 하는 거야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1204,1204,1204,train,11,앙상블 하는 구체적인 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1205,1205,1205,train,11,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1206,1206,1206,train,11,보팅에 대해 자세히 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1207,1207,1207,train,11,앙상블 중에 Voting 이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1208,1208,1208,train,11,보팅의 방법에는 구체적으로 뭐가 있지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1209,1209,1209,train,11,Bagging 이 뭔지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1210,1210,1210,train,11,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1211,1211,1211,train,11,Stacking 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1212,1212,1212,train,11,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1213,1213,1213,train,11,가우시안 혼합이 뭔지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1214,1214,1214,train,11,K-means Clustering 이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1215,1215,1215,train,11,K-means Clustering 의 방법을 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1216,1216,1216,train,11,kNN 에 대해 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1217,1217,1217,train,11,k Nearest Neighbor 알고리즘이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1218,1218,1218,train,11,지도학습 비지도학습 이런 게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1219,1219,1219,train,11,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1220,1220,1220,train,11,강화학습? 지도학습? 그게 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1221,1221,1221,train,11,지도학습과 비지도학습의 차이가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1222,1222,1222,train,11,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1223,1223,1223,train,11,분류와 회귀 문제가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1224,1224,1224,train,11,Regression 이랑 Classification 이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1225,1225,1225,train,11,Naïve Bayes 가 뭔지 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1226,1226,1226,train,11,서포트 벡터 머신이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1227,1227,1227,train,11,SVM이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1228,1228,1228,train,11,K-fold Cross Validation,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1229,1229,1229,train,11,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1230,1230,1230,train,11,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1231,1231,1231,train,11,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1232,1232,1232,train,11,Valid 데이터가 굳이 왜 필요하지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1233,1233,1233,train,11,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1234,1234,1234,train,11,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1235,1235,1235,train,11,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1236,1236,1236,train,11,머신러닝은 그럼 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1237,1237,1237,train,11,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1238,1238,1238,train,11,딥러닝에서 학습률이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1239,1239,1239,train,11,learning rate 가 뭔지 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1240,1240,1240,train,11,자주 쓰는 Loss Function 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1241,1241,1241,train,11,Overfitting 이 뭔지 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1242,1242,1242,train,11,Overfitting 해결하는 방법은 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1243,1243,1243,train,11,전이학습이 뭐지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1244,1244,1244,train,11,Transfer Learning 이 뭔지 궁금해!,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1245,1245,1245,train,11,활성화 함수? 그게 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1246,1246,1246,train,11,활성화 함수는 왜 필요해?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1247,1247,1247,train,11,CNN이 뭐야? 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1248,1248,1248,train,11,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1249,1249,1249,train,11,cosine similarity가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1250,1250,1250,train,11,코사인 유사도가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1251,1251,1251,train,11,코사인 유사도 계산법 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1252,1252,1252,train,11,코사인 유사도의 특징을 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1253,1253,1253,train,11,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1254,1254,1254,train,11,Accuracy 는 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1255,1255,1255,train,11,True Positive 같은 건 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1256,1256,1256,train,11,True Negative 는?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1257,1257,1257,train,11,False Positive 는 뭐지 그럼?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1258,1258,1258,train,11,False Negative 는 뭐야 그러면?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1259,1259,1259,train,11,Recall 은 어떻게 계산해?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1260,1260,1260,train,12,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1261,1261,1261,train,12,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1262,1262,1262,train,12,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1263,1263,1263,train,12,F1 Score 구하는 수식을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1264,1264,1264,train,12,F1 Score 장점이 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1265,1265,1265,train,12,IoU 가 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1266,1266,1266,train,12,특이도라는 걸 봤는데 그게 뭔지 궁금해!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1267,1267,1267,train,12,이진 분류에서 쓰이는 Metric 을 알려줘!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1268,1268,1268,train,12,PR-AUC랑 ROC-AUC가 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1269,1269,1269,train,12,PR-AUC가 뭔지 자세히 알려줘!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1270,1270,1270,train,12,ROC-AUC가 뭔지 아주 자세히 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1271,1271,1271,train,12,True Positive Rate 가 뭐야? 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1272,1272,1272,train,12,False Positive Rate 는 뭐지 그러면?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1273,1273,1273,train,12,Confusion Matrix 가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.1
1274,1274,1274,train,12,Confusion Matrix 만드는 법을 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.1
1275,1275,1275,train,12,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
1276,1276,1276,train,12,Normalization 이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1277,1277,1277,train,12,정규화가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1278,1278,1278,train,12,min-max 정규화가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1279,1279,1279,train,12,Z score normalization 이 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1280,1280,1280,train,12,Clipping 에 대해서 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1281,1281,1281,train,12,Clipping 을 하면 뭐가 좋아?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1282,1282,1282,train,12,로그 스케일링이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1283,1283,1283,train,12,Outlier 가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
1284,1284,1284,train,12,이상치가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1285,1285,1285,train,12,Outlier 를 제거해야 하는 이유는 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1286,1286,1286,train,12,Outlier 를 제거하는 방법에 대해 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1287,1287,1287,train,12,PCA 가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1288,1288,1288,train,12,주성분 분석이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1289,1289,1289,train,12,PCA 는 왜 하는 거지 그러면?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1290,1290,1290,train,12,데이터 불균형이 뭔지 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1291,1291,1291,train,12,데이터 불균형 해결하는 법이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1292,1292,1292,train,12,데이터를 새로 추가하거나 제거하는 법 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1293,1293,1293,train,12,그러면 학습 환경만 바꾸는 방법은 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1294,1294,1294,train,12,Augmentation 이 뭔지 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1295,1295,1295,train,12,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1296,1296,1296,train,12,Undersampling 이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1297,1297,1297,train,12,그럼 Oversampling 은 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1298,1298,1298,train,12,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1299,1299,1299,train,12,Undersampling 하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1300,1300,1300,train,12,Oversampling 방법은 어떤 게 있어?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1301,1301,1301,train,12,차원의 저주가 뭐지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1302,1302,1302,train,12,차원의 저주가 구체적으로 어떤 문제야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1303,1303,1303,train,12,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1304,1304,1304,train,12,의사결정 나무,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1305,1305,1305,train,12,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1306,1306,1306,train,12,앙상블이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1307,1307,1307,train,12,앙상블을 왜 하는 거야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1308,1308,1308,train,12,앙상블 하는 구체적인 방법 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1309,1309,1309,train,12,앙상블은 정확히 어떻게 하는 건지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1310,1310,1310,train,12,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1311,1311,1311,train,12,앙상블 중에 Voting 이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1312,1312,1312,train,12,보팅의 방법에는 구체적으로 뭐가 있지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1313,1313,1313,train,12,Bagging 이 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1314,1314,1314,train,12,그럼 Boosting 은 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1315,1315,1315,train,12,Stacking 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1316,1316,1316,train,12,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1317,1317,1317,train,12,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1318,1318,1318,train,12,K-means Clustering 이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1319,1319,1319,train,12,K-means Clustering 의 방법을 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1320,1320,1320,train,12,kNN 에 대해 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1321,1321,1321,train,12,k Nearest Neighbor 알고리즘이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1322,1322,1322,train,12,지도학습 비지도학습 이런 게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1323,1323,1323,train,12,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1324,1324,1324,train,12,강화학습? 지도학습? 그게 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1325,1325,1325,train,12,지도학습과 비지도학습의 차이가 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1326,1326,1326,train,12,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1327,1327,1327,train,12,분류와 회귀 문제가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1328,1328,1328,train,12,Regression 이랑 Classification 이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1329,1329,1329,train,12,Naïve Bayes 가 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1330,1330,1330,train,12,서포트 벡터 머신이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1331,1331,1331,train,12,SVM이 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1332,1332,1332,train,12,K-fold Cross Validation,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1333,1333,1333,train,12,K-fold Cross Validation을 굳이 왜 하는 거야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1334,1334,1334,train,12,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1335,1335,1335,train,12,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1336,1336,1336,train,12,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1337,1337,1337,train,12,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1338,1338,1338,train,12,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1339,1339,1339,train,12,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1340,1340,1340,train,12,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.1
1341,1341,1341,train,12,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1342,1342,1342,train,12,딥러닝에서 학습률이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1343,1343,1343,train,12,learning rate 가 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1344,1344,1344,train,12,자주 쓰는 Loss Function 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1345,1345,1345,train,12,Overfitting 이 뭔지 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1346,1346,1346,train,12,Overfitting 해결하는 방법은 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1347,1347,1347,train,12,전이학습이 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1348,1348,1348,train,12,Transfer Learning 이 뭔지 궁금해!,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1349,1349,1349,train,12,활성화 함수? 그게 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1350,1350,1350,train,12,활성화 함수는 왜 필요해?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1351,1351,1351,train,12,CNN이 뭐야? 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1352,1352,1352,train,12,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1353,1353,1353,train,12,cosine similarity가 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1354,1354,1354,train,12,코사인 유사도가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1355,1355,1355,train,12,코사인 유사도 계산법 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1356,1356,1356,train,12,코사인 유사도의 특징을 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1357,1357,1357,train,12,머신러닝에서 많이 쓰이는 평가지표 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1358,1358,1358,train,12,Accuracy 는 어떻게 계산해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1359,1359,1359,train,12,True Positive 같은 건 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1360,1360,1360,train,12,True Negative 는?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1361,1361,1361,train,12,False Positive 는 뭐지 그럼?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1362,1362,1362,train,12,False Negative 는 뭐야 그러면?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1363,1363,1363,train,12,Recall 은 어떻게 계산해?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1364,1364,1364,train,12,Recall 은 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1365,1365,1365,train,13,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1366,1366,1366,train,13,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1367,1367,1367,train,13,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1368,1368,1368,train,13,F1 Score 장점이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1369,1369,1369,train,13,IoU 가 뭔지 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1370,1370,1370,train,13,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1371,1371,1371,train,13,이진 분류에서 쓰이는 Metric 을 알려줘!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1372,1372,1372,train,13,PR-AUC랑 ROC-AUC가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1373,1373,1373,train,13,PR-AUC가 뭔지 자세히 알려줘!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1374,1374,1374,train,13,ROC-AUC가 뭔지 아주 자세히 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1375,1375,1375,train,13,True Positive Rate 가 뭐야? 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1376,1376,1376,train,13,False Positive Rate 는 뭐지 그러면?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1377,1377,1377,train,13,Confusion Matrix 가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.1
1378,1378,1378,train,13,Confusion Matrix 만드는 법을 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.1
1379,1379,1379,train,13,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
1380,1380,1380,train,13,Normalization 이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1381,1381,1381,train,13,정규화가 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1382,1382,1382,train,13,min-max 정규화가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1383,1383,1383,train,13,Z score normalization 이 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1384,1384,1384,train,13,Clipping 에 대해서 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1385,1385,1385,train,13,Clipping 을 하면 뭐가 좋아?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1386,1386,1386,train,13,로그 스케일링이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1387,1387,1387,train,13,Outlier 가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1388,1388,1388,train,13,이상치가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
1389,1389,1389,train,13,Outlier 를 제거해야 하는 이유는 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1390,1390,1390,train,13,Outlier 를 제거하는 방법에 대해 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1391,1391,1391,train,13,PCA 가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1392,1392,1392,train,13,주성분 분석이 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1393,1393,1393,train,13,PCA 는 왜 하는 거지 그러면?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1394,1394,1394,train,13,데이터 불균형이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1395,1395,1395,train,13,데이터 불균형 해결하는 법이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1396,1396,1396,train,13,데이터를 새로 추가하거나 제거하는 법 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1397,1397,1397,train,13,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1398,1398,1398,train,13,Augmentation 이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1399,1399,1399,train,13,Undersampling 이랑 Oversampling 이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1400,1400,1400,train,13,Undersampling 이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1401,1401,1401,train,13,그럼 Oversampling 은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1402,1402,1402,train,13,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1403,1403,1403,train,13,Undersampling 하는 방법 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1404,1404,1404,train,13,Oversampling 방법은 어떤 게 있어?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1405,1405,1405,train,13,차원의 저주가 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1406,1406,1406,train,13,차원의 저주가 구체적으로 어떤 문제야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1407,1407,1407,train,13,Decision Tree 가 뭔지 자세히 알고 싶어,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1408,1408,1408,train,13,의사결정 나무,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1409,1409,1409,train,13,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1410,1410,1410,train,13,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1411,1411,1411,train,13,앙상블을 왜 하는 거야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1412,1412,1412,train,13,앙상블 하는 구체적인 방법 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1413,1413,1413,train,13,앙상블은 정확히 어떻게 하는 건지 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1414,1414,1414,train,13,보팅에 대해 자세히 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1415,1415,1415,train,13,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1416,1416,1416,train,13,보팅의 방법에는 구체적으로 뭐가 있지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1417,1417,1417,train,13,Bagging 이 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1418,1418,1418,train,13,그럼 Boosting 은 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1419,1419,1419,train,13,Stacking 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1420,1420,1420,train,13,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1421,1421,1421,train,13,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1422,1422,1422,train,13,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1423,1423,1423,train,13,K-means Clustering 의 방법을 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1424,1424,1424,train,13,kNN 에 대해 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1425,1425,1425,train,13,k Nearest Neighbor 알고리즘이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1426,1426,1426,train,13,지도학습 비지도학습 이런 게 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1427,1427,1427,train,13,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1428,1428,1428,train,13,강화학습? 지도학습? 그게 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1429,1429,1429,train,13,지도학습과 비지도학습의 차이가 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1430,1430,1430,train,13,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1431,1431,1431,train,13,분류와 회귀 문제가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1432,1432,1432,train,13,Regression 이랑 Classification 이 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1433,1433,1433,train,13,Naïve Bayes 가 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1434,1434,1434,train,13,서포트 벡터 머신이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1435,1435,1435,train,13,SVM이 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1436,1436,1436,train,13,K-fold Cross Validation,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1437,1437,1437,train,13,K-fold Cross Validation을 굳이 왜 하는 거야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1438,1438,1438,train,13,하이퍼파라미터가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1439,1439,1439,train,13,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1440,1440,1440,train,13,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1441,1441,1441,train,13,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1442,1442,1442,train,13,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1443,1443,1443,train,13,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1444,1444,1444,train,13,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.1
1445,1445,1445,train,13,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1446,1446,1446,train,13,딥러닝에서 학습률이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1447,1447,1447,train,13,learning rate 가 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1448,1448,1448,train,13,자주 쓰는 Loss Function 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1449,1449,1449,train,13,Overfitting 이 뭔지 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1450,1450,1450,train,13,Overfitting 해결하는 방법은 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1451,1451,1451,train,13,전이학습이 뭐지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1452,1452,1452,train,13,Transfer Learning 이 뭔지 궁금해!,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1453,1453,1453,train,13,활성화 함수? 그게 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1454,1454,1454,train,13,활성화 함수는 왜 필요해?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1455,1455,1455,train,13,CNN이 뭐야? 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1456,1456,1456,train,13,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1457,1457,1457,train,13,cosine similarity가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1458,1458,1458,train,13,코사인 유사도가 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1459,1459,1459,train,13,코사인 유사도 계산법 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1460,1460,1460,train,13,코사인 유사도의 특징을 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1461,1461,1461,train,13,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1462,1462,1462,train,13,Accuracy 는 어떻게 계산해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1463,1463,1463,train,13,True Positive 같은 건 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1464,1464,1464,train,13,True Negative 는?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1465,1465,1465,train,13,False Positive 는 뭐지 그럼?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1466,1466,1466,train,13,False Negative 는 뭐야 그러면?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1467,1467,1467,train,13,Recall 은 어떻게 계산해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1468,1468,1468,train,13,Recall 은 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1469,1469,1469,train,13,Precision 은 어떻게 계산하지,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1470,1470,1470,train,14,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1471,1471,1471,train,14,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1472,1472,1472,train,14,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1473,1473,1473,train,14,IoU 가 뭔지 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1474,1474,1474,train,14,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1475,1475,1475,train,14,이진 분류에서 쓰이는 Metric 을 알려줘!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1476,1476,1476,train,14,PR-AUC랑 ROC-AUC가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1477,1477,1477,train,14,PR-AUC가 뭔지 자세히 알려줘!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1478,1478,1478,train,14,ROC-AUC가 뭔지 아주 자세히 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1479,1479,1479,train,14,True Positive Rate 가 뭐야? 궁금해!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1480,1480,1480,train,14,False Positive Rate 는 뭐지 그러면?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1481,1481,1481,train,14,Confusion Matrix 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1482,1482,1482,train,14,Confusion Matrix 만드는 법을 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.1
1483,1483,1483,train,14,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
1484,1484,1484,train,14,Normalization 이 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1485,1485,1485,train,14,정규화가 뭔지 궁금해,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1486,1486,1486,train,14,min-max 정규화가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1487,1487,1487,train,14,Z score normalization 이 뭐지?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1488,1488,1488,train,14,Clipping 에 대해서 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1489,1489,1489,train,14,Clipping 을 하면 뭐가 좋아?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1490,1490,1490,train,14,로그 스케일링이 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1491,1491,1491,train,14,Outlier 가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1492,1492,1492,train,14,이상치가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1493,1493,1493,train,14,Outlier 를 제거해야 하는 이유는 뭐지?,True Positive Rate : recall 의 다른 이름,0.0
1494,1494,1494,train,14,Outlier 를 제거하는 방법에 대해 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1495,1495,1495,train,14,PCA 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1496,1496,1496,train,14,주성분 분석이 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1497,1497,1497,train,14,PCA 는 왜 하는 거지 그러면?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1498,1498,1498,train,14,데이터 불균형이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1499,1499,1499,train,14,데이터 불균형 해결하는 법이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1500,1500,1500,train,14,데이터를 새로 추가하거나 제거하는 법 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1501,1501,1501,train,14,그러면 학습 환경만 바꾸는 방법은 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1502,1502,1502,train,14,Augmentation 이 뭔지 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1503,1503,1503,train,14,Undersampling 이랑 Oversampling 이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1504,1504,1504,train,14,Undersampling 이 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1505,1505,1505,train,14,그럼 Oversampling 은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1506,1506,1506,train,14,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1507,1507,1507,train,14,Undersampling 하는 방법 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1508,1508,1508,train,14,Oversampling 방법은 어떤 게 있어?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1509,1509,1509,train,14,차원의 저주가 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1510,1510,1510,train,14,차원의 저주가 구체적으로 어떤 문제야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1511,1511,1511,train,14,Decision Tree 가 뭔지 자세히 알고 싶어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1512,1512,1512,train,14,의사결정 나무,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1513,1513,1513,train,14,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1514,1514,1514,train,14,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1515,1515,1515,train,14,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1516,1516,1516,train,14,앙상블 하는 구체적인 방법 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1517,1517,1517,train,14,앙상블은 정확히 어떻게 하는 건지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1518,1518,1518,train,14,보팅에 대해 자세히 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1519,1519,1519,train,14,앙상블 중에 Voting 이 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1520,1520,1520,train,14,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1521,1521,1521,train,14,Bagging 이 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1522,1522,1522,train,14,그럼 Boosting 은 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1523,1523,1523,train,14,Stacking 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1524,1524,1524,train,14,Gaussian Mixture 모델이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1525,1525,1525,train,14,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1526,1526,1526,train,14,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1527,1527,1527,train,14,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1528,1528,1528,train,14,kNN 에 대해 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1529,1529,1529,train,14,k Nearest Neighbor 알고리즘이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1530,1530,1530,train,14,지도학습 비지도학습 이런 게 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1531,1531,1531,train,14,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1532,1532,1532,train,14,강화학습? 지도학습? 그게 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1533,1533,1533,train,14,지도학습과 비지도학습의 차이가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1534,1534,1534,train,14,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1535,1535,1535,train,14,분류와 회귀 문제가 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1536,1536,1536,train,14,Regression 이랑 Classification 이 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1537,1537,1537,train,14,Naïve Bayes 가 뭔지 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1538,1538,1538,train,14,서포트 벡터 머신이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1539,1539,1539,train,14,SVM이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1540,1540,1540,train,14,K-fold Cross Validation,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1541,1541,1541,train,14,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1542,1542,1542,train,14,하이퍼파라미터가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1543,1543,1543,train,14,One-hot 방식이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1544,1544,1544,train,14,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1545,1545,1545,train,14,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1546,1546,1546,train,14,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1547,1547,1547,train,14,인공지능이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.1
1548,1548,1548,train,14,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.1
1549,1549,1549,train,14,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1550,1550,1550,train,14,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1551,1551,1551,train,14,learning rate 가 뭔지 궁금해!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1552,1552,1552,train,14,자주 쓰는 Loss Function 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1553,1553,1553,train,14,Overfitting 이 뭔지 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1554,1554,1554,train,14,Overfitting 해결하는 방법은 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1555,1555,1555,train,14,전이학습이 뭐지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1556,1556,1556,train,14,Transfer Learning 이 뭔지 궁금해!,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1557,1557,1557,train,14,활성화 함수? 그게 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1558,1558,1558,train,14,활성화 함수는 왜 필요해?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1559,1559,1559,train,14,CNN이 뭐야? 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1560,1560,1560,train,14,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1561,1561,1561,train,14,cosine similarity가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1562,1562,1562,train,14,코사인 유사도가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1563,1563,1563,train,14,코사인 유사도 계산법 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1564,1564,1564,train,14,코사인 유사도의 특징을 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1565,1565,1565,train,14,머신러닝에서 많이 쓰이는 평가지표 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1566,1566,1566,train,14,Accuracy 는 어떻게 계산해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1567,1567,1567,train,14,True Positive 같은 건 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1568,1568,1568,train,14,True Negative 는?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1569,1569,1569,train,14,False Positive 는 뭐지 그럼?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1570,1570,1570,train,14,False Negative 는 뭐야 그러면?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1571,1571,1571,train,14,Recall 은 어떻게 계산해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1572,1572,1572,train,14,Recall 은 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1573,1573,1573,train,14,Precision 은 어떻게 계산하지,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1574,1574,1574,train,14,Recall 과 Precision 이 자꾸 헷갈리네,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1575,1575,1575,train,15,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1576,1576,1576,train,15,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1577,1577,1577,train,15,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1578,1578,1578,train,15,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1579,1579,1579,train,15,이진 분류에서 쓰이는 Metric 을 알려줘!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1580,1580,1580,train,15,PR-AUC랑 ROC-AUC가 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1581,1581,1581,train,15,PR-AUC가 뭔지 자세히 알려줘!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1582,1582,1582,train,15,ROC-AUC가 뭔지 아주 자세히 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1583,1583,1583,train,15,True Positive Rate 가 뭐야? 궁금해!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1584,1584,1584,train,15,False Positive Rate 는 뭐지 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1585,1585,1585,train,15,Confusion Matrix 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1586,1586,1586,train,15,Confusion Matrix 만드는 법을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1587,1587,1587,train,15,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1588,1588,1588,train,15,Normalization 이 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1589,1589,1589,train,15,정규화가 뭔지 궁금해,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1590,1590,1590,train,15,min-max 정규화가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1591,1591,1591,train,15,Z score normalization 이 뭐지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1592,1592,1592,train,15,Clipping 에 대해서 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1593,1593,1593,train,15,Clipping 을 하면 뭐가 좋아?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1594,1594,1594,train,15,로그 스케일링이 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1595,1595,1595,train,15,Outlier 가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1596,1596,1596,train,15,이상치가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1597,1597,1597,train,15,Outlier 를 제거해야 하는 이유는 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1598,1598,1598,train,15,Outlier 를 제거하는 방법에 대해 알려줘,True Positive Rate : recall 의 다른 이름,0.0
1599,1599,1599,train,15,PCA 가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1600,1600,1600,train,15,주성분 분석이 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1601,1601,1601,train,15,PCA 는 왜 하는 거지 그러면?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1602,1602,1602,train,15,데이터 불균형이 뭔지 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1603,1603,1603,train,15,데이터 불균형 해결하는 법이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1604,1604,1604,train,15,데이터를 새로 추가하거나 제거하는 법 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1605,1605,1605,train,15,그러면 학습 환경만 바꾸는 방법은 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1606,1606,1606,train,15,Augmentation 이 뭔지 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1607,1607,1607,train,15,Undersampling 이랑 Oversampling 이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1608,1608,1608,train,15,Undersampling 이 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1609,1609,1609,train,15,그럼 Oversampling 은 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1610,1610,1610,train,15,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1611,1611,1611,train,15,Undersampling 하는 방법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1612,1612,1612,train,15,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1613,1613,1613,train,15,차원의 저주가 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1614,1614,1614,train,15,차원의 저주가 구체적으로 어떤 문제야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1615,1615,1615,train,15,Decision Tree 가 뭔지 자세히 알고 싶어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1616,1616,1616,train,15,의사결정 나무,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1617,1617,1617,train,15,Decision Tree 로 결정하는 방법은?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1618,1618,1618,train,15,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1619,1619,1619,train,15,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1620,1620,1620,train,15,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1621,1621,1621,train,15,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1622,1622,1622,train,15,보팅에 대해 자세히 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1623,1623,1623,train,15,앙상블 중에 Voting 이 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1624,1624,1624,train,15,보팅의 방법에는 구체적으로 뭐가 있지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1625,1625,1625,train,15,Bagging 이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1626,1626,1626,train,15,그럼 Boosting 은 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1627,1627,1627,train,15,Stacking 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1628,1628,1628,train,15,Gaussian Mixture 모델이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1629,1629,1629,train,15,가우시안 혼합이 뭔지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1630,1630,1630,train,15,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1631,1631,1631,train,15,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1632,1632,1632,train,15,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1633,1633,1633,train,15,k Nearest Neighbor 알고리즘이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1634,1634,1634,train,15,지도학습 비지도학습 이런 게 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1635,1635,1635,train,15,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1636,1636,1636,train,15,강화학습? 지도학습? 그게 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1637,1637,1637,train,15,지도학습과 비지도학습의 차이가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1638,1638,1638,train,15,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1639,1639,1639,train,15,분류와 회귀 문제가 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1640,1640,1640,train,15,Regression 이랑 Classification 이 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1641,1641,1641,train,15,Naïve Bayes 가 뭔지 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1642,1642,1642,train,15,서포트 벡터 머신이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1643,1643,1643,train,15,SVM이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1644,1644,1644,train,15,K-fold Cross Validation,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1645,1645,1645,train,15,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1646,1646,1646,train,15,하이퍼파라미터가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1647,1647,1647,train,15,One-hot 방식이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1648,1648,1648,train,15,Valid 데이터가 굳이 왜 필요하지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1649,1649,1649,train,15,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1650,1650,1650,train,15,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1651,1651,1651,train,15,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1652,1652,1652,train,15,머신러닝은 그럼 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.1
1653,1653,1653,train,15,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1654,1654,1654,train,15,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1655,1655,1655,train,15,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1656,1656,1656,train,15,자주 쓰는 Loss Function 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1657,1657,1657,train,15,Overfitting 이 뭔지 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1658,1658,1658,train,15,Overfitting 해결하는 방법은 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1659,1659,1659,train,15,전이학습이 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1660,1660,1660,train,15,Transfer Learning 이 뭔지 궁금해!,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1661,1661,1661,train,15,활성화 함수? 그게 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1662,1662,1662,train,15,활성화 함수는 왜 필요해?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1663,1663,1663,train,15,CNN이 뭐야? 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1664,1664,1664,train,15,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1665,1665,1665,train,15,cosine similarity가 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1666,1666,1666,train,15,코사인 유사도가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1667,1667,1667,train,15,코사인 유사도 계산법 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1668,1668,1668,train,15,코사인 유사도의 특징을 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1669,1669,1669,train,15,머신러닝에서 많이 쓰이는 평가지표 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1670,1670,1670,train,15,Accuracy 는 어떻게 계산해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1671,1671,1671,train,15,True Positive 같은 건 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1672,1672,1672,train,15,True Negative 는?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1673,1673,1673,train,15,False Positive 는 뭐지 그럼?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1674,1674,1674,train,15,False Negative 는 뭐야 그러면?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1675,1675,1675,train,15,Recall 은 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1676,1676,1676,train,15,Recall 은 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1677,1677,1677,train,15,Precision 은 어떻게 계산하지,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1678,1678,1678,train,15,Recall 과 Precision 이 자꾸 헷갈리네,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1679,1679,1679,train,15,F1 이 뭔지 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1680,1680,1680,train,16,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1681,1681,1681,train,16,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1682,1682,1682,train,16,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1683,1683,1683,train,16,이진 분류에서 쓰이는 Metric 을 알려줘!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1684,1684,1684,train,16,PR-AUC랑 ROC-AUC가 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1685,1685,1685,train,16,PR-AUC가 뭔지 자세히 알려줘!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1686,1686,1686,train,16,ROC-AUC가 뭔지 아주 자세히 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1687,1687,1687,train,16,True Positive Rate 가 뭐야? 궁금해!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1688,1688,1688,train,16,False Positive Rate 는 뭐지 그러면?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1689,1689,1689,train,16,Confusion Matrix 가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.1
1690,1690,1690,train,16,Confusion Matrix 만드는 법을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1691,1691,1691,train,16,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1692,1692,1692,train,16,Normalization 이 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
1693,1693,1693,train,16,정규화가 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1694,1694,1694,train,16,min-max 정규화가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1695,1695,1695,train,16,Z score normalization 이 뭐지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1696,1696,1696,train,16,Clipping 에 대해서 자세히 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1697,1697,1697,train,16,Clipping 을 하면 뭐가 좋아?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1698,1698,1698,train,16,로그 스케일링이 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1699,1699,1699,train,16,Outlier 가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1700,1700,1700,train,16,이상치가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1701,1701,1701,train,16,Outlier 를 제거해야 하는 이유는 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1702,1702,1702,train,16,Outlier 를 제거하는 방법에 대해 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1703,1703,1703,train,16,PCA 가 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
1704,1704,1704,train,16,주성분 분석이 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1705,1705,1705,train,16,PCA 는 왜 하는 거지 그러면?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1706,1706,1706,train,16,데이터 불균형이 뭔지 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1707,1707,1707,train,16,데이터 불균형 해결하는 법이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1708,1708,1708,train,16,데이터를 새로 추가하거나 제거하는 법 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1709,1709,1709,train,16,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1710,1710,1710,train,16,Augmentation 이 뭔지 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1711,1711,1711,train,16,Undersampling 이랑 Oversampling 이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1712,1712,1712,train,16,Undersampling 이 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1713,1713,1713,train,16,그럼 Oversampling 은 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1714,1714,1714,train,16,데이터 불균형을 고려한 성능지표를 추천해 줘!,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1715,1715,1715,train,16,Undersampling 하는 방법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1716,1716,1716,train,16,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1717,1717,1717,train,16,차원의 저주가 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1718,1718,1718,train,16,차원의 저주가 구체적으로 어떤 문제야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1719,1719,1719,train,16,Decision Tree 가 뭔지 자세히 알고 싶어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1720,1720,1720,train,16,의사결정 나무,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1721,1721,1721,train,16,Decision Tree 로 결정하는 방법은?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1722,1722,1722,train,16,앙상블이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1723,1723,1723,train,16,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1724,1724,1724,train,16,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1725,1725,1725,train,16,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1726,1726,1726,train,16,보팅에 대해 자세히 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1727,1727,1727,train,16,앙상블 중에 Voting 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1728,1728,1728,train,16,보팅의 방법에는 구체적으로 뭐가 있지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1729,1729,1729,train,16,Bagging 이 뭔지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1730,1730,1730,train,16,그럼 Boosting 은 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1731,1731,1731,train,16,Stacking 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1732,1732,1732,train,16,Gaussian Mixture 모델이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1733,1733,1733,train,16,가우시안 혼합이 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1734,1734,1734,train,16,K-means Clustering 이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1735,1735,1735,train,16,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1736,1736,1736,train,16,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1737,1737,1737,train,16,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1738,1738,1738,train,16,지도학습 비지도학습 이런 게 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1739,1739,1739,train,16,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1740,1740,1740,train,16,강화학습? 지도학습? 그게 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1741,1741,1741,train,16,지도학습과 비지도학습의 차이가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1742,1742,1742,train,16,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1743,1743,1743,train,16,분류와 회귀 문제가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1744,1744,1744,train,16,Regression 이랑 Classification 이 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1745,1745,1745,train,16,Naïve Bayes 가 뭔지 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1746,1746,1746,train,16,서포트 벡터 머신이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1747,1747,1747,train,16,SVM이 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1748,1748,1748,train,16,K-fold Cross Validation,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1749,1749,1749,train,16,K-fold Cross Validation을 굳이 왜 하는 거야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1750,1750,1750,train,16,하이퍼파라미터가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1751,1751,1751,train,16,One-hot 방식이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1752,1752,1752,train,16,Valid 데이터가 굳이 왜 필요하지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1753,1753,1753,train,16,Train 데이터셋을 왜 순서를 섞어야 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1754,1754,1754,train,16,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1755,1755,1755,train,16,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1756,1756,1756,train,16,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1757,1757,1757,train,16,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1758,1758,1758,train,16,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1759,1759,1759,train,16,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1760,1760,1760,train,16,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1761,1761,1761,train,16,Overfitting 이 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1762,1762,1762,train,16,Overfitting 해결하는 방법은 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1763,1763,1763,train,16,전이학습이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1764,1764,1764,train,16,Transfer Learning 이 뭔지 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1765,1765,1765,train,16,활성화 함수? 그게 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1766,1766,1766,train,16,활성화 함수는 왜 필요해?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1767,1767,1767,train,16,CNN이 뭐야? 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1768,1768,1768,train,16,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1769,1769,1769,train,16,cosine similarity가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1770,1770,1770,train,16,코사인 유사도가 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1771,1771,1771,train,16,코사인 유사도 계산법 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1772,1772,1772,train,16,코사인 유사도의 특징을 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1773,1773,1773,train,16,머신러닝에서 많이 쓰이는 평가지표 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1774,1774,1774,train,16,Accuracy 는 어떻게 계산해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1775,1775,1775,train,16,True Positive 같은 건 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1776,1776,1776,train,16,True Negative 는?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1777,1777,1777,train,16,False Positive 는 뭐지 그럼?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1778,1778,1778,train,16,False Negative 는 뭐야 그러면?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1779,1779,1779,train,16,Recall 은 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1780,1780,1780,train,16,Recall 은 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1781,1781,1781,train,16,Precision 은 어떻게 계산하지,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1782,1782,1782,train,16,Recall 과 Precision 이 자꾸 헷갈리네,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1783,1783,1783,train,16,F1 이 뭔지 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1784,1784,1784,train,16,F1 Score 구하는 수식을 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1785,1785,1785,train,17,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1786,1786,1786,train,17,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1787,1787,1787,train,17,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1788,1788,1788,train,17,PR-AUC랑 ROC-AUC가 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1789,1789,1789,train,17,PR-AUC가 뭔지 자세히 알려줘!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1790,1790,1790,train,17,ROC-AUC가 뭔지 아주 자세히 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1791,1791,1791,train,17,True Positive Rate 가 뭐야? 궁금해!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1792,1792,1792,train,17,False Positive Rate 는 뭐지 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1793,1793,1793,train,17,Confusion Matrix 가 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.1
1794,1794,1794,train,17,Confusion Matrix 만드는 법을 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.1
1795,1795,1795,train,17,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1796,1796,1796,train,17,Normalization 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
1797,1797,1797,train,17,정규화가 뭔지 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
1798,1798,1798,train,17,min-max 정규화가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1799,1799,1799,train,17,Z score normalization 이 뭐지?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1800,1800,1800,train,17,Clipping 에 대해서 자세히 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1801,1801,1801,train,17,Clipping 을 하면 뭐가 좋아?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1802,1802,1802,train,17,로그 스케일링이 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1803,1803,1803,train,17,Outlier 가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1804,1804,1804,train,17,이상치가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1805,1805,1805,train,17,Outlier 를 제거해야 하는 이유는 뭐지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1806,1806,1806,train,17,Outlier 를 제거하는 방법에 대해 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1807,1807,1807,train,17,PCA 가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1808,1808,1808,train,17,주성분 분석이 뭐지?,True Positive Rate : recall 의 다른 이름,0.0
1809,1809,1809,train,17,PCA 는 왜 하는 거지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1810,1810,1810,train,17,데이터 불균형이 뭔지 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1811,1811,1811,train,17,데이터 불균형 해결하는 법이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1812,1812,1812,train,17,데이터를 새로 추가하거나 제거하는 법 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1813,1813,1813,train,17,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1814,1814,1814,train,17,Augmentation 이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1815,1815,1815,train,17,Undersampling 이랑 Oversampling 이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1816,1816,1816,train,17,Undersampling 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1817,1817,1817,train,17,그럼 Oversampling 은 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1818,1818,1818,train,17,데이터 불균형을 고려한 성능지표를 추천해 줘!,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1819,1819,1819,train,17,Undersampling 하는 방법 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1820,1820,1820,train,17,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1821,1821,1821,train,17,차원의 저주가 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1822,1822,1822,train,17,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1823,1823,1823,train,17,Decision Tree 가 뭔지 자세히 알고 싶어,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1824,1824,1824,train,17,의사결정 나무,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1825,1825,1825,train,17,Decision Tree 로 결정하는 방법은?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1826,1826,1826,train,17,앙상블이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1827,1827,1827,train,17,앙상블을 왜 하는 거야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1828,1828,1828,train,17,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1829,1829,1829,train,17,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1830,1830,1830,train,17,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1831,1831,1831,train,17,앙상블 중에 Voting 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1832,1832,1832,train,17,보팅의 방법에는 구체적으로 뭐가 있지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1833,1833,1833,train,17,Bagging 이 뭔지 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1834,1834,1834,train,17,그럼 Boosting 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1835,1835,1835,train,17,Stacking 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1836,1836,1836,train,17,Gaussian Mixture 모델이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1837,1837,1837,train,17,가우시안 혼합이 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1838,1838,1838,train,17,K-means Clustering 이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1839,1839,1839,train,17,K-means Clustering 의 방법을 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1840,1840,1840,train,17,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1841,1841,1841,train,17,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1842,1842,1842,train,17,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1843,1843,1843,train,17,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1844,1844,1844,train,17,강화학습? 지도학습? 그게 뭐지?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1845,1845,1845,train,17,지도학습과 비지도학습의 차이가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1846,1846,1846,train,17,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1847,1847,1847,train,17,분류와 회귀 문제가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1848,1848,1848,train,17,Regression 이랑 Classification 이 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1849,1849,1849,train,17,Naïve Bayes 가 뭔지 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1850,1850,1850,train,17,서포트 벡터 머신이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1851,1851,1851,train,17,SVM이 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1852,1852,1852,train,17,K-fold Cross Validation,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1853,1853,1853,train,17,K-fold Cross Validation을 굳이 왜 하는 거야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1854,1854,1854,train,17,하이퍼파라미터가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1855,1855,1855,train,17,One-hot 방식이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1856,1856,1856,train,17,Valid 데이터가 굳이 왜 필요하지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1857,1857,1857,train,17,Train 데이터셋을 왜 순서를 섞어야 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1858,1858,1858,train,17,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1859,1859,1859,train,17,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1860,1860,1860,train,17,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1861,1861,1861,train,17,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1862,1862,1862,train,17,딥러닝에서 학습률이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1863,1863,1863,train,17,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1864,1864,1864,train,17,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1865,1865,1865,train,17,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1866,1866,1866,train,17,Overfitting 해결하는 방법은 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1867,1867,1867,train,17,전이학습이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1868,1868,1868,train,17,Transfer Learning 이 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1869,1869,1869,train,17,활성화 함수? 그게 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1870,1870,1870,train,17,활성화 함수는 왜 필요해?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1871,1871,1871,train,17,CNN이 뭐야? 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1872,1872,1872,train,17,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1873,1873,1873,train,17,cosine similarity가 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1874,1874,1874,train,17,코사인 유사도가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1875,1875,1875,train,17,코사인 유사도 계산법 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1876,1876,1876,train,17,코사인 유사도의 특징을 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1877,1877,1877,train,17,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.1
1878,1878,1878,train,17,Accuracy 는 어떻게 계산해?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1879,1879,1879,train,17,True Positive 같은 건 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1880,1880,1880,train,17,True Negative 는?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1881,1881,1881,train,17,False Positive 는 뭐지 그럼?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1882,1882,1882,train,17,False Negative 는 뭐야 그러면?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1883,1883,1883,train,17,Recall 은 어떻게 계산해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1884,1884,1884,train,17,Recall 은 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1885,1885,1885,train,17,Precision 은 어떻게 계산하지,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1886,1886,1886,train,17,Recall 과 Precision 이 자꾸 헷갈리네,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1887,1887,1887,train,17,F1 이 뭔지 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1888,1888,1888,train,17,F1 Score 구하는 수식을 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1889,1889,1889,train,17,F1 Score 장점이 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1890,1890,1890,train,18,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1891,1891,1891,train,18,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1892,1892,1892,train,18,PR-AUC랑 ROC-AUC가 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1893,1893,1893,train,18,PR-AUC가 뭔지 자세히 알려줘!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1894,1894,1894,train,18,ROC-AUC가 뭔지 아주 자세히 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1895,1895,1895,train,18,True Positive Rate 가 뭐야? 궁금해!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1896,1896,1896,train,18,False Positive Rate 는 뭐지 그러면?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1897,1897,1897,train,18,Confusion Matrix 가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.1
1898,1898,1898,train,18,Confusion Matrix 만드는 법을 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.1
1899,1899,1899,train,18,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1900,1900,1900,train,18,Normalization 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
1901,1901,1901,train,18,정규화가 뭔지 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
1902,1902,1902,train,18,min-max 정규화가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
1903,1903,1903,train,18,Z score normalization 이 뭐지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1904,1904,1904,train,18,Clipping 에 대해서 자세히 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1905,1905,1905,train,18,Clipping 을 하면 뭐가 좋아?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1906,1906,1906,train,18,로그 스케일링이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1907,1907,1907,train,18,Outlier 가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1908,1908,1908,train,18,이상치가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1909,1909,1909,train,18,Outlier 를 제거해야 하는 이유는 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1910,1910,1910,train,18,Outlier 를 제거하는 방법에 대해 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1911,1911,1911,train,18,PCA 가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1912,1912,1912,train,18,주성분 분석이 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1913,1913,1913,train,18,PCA 는 왜 하는 거지 그러면?,True Positive Rate : recall 의 다른 이름,0.0
1914,1914,1914,train,18,데이터 불균형이 뭔지 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1915,1915,1915,train,18,데이터 불균형 해결하는 법이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1916,1916,1916,train,18,데이터를 새로 추가하거나 제거하는 법 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1917,1917,1917,train,18,그러면 학습 환경만 바꾸는 방법은 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1918,1918,1918,train,18,Augmentation 이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1919,1919,1919,train,18,Undersampling 이랑 Oversampling 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1920,1920,1920,train,18,Undersampling 이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1921,1921,1921,train,18,그럼 Oversampling 은 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1922,1922,1922,train,18,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1923,1923,1923,train,18,Undersampling 하는 방법 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1924,1924,1924,train,18,Oversampling 방법은 어떤 게 있어?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1925,1925,1925,train,18,차원의 저주가 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1926,1926,1926,train,18,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1927,1927,1927,train,18,Decision Tree 가 뭔지 자세히 알고 싶어,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1928,1928,1928,train,18,의사결정 나무,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1929,1929,1929,train,18,Decision Tree 로 결정하는 방법은?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1930,1930,1930,train,18,앙상블이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1931,1931,1931,train,18,앙상블을 왜 하는 거야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1932,1932,1932,train,18,앙상블 하는 구체적인 방법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1933,1933,1933,train,18,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1934,1934,1934,train,18,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1935,1935,1935,train,18,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1936,1936,1936,train,18,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1937,1937,1937,train,18,Bagging 이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1938,1938,1938,train,18,그럼 Boosting 은 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1939,1939,1939,train,18,Stacking 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1940,1940,1940,train,18,Gaussian Mixture 모델이 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1941,1941,1941,train,18,가우시안 혼합이 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1942,1942,1942,train,18,K-means Clustering 이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1943,1943,1943,train,18,K-means Clustering 의 방법을 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1944,1944,1944,train,18,kNN 에 대해 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1945,1945,1945,train,18,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1946,1946,1946,train,18,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1947,1947,1947,train,18,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1948,1948,1948,train,18,강화학습? 지도학습? 그게 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1949,1949,1949,train,18,지도학습과 비지도학습의 차이가 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1950,1950,1950,train,18,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1951,1951,1951,train,18,분류와 회귀 문제가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1952,1952,1952,train,18,Regression 이랑 Classification 이 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1953,1953,1953,train,18,Naïve Bayes 가 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1954,1954,1954,train,18,서포트 벡터 머신이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1955,1955,1955,train,18,SVM이 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1956,1956,1956,train,18,K-fold Cross Validation,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1957,1957,1957,train,18,K-fold Cross Validation을 굳이 왜 하는 거야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1958,1958,1958,train,18,하이퍼파라미터가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1959,1959,1959,train,18,One-hot 방식이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1960,1960,1960,train,18,Valid 데이터가 굳이 왜 필요하지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1961,1961,1961,train,18,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1962,1962,1962,train,18,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1963,1963,1963,train,18,인공지능이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1964,1964,1964,train,18,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1965,1965,1965,train,18,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1966,1966,1966,train,18,딥러닝에서 학습률이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1967,1967,1967,train,18,learning rate 가 뭔지 궁금해!,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1968,1968,1968,train,18,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1969,1969,1969,train,18,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1970,1970,1970,train,18,Overfitting 해결하는 방법은 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1971,1971,1971,train,18,전이학습이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1972,1972,1972,train,18,Transfer Learning 이 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1973,1973,1973,train,18,활성화 함수? 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1974,1974,1974,train,18,활성화 함수는 왜 필요해?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1975,1975,1975,train,18,CNN이 뭐야? 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1976,1976,1976,train,18,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1977,1977,1977,train,18,cosine similarity가 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1978,1978,1978,train,18,코사인 유사도가 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1979,1979,1979,train,18,코사인 유사도 계산법 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1980,1980,1980,train,18,코사인 유사도의 특징을 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1981,1981,1981,train,18,머신러닝에서 많이 쓰이는 평가지표 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1982,1982,1982,train,18,Accuracy 는 어떻게 계산해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1983,1983,1983,train,18,True Positive 같은 건 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1984,1984,1984,train,18,True Negative 는?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1985,1985,1985,train,18,False Positive 는 뭐지 그럼?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1986,1986,1986,train,18,False Negative 는 뭐야 그러면?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1987,1987,1987,train,18,Recall 은 어떻게 계산해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1988,1988,1988,train,18,Recall 은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1989,1989,1989,train,18,Precision 은 어떻게 계산하지,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1990,1990,1990,train,18,Recall 과 Precision 이 자꾸 헷갈리네,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1991,1991,1991,train,18,F1 이 뭔지 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1992,1992,1992,train,18,F1 Score 구하는 수식을 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1993,1993,1993,train,18,F1 Score 장점이 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1994,1994,1994,train,18,IoU 가 뭔지 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1995,1995,1995,train,19,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1996,1996,1996,train,19,PR-AUC랑 ROC-AUC가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1997,1997,1997,train,19,PR-AUC가 뭔지 자세히 알려줘!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1998,1998,1998,train,19,ROC-AUC가 뭔지 아주 자세히 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1999,1999,1999,train,19,True Positive Rate 가 뭐야? 궁금해!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2000,2000,2000,train,19,False Positive Rate 는 뭐지 그러면?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2001,2001,2001,train,19,Confusion Matrix 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.1
2002,2002,2002,train,19,Confusion Matrix 만드는 법을 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.1
2003,2003,2003,train,19,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2004,2004,2004,train,19,Normalization 이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
2005,2005,2005,train,19,정규화가 뭔지 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2006,2006,2006,train,19,min-max 정규화가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2007,2007,2007,train,19,Z score normalization 이 뭐지?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
2008,2008,2008,train,19,Clipping 에 대해서 자세히 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
2009,2009,2009,train,19,Clipping 을 하면 뭐가 좋아?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
2010,2010,2010,train,19,로그 스케일링이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
2011,2011,2011,train,19,Outlier 가 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
2012,2012,2012,train,19,이상치가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
2013,2013,2013,train,19,Outlier 를 제거해야 하는 이유는 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
2014,2014,2014,train,19,Outlier 를 제거하는 방법에 대해 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
2015,2015,2015,train,19,PCA 가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
2016,2016,2016,train,19,주성분 분석이 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2017,2017,2017,train,19,PCA 는 왜 하는 거지 그러면?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2018,2018,2018,train,19,데이터 불균형이 뭔지 알려줘,True Positive Rate : recall 의 다른 이름,0.0
2019,2019,2019,train,19,데이터 불균형 해결하는 법이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2020,2020,2020,train,19,데이터를 새로 추가하거나 제거하는 법 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2021,2021,2021,train,19,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2022,2022,2022,train,19,Augmentation 이 뭔지 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2023,2023,2023,train,19,Undersampling 이랑 Oversampling 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2024,2024,2024,train,19,Undersampling 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2025,2025,2025,train,19,그럼 Oversampling 은 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
2026,2026,2026,train,19,데이터 불균형을 고려한 성능지표를 추천해 줘!,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2027,2027,2027,train,19,Undersampling 하는 방법 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2028,2028,2028,train,19,Oversampling 방법은 어떤 게 있어?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2029,2029,2029,train,19,차원의 저주가 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2030,2030,2030,train,19,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2031,2031,2031,train,19,Decision Tree 가 뭔지 자세히 알고 싶어,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2032,2032,2032,train,19,의사결정 나무,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2033,2033,2033,train,19,Decision Tree 로 결정하는 방법은?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2034,2034,2034,train,19,앙상블이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2035,2035,2035,train,19,앙상블을 왜 하는 거야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2036,2036,2036,train,19,앙상블 하는 구체적인 방법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2037,2037,2037,train,19,앙상블은 정확히 어떻게 하는 건지 궁금해,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
2038,2038,2038,train,19,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
2039,2039,2039,train,19,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
2040,2040,2040,train,19,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
2041,2041,2041,train,19,Bagging 이 뭔지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
2042,2042,2042,train,19,그럼 Boosting 은 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
2043,2043,2043,train,19,Stacking 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
2044,2044,2044,train,19,Gaussian Mixture 모델이 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2045,2045,2045,train,19,가우시안 혼합이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2046,2046,2046,train,19,K-means Clustering 이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2047,2047,2047,train,19,K-means Clustering 의 방법을 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2048,2048,2048,train,19,kNN 에 대해 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2049,2049,2049,train,19,k Nearest Neighbor 알고리즘이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2050,2050,2050,train,19,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2051,2051,2051,train,19,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2052,2052,2052,train,19,강화학습? 지도학습? 그게 뭐지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2053,2053,2053,train,19,지도학습과 비지도학습의 차이가 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
2054,2054,2054,train,19,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
2055,2055,2055,train,19,분류와 회귀 문제가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2056,2056,2056,train,19,Regression 이랑 Classification 이 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2057,2057,2057,train,19,Naïve Bayes 가 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2058,2058,2058,train,19,서포트 벡터 머신이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2059,2059,2059,train,19,SVM이 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2060,2060,2060,train,19,K-fold Cross Validation,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2061,2061,2061,train,19,K-fold Cross Validation을 굳이 왜 하는 거야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2062,2062,2062,train,19,하이퍼파라미터가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2063,2063,2063,train,19,One-hot 방식이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2064,2064,2064,train,19,Valid 데이터가 굳이 왜 필요하지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2065,2065,2065,train,19,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2066,2066,2066,train,19,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2067,2067,2067,train,19,인공지능이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2068,2068,2068,train,19,머신러닝은 그럼 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2069,2069,2069,train,19,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2070,2070,2070,train,19,딥러닝에서 학습률이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2071,2071,2071,train,19,learning rate 가 뭔지 궁금해!,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2072,2072,2072,train,19,자주 쓰는 Loss Function 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2073,2073,2073,train,19,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2074,2074,2074,train,19,Overfitting 해결하는 방법은 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2075,2075,2075,train,19,전이학습이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2076,2076,2076,train,19,Transfer Learning 이 뭔지 궁금해!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2077,2077,2077,train,19,활성화 함수? 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2078,2078,2078,train,19,활성화 함수는 왜 필요해?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2079,2079,2079,train,19,CNN이 뭐야? 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2080,2080,2080,train,19,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2081,2081,2081,train,19,cosine similarity가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2082,2082,2082,train,19,코사인 유사도가 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2083,2083,2083,train,19,코사인 유사도 계산법 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2084,2084,2084,train,19,코사인 유사도의 특징을 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2085,2085,2085,train,19,머신러닝에서 많이 쓰이는 평가지표 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
2086,2086,2086,train,19,Accuracy 는 어떻게 계산해?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2087,2087,2087,train,19,True Positive 같은 건 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2088,2088,2088,train,19,True Negative 는?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2089,2089,2089,train,19,False Positive 는 뭐지 그럼?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2090,2090,2090,train,19,False Negative 는 뭐야 그러면?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2091,2091,2091,train,19,Recall 은 어떻게 계산해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2092,2092,2092,train,19,Recall 은 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2093,2093,2093,train,19,Precision 은 어떻게 계산하지,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2094,2094,2094,train,19,Recall 과 Precision 이 자꾸 헷갈리네,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2095,2095,2095,train,19,F1 이 뭔지 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2096,2096,2096,train,19,F1 Score 구하는 수식을 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2097,2097,2097,train,19,F1 Score 장점이 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2098,2098,2098,train,19,IoU 가 뭔지 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2099,2099,2099,train,19,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2100,2100,2100,test,0,코사인 유사도가 뭔지 궁금해,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2101,2101,2101,test,0,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2102,2102,2102,test,0,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,1.0
2103,2103,2103,test,0,코사인 유사도 특징이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",1.0
2104,2104,2104,test,0,머신러닝 모델 평가하는 방법 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",1.0
2105,2105,2105,test,0,Accuracy 계산 어떻게 하지?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),1.0
2106,2106,2106,test,0,True Positive 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,1.0
2107,2107,2107,test,0,True Negative 는 뭔지 궁금해 그럼,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,1.0
2108,2108,2108,test,0,False Positive 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,1.0
2109,2109,2109,test,0,False Negative (FN),False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,1.0
2110,2110,2110,test,0,Recall 계산법 어떻게 하는 거지?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
2111,2111,2111,test,0,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
2112,2112,2112,test,0,Precision 어떻게 계산하는지 정말 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),1.0
2113,2113,2113,test,0,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",1.0
2114,2114,2114,test,0,F1 Score 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,1.0
2115,2115,2115,test,0,F1 Score 계산식 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),1.0
2116,2116,2116,test,0,F1 Score 는 왜 쓰는 거지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",1.0
2117,2117,2117,test,0,IoU 라는 게 있는데 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),1.0
2118,2118,2118,test,0,특이도는 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),1.0
2119,2119,2119,test,0,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",1.0
2120,2120,2120,test,0,"PR-AUC, ROC-AUC 가 뭐야?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",1.0
2121,2121,2121,test,0,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
2122,2122,2122,test,0,ROC-AUC 는 뭔지 정말 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
2123,2123,2123,test,0,True Positive Rate 구하는 방법을 알려줘,True Positive Rate : recall 의 다른 이름,1.0
2124,2124,2124,test,0,False Positive Rate 가 뭔지 정말 궁금하다,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),1.0
2125,2125,2125,test,0,Confusion Matrix (혼동 행렬) 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",1.0
2126,2126,2126,test,0,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",1.0
2127,2127,2127,test,0,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",1.0
2128,2128,2128,test,0,Normalization 정규화 그게 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
2129,2129,2129,test,0,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
2130,2130,2130,test,0,Min-Max 정규화가 뭔지 잘 모르겠어,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),1.0
2131,2131,2131,test,0,Z 스코어 정규화가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,1.0
2132,2132,2132,test,0,Clipping? 클리핑? 그게 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",1.0
2133,2133,2133,test,0,클리핑 이거 쓸데없이 하는 거 아니야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,1.0
2134,2134,2134,test,0,로그 스케일링도 정규화 같은데 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,1.0
2135,2135,2135,test,0,Outlier 개념,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
2136,2136,2136,test,0,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
2137,2137,2137,test,0,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,1.0
2138,2138,2138,test,0,Outlier 없애려면 어떻게 해야 되지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",1.0
2139,2139,2139,test,0,PCA에 대해 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
2140,2140,2140,test,0,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
2141,2141,2141,test,0,PCA 그거 왜 하는 건지 모르겠어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,1.0
2142,2142,2142,test,0,데이터가 불균형하다고? 그게 뭐지,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,1.0
2143,2143,2143,test,0,데이터 불균형 어떻게 하면 해결할 수 있지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",1.0
2144,2144,2144,test,0,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",1.0
2145,2145,2145,test,0,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",1.0
2146,2146,2146,test,0,데이터 증강이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",1.0
2147,2147,2147,test,0,언더샘플링이랑 오버샘플링이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,1.0
2148,2148,2148,test,0,Undersampling 에 대해서 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,1.0
2149,2149,2149,test,0,oversampling 이 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,1.0
2150,2150,2150,test,0,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",1.0
2151,2151,2151,test,0,undersampling 방법은 뭐가 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",1.0
2152,2152,2152,test,0,Oversampling 하는 방법,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),1.0
2153,2153,2153,test,0,차원의 저주가 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",1.0
2154,2154,2154,test,0,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",1.0
2155,2155,2155,test,0,의사결정 나무가 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
2156,2156,2156,test,0,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
2157,2157,2157,test,0,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,1.0
2158,2158,2158,test,0,앙상블이 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,1.0
2159,2159,2159,test,0,앙상블 하는 이유,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,1.0
2160,2160,2160,test,0,앙상블 방법,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
2161,2161,2161,test,0,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
2162,2162,2162,test,0,Voting? 그게 뭐지,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
2163,2163,2163,test,0,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
2164,2164,2164,test,0,보팅 방법 구체적으로 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",1.0
2165,2165,2165,test,0,배깅이뭐야,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",1.0
2166,2166,2166,test,0,부스팅이 뭐지 그러면,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",1.0
2167,2167,2167,test,0,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",1.0
2168,2168,2168,test,0,가우시안 혼합? 그게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
2169,2169,2169,test,0,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
2170,2170,2170,test,0,K-means Clustering 너 알지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",1.0
2171,2171,2171,test,0,K-means Clustering 방법,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",1.0
2172,2172,2172,test,0,KNN 알고리즘 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
2173,2173,2173,test,0,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
2174,2174,2174,test,0,지도학습 강화학습 비지도학습 이런게 뭐지,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2175,2175,2175,test,0,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2176,2176,2176,test,0,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2177,2177,2177,test,0,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",1.0
2178,2178,2178,test,0,머신러닝 문제에는 뭐가 있지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2179,2179,2179,test,0,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2180,2180,2180,test,0,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2181,2181,2181,test,0,Naïve Bayes 뭐야,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",1.0
2182,2182,2182,test,0,서포트 벡터 머신? 그게 뭐지? 알려줘!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
2183,2183,2183,test,0,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
2184,2184,2184,test,0,K-fold Cross Validation 정의,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",1.0
2185,2185,2185,test,0,K-fold Cross Validation 하는 이유는?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,1.0
2186,2186,2186,test,0,Hyper parameter 가 대체 뭐지,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",1.0
2187,2187,2187,test,0,One-hot? 그것도 머신러닝 모델이야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",1.0
2188,2188,2188,test,0,Valid 데이터 쓰는 이유가 궁금해,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,1.0
2189,2189,2189,test,0,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",1.0
2190,2190,2190,test,0,인공지능 머신러닝 딥러닝의 관계는?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",1.0
2191,2191,2191,test,0,인공지능 정의,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",1.0
2192,2192,2192,test,0,머신러닝은 인공지능에 속하는 거 맞지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",1.0
2193,2193,2193,test,0,딥러닝이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,1.0
2194,2194,2194,test,0,딥러닝의 learning rate 그게 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
2195,2195,2195,test,0,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
2196,2196,2196,test,0,자주 쓰이는 손실 함수는 뭐가 있을까,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",1.0
2197,2197,2197,test,0,오버피팅이 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,1.0
2198,2198,2198,test,0,Overfitting 대체 어떻게 해결하지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",1.0
2199,2199,2199,test,0,전이학습? 그게 뭐야 도대체?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
2200,2200,2200,test,0,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
2201,2201,2201,test,0,활성화 함수? 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",1.0
2202,2202,2202,test,0,굳이 활성화 함수 왜 써?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,1.0
2203,2203,2203,test,0,CNN이 뭐야? 이미지 인식에 좋다던데,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",1.0
2204,2204,2204,test,0,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",1.0
2205,2205,2205,test,1,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2206,2206,2206,test,1,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2207,2207,2207,test,1,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.5
2208,2208,2208,test,1,머신러닝 모델 평가하는 방법 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2209,2209,2209,test,1,Accuracy 계산 어떻게 하지?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2210,2210,2210,test,1,True Positive 가 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.1
2211,2211,2211,test,1,True Negative 는 뭔지 궁금해 그럼,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2212,2212,2212,test,1,False Positive 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2213,2213,2213,test,1,False Negative (FN),False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2214,2214,2214,test,1,Recall 계산법 어떻게 하는 거지?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2215,2215,2215,test,1,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
2216,2216,2216,test,1,Precision 어떻게 계산하는지 정말 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2217,2217,2217,test,1,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.5
2218,2218,2218,test,1,F1 Score 가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2219,2219,2219,test,1,F1 Score 계산식 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
2220,2220,2220,test,1,F1 Score 는 왜 쓰는 거지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.5
2221,2221,2221,test,1,IoU 라는 게 있는데 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2222,2222,2222,test,1,특이도는 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2223,2223,2223,test,1,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2224,2224,2224,test,1,"PR-AUC, ROC-AUC 가 뭐야?","binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2225,2225,2225,test,1,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.5
2226,2226,2226,test,1,ROC-AUC 는 뭔지 정말 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2227,2227,2227,test,1,True Positive Rate 구하는 방법을 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2228,2228,2228,test,1,False Positive Rate 가 뭔지 정말 궁금하다,True Positive Rate : recall 의 다른 이름,0.25
2229,2229,2229,test,1,Confusion Matrix (혼동 행렬) 이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.25
2230,2230,2230,test,1,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.5
2231,2231,2231,test,1,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.25
2232,2232,2232,test,1,Normalization 정규화 그게 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2233,2233,2233,test,1,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
2234,2234,2234,test,1,Min-Max 정규화가 뭔지 잘 모르겠어,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2235,2235,2235,test,1,Z 스코어 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2236,2236,2236,test,1,Clipping? 클리핑? 그게 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
2237,2237,2237,test,1,클리핑 이거 쓸데없이 하는 거 아니야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.5
2238,2238,2238,test,1,로그 스케일링도 정규화 같은데 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
2239,2239,2239,test,1,Outlier 개념,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2240,2240,2240,test,1,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
2241,2241,2241,test,1,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2242,2242,2242,test,1,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.5
2243,2243,2243,test,1,PCA에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2244,2244,2244,test,1,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
2245,2245,2245,test,1,PCA 그거 왜 하는 건지 모르겠어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
2246,2246,2246,test,1,데이터가 불균형하다고? 그게 뭐지,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2247,2247,2247,test,1,데이터 불균형 어떻게 하면 해결할 수 있지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.5
2248,2248,2248,test,1,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.5
2249,2249,2249,test,1,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2250,2250,2250,test,1,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.1
2251,2251,2251,test,1,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2252,2252,2252,test,1,Undersampling 에 대해서 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
2253,2253,2253,test,1,oversampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
2254,2254,2254,test,1,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.1
2255,2255,2255,test,1,undersampling 방법은 뭐가 있어?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
2256,2256,2256,test,1,Oversampling 하는 방법,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.25
2257,2257,2257,test,1,차원의 저주가 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2258,2258,2258,test,1,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.5
2259,2259,2259,test,1,의사결정 나무가 뭔지 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2260,2260,2260,test,1,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
2261,2261,2261,test,1,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
2262,2262,2262,test,1,앙상블이 뭐지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2263,2263,2263,test,1,앙상블 하는 이유,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
2264,2264,2264,test,1,앙상블 방법,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
2265,2265,2265,test,1,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
2266,2266,2266,test,1,Voting? 그게 뭐지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2267,2267,2267,test,1,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
2268,2268,2268,test,1,보팅 방법 구체적으로 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
2269,2269,2269,test,1,배깅이뭐야,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
2270,2270,2270,test,1,부스팅이 뭐지 그러면,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
2271,2271,2271,test,1,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.25
2272,2272,2272,test,1,가우시안 혼합? 그게 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2273,2273,2273,test,1,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
2274,2274,2274,test,1,K-means Clustering 너 알지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2275,2275,2275,test,1,K-means Clustering 방법,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.5
2276,2276,2276,test,1,KNN 알고리즘 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2277,2277,2277,test,1,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
2278,2278,2278,test,1,지도학습 강화학습 비지도학습 이런게 뭐지,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2279,2279,2279,test,1,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2280,2280,2280,test,1,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2281,2281,2281,test,1,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
2282,2282,2282,test,1,머신러닝 문제에는 뭐가 있지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2283,2283,2283,test,1,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2284,2284,2284,test,1,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2285,2285,2285,test,1,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2286,2286,2286,test,1,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2287,2287,2287,test,1,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
2288,2288,2288,test,1,K-fold Cross Validation 정의,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2289,2289,2289,test,1,K-fold Cross Validation 하는 이유는?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.5
2290,2290,2290,test,1,Hyper parameter 가 대체 뭐지,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2291,2291,2291,test,1,One-hot? 그것도 머신러닝 모델이야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2292,2292,2292,test,1,Valid 데이터 쓰는 이유가 궁금해,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.25
2293,2293,2293,test,1,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2294,2294,2294,test,1,인공지능 머신러닝 딥러닝의 관계는?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2295,2295,2295,test,1,인공지능 정의,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.5
2296,2296,2296,test,1,머신러닝은 인공지능에 속하는 거 맞지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
2297,2297,2297,test,1,딥러닝이 뭔지 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.25
2298,2298,2298,test,1,딥러닝의 learning rate 그게 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.1
2299,2299,2299,test,1,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
2300,2300,2300,test,1,자주 쓰이는 손실 함수는 뭐가 있을까,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2301,2301,2301,test,1,오버피팅이 뭐야,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2302,2302,2302,test,1,Overfitting 대체 어떻게 해결하지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.5
2303,2303,2303,test,1,전이학습? 그게 뭐야 도대체?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2304,2304,2304,test,1,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
2305,2305,2305,test,1,활성화 함수? 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2306,2306,2306,test,1,굳이 활성화 함수 왜 써?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.5
2307,2307,2307,test,1,CNN이 뭐야? 이미지 인식에 좋다던데,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2308,2308,2308,test,1,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2309,2309,2309,test,1,코사인 유사도가 뭔지 궁금해,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2310,2310,2310,test,2,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2311,2311,2311,test,2,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2312,2312,2312,test,2,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2313,2313,2313,test,2,Accuracy 계산 어떻게 하지?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2314,2314,2314,test,2,True Positive 가 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2315,2315,2315,test,2,True Negative 는 뭔지 궁금해 그럼,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2316,2316,2316,test,2,False Positive 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2317,2317,2317,test,2,False Negative (FN),True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2318,2318,2318,test,2,Recall 계산법 어떻게 하는 거지?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2319,2319,2319,test,2,Recall 이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2320,2320,2320,test,2,Precision 어떻게 계산하는지 정말 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2321,2321,2321,test,2,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2322,2322,2322,test,2,F1 Score 가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
2323,2323,2323,test,2,F1 Score 계산식 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2324,2324,2324,test,2,F1 Score 는 왜 쓰는 거지?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
2325,2325,2325,test,2,IoU 라는 게 있는데 뭔지 궁금해,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
2326,2326,2326,test,2,특이도는 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2327,2327,2327,test,2,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2328,2328,2328,test,2,"PR-AUC, ROC-AUC 가 뭐야?",Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2329,2329,2329,test,2,PR-AUC 에 대해 아주 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2330,2330,2330,test,2,ROC-AUC 는 뭔지 정말 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
2331,2331,2331,test,2,True Positive Rate 구하는 방법을 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2332,2332,2332,test,2,False Positive Rate 가 뭔지 정말 궁금하다,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2333,2333,2333,test,2,Confusion Matrix (혼동 행렬) 이 뭐야?,True Positive Rate : recall 의 다른 이름,0.1
2334,2334,2334,test,2,Confusion Matrix 는 그럼 어떻게 만들어?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
2335,2335,2335,test,2,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.1
2336,2336,2336,test,2,Normalization 정규화 그게 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2337,2337,2337,test,2,정규화가 뭐지? 정말 궁금해!,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2338,2338,2338,test,2,Min-Max 정규화가 뭔지 잘 모르겠어,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2339,2339,2339,test,2,Z 스코어 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2340,2340,2340,test,2,Clipping? 클리핑? 그게 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2341,2341,2341,test,2,클리핑 이거 쓸데없이 하는 거 아니야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
2342,2342,2342,test,2,로그 스케일링도 정규화 같은데 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.25
2343,2343,2343,test,2,Outlier 개념,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
2344,2344,2344,test,2,이상치가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2345,2345,2345,test,2,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2346,2346,2346,test,2,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2347,2347,2347,test,2,PCA에 대해 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2348,2348,2348,test,2,주성분 분석?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2349,2349,2349,test,2,PCA 그거 왜 하는 건지 모르겠어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
2350,2350,2350,test,2,데이터가 불균형하다고? 그게 뭐지,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2351,2351,2351,test,2,데이터 불균형 어떻게 하면 해결할 수 있지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2352,2352,2352,test,2,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
2353,2353,2353,test,2,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
2354,2354,2354,test,2,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2355,2355,2355,test,2,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
2356,2356,2356,test,2,Undersampling 에 대해서 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2357,2357,2357,test,2,oversampling 이 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.25
2358,2358,2358,test,2,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.1
2359,2359,2359,test,2,undersampling 방법은 뭐가 있어?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
2360,2360,2360,test,2,Oversampling 하는 방법,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
2361,2361,2361,test,2,차원의 저주가 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2362,2362,2362,test,2,차원의 저주는 저주인데 정확히 뭐가 문제야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2363,2363,2363,test,2,의사결정 나무가 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2364,2364,2364,test,2,Decision Tree 가 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2365,2365,2365,test,2,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
2366,2366,2366,test,2,앙상블이 뭐지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2367,2367,2367,test,2,앙상블 하는 이유,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2368,2368,2368,test,2,앙상블 방법,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
2369,2369,2369,test,2,Ensemble 정확히 어떻게 하지,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
2370,2370,2370,test,2,Voting? 그게 뭐지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2371,2371,2371,test,2,앙상블 중에서 보팅 있잖아 그게 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2372,2372,2372,test,2,보팅 방법 구체적으로 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
2373,2373,2373,test,2,배깅이뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2374,2374,2374,test,2,부스팅이 뭐지 그러면,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
2375,2375,2375,test,2,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
2376,2376,2376,test,2,가우시안 혼합? 그게 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2377,2377,2377,test,2,Gaussian Mixture 어려운 것 같은데 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2378,2378,2378,test,2,K-means Clustering 너 알지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2379,2379,2379,test,2,K-means Clustering 방법,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2380,2380,2380,test,2,KNN 알고리즘 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2381,2381,2381,test,2,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2382,2382,2382,test,2,지도학습 강화학습 비지도학습 이런게 뭐지,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2383,2383,2383,test,2,머신러닝 방법 종류 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2384,2384,2384,test,2,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2385,2385,2385,test,2,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
2386,2386,2386,test,2,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2387,2387,2387,test,2,분류랑 회귀가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2388,2388,2388,test,2,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2389,2389,2389,test,2,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2390,2390,2390,test,2,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2391,2391,2391,test,2,SVM 제발 알려줘 제발,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2392,2392,2392,test,2,K-fold Cross Validation 정의,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2393,2393,2393,test,2,K-fold Cross Validation 하는 이유는?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2394,2394,2394,test,2,Hyper parameter 가 대체 뭐지,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2395,2395,2395,test,2,One-hot? 그것도 머신러닝 모델이야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2396,2396,2396,test,2,Valid 데이터 쓰는 이유가 궁금해,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2397,2397,2397,test,2,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2398,2398,2398,test,2,인공지능 머신러닝 딥러닝의 관계는?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2399,2399,2399,test,2,인공지능 정의,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2400,2400,2400,test,2,머신러닝은 인공지능에 속하는 거 맞지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
2401,2401,2401,test,2,딥러닝이 뭔지 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
2402,2402,2402,test,2,딥러닝의 learning rate 그게 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2403,2403,2403,test,2,학습률? Learning rate? 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2404,2404,2404,test,2,자주 쓰이는 손실 함수는 뭐가 있을까,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2405,2405,2405,test,2,오버피팅이 뭐야,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2406,2406,2406,test,2,Overfitting 대체 어떻게 해결하지?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2407,2407,2407,test,2,전이학습? 그게 뭐야 도대체?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2408,2408,2408,test,2,Transfer Learning 요즘 대세라던데 뭐야,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2409,2409,2409,test,2,활성화 함수? 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2410,2410,2410,test,2,굳이 활성화 함수 왜 써?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2411,2411,2411,test,2,CNN이 뭐야? 이미지 인식에 좋다던데,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2412,2412,2412,test,2,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2413,2413,2413,test,2,코사인 유사도가 뭔지 궁금해,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2414,2414,2414,test,2,Cosine Similarity 에 대해 알려줘!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2415,2415,2415,test,3,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2416,2416,2416,test,3,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2417,2417,2417,test,3,Accuracy 계산 어떻게 하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2418,2418,2418,test,3,True Positive 가 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2419,2419,2419,test,3,True Negative 는 뭔지 궁금해 그럼,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2420,2420,2420,test,3,False Positive 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2421,2421,2421,test,3,False Negative (FN),True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2422,2422,2422,test,3,Recall 계산법 어떻게 하는 거지?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2423,2423,2423,test,3,Recall 이 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2424,2424,2424,test,3,Precision 어떻게 계산하는지 정말 궁금해,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2425,2425,2425,test,3,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.5
2426,2426,2426,test,3,F1 Score 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2427,2427,2427,test,3,F1 Score 계산식 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
2428,2428,2428,test,3,F1 Score 는 왜 쓰는 거지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2429,2429,2429,test,3,IoU 라는 게 있는데 뭔지 궁금해,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
2430,2430,2430,test,3,특이도는 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
2431,2431,2431,test,3,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2432,2432,2432,test,3,"PR-AUC, ROC-AUC 가 뭐야?",IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2433,2433,2433,test,3,PR-AUC 에 대해 아주 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2434,2434,2434,test,3,ROC-AUC 는 뭔지 정말 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2435,2435,2435,test,3,True Positive Rate 구하는 방법을 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
2436,2436,2436,test,3,False Positive Rate 가 뭔지 정말 궁금하다,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2437,2437,2437,test,3,Confusion Matrix (혼동 행렬) 이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
2438,2438,2438,test,3,Confusion Matrix 는 그럼 어떻게 만들어?,True Positive Rate : recall 의 다른 이름,0.1
2439,2439,2439,test,3,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
2440,2440,2440,test,3,Normalization 정규화 그게 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2441,2441,2441,test,3,정규화가 뭐지? 정말 궁금해!,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2442,2442,2442,test,3,Min-Max 정규화가 뭔지 잘 모르겠어,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2443,2443,2443,test,3,Z 스코어 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2444,2444,2444,test,3,Clipping? 클리핑? 그게 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2445,2445,2445,test,3,클리핑 이거 쓸데없이 하는 거 아니야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2446,2446,2446,test,3,로그 스케일링도 정규화 같은데 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
2447,2447,2447,test,3,Outlier 개념,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2448,2448,2448,test,3,이상치가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2449,2449,2449,test,3,Outlier 없애야 되는 이유가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2450,2450,2450,test,3,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2451,2451,2451,test,3,PCA에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2452,2452,2452,test,3,주성분 분석?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2453,2453,2453,test,3,PCA 그거 왜 하는 건지 모르겠어,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2454,2454,2454,test,3,데이터가 불균형하다고? 그게 뭐지,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2455,2455,2455,test,3,데이터 불균형 어떻게 하면 해결할 수 있지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2456,2456,2456,test,3,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2457,2457,2457,test,3,학습 환경만 바꾸는 방법도 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
2458,2458,2458,test,3,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
2459,2459,2459,test,3,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2460,2460,2460,test,3,Undersampling 에 대해서 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
2461,2461,2461,test,3,oversampling 이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2462,2462,2462,test,3,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.1
2463,2463,2463,test,3,undersampling 방법은 뭐가 있어?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
2464,2464,2464,test,3,Oversampling 하는 방법,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
2465,2465,2465,test,3,차원의 저주가 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2466,2466,2466,test,3,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2467,2467,2467,test,3,의사결정 나무가 뭔지 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2468,2468,2468,test,3,Decision Tree 가 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2469,2469,2469,test,3,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2470,2470,2470,test,3,앙상블이 뭐지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2471,2471,2471,test,3,앙상블 하는 이유,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2472,2472,2472,test,3,앙상블 방법,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2473,2473,2473,test,3,Ensemble 정확히 어떻게 하지,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
2474,2474,2474,test,3,Voting? 그게 뭐지,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
2475,2475,2475,test,3,앙상블 중에서 보팅 있잖아 그게 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2476,2476,2476,test,3,보팅 방법 구체적으로 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2477,2477,2477,test,3,배깅이뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2478,2478,2478,test,3,부스팅이 뭐지 그러면,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2479,2479,2479,test,3,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
2480,2480,2480,test,3,가우시안 혼합? 그게 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2481,2481,2481,test,3,Gaussian Mixture 어려운 것 같은데 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2482,2482,2482,test,3,K-means Clustering 너 알지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2483,2483,2483,test,3,K-means Clustering 방법,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2484,2484,2484,test,3,KNN 알고리즘 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2485,2485,2485,test,3,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2486,2486,2486,test,3,지도학습 강화학습 비지도학습 이런게 뭐지,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2487,2487,2487,test,3,머신러닝 방법 종류 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2488,2488,2488,test,3,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2489,2489,2489,test,3,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
2490,2490,2490,test,3,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2491,2491,2491,test,3,분류랑 회귀가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2492,2492,2492,test,3,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2493,2493,2493,test,3,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2494,2494,2494,test,3,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2495,2495,2495,test,3,SVM 제발 알려줘 제발,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2496,2496,2496,test,3,K-fold Cross Validation 정의,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2497,2497,2497,test,3,K-fold Cross Validation 하는 이유는?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2498,2498,2498,test,3,Hyper parameter 가 대체 뭐지,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2499,2499,2499,test,3,One-hot? 그것도 머신러닝 모델이야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2500,2500,2500,test,3,Valid 데이터 쓰는 이유가 궁금해,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2501,2501,2501,test,3,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2502,2502,2502,test,3,인공지능 머신러닝 딥러닝의 관계는?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2503,2503,2503,test,3,인공지능 정의,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2504,2504,2504,test,3,머신러닝은 인공지능에 속하는 거 맞지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2505,2505,2505,test,3,딥러닝이 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
2506,2506,2506,test,3,딥러닝의 learning rate 그게 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2507,2507,2507,test,3,학습률? Learning rate? 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2508,2508,2508,test,3,자주 쓰이는 손실 함수는 뭐가 있을까,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2509,2509,2509,test,3,오버피팅이 뭐야,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2510,2510,2510,test,3,Overfitting 대체 어떻게 해결하지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2511,2511,2511,test,3,전이학습? 그게 뭐야 도대체?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2512,2512,2512,test,3,Transfer Learning 요즘 대세라던데 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2513,2513,2513,test,3,활성화 함수? 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2514,2514,2514,test,3,굳이 활성화 함수 왜 써?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2515,2515,2515,test,3,CNN이 뭐야? 이미지 인식에 좋다던데,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2516,2516,2516,test,3,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2517,2517,2517,test,3,코사인 유사도가 뭔지 궁금해,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2518,2518,2518,test,3,Cosine Similarity 에 대해 알려줘!,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2519,2519,2519,test,3,Cosine Similarity 는 어떻게 계산하지?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2520,2520,2520,test,4,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2521,2521,2521,test,4,Accuracy 계산 어떻게 하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2522,2522,2522,test,4,True Positive 가 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2523,2523,2523,test,4,True Negative 는 뭔지 궁금해 그럼,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2524,2524,2524,test,4,False Positive 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2525,2525,2525,test,4,False Negative (FN),Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2526,2526,2526,test,4,Recall 계산법 어떻게 하는 거지?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2527,2527,2527,test,4,Recall 이 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2528,2528,2528,test,4,Precision 어떻게 계산하는지 정말 궁금해,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2529,2529,2529,test,4,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2530,2530,2530,test,4,F1 Score 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2531,2531,2531,test,4,F1 Score 계산식 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2532,2532,2532,test,4,F1 Score 는 왜 쓰는 거지?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
2533,2533,2533,test,4,IoU 라는 게 있는데 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2534,2534,2534,test,4,특이도는 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
2535,2535,2535,test,4,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
2536,2536,2536,test,4,"PR-AUC, ROC-AUC 가 뭐야?","F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2537,2537,2537,test,4,PR-AUC 에 대해 아주 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2538,2538,2538,test,4,ROC-AUC 는 뭔지 정말 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2539,2539,2539,test,4,True Positive Rate 구하는 방법을 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2540,2540,2540,test,4,False Positive Rate 가 뭔지 정말 궁금하다,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
2541,2541,2541,test,4,Confusion Matrix (혼동 행렬) 이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
2542,2542,2542,test,4,Confusion Matrix 는 그럼 어떻게 만들어?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
2543,2543,2543,test,4,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,True Positive Rate : recall 의 다른 이름,0.25
2544,2544,2544,test,4,Normalization 정규화 그게 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2545,2545,2545,test,4,정규화가 뭐지? 정말 궁금해!,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2546,2546,2546,test,4,Min-Max 정규화가 뭔지 잘 모르겠어,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2547,2547,2547,test,4,Z 스코어 정규화가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2548,2548,2548,test,4,Clipping? 클리핑? 그게 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2549,2549,2549,test,4,클리핑 이거 쓸데없이 하는 거 아니야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2550,2550,2550,test,4,로그 스케일링도 정규화 같은데 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2551,2551,2551,test,4,Outlier 개념,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2552,2552,2552,test,4,이상치가 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2553,2553,2553,test,4,Outlier 없애야 되는 이유가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2554,2554,2554,test,4,Outlier 없애려면 어떻게 해야 되지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2555,2555,2555,test,4,PCA에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2556,2556,2556,test,4,주성분 분석?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2557,2557,2557,test,4,PCA 그거 왜 하는 건지 모르겠어,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2558,2558,2558,test,4,데이터가 불균형하다고? 그게 뭐지,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2559,2559,2559,test,4,데이터 불균형 어떻게 하면 해결할 수 있지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2560,2560,2560,test,4,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2561,2561,2561,test,4,학습 환경만 바꾸는 방법도 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2562,2562,2562,test,4,데이터 증강이 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
2563,2563,2563,test,4,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
2564,2564,2564,test,4,Undersampling 에 대해서 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2565,2565,2565,test,4,oversampling 이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
2566,2566,2566,test,4,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2567,2567,2567,test,4,undersampling 방법은 뭐가 있어?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
2568,2568,2568,test,4,Oversampling 하는 방법,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
2569,2569,2569,test,4,차원의 저주가 뭔지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2570,2570,2570,test,4,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2571,2571,2571,test,4,의사결정 나무가 뭔지 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2572,2572,2572,test,4,Decision Tree 가 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2573,2573,2573,test,4,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2574,2574,2574,test,4,앙상블이 뭐지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2575,2575,2575,test,4,앙상블 하는 이유,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2576,2576,2576,test,4,앙상블 방법,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2577,2577,2577,test,4,Ensemble 정확히 어떻게 하지,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2578,2578,2578,test,4,Voting? 그게 뭐지,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
2579,2579,2579,test,4,앙상블 중에서 보팅 있잖아 그게 뭐야,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
2580,2580,2580,test,4,보팅 방법 구체적으로 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2581,2581,2581,test,4,배깅이뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2582,2582,2582,test,4,부스팅이 뭐지 그러면,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2583,2583,2583,test,4,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2584,2584,2584,test,4,가우시안 혼합? 그게 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2585,2585,2585,test,4,Gaussian Mixture 어려운 것 같은데 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2586,2586,2586,test,4,K-means Clustering 너 알지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2587,2587,2587,test,4,K-means Clustering 방법,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2588,2588,2588,test,4,KNN 알고리즘 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2589,2589,2589,test,4,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2590,2590,2590,test,4,지도학습 강화학습 비지도학습 이런게 뭐지,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2591,2591,2591,test,4,머신러닝 방법 종류 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2592,2592,2592,test,4,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2593,2593,2593,test,4,지도학습이랑 비지도랑 뭐가 달라 그러면?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2594,2594,2594,test,4,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2595,2595,2595,test,4,분류랑 회귀가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2596,2596,2596,test,4,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2597,2597,2597,test,4,Naïve Bayes 뭐야,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2598,2598,2598,test,4,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2599,2599,2599,test,4,SVM 제발 알려줘 제발,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2600,2600,2600,test,4,K-fold Cross Validation 정의,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2601,2601,2601,test,4,K-fold Cross Validation 하는 이유는?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2602,2602,2602,test,4,Hyper parameter 가 대체 뭐지,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2603,2603,2603,test,4,One-hot? 그것도 머신러닝 모델이야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2604,2604,2604,test,4,Valid 데이터 쓰는 이유가 궁금해,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2605,2605,2605,test,4,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2606,2606,2606,test,4,인공지능 머신러닝 딥러닝의 관계는?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2607,2607,2607,test,4,인공지능 정의,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2608,2608,2608,test,4,머신러닝은 인공지능에 속하는 거 맞지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2609,2609,2609,test,4,딥러닝이 뭔지 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2610,2610,2610,test,4,딥러닝의 learning rate 그게 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.1
2611,2611,2611,test,4,학습률? Learning rate? 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2612,2612,2612,test,4,자주 쓰이는 손실 함수는 뭐가 있을까,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2613,2613,2613,test,4,오버피팅이 뭐야,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2614,2614,2614,test,4,Overfitting 대체 어떻게 해결하지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2615,2615,2615,test,4,전이학습? 그게 뭐야 도대체?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2616,2616,2616,test,4,Transfer Learning 요즘 대세라던데 뭐야,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2617,2617,2617,test,4,활성화 함수? 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2618,2618,2618,test,4,굳이 활성화 함수 왜 써?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2619,2619,2619,test,4,CNN이 뭐야? 이미지 인식에 좋다던데,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2620,2620,2620,test,4,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2621,2621,2621,test,4,코사인 유사도가 뭔지 궁금해,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2622,2622,2622,test,4,Cosine Similarity 에 대해 알려줘!,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2623,2623,2623,test,4,Cosine Similarity 는 어떻게 계산하지?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2624,2624,2624,test,4,코사인 유사도 특징이 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
