,data_type,repeat,user_question,rag_retrieved_data
0,train,0,cosine similarity가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1,train,0,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2,train,0,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
3,train,0,코사인 유사도의 특징을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
4,train,0,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
5,train,0,Accuracy 는 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
6,train,0,True Positive 같은 건 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
7,train,0,True Negative 는?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
8,train,0,False Positive 는 뭐지 그럼?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
9,train,0,False Negative 는 뭐야 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
10,train,0,Recall 은 어떻게 계산해?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
11,train,0,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
12,train,0,Precision 은 어떻게 계산하지,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
13,train,0,Recall 과 Precision 이 자꾸 헷갈리네,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
14,train,0,F1 이 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
15,train,0,F1 Score 구하는 수식을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
16,train,0,F1 Score 장점이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
17,train,0,IoU 가 뭔지 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
18,train,0,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
19,train,0,이진 분류에서 쓰이는 Metric 을 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
20,train,0,PR-AUC랑 ROC-AUC가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
21,train,0,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
22,train,0,ROC-AUC가 뭔지 아주 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
23,train,0,True Positive Rate 가 뭐야? 궁금해!,True Positive Rate : recall 의 다른 이름
24,train,0,False Positive Rate 는 뭐지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
25,train,0,Confusion Matrix 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
26,train,0,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
27,train,0,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
28,train,0,Normalization 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
29,train,0,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
30,train,0,min-max 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
31,train,0,Z score normalization 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
32,train,0,Clipping 에 대해서 자세히 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
33,train,0,Clipping 을 하면 뭐가 좋아?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
34,train,0,로그 스케일링이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
35,train,0,Outlier 가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
36,train,0,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
37,train,0,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
38,train,0,Outlier 를 제거하는 방법에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
39,train,0,PCA 가 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
40,train,0,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
41,train,0,PCA 는 왜 하는 거지 그러면?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
42,train,0,데이터 불균형이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
43,train,0,데이터 불균형 해결하는 법이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
44,train,0,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
45,train,0,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
46,train,0,Augmentation 이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
47,train,0,Undersampling 이랑 Oversampling 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
48,train,0,Undersampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
49,train,0,그럼 Oversampling 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가
50,train,0,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
51,train,0,Undersampling 하는 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
52,train,0,Oversampling 방법은 어떤 게 있어?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
53,train,0,차원의 저주가 뭐지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
54,train,0,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
55,train,0,Decision Tree 가 뭔지 자세히 알고 싶어,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
56,train,0,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
57,train,0,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
58,train,0,앙상블이 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
59,train,0,앙상블을 왜 하는 거야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
60,train,0,앙상블 하는 구체적인 방법 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
61,train,0,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
62,train,0,보팅에 대해 자세히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
63,train,0,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
64,train,0,보팅의 방법에는 구체적으로 뭐가 있지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
65,train,0,Bagging 이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
66,train,0,그럼 Boosting 은 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
67,train,0,Stacking 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
68,train,0,Gaussian Mixture 모델이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
69,train,0,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
70,train,0,K-means Clustering 이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
71,train,0,K-means Clustering 의 방법을 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
72,train,0,kNN 에 대해 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
73,train,0,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
74,train,0,지도학습 비지도학습 이런 게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
75,train,0,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
76,train,0,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
77,train,0,지도학습과 비지도학습의 차이가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
78,train,0,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
79,train,0,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
80,train,0,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
81,train,0,Naïve Bayes 가 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
82,train,0,서포트 벡터 머신이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
83,train,0,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
84,train,0,K-fold Cross Validation,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
85,train,0,K-fold Cross Validation을 굳이 왜 하는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
86,train,0,하이퍼파라미터가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
87,train,0,One-hot 방식이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
88,train,0,Valid 데이터가 굳이 왜 필요하지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
89,train,0,Train 데이터셋을 왜 순서를 섞어야 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
90,train,0,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
91,train,0,인공지능이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
92,train,0,머신러닝은 그럼 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
93,train,0,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
94,train,0,딥러닝에서 학습률이 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
95,train,0,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
96,train,0,자주 쓰는 Loss Function 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
97,train,0,Overfitting 이 뭔지 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
98,train,0,Overfitting 해결하는 방법은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
99,train,0,전이학습이 뭐지?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
100,train,0,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
101,train,0,활성화 함수? 그게 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
102,train,0,활성화 함수는 왜 필요해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
103,train,0,CNN이 뭐야? 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
104,train,0,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
105,train,1,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
106,train,1,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
107,train,1,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
108,train,1,머신러닝에서 많이 쓰이는 평가지표 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
109,train,1,Accuracy 는 어떻게 계산해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
110,train,1,True Positive 같은 건 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
111,train,1,True Negative 는?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
112,train,1,False Positive 는 뭐지 그럼?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
113,train,1,False Negative 는 뭐야 그러면?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
114,train,1,Recall 은 어떻게 계산해?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
115,train,1,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
116,train,1,Precision 은 어떻게 계산하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
117,train,1,Recall 과 Precision 이 자꾸 헷갈리네,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
118,train,1,F1 이 뭔지 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
119,train,1,F1 Score 구하는 수식을 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
120,train,1,F1 Score 장점이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
121,train,1,IoU 가 뭔지 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
122,train,1,특이도라는 걸 봤는데 그게 뭔지 궁금해!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
123,train,1,이진 분류에서 쓰이는 Metric 을 알려줘!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
124,train,1,PR-AUC랑 ROC-AUC가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
125,train,1,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
126,train,1,ROC-AUC가 뭔지 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
127,train,1,True Positive Rate 가 뭐야? 궁금해!,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
128,train,1,False Positive Rate 는 뭐지 그러면?,True Positive Rate : recall 의 다른 이름
129,train,1,Confusion Matrix 가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
130,train,1,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
131,train,1,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
132,train,1,Normalization 이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
133,train,1,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
134,train,1,min-max 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
135,train,1,Z score normalization 이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
136,train,1,Clipping 에 대해서 자세히 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
137,train,1,Clipping 을 하면 뭐가 좋아?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
138,train,1,로그 스케일링이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
139,train,1,Outlier 가 뭔지 궁금해,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
140,train,1,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
141,train,1,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
142,train,1,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
143,train,1,PCA 가 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
144,train,1,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
145,train,1,PCA 는 왜 하는 거지 그러면?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
146,train,1,데이터 불균형이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
147,train,1,데이터 불균형 해결하는 법이 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
148,train,1,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
149,train,1,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
150,train,1,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
151,train,1,Undersampling 이랑 Oversampling 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
152,train,1,Undersampling 이 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
153,train,1,그럼 Oversampling 은 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
154,train,1,데이터 불균형을 고려한 성능지표를 추천해 줘!,Oversampling : 데이터가 적은 Class 의 데이터 증가
155,train,1,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
156,train,1,Oversampling 방법은 어떤 게 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
157,train,1,차원의 저주가 뭐지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
158,train,1,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
159,train,1,Decision Tree 가 뭔지 자세히 알고 싶어,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
160,train,1,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
161,train,1,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
162,train,1,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
163,train,1,앙상블을 왜 하는 거야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
164,train,1,앙상블 하는 구체적인 방법 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
165,train,1,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
166,train,1,보팅에 대해 자세히 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
167,train,1,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
168,train,1,보팅의 방법에는 구체적으로 뭐가 있지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
169,train,1,Bagging 이 뭔지 궁금해,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
170,train,1,그럼 Boosting 은 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
171,train,1,Stacking 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
172,train,1,Gaussian Mixture 모델이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
173,train,1,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
174,train,1,K-means Clustering 이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
175,train,1,K-means Clustering 의 방법을 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
176,train,1,kNN 에 대해 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
177,train,1,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
178,train,1,지도학습 비지도학습 이런 게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
179,train,1,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
180,train,1,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
181,train,1,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
182,train,1,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
183,train,1,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
184,train,1,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
185,train,1,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
186,train,1,서포트 벡터 머신이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
187,train,1,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
188,train,1,K-fold Cross Validation,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
189,train,1,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
190,train,1,하이퍼파라미터가 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
191,train,1,One-hot 방식이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
192,train,1,Valid 데이터가 굳이 왜 필요하지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
193,train,1,Train 데이터셋을 왜 순서를 섞어야 돼?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
194,train,1,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
195,train,1,인공지능이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
196,train,1,머신러닝은 그럼 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
197,train,1,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
198,train,1,딥러닝에서 학습률이 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
199,train,1,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
200,train,1,자주 쓰는 Loss Function 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
201,train,1,Overfitting 이 뭔지 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
202,train,1,Overfitting 해결하는 방법은 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
203,train,1,전이학습이 뭐지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
204,train,1,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
205,train,1,활성화 함수? 그게 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
206,train,1,활성화 함수는 왜 필요해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
207,train,1,CNN이 뭐야? 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
208,train,1,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
209,train,1,cosine similarity가 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
210,train,2,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
211,train,2,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
212,train,2,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
213,train,2,Accuracy 는 어떻게 계산해?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
214,train,2,True Positive 같은 건 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
215,train,2,True Negative 는?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
216,train,2,False Positive 는 뭐지 그럼?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
217,train,2,False Negative 는 뭐야 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
218,train,2,Recall 은 어떻게 계산해?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
219,train,2,Recall 은 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
220,train,2,Precision 은 어떻게 계산하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
221,train,2,Recall 과 Precision 이 자꾸 헷갈리네,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
222,train,2,F1 이 뭔지 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
223,train,2,F1 Score 구하는 수식을 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
224,train,2,F1 Score 장점이 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
225,train,2,IoU 가 뭔지 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
226,train,2,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
227,train,2,이진 분류에서 쓰이는 Metric 을 알려줘!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
228,train,2,PR-AUC랑 ROC-AUC가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
229,train,2,PR-AUC가 뭔지 자세히 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
230,train,2,ROC-AUC가 뭔지 아주 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
231,train,2,True Positive Rate 가 뭐야? 궁금해!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
232,train,2,False Positive Rate 는 뭐지 그러면?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
233,train,2,Confusion Matrix 가 뭐야?,True Positive Rate : recall 의 다른 이름
234,train,2,Confusion Matrix 만드는 법을 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
235,train,2,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
236,train,2,Normalization 이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
237,train,2,정규화가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
238,train,2,min-max 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
239,train,2,Z score normalization 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
240,train,2,Clipping 에 대해서 자세히 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
241,train,2,Clipping 을 하면 뭐가 좋아?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
242,train,2,로그 스케일링이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
243,train,2,Outlier 가 뭔지 궁금해,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
244,train,2,이상치가 뭔지 궁금해,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
245,train,2,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
246,train,2,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
247,train,2,PCA 가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
248,train,2,주성분 분석이 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
249,train,2,PCA 는 왜 하는 거지 그러면?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
250,train,2,데이터 불균형이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
251,train,2,데이터 불균형 해결하는 법이 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
252,train,2,데이터를 새로 추가하거나 제거하는 법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
253,train,2,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
254,train,2,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
255,train,2,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
256,train,2,Undersampling 이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
257,train,2,그럼 Oversampling 은 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
258,train,2,데이터 불균형을 고려한 성능지표를 추천해 줘!,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
259,train,2,Undersampling 하는 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가
260,train,2,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
261,train,2,차원의 저주가 뭐지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
262,train,2,차원의 저주가 구체적으로 어떤 문제야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
263,train,2,Decision Tree 가 뭔지 자세히 알고 싶어,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
264,train,2,의사결정 나무,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
265,train,2,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
266,train,2,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
267,train,2,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
268,train,2,앙상블 하는 구체적인 방법 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
269,train,2,앙상블은 정확히 어떻게 하는 건지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
270,train,2,보팅에 대해 자세히 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
271,train,2,앙상블 중에 Voting 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
272,train,2,보팅의 방법에는 구체적으로 뭐가 있지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
273,train,2,Bagging 이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
274,train,2,그럼 Boosting 은 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
275,train,2,Stacking 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
276,train,2,Gaussian Mixture 모델이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
277,train,2,가우시안 혼합이 뭔지 궁금해,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
278,train,2,K-means Clustering 이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
279,train,2,K-means Clustering 의 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
280,train,2,kNN 에 대해 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
281,train,2,k Nearest Neighbor 알고리즘이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
282,train,2,지도학습 비지도학습 이런 게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
283,train,2,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
284,train,2,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
285,train,2,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
286,train,2,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
287,train,2,분류와 회귀 문제가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
288,train,2,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
289,train,2,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
290,train,2,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
291,train,2,SVM이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
292,train,2,K-fold Cross Validation,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
293,train,2,K-fold Cross Validation을 굳이 왜 하는 거야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
294,train,2,하이퍼파라미터가 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
295,train,2,One-hot 방식이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
296,train,2,Valid 데이터가 굳이 왜 필요하지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
297,train,2,Train 데이터셋을 왜 순서를 섞어야 돼?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
298,train,2,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
299,train,2,인공지능이 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
300,train,2,머신러닝은 그럼 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
301,train,2,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
302,train,2,딥러닝에서 학습률이 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
303,train,2,learning rate 가 뭔지 궁금해!,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
304,train,2,자주 쓰는 Loss Function 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
305,train,2,Overfitting 이 뭔지 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
306,train,2,Overfitting 해결하는 방법은 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
307,train,2,전이학습이 뭐지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
308,train,2,Transfer Learning 이 뭔지 궁금해!,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
309,train,2,활성화 함수? 그게 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
310,train,2,활성화 함수는 왜 필요해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
311,train,2,CNN이 뭐야? 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
312,train,2,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
313,train,2,cosine similarity가 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
314,train,2,코사인 유사도가 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
315,train,3,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
316,train,3,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
317,train,3,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
318,train,3,True Positive 같은 건 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
319,train,3,True Negative 는?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
320,train,3,False Positive 는 뭐지 그럼?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
321,train,3,False Negative 는 뭐야 그러면?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
322,train,3,Recall 은 어떻게 계산해?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
323,train,3,Recall 은 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
324,train,3,Precision 은 어떻게 계산하지,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
325,train,3,Recall 과 Precision 이 자꾸 헷갈리네,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
326,train,3,F1 이 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
327,train,3,F1 Score 구하는 수식을 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
328,train,3,F1 Score 장점이 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
329,train,3,IoU 가 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
330,train,3,특이도라는 걸 봤는데 그게 뭔지 궁금해!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
331,train,3,이진 분류에서 쓰이는 Metric 을 알려줘!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
332,train,3,PR-AUC랑 ROC-AUC가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
333,train,3,PR-AUC가 뭔지 자세히 알려줘!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
334,train,3,ROC-AUC가 뭔지 아주 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
335,train,3,True Positive Rate 가 뭐야? 궁금해!,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
336,train,3,False Positive Rate 는 뭐지 그러면?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
337,train,3,Confusion Matrix 가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
338,train,3,Confusion Matrix 만드는 법을 알려줘,True Positive Rate : recall 의 다른 이름
339,train,3,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
340,train,3,Normalization 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
341,train,3,정규화가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
342,train,3,min-max 정규화가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
343,train,3,Z score normalization 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
344,train,3,Clipping 에 대해서 자세히 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
345,train,3,Clipping 을 하면 뭐가 좋아?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
346,train,3,로그 스케일링이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
347,train,3,Outlier 가 뭔지 궁금해,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
348,train,3,이상치가 뭔지 궁금해,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
349,train,3,Outlier 를 제거해야 하는 이유는 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
350,train,3,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
351,train,3,PCA 가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
352,train,3,주성분 분석이 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
353,train,3,PCA 는 왜 하는 거지 그러면?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
354,train,3,데이터 불균형이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
355,train,3,데이터 불균형 해결하는 법이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
356,train,3,데이터를 새로 추가하거나 제거하는 법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
357,train,3,그러면 학습 환경만 바꾸는 방법은 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
358,train,3,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
359,train,3,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
360,train,3,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
361,train,3,그럼 Oversampling 은 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
362,train,3,데이터 불균형을 고려한 성능지표를 추천해 줘!,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
363,train,3,Undersampling 하는 방법 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
364,train,3,Oversampling 방법은 어떤 게 있어?,Oversampling : 데이터가 적은 Class 의 데이터 증가
365,train,3,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
366,train,3,차원의 저주가 구체적으로 어떤 문제야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
367,train,3,Decision Tree 가 뭔지 자세히 알고 싶어,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
368,train,3,의사결정 나무,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
369,train,3,Decision Tree 로 결정하는 방법은?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
370,train,3,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
371,train,3,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
372,train,3,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
373,train,3,앙상블은 정확히 어떻게 하는 건지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
374,train,3,보팅에 대해 자세히 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
375,train,3,앙상블 중에 Voting 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
376,train,3,보팅의 방법에는 구체적으로 뭐가 있지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
377,train,3,Bagging 이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
378,train,3,그럼 Boosting 은 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
379,train,3,Stacking 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
380,train,3,Gaussian Mixture 모델이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
381,train,3,가우시안 혼합이 뭔지 궁금해,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
382,train,3,K-means Clustering 이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
383,train,3,K-means Clustering 의 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
384,train,3,kNN 에 대해 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
385,train,3,k Nearest Neighbor 알고리즘이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
386,train,3,지도학습 비지도학습 이런 게 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
387,train,3,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
388,train,3,강화학습? 지도학습? 그게 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
389,train,3,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
390,train,3,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
391,train,3,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
392,train,3,Regression 이랑 Classification 이 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
393,train,3,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
394,train,3,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
395,train,3,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
396,train,3,K-fold Cross Validation,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
397,train,3,K-fold Cross Validation을 굳이 왜 하는 거야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
398,train,3,하이퍼파라미터가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
399,train,3,One-hot 방식이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
400,train,3,Valid 데이터가 굳이 왜 필요하지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
401,train,3,Train 데이터셋을 왜 순서를 섞어야 돼?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
402,train,3,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
403,train,3,인공지능이 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
404,train,3,머신러닝은 그럼 뭐지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
405,train,3,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
406,train,3,딥러닝에서 학습률이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
407,train,3,learning rate 가 뭔지 궁금해!,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
408,train,3,자주 쓰는 Loss Function 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
409,train,3,Overfitting 이 뭔지 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
410,train,3,Overfitting 해결하는 방법은 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
411,train,3,전이학습이 뭐지?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
412,train,3,Transfer Learning 이 뭔지 궁금해!,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
413,train,3,활성화 함수? 그게 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
414,train,3,활성화 함수는 왜 필요해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
415,train,3,CNN이 뭐야? 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
416,train,3,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
417,train,3,cosine similarity가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
418,train,3,코사인 유사도가 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
419,train,3,코사인 유사도 계산법 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
420,train,4,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
421,train,4,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
422,train,4,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
423,train,4,True Negative 는?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
424,train,4,False Positive 는 뭐지 그럼?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
425,train,4,False Negative 는 뭐야 그러면?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
426,train,4,Recall 은 어떻게 계산해?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
427,train,4,Recall 은 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
428,train,4,Precision 은 어떻게 계산하지,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
429,train,4,Recall 과 Precision 이 자꾸 헷갈리네,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
430,train,4,F1 이 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
431,train,4,F1 Score 구하는 수식을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
432,train,4,F1 Score 장점이 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
433,train,4,IoU 가 뭔지 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
434,train,4,특이도라는 걸 봤는데 그게 뭔지 궁금해!,F1 Score 개념 : Recall 과 Precision 의 조화 평균
435,train,4,이진 분류에서 쓰이는 Metric 을 알려줘!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
436,train,4,PR-AUC랑 ROC-AUC가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
437,train,4,PR-AUC가 뭔지 자세히 알려줘!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
438,train,4,ROC-AUC가 뭔지 아주 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
439,train,4,True Positive Rate 가 뭐야? 궁금해!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
440,train,4,False Positive Rate 는 뭐지 그러면?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
441,train,4,Confusion Matrix 가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
442,train,4,Confusion Matrix 만드는 법을 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
443,train,4,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",True Positive Rate : recall 의 다른 이름
444,train,4,Normalization 이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
445,train,4,정규화가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
446,train,4,min-max 정규화가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
447,train,4,Z score normalization 이 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
448,train,4,Clipping 에 대해서 자세히 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
449,train,4,Clipping 을 하면 뭐가 좋아?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
450,train,4,로그 스케일링이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
451,train,4,Outlier 가 뭔지 궁금해,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
452,train,4,이상치가 뭔지 궁금해,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
453,train,4,Outlier 를 제거해야 하는 이유는 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
454,train,4,Outlier 를 제거하는 방법에 대해 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
455,train,4,PCA 가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
456,train,4,주성분 분석이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
457,train,4,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
458,train,4,데이터 불균형이 뭔지 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
459,train,4,데이터 불균형 해결하는 법이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
460,train,4,데이터를 새로 추가하거나 제거하는 법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
461,train,4,그러면 학습 환경만 바꾸는 방법은 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
462,train,4,Augmentation 이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
463,train,4,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
464,train,4,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
465,train,4,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
466,train,4,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
467,train,4,Undersampling 하는 방법 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
468,train,4,Oversampling 방법은 어떤 게 있어?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
469,train,4,차원의 저주가 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가
470,train,4,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
471,train,4,Decision Tree 가 뭔지 자세히 알고 싶어,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
472,train,4,의사결정 나무,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
473,train,4,Decision Tree 로 결정하는 방법은?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
474,train,4,앙상블이 뭔지 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
475,train,4,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
476,train,4,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
477,train,4,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
478,train,4,보팅에 대해 자세히 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
479,train,4,앙상블 중에 Voting 이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
480,train,4,보팅의 방법에는 구체적으로 뭐가 있지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
481,train,4,Bagging 이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
482,train,4,그럼 Boosting 은 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
483,train,4,Stacking 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
484,train,4,Gaussian Mixture 모델이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
485,train,4,가우시안 혼합이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
486,train,4,K-means Clustering 이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
487,train,4,K-means Clustering 의 방법을 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
488,train,4,kNN 에 대해 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
489,train,4,k Nearest Neighbor 알고리즘이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
490,train,4,지도학습 비지도학습 이런 게 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
491,train,4,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
492,train,4,강화학습? 지도학습? 그게 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
493,train,4,지도학습과 비지도학습의 차이가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
494,train,4,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
495,train,4,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
496,train,4,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
497,train,4,Naïve Bayes 가 뭔지 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
498,train,4,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
499,train,4,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
500,train,4,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
501,train,4,K-fold Cross Validation을 굳이 왜 하는 거야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
502,train,4,하이퍼파라미터가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
503,train,4,One-hot 방식이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
504,train,4,Valid 데이터가 굳이 왜 필요하지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
505,train,4,Train 데이터셋을 왜 순서를 섞어야 돼?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
506,train,4,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
507,train,4,인공지능이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
508,train,4,머신러닝은 그럼 뭐지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
509,train,4,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
510,train,4,딥러닝에서 학습률이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
511,train,4,learning rate 가 뭔지 궁금해!,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
512,train,4,자주 쓰는 Loss Function 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
513,train,4,Overfitting 이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
514,train,4,Overfitting 해결하는 방법은 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
515,train,4,전이학습이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
516,train,4,Transfer Learning 이 뭔지 궁금해!,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
517,train,4,활성화 함수? 그게 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
518,train,4,활성화 함수는 왜 필요해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
519,train,4,CNN이 뭐야? 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
520,train,4,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
521,train,4,cosine similarity가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
522,train,4,코사인 유사도가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
523,train,4,코사인 유사도 계산법 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
524,train,4,코사인 유사도의 특징을 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
525,train,5,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
526,train,5,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
527,train,5,True Negative 는?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
528,train,5,False Positive 는 뭐지 그럼?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
529,train,5,False Negative 는 뭐야 그러면?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
530,train,5,Recall 은 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
531,train,5,Recall 은 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
532,train,5,Precision 은 어떻게 계산하지,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
533,train,5,Recall 과 Precision 이 자꾸 헷갈리네,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
534,train,5,F1 이 뭔지 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
535,train,5,F1 Score 구하는 수식을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
536,train,5,F1 Score 장점이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
537,train,5,IoU 가 뭔지 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
538,train,5,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
539,train,5,이진 분류에서 쓰이는 Metric 을 알려줘!,F1 Score 개념 : Recall 과 Precision 의 조화 평균
540,train,5,PR-AUC랑 ROC-AUC가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
541,train,5,PR-AUC가 뭔지 자세히 알려줘!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
542,train,5,ROC-AUC가 뭔지 아주 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
543,train,5,True Positive Rate 가 뭐야? 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
544,train,5,False Positive Rate 는 뭐지 그러면?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
545,train,5,Confusion Matrix 가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
546,train,5,Confusion Matrix 만드는 법을 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
547,train,5,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
548,train,5,Normalization 이 뭐야?,True Positive Rate : recall 의 다른 이름
549,train,5,정규화가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
550,train,5,min-max 정규화가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
551,train,5,Z score normalization 이 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
552,train,5,Clipping 에 대해서 자세히 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
553,train,5,Clipping 을 하면 뭐가 좋아?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
554,train,5,로그 스케일링이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
555,train,5,Outlier 가 뭔지 궁금해,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
556,train,5,이상치가 뭔지 궁금해,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
557,train,5,Outlier 를 제거해야 하는 이유는 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
558,train,5,Outlier 를 제거하는 방법에 대해 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
559,train,5,PCA 가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
560,train,5,주성분 분석이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
561,train,5,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
562,train,5,데이터 불균형이 뭔지 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
563,train,5,데이터 불균형 해결하는 법이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
564,train,5,데이터를 새로 추가하거나 제거하는 법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
565,train,5,그러면 학습 환경만 바꾸는 방법은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
566,train,5,Augmentation 이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
567,train,5,Undersampling 이랑 Oversampling 이 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
568,train,5,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
569,train,5,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
570,train,5,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
571,train,5,Undersampling 하는 방법 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
572,train,5,Oversampling 방법은 어떤 게 있어?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
573,train,5,차원의 저주가 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
574,train,5,차원의 저주가 구체적으로 어떤 문제야?,Oversampling : 데이터가 적은 Class 의 데이터 증가
575,train,5,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
576,train,5,의사결정 나무,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
577,train,5,Decision Tree 로 결정하는 방법은?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
578,train,5,앙상블이 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
579,train,5,앙상블을 왜 하는 거야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
580,train,5,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
581,train,5,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
582,train,5,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
583,train,5,앙상블 중에 Voting 이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
584,train,5,보팅의 방법에는 구체적으로 뭐가 있지?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
585,train,5,Bagging 이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
586,train,5,그럼 Boosting 은 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
587,train,5,Stacking 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
588,train,5,Gaussian Mixture 모델이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
589,train,5,가우시안 혼합이 뭔지 궁금해,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
590,train,5,K-means Clustering 이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
591,train,5,K-means Clustering 의 방법을 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
592,train,5,kNN 에 대해 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
593,train,5,k Nearest Neighbor 알고리즘이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
594,train,5,지도학습 비지도학습 이런 게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
595,train,5,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
596,train,5,강화학습? 지도학습? 그게 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
597,train,5,지도학습과 비지도학습의 차이가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
598,train,5,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
599,train,5,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
600,train,5,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
601,train,5,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
602,train,5,서포트 벡터 머신이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
603,train,5,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
604,train,5,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
605,train,5,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
606,train,5,하이퍼파라미터가 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
607,train,5,One-hot 방식이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
608,train,5,Valid 데이터가 굳이 왜 필요하지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
609,train,5,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
610,train,5,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
611,train,5,인공지능이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
612,train,5,머신러닝은 그럼 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
613,train,5,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
614,train,5,딥러닝에서 학습률이 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
615,train,5,learning rate 가 뭔지 궁금해!,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
616,train,5,자주 쓰는 Loss Function 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
617,train,5,Overfitting 이 뭔지 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
618,train,5,Overfitting 해결하는 방법은 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
619,train,5,전이학습이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
620,train,5,Transfer Learning 이 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
621,train,5,활성화 함수? 그게 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
622,train,5,활성화 함수는 왜 필요해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
623,train,5,CNN이 뭐야? 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
624,train,5,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
625,train,5,cosine similarity가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
626,train,5,코사인 유사도가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
627,train,5,코사인 유사도 계산법 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
628,train,5,코사인 유사도의 특징을 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
629,train,5,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
630,train,6,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
631,train,6,True Negative 는?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
632,train,6,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
633,train,6,False Negative 는 뭐야 그러면?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
634,train,6,Recall 은 어떻게 계산해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
635,train,6,Recall 은 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
636,train,6,Precision 은 어떻게 계산하지,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
637,train,6,Recall 과 Precision 이 자꾸 헷갈리네,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
638,train,6,F1 이 뭔지 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
639,train,6,F1 Score 구하는 수식을 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
640,train,6,F1 Score 장점이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
641,train,6,IoU 가 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
642,train,6,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
643,train,6,이진 분류에서 쓰이는 Metric 을 알려줘!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
644,train,6,PR-AUC랑 ROC-AUC가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
645,train,6,PR-AUC가 뭔지 자세히 알려줘!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
646,train,6,ROC-AUC가 뭔지 아주 자세히 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
647,train,6,True Positive Rate 가 뭐야? 궁금해!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
648,train,6,False Positive Rate 는 뭐지 그러면?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
649,train,6,Confusion Matrix 가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
650,train,6,Confusion Matrix 만드는 법을 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
651,train,6,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
652,train,6,Normalization 이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
653,train,6,정규화가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름
654,train,6,min-max 정규화가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
655,train,6,Z score normalization 이 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
656,train,6,Clipping 에 대해서 자세히 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
657,train,6,Clipping 을 하면 뭐가 좋아?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
658,train,6,로그 스케일링이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
659,train,6,Outlier 가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
660,train,6,이상치가 뭔지 궁금해,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
661,train,6,Outlier 를 제거해야 하는 이유는 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
662,train,6,Outlier 를 제거하는 방법에 대해 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
663,train,6,PCA 가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
664,train,6,주성분 분석이 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
665,train,6,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
666,train,6,데이터 불균형이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
667,train,6,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
668,train,6,데이터를 새로 추가하거나 제거하는 법 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
669,train,6,그러면 학습 환경만 바꾸는 방법은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
670,train,6,Augmentation 이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
671,train,6,Undersampling 이랑 Oversampling 이 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
672,train,6,Undersampling 이 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
673,train,6,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
674,train,6,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
675,train,6,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
676,train,6,Oversampling 방법은 어떤 게 있어?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
677,train,6,차원의 저주가 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
678,train,6,차원의 저주가 구체적으로 어떤 문제야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
679,train,6,Decision Tree 가 뭔지 자세히 알고 싶어,Oversampling : 데이터가 적은 Class 의 데이터 증가
680,train,6,의사결정 나무,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
681,train,6,Decision Tree 로 결정하는 방법은?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
682,train,6,앙상블이 뭔지 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
683,train,6,앙상블을 왜 하는 거야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
684,train,6,앙상블 하는 구체적인 방법 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
685,train,6,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
686,train,6,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
687,train,6,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
688,train,6,보팅의 방법에는 구체적으로 뭐가 있지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
689,train,6,Bagging 이 뭔지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
690,train,6,그럼 Boosting 은 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
691,train,6,Stacking 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
692,train,6,Gaussian Mixture 모델이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
693,train,6,가우시안 혼합이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
694,train,6,K-means Clustering 이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
695,train,6,K-means Clustering 의 방법을 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
696,train,6,kNN 에 대해 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
697,train,6,k Nearest Neighbor 알고리즘이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
698,train,6,지도학습 비지도학습 이런 게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
699,train,6,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
700,train,6,강화학습? 지도학습? 그게 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
701,train,6,지도학습과 비지도학습의 차이가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
702,train,6,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
703,train,6,분류와 회귀 문제가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
704,train,6,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
705,train,6,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
706,train,6,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
707,train,6,SVM이 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
708,train,6,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
709,train,6,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
710,train,6,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
711,train,6,One-hot 방식이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
712,train,6,Valid 데이터가 굳이 왜 필요하지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
713,train,6,Train 데이터셋을 왜 순서를 섞어야 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
714,train,6,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
715,train,6,인공지능이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
716,train,6,머신러닝은 그럼 뭐지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
717,train,6,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
718,train,6,딥러닝에서 학습률이 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
719,train,6,learning rate 가 뭔지 궁금해!,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
720,train,6,자주 쓰는 Loss Function 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
721,train,6,Overfitting 이 뭔지 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
722,train,6,Overfitting 해결하는 방법은 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
723,train,6,전이학습이 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
724,train,6,Transfer Learning 이 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
725,train,6,활성화 함수? 그게 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
726,train,6,활성화 함수는 왜 필요해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
727,train,6,CNN이 뭐야? 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
728,train,6,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
729,train,6,cosine similarity가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
730,train,6,코사인 유사도가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
731,train,6,코사인 유사도 계산법 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
732,train,6,코사인 유사도의 특징을 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
733,train,6,머신러닝에서 많이 쓰이는 평가지표 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
734,train,6,Accuracy 는 어떻게 계산해?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
735,train,7,True Negative 는?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
736,train,7,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
737,train,7,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
738,train,7,Recall 은 어떻게 계산해?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
739,train,7,Recall 은 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
740,train,7,Precision 은 어떻게 계산하지,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
741,train,7,Recall 과 Precision 이 자꾸 헷갈리네,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
742,train,7,F1 이 뭔지 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
743,train,7,F1 Score 구하는 수식을 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
744,train,7,F1 Score 장점이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
745,train,7,IoU 가 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
746,train,7,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
747,train,7,이진 분류에서 쓰이는 Metric 을 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
748,train,7,PR-AUC랑 ROC-AUC가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
749,train,7,PR-AUC가 뭔지 자세히 알려줘!,F1 Score 개념 : Recall 과 Precision 의 조화 평균
750,train,7,ROC-AUC가 뭔지 아주 자세히 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
751,train,7,True Positive Rate 가 뭐야? 궁금해!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
752,train,7,False Positive Rate 는 뭐지 그러면?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
753,train,7,Confusion Matrix 가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
754,train,7,Confusion Matrix 만드는 법을 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
755,train,7,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
756,train,7,Normalization 이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
757,train,7,정규화가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
758,train,7,min-max 정규화가 뭐야?,True Positive Rate : recall 의 다른 이름
759,train,7,Z score normalization 이 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
760,train,7,Clipping 에 대해서 자세히 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
761,train,7,Clipping 을 하면 뭐가 좋아?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
762,train,7,로그 스케일링이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
763,train,7,Outlier 가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
764,train,7,이상치가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
765,train,7,Outlier 를 제거해야 하는 이유는 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
766,train,7,Outlier 를 제거하는 방법에 대해 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
767,train,7,PCA 가 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
768,train,7,주성분 분석이 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
769,train,7,PCA 는 왜 하는 거지 그러면?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
770,train,7,데이터 불균형이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
771,train,7,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
772,train,7,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
773,train,7,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
774,train,7,Augmentation 이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
775,train,7,Undersampling 이랑 Oversampling 이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
776,train,7,Undersampling 이 뭐지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
777,train,7,그럼 Oversampling 은 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
778,train,7,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
779,train,7,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
780,train,7,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
781,train,7,차원의 저주가 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
782,train,7,차원의 저주가 구체적으로 어떤 문제야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
783,train,7,Decision Tree 가 뭔지 자세히 알고 싶어,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
784,train,7,의사결정 나무,Oversampling : 데이터가 적은 Class 의 데이터 증가
785,train,7,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
786,train,7,앙상블이 뭔지 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
787,train,7,앙상블을 왜 하는 거야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
788,train,7,앙상블 하는 구체적인 방법 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
789,train,7,앙상블은 정확히 어떻게 하는 건지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
790,train,7,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
791,train,7,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
792,train,7,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
793,train,7,Bagging 이 뭔지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
794,train,7,그럼 Boosting 은 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
795,train,7,Stacking 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
796,train,7,Gaussian Mixture 모델이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
797,train,7,가우시안 혼합이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
798,train,7,K-means Clustering 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
799,train,7,K-means Clustering 의 방법을 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
800,train,7,kNN 에 대해 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
801,train,7,k Nearest Neighbor 알고리즘이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
802,train,7,지도학습 비지도학습 이런 게 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
803,train,7,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
804,train,7,강화학습? 지도학습? 그게 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
805,train,7,지도학습과 비지도학습의 차이가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
806,train,7,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
807,train,7,분류와 회귀 문제가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
808,train,7,Regression 이랑 Classification 이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
809,train,7,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
810,train,7,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
811,train,7,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
812,train,7,K-fold Cross Validation,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
813,train,7,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
814,train,7,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
815,train,7,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
816,train,7,Valid 데이터가 굳이 왜 필요하지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
817,train,7,Train 데이터셋을 왜 순서를 섞어야 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
818,train,7,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
819,train,7,인공지능이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
820,train,7,머신러닝은 그럼 뭐지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
821,train,7,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
822,train,7,딥러닝에서 학습률이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
823,train,7,learning rate 가 뭔지 궁금해!,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
824,train,7,자주 쓰는 Loss Function 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
825,train,7,Overfitting 이 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
826,train,7,Overfitting 해결하는 방법은 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
827,train,7,전이학습이 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
828,train,7,Transfer Learning 이 뭔지 궁금해!,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
829,train,7,활성화 함수? 그게 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
830,train,7,활성화 함수는 왜 필요해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
831,train,7,CNN이 뭐야? 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
832,train,7,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
833,train,7,cosine similarity가 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
834,train,7,코사인 유사도가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
835,train,7,코사인 유사도 계산법 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
836,train,7,코사인 유사도의 특징을 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
837,train,7,머신러닝에서 많이 쓰이는 평가지표 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
838,train,7,Accuracy 는 어떻게 계산해?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
839,train,7,True Positive 같은 건 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
840,train,8,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
841,train,8,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
842,train,8,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
843,train,8,Recall 은 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
844,train,8,Precision 은 어떻게 계산하지,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
845,train,8,Recall 과 Precision 이 자꾸 헷갈리네,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
846,train,8,F1 이 뭔지 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
847,train,8,F1 Score 구하는 수식을 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
848,train,8,F1 Score 장점이 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
849,train,8,IoU 가 뭔지 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
850,train,8,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
851,train,8,이진 분류에서 쓰이는 Metric 을 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
852,train,8,PR-AUC랑 ROC-AUC가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
853,train,8,PR-AUC가 뭔지 자세히 알려줘!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
854,train,8,ROC-AUC가 뭔지 아주 자세히 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
855,train,8,True Positive Rate 가 뭐야? 궁금해!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
856,train,8,False Positive Rate 는 뭐지 그러면?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
857,train,8,Confusion Matrix 가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
858,train,8,Confusion Matrix 만드는 법을 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
859,train,8,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
860,train,8,Normalization 이 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
861,train,8,정규화가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
862,train,8,min-max 정규화가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
863,train,8,Z score normalization 이 뭐지?,True Positive Rate : recall 의 다른 이름
864,train,8,Clipping 에 대해서 자세히 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
865,train,8,Clipping 을 하면 뭐가 좋아?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
866,train,8,로그 스케일링이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
867,train,8,Outlier 가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
868,train,8,이상치가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
869,train,8,Outlier 를 제거해야 하는 이유는 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
870,train,8,Outlier 를 제거하는 방법에 대해 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
871,train,8,PCA 가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
872,train,8,주성분 분석이 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
873,train,8,PCA 는 왜 하는 거지 그러면?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
874,train,8,데이터 불균형이 뭔지 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
875,train,8,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
876,train,8,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
877,train,8,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
878,train,8,Augmentation 이 뭔지 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
879,train,8,Undersampling 이랑 Oversampling 이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
880,train,8,Undersampling 이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
881,train,8,그럼 Oversampling 은 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
882,train,8,데이터 불균형을 고려한 성능지표를 추천해 줘!,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
883,train,8,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
884,train,8,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
885,train,8,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
886,train,8,차원의 저주가 구체적으로 어떤 문제야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
887,train,8,Decision Tree 가 뭔지 자세히 알고 싶어,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
888,train,8,의사결정 나무,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
889,train,8,Decision Tree 로 결정하는 방법은?,Oversampling : 데이터가 적은 Class 의 데이터 증가
890,train,8,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
891,train,8,앙상블을 왜 하는 거야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
892,train,8,앙상블 하는 구체적인 방법 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
893,train,8,앙상블은 정확히 어떻게 하는 건지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
894,train,8,보팅에 대해 자세히 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
895,train,8,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
896,train,8,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
897,train,8,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
898,train,8,그럼 Boosting 은 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
899,train,8,Stacking 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
900,train,8,Gaussian Mixture 모델이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
901,train,8,가우시안 혼합이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
902,train,8,K-means Clustering 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
903,train,8,K-means Clustering 의 방법을 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
904,train,8,kNN 에 대해 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
905,train,8,k Nearest Neighbor 알고리즘이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
906,train,8,지도학습 비지도학습 이런 게 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
907,train,8,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
908,train,8,강화학습? 지도학습? 그게 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
909,train,8,지도학습과 비지도학습의 차이가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
910,train,8,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
911,train,8,분류와 회귀 문제가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
912,train,8,Regression 이랑 Classification 이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
913,train,8,Naïve Bayes 가 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
914,train,8,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
915,train,8,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
916,train,8,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
917,train,8,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
918,train,8,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
919,train,8,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
920,train,8,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
921,train,8,Train 데이터셋을 왜 순서를 섞어야 돼?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
922,train,8,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
923,train,8,인공지능이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
924,train,8,머신러닝은 그럼 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
925,train,8,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
926,train,8,딥러닝에서 학습률이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
927,train,8,learning rate 가 뭔지 궁금해!,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
928,train,8,자주 쓰는 Loss Function 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
929,train,8,Overfitting 이 뭔지 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
930,train,8,Overfitting 해결하는 방법은 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
931,train,8,전이학습이 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
932,train,8,Transfer Learning 이 뭔지 궁금해!,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
933,train,8,활성화 함수? 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
934,train,8,활성화 함수는 왜 필요해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
935,train,8,CNN이 뭐야? 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
936,train,8,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
937,train,8,cosine similarity가 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
938,train,8,코사인 유사도가 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
939,train,8,코사인 유사도 계산법 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
940,train,8,코사인 유사도의 특징을 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
941,train,8,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
942,train,8,Accuracy 는 어떻게 계산해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
943,train,8,True Positive 같은 건 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
944,train,8,True Negative 는?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
945,train,9,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
946,train,9,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
947,train,9,Recall 은 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
948,train,9,Precision 은 어떻게 계산하지,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
949,train,9,Recall 과 Precision 이 자꾸 헷갈리네,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
950,train,9,F1 이 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
951,train,9,F1 Score 구하는 수식을 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
952,train,9,F1 Score 장점이 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
953,train,9,IoU 가 뭔지 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
954,train,9,특이도라는 걸 봤는데 그게 뭔지 궁금해!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
955,train,9,이진 분류에서 쓰이는 Metric 을 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
956,train,9,PR-AUC랑 ROC-AUC가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
957,train,9,PR-AUC가 뭔지 자세히 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
958,train,9,ROC-AUC가 뭔지 아주 자세히 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
959,train,9,True Positive Rate 가 뭐야? 궁금해!,F1 Score 개념 : Recall 과 Precision 의 조화 평균
960,train,9,False Positive Rate 는 뭐지 그러면?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
961,train,9,Confusion Matrix 가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
962,train,9,Confusion Matrix 만드는 법을 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
963,train,9,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
964,train,9,Normalization 이 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
965,train,9,정규화가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
966,train,9,min-max 정규화가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
967,train,9,Z score normalization 이 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
968,train,9,Clipping 에 대해서 자세히 알려줘,True Positive Rate : recall 의 다른 이름
969,train,9,Clipping 을 하면 뭐가 좋아?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
970,train,9,로그 스케일링이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
971,train,9,Outlier 가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
972,train,9,이상치가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
973,train,9,Outlier 를 제거해야 하는 이유는 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
974,train,9,Outlier 를 제거하는 방법에 대해 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
975,train,9,PCA 가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
976,train,9,주성분 분석이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
977,train,9,PCA 는 왜 하는 거지 그러면?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
978,train,9,데이터 불균형이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
979,train,9,데이터 불균형 해결하는 법이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
980,train,9,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
981,train,9,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
982,train,9,Augmentation 이 뭔지 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
983,train,9,Undersampling 이랑 Oversampling 이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
984,train,9,Undersampling 이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
985,train,9,그럼 Oversampling 은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
986,train,9,데이터 불균형을 고려한 성능지표를 추천해 줘!,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
987,train,9,Undersampling 하는 방법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
988,train,9,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
989,train,9,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
990,train,9,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
991,train,9,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
992,train,9,의사결정 나무,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
993,train,9,Decision Tree 로 결정하는 방법은?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
994,train,9,앙상블이 뭔지 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가
995,train,9,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
996,train,9,앙상블 하는 구체적인 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
997,train,9,앙상블은 정확히 어떻게 하는 건지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
998,train,9,보팅에 대해 자세히 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
999,train,9,앙상블 중에 Voting 이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1000,train,9,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1001,train,9,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1002,train,9,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1003,train,9,Stacking 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1004,train,9,Gaussian Mixture 모델이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1005,train,9,가우시안 혼합이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1006,train,9,K-means Clustering 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1007,train,9,K-means Clustering 의 방법을 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1008,train,9,kNN 에 대해 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1009,train,9,k Nearest Neighbor 알고리즘이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1010,train,9,지도학습 비지도학습 이런 게 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1011,train,9,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1012,train,9,강화학습? 지도학습? 그게 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1013,train,9,지도학습과 비지도학습의 차이가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1014,train,9,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1015,train,9,분류와 회귀 문제가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1016,train,9,Regression 이랑 Classification 이 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1017,train,9,Naïve Bayes 가 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1018,train,9,서포트 벡터 머신이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1019,train,9,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1020,train,9,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1021,train,9,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1022,train,9,하이퍼파라미터가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1023,train,9,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1024,train,9,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1025,train,9,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1026,train,9,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1027,train,9,인공지능이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1028,train,9,머신러닝은 그럼 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1029,train,9,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1030,train,9,딥러닝에서 학습률이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1031,train,9,learning rate 가 뭔지 궁금해!,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1032,train,9,자주 쓰는 Loss Function 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1033,train,9,Overfitting 이 뭔지 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1034,train,9,Overfitting 해결하는 방법은 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1035,train,9,전이학습이 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1036,train,9,Transfer Learning 이 뭔지 궁금해!,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1037,train,9,활성화 함수? 그게 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1038,train,9,활성화 함수는 왜 필요해?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1039,train,9,CNN이 뭐야? 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1040,train,9,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1041,train,9,cosine similarity가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1042,train,9,코사인 유사도가 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1043,train,9,코사인 유사도 계산법 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1044,train,9,코사인 유사도의 특징을 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1045,train,9,머신러닝에서 많이 쓰이는 평가지표 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1046,train,9,Accuracy 는 어떻게 계산해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1047,train,9,True Positive 같은 건 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1048,train,9,True Negative 는?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1049,train,9,False Positive 는 뭐지 그럼?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1050,train,10,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1051,train,10,Recall 은 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1052,train,10,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1053,train,10,Recall 과 Precision 이 자꾸 헷갈리네,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1054,train,10,F1 이 뭔지 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1055,train,10,F1 Score 구하는 수식을 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1056,train,10,F1 Score 장점이 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1057,train,10,IoU 가 뭔지 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1058,train,10,특이도라는 걸 봤는데 그게 뭔지 궁금해!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1059,train,10,이진 분류에서 쓰이는 Metric 을 알려줘!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1060,train,10,PR-AUC랑 ROC-AUC가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1061,train,10,PR-AUC가 뭔지 자세히 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1062,train,10,ROC-AUC가 뭔지 아주 자세히 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1063,train,10,True Positive Rate 가 뭐야? 궁금해!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1064,train,10,False Positive Rate 는 뭐지 그러면?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1065,train,10,Confusion Matrix 가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1066,train,10,Confusion Matrix 만드는 법을 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1067,train,10,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1068,train,10,Normalization 이 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1069,train,10,정규화가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1070,train,10,min-max 정규화가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1071,train,10,Z score normalization 이 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1072,train,10,Clipping 에 대해서 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1073,train,10,Clipping 을 하면 뭐가 좋아?,True Positive Rate : recall 의 다른 이름
1074,train,10,로그 스케일링이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1075,train,10,Outlier 가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1076,train,10,이상치가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1077,train,10,Outlier 를 제거해야 하는 이유는 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1078,train,10,Outlier 를 제거하는 방법에 대해 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1079,train,10,PCA 가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1080,train,10,주성분 분석이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1081,train,10,PCA 는 왜 하는 거지 그러면?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1082,train,10,데이터 불균형이 뭔지 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1083,train,10,데이터 불균형 해결하는 법이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1084,train,10,데이터를 새로 추가하거나 제거하는 법 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1085,train,10,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1086,train,10,Augmentation 이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1087,train,10,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1088,train,10,Undersampling 이 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1089,train,10,그럼 Oversampling 은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1090,train,10,데이터 불균형을 고려한 성능지표를 추천해 줘!,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1091,train,10,Undersampling 하는 방법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1092,train,10,Oversampling 방법은 어떤 게 있어?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1093,train,10,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1094,train,10,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1095,train,10,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1096,train,10,의사결정 나무,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1097,train,10,Decision Tree 로 결정하는 방법은?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1098,train,10,앙상블이 뭔지 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1099,train,10,앙상블을 왜 하는 거야?,Oversampling : 데이터가 적은 Class 의 데이터 증가
1100,train,10,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1101,train,10,앙상블은 정확히 어떻게 하는 건지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1102,train,10,보팅에 대해 자세히 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1103,train,10,앙상블 중에 Voting 이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1104,train,10,보팅의 방법에는 구체적으로 뭐가 있지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1105,train,10,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1106,train,10,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1107,train,10,Stacking 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1108,train,10,Gaussian Mixture 모델이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1109,train,10,가우시안 혼합이 뭔지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1110,train,10,K-means Clustering 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1111,train,10,K-means Clustering 의 방법을 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1112,train,10,kNN 에 대해 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1113,train,10,k Nearest Neighbor 알고리즘이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1114,train,10,지도학습 비지도학습 이런 게 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1115,train,10,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1116,train,10,강화학습? 지도학습? 그게 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1117,train,10,지도학습과 비지도학습의 차이가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1118,train,10,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1119,train,10,분류와 회귀 문제가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1120,train,10,Regression 이랑 Classification 이 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1121,train,10,Naïve Bayes 가 뭔지 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1122,train,10,서포트 벡터 머신이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1123,train,10,SVM이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1124,train,10,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1125,train,10,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1126,train,10,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1127,train,10,One-hot 방식이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1128,train,10,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1129,train,10,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1130,train,10,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1131,train,10,인공지능이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1132,train,10,머신러닝은 그럼 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1133,train,10,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1134,train,10,딥러닝에서 학습률이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1135,train,10,learning rate 가 뭔지 궁금해!,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1136,train,10,자주 쓰는 Loss Function 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1137,train,10,Overfitting 이 뭔지 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1138,train,10,Overfitting 해결하는 방법은 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1139,train,10,전이학습이 뭐지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1140,train,10,Transfer Learning 이 뭔지 궁금해!,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1141,train,10,활성화 함수? 그게 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1142,train,10,활성화 함수는 왜 필요해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1143,train,10,CNN이 뭐야? 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1144,train,10,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1145,train,10,cosine similarity가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1146,train,10,코사인 유사도가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1147,train,10,코사인 유사도 계산법 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1148,train,10,코사인 유사도의 특징을 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1149,train,10,머신러닝에서 많이 쓰이는 평가지표 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1150,train,10,Accuracy 는 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1151,train,10,True Positive 같은 건 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1152,train,10,True Negative 는?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1153,train,10,False Positive 는 뭐지 그럼?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1154,train,10,False Negative 는 뭐야 그러면?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1155,train,11,Recall 은 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1156,train,11,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1157,train,11,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1158,train,11,F1 이 뭔지 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1159,train,11,F1 Score 구하는 수식을 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1160,train,11,F1 Score 장점이 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1161,train,11,IoU 가 뭔지 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1162,train,11,특이도라는 걸 봤는데 그게 뭔지 궁금해!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1163,train,11,이진 분류에서 쓰이는 Metric 을 알려줘!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1164,train,11,PR-AUC랑 ROC-AUC가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1165,train,11,PR-AUC가 뭔지 자세히 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1166,train,11,ROC-AUC가 뭔지 아주 자세히 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1167,train,11,True Positive Rate 가 뭐야? 궁금해!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1168,train,11,False Positive Rate 는 뭐지 그러면?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1169,train,11,Confusion Matrix 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1170,train,11,Confusion Matrix 만드는 법을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1171,train,11,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1172,train,11,Normalization 이 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1173,train,11,정규화가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1174,train,11,min-max 정규화가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1175,train,11,Z score normalization 이 뭐지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1176,train,11,Clipping 에 대해서 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1177,train,11,Clipping 을 하면 뭐가 좋아?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1178,train,11,로그 스케일링이 뭐야?,True Positive Rate : recall 의 다른 이름
1179,train,11,Outlier 가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1180,train,11,이상치가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1181,train,11,Outlier 를 제거해야 하는 이유는 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1182,train,11,Outlier 를 제거하는 방법에 대해 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1183,train,11,PCA 가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1184,train,11,주성분 분석이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1185,train,11,PCA 는 왜 하는 거지 그러면?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1186,train,11,데이터 불균형이 뭔지 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1187,train,11,데이터 불균형 해결하는 법이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1188,train,11,데이터를 새로 추가하거나 제거하는 법 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1189,train,11,그러면 학습 환경만 바꾸는 방법은 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1190,train,11,Augmentation 이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1191,train,11,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1192,train,11,Undersampling 이 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1193,train,11,그럼 Oversampling 은 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1194,train,11,데이터 불균형을 고려한 성능지표를 추천해 줘!,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1195,train,11,Undersampling 하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1196,train,11,Oversampling 방법은 어떤 게 있어?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1197,train,11,차원의 저주가 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1198,train,11,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1199,train,11,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1200,train,11,의사결정 나무,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1201,train,11,Decision Tree 로 결정하는 방법은?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1202,train,11,앙상블이 뭔지 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1203,train,11,앙상블을 왜 하는 거야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1204,train,11,앙상블 하는 구체적인 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가
1205,train,11,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1206,train,11,보팅에 대해 자세히 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1207,train,11,앙상블 중에 Voting 이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1208,train,11,보팅의 방법에는 구체적으로 뭐가 있지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1209,train,11,Bagging 이 뭔지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1210,train,11,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1211,train,11,Stacking 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1212,train,11,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1213,train,11,가우시안 혼합이 뭔지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1214,train,11,K-means Clustering 이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1215,train,11,K-means Clustering 의 방법을 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1216,train,11,kNN 에 대해 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1217,train,11,k Nearest Neighbor 알고리즘이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1218,train,11,지도학습 비지도학습 이런 게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1219,train,11,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1220,train,11,강화학습? 지도학습? 그게 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1221,train,11,지도학습과 비지도학습의 차이가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1222,train,11,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1223,train,11,분류와 회귀 문제가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1224,train,11,Regression 이랑 Classification 이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1225,train,11,Naïve Bayes 가 뭔지 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1226,train,11,서포트 벡터 머신이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1227,train,11,SVM이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1228,train,11,K-fold Cross Validation,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1229,train,11,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1230,train,11,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1231,train,11,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1232,train,11,Valid 데이터가 굳이 왜 필요하지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1233,train,11,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1234,train,11,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1235,train,11,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1236,train,11,머신러닝은 그럼 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1237,train,11,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1238,train,11,딥러닝에서 학습률이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1239,train,11,learning rate 가 뭔지 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1240,train,11,자주 쓰는 Loss Function 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1241,train,11,Overfitting 이 뭔지 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1242,train,11,Overfitting 해결하는 방법은 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1243,train,11,전이학습이 뭐지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1244,train,11,Transfer Learning 이 뭔지 궁금해!,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1245,train,11,활성화 함수? 그게 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1246,train,11,활성화 함수는 왜 필요해?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1247,train,11,CNN이 뭐야? 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1248,train,11,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1249,train,11,cosine similarity가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1250,train,11,코사인 유사도가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1251,train,11,코사인 유사도 계산법 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1252,train,11,코사인 유사도의 특징을 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1253,train,11,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1254,train,11,Accuracy 는 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1255,train,11,True Positive 같은 건 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1256,train,11,True Negative 는?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1257,train,11,False Positive 는 뭐지 그럼?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1258,train,11,False Negative 는 뭐야 그러면?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1259,train,11,Recall 은 어떻게 계산해?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1260,train,12,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1261,train,12,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1262,train,12,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1263,train,12,F1 Score 구하는 수식을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1264,train,12,F1 Score 장점이 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1265,train,12,IoU 가 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1266,train,12,특이도라는 걸 봤는데 그게 뭔지 궁금해!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1267,train,12,이진 분류에서 쓰이는 Metric 을 알려줘!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1268,train,12,PR-AUC랑 ROC-AUC가 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1269,train,12,PR-AUC가 뭔지 자세히 알려줘!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1270,train,12,ROC-AUC가 뭔지 아주 자세히 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1271,train,12,True Positive Rate 가 뭐야? 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1272,train,12,False Positive Rate 는 뭐지 그러면?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1273,train,12,Confusion Matrix 가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1274,train,12,Confusion Matrix 만드는 법을 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1275,train,12,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1276,train,12,Normalization 이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1277,train,12,정규화가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1278,train,12,min-max 정규화가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1279,train,12,Z score normalization 이 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1280,train,12,Clipping 에 대해서 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1281,train,12,Clipping 을 하면 뭐가 좋아?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1282,train,12,로그 스케일링이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1283,train,12,Outlier 가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름
1284,train,12,이상치가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1285,train,12,Outlier 를 제거해야 하는 이유는 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1286,train,12,Outlier 를 제거하는 방법에 대해 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1287,train,12,PCA 가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1288,train,12,주성분 분석이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1289,train,12,PCA 는 왜 하는 거지 그러면?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1290,train,12,데이터 불균형이 뭔지 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1291,train,12,데이터 불균형 해결하는 법이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1292,train,12,데이터를 새로 추가하거나 제거하는 법 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1293,train,12,그러면 학습 환경만 바꾸는 방법은 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1294,train,12,Augmentation 이 뭔지 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1295,train,12,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1296,train,12,Undersampling 이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1297,train,12,그럼 Oversampling 은 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1298,train,12,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1299,train,12,Undersampling 하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1300,train,12,Oversampling 방법은 어떤 게 있어?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1301,train,12,차원의 저주가 뭐지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1302,train,12,차원의 저주가 구체적으로 어떤 문제야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1303,train,12,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1304,train,12,의사결정 나무,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1305,train,12,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1306,train,12,앙상블이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1307,train,12,앙상블을 왜 하는 거야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1308,train,12,앙상블 하는 구체적인 방법 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1309,train,12,앙상블은 정확히 어떻게 하는 건지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가
1310,train,12,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1311,train,12,앙상블 중에 Voting 이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1312,train,12,보팅의 방법에는 구체적으로 뭐가 있지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1313,train,12,Bagging 이 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1314,train,12,그럼 Boosting 은 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1315,train,12,Stacking 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1316,train,12,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1317,train,12,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1318,train,12,K-means Clustering 이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1319,train,12,K-means Clustering 의 방법을 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1320,train,12,kNN 에 대해 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1321,train,12,k Nearest Neighbor 알고리즘이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1322,train,12,지도학습 비지도학습 이런 게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1323,train,12,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1324,train,12,강화학습? 지도학습? 그게 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1325,train,12,지도학습과 비지도학습의 차이가 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1326,train,12,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1327,train,12,분류와 회귀 문제가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1328,train,12,Regression 이랑 Classification 이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1329,train,12,Naïve Bayes 가 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1330,train,12,서포트 벡터 머신이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1331,train,12,SVM이 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1332,train,12,K-fold Cross Validation,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1333,train,12,K-fold Cross Validation을 굳이 왜 하는 거야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1334,train,12,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1335,train,12,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1336,train,12,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1337,train,12,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1338,train,12,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1339,train,12,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1340,train,12,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1341,train,12,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1342,train,12,딥러닝에서 학습률이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1343,train,12,learning rate 가 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1344,train,12,자주 쓰는 Loss Function 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1345,train,12,Overfitting 이 뭔지 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1346,train,12,Overfitting 해결하는 방법은 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1347,train,12,전이학습이 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1348,train,12,Transfer Learning 이 뭔지 궁금해!,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1349,train,12,활성화 함수? 그게 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1350,train,12,활성화 함수는 왜 필요해?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1351,train,12,CNN이 뭐야? 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1352,train,12,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1353,train,12,cosine similarity가 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1354,train,12,코사인 유사도가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1355,train,12,코사인 유사도 계산법 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1356,train,12,코사인 유사도의 특징을 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1357,train,12,머신러닝에서 많이 쓰이는 평가지표 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1358,train,12,Accuracy 는 어떻게 계산해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1359,train,12,True Positive 같은 건 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1360,train,12,True Negative 는?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1361,train,12,False Positive 는 뭐지 그럼?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1362,train,12,False Negative 는 뭐야 그러면?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1363,train,12,Recall 은 어떻게 계산해?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1364,train,12,Recall 은 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1365,train,13,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1366,train,13,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1367,train,13,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1368,train,13,F1 Score 장점이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1369,train,13,IoU 가 뭔지 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1370,train,13,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1371,train,13,이진 분류에서 쓰이는 Metric 을 알려줘!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1372,train,13,PR-AUC랑 ROC-AUC가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1373,train,13,PR-AUC가 뭔지 자세히 알려줘!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1374,train,13,ROC-AUC가 뭔지 아주 자세히 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1375,train,13,True Positive Rate 가 뭐야? 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1376,train,13,False Positive Rate 는 뭐지 그러면?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1377,train,13,Confusion Matrix 가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1378,train,13,Confusion Matrix 만드는 법을 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1379,train,13,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",F1 Score 개념 : Recall 과 Precision 의 조화 평균
1380,train,13,Normalization 이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1381,train,13,정규화가 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1382,train,13,min-max 정규화가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1383,train,13,Z score normalization 이 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1384,train,13,Clipping 에 대해서 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1385,train,13,Clipping 을 하면 뭐가 좋아?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1386,train,13,로그 스케일링이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1387,train,13,Outlier 가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1388,train,13,이상치가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름
1389,train,13,Outlier 를 제거해야 하는 이유는 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1390,train,13,Outlier 를 제거하는 방법에 대해 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1391,train,13,PCA 가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1392,train,13,주성분 분석이 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1393,train,13,PCA 는 왜 하는 거지 그러면?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1394,train,13,데이터 불균형이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1395,train,13,데이터 불균형 해결하는 법이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1396,train,13,데이터를 새로 추가하거나 제거하는 법 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1397,train,13,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1398,train,13,Augmentation 이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1399,train,13,Undersampling 이랑 Oversampling 이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1400,train,13,Undersampling 이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1401,train,13,그럼 Oversampling 은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1402,train,13,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1403,train,13,Undersampling 하는 방법 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1404,train,13,Oversampling 방법은 어떤 게 있어?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1405,train,13,차원의 저주가 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1406,train,13,차원의 저주가 구체적으로 어떤 문제야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1407,train,13,Decision Tree 가 뭔지 자세히 알고 싶어,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1408,train,13,의사결정 나무,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1409,train,13,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1410,train,13,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1411,train,13,앙상블을 왜 하는 거야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1412,train,13,앙상블 하는 구체적인 방법 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1413,train,13,앙상블은 정확히 어떻게 하는 건지 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1414,train,13,보팅에 대해 자세히 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가
1415,train,13,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1416,train,13,보팅의 방법에는 구체적으로 뭐가 있지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1417,train,13,Bagging 이 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1418,train,13,그럼 Boosting 은 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1419,train,13,Stacking 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1420,train,13,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1421,train,13,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1422,train,13,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1423,train,13,K-means Clustering 의 방법을 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1424,train,13,kNN 에 대해 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1425,train,13,k Nearest Neighbor 알고리즘이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1426,train,13,지도학습 비지도학습 이런 게 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1427,train,13,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1428,train,13,강화학습? 지도학습? 그게 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1429,train,13,지도학습과 비지도학습의 차이가 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1430,train,13,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1431,train,13,분류와 회귀 문제가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1432,train,13,Regression 이랑 Classification 이 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1433,train,13,Naïve Bayes 가 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1434,train,13,서포트 벡터 머신이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1435,train,13,SVM이 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1436,train,13,K-fold Cross Validation,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1437,train,13,K-fold Cross Validation을 굳이 왜 하는 거야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1438,train,13,하이퍼파라미터가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1439,train,13,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1440,train,13,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1441,train,13,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1442,train,13,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1443,train,13,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1444,train,13,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1445,train,13,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1446,train,13,딥러닝에서 학습률이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1447,train,13,learning rate 가 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1448,train,13,자주 쓰는 Loss Function 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1449,train,13,Overfitting 이 뭔지 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1450,train,13,Overfitting 해결하는 방법은 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1451,train,13,전이학습이 뭐지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1452,train,13,Transfer Learning 이 뭔지 궁금해!,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1453,train,13,활성화 함수? 그게 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1454,train,13,활성화 함수는 왜 필요해?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1455,train,13,CNN이 뭐야? 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1456,train,13,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1457,train,13,cosine similarity가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1458,train,13,코사인 유사도가 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1459,train,13,코사인 유사도 계산법 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1460,train,13,코사인 유사도의 특징을 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1461,train,13,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1462,train,13,Accuracy 는 어떻게 계산해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1463,train,13,True Positive 같은 건 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1464,train,13,True Negative 는?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1465,train,13,False Positive 는 뭐지 그럼?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1466,train,13,False Negative 는 뭐야 그러면?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1467,train,13,Recall 은 어떻게 계산해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1468,train,13,Recall 은 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1469,train,13,Precision 은 어떻게 계산하지,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1470,train,14,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1471,train,14,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1472,train,14,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1473,train,14,IoU 가 뭔지 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1474,train,14,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1475,train,14,이진 분류에서 쓰이는 Metric 을 알려줘!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1476,train,14,PR-AUC랑 ROC-AUC가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1477,train,14,PR-AUC가 뭔지 자세히 알려줘!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1478,train,14,ROC-AUC가 뭔지 아주 자세히 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1479,train,14,True Positive Rate 가 뭐야? 궁금해!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1480,train,14,False Positive Rate 는 뭐지 그러면?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1481,train,14,Confusion Matrix 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1482,train,14,Confusion Matrix 만드는 법을 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1483,train,14,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1484,train,14,Normalization 이 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1485,train,14,정규화가 뭔지 궁금해,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1486,train,14,min-max 정규화가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1487,train,14,Z score normalization 이 뭐지?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1488,train,14,Clipping 에 대해서 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1489,train,14,Clipping 을 하면 뭐가 좋아?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1490,train,14,로그 스케일링이 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1491,train,14,Outlier 가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1492,train,14,이상치가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1493,train,14,Outlier 를 제거해야 하는 이유는 뭐지?,True Positive Rate : recall 의 다른 이름
1494,train,14,Outlier 를 제거하는 방법에 대해 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1495,train,14,PCA 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1496,train,14,주성분 분석이 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1497,train,14,PCA 는 왜 하는 거지 그러면?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1498,train,14,데이터 불균형이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1499,train,14,데이터 불균형 해결하는 법이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1500,train,14,데이터를 새로 추가하거나 제거하는 법 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1501,train,14,그러면 학습 환경만 바꾸는 방법은 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1502,train,14,Augmentation 이 뭔지 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1503,train,14,Undersampling 이랑 Oversampling 이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1504,train,14,Undersampling 이 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1505,train,14,그럼 Oversampling 은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1506,train,14,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1507,train,14,Undersampling 하는 방법 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1508,train,14,Oversampling 방법은 어떤 게 있어?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1509,train,14,차원의 저주가 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1510,train,14,차원의 저주가 구체적으로 어떤 문제야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1511,train,14,Decision Tree 가 뭔지 자세히 알고 싶어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1512,train,14,의사결정 나무,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1513,train,14,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1514,train,14,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1515,train,14,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1516,train,14,앙상블 하는 구체적인 방법 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1517,train,14,앙상블은 정확히 어떻게 하는 건지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1518,train,14,보팅에 대해 자세히 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1519,train,14,앙상블 중에 Voting 이 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가
1520,train,14,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1521,train,14,Bagging 이 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1522,train,14,그럼 Boosting 은 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1523,train,14,Stacking 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1524,train,14,Gaussian Mixture 모델이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1525,train,14,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1526,train,14,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1527,train,14,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1528,train,14,kNN 에 대해 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1529,train,14,k Nearest Neighbor 알고리즘이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1530,train,14,지도학습 비지도학습 이런 게 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1531,train,14,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1532,train,14,강화학습? 지도학습? 그게 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1533,train,14,지도학습과 비지도학습의 차이가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1534,train,14,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1535,train,14,분류와 회귀 문제가 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1536,train,14,Regression 이랑 Classification 이 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1537,train,14,Naïve Bayes 가 뭔지 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1538,train,14,서포트 벡터 머신이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1539,train,14,SVM이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1540,train,14,K-fold Cross Validation,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1541,train,14,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1542,train,14,하이퍼파라미터가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1543,train,14,One-hot 방식이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1544,train,14,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1545,train,14,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1546,train,14,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1547,train,14,인공지능이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1548,train,14,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1549,train,14,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1550,train,14,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1551,train,14,learning rate 가 뭔지 궁금해!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1552,train,14,자주 쓰는 Loss Function 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1553,train,14,Overfitting 이 뭔지 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1554,train,14,Overfitting 해결하는 방법은 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1555,train,14,전이학습이 뭐지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1556,train,14,Transfer Learning 이 뭔지 궁금해!,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1557,train,14,활성화 함수? 그게 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1558,train,14,활성화 함수는 왜 필요해?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1559,train,14,CNN이 뭐야? 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1560,train,14,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1561,train,14,cosine similarity가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1562,train,14,코사인 유사도가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1563,train,14,코사인 유사도 계산법 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1564,train,14,코사인 유사도의 특징을 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1565,train,14,머신러닝에서 많이 쓰이는 평가지표 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1566,train,14,Accuracy 는 어떻게 계산해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1567,train,14,True Positive 같은 건 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1568,train,14,True Negative 는?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1569,train,14,False Positive 는 뭐지 그럼?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1570,train,14,False Negative 는 뭐야 그러면?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1571,train,14,Recall 은 어떻게 계산해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1572,train,14,Recall 은 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1573,train,14,Precision 은 어떻게 계산하지,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1574,train,14,Recall 과 Precision 이 자꾸 헷갈리네,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1575,train,15,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1576,train,15,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1577,train,15,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1578,train,15,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1579,train,15,이진 분류에서 쓰이는 Metric 을 알려줘!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1580,train,15,PR-AUC랑 ROC-AUC가 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1581,train,15,PR-AUC가 뭔지 자세히 알려줘!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1582,train,15,ROC-AUC가 뭔지 아주 자세히 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1583,train,15,True Positive Rate 가 뭐야? 궁금해!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1584,train,15,False Positive Rate 는 뭐지 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1585,train,15,Confusion Matrix 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1586,train,15,Confusion Matrix 만드는 법을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1587,train,15,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1588,train,15,Normalization 이 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1589,train,15,정규화가 뭔지 궁금해,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1590,train,15,min-max 정규화가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1591,train,15,Z score normalization 이 뭐지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1592,train,15,Clipping 에 대해서 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1593,train,15,Clipping 을 하면 뭐가 좋아?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1594,train,15,로그 스케일링이 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1595,train,15,Outlier 가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1596,train,15,이상치가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1597,train,15,Outlier 를 제거해야 하는 이유는 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1598,train,15,Outlier 를 제거하는 방법에 대해 알려줘,True Positive Rate : recall 의 다른 이름
1599,train,15,PCA 가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1600,train,15,주성분 분석이 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1601,train,15,PCA 는 왜 하는 거지 그러면?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1602,train,15,데이터 불균형이 뭔지 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1603,train,15,데이터 불균형 해결하는 법이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1604,train,15,데이터를 새로 추가하거나 제거하는 법 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1605,train,15,그러면 학습 환경만 바꾸는 방법은 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1606,train,15,Augmentation 이 뭔지 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1607,train,15,Undersampling 이랑 Oversampling 이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1608,train,15,Undersampling 이 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1609,train,15,그럼 Oversampling 은 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1610,train,15,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1611,train,15,Undersampling 하는 방법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1612,train,15,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1613,train,15,차원의 저주가 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1614,train,15,차원의 저주가 구체적으로 어떤 문제야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1615,train,15,Decision Tree 가 뭔지 자세히 알고 싶어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1616,train,15,의사결정 나무,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1617,train,15,Decision Tree 로 결정하는 방법은?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1618,train,15,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1619,train,15,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1620,train,15,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1621,train,15,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1622,train,15,보팅에 대해 자세히 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1623,train,15,앙상블 중에 Voting 이 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1624,train,15,보팅의 방법에는 구체적으로 뭐가 있지?,Oversampling : 데이터가 적은 Class 의 데이터 증가
1625,train,15,Bagging 이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1626,train,15,그럼 Boosting 은 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1627,train,15,Stacking 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1628,train,15,Gaussian Mixture 모델이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1629,train,15,가우시안 혼합이 뭔지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1630,train,15,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1631,train,15,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1632,train,15,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1633,train,15,k Nearest Neighbor 알고리즘이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1634,train,15,지도학습 비지도학습 이런 게 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1635,train,15,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1636,train,15,강화학습? 지도학습? 그게 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1637,train,15,지도학습과 비지도학습의 차이가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1638,train,15,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1639,train,15,분류와 회귀 문제가 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1640,train,15,Regression 이랑 Classification 이 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1641,train,15,Naïve Bayes 가 뭔지 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1642,train,15,서포트 벡터 머신이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1643,train,15,SVM이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1644,train,15,K-fold Cross Validation,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1645,train,15,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1646,train,15,하이퍼파라미터가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1647,train,15,One-hot 방식이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1648,train,15,Valid 데이터가 굳이 왜 필요하지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1649,train,15,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1650,train,15,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1651,train,15,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1652,train,15,머신러닝은 그럼 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1653,train,15,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1654,train,15,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1655,train,15,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1656,train,15,자주 쓰는 Loss Function 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1657,train,15,Overfitting 이 뭔지 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1658,train,15,Overfitting 해결하는 방법은 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1659,train,15,전이학습이 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1660,train,15,Transfer Learning 이 뭔지 궁금해!,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1661,train,15,활성화 함수? 그게 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1662,train,15,활성화 함수는 왜 필요해?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1663,train,15,CNN이 뭐야? 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1664,train,15,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1665,train,15,cosine similarity가 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1666,train,15,코사인 유사도가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1667,train,15,코사인 유사도 계산법 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1668,train,15,코사인 유사도의 특징을 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1669,train,15,머신러닝에서 많이 쓰이는 평가지표 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1670,train,15,Accuracy 는 어떻게 계산해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1671,train,15,True Positive 같은 건 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1672,train,15,True Negative 는?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1673,train,15,False Positive 는 뭐지 그럼?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1674,train,15,False Negative 는 뭐야 그러면?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1675,train,15,Recall 은 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1676,train,15,Recall 은 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1677,train,15,Precision 은 어떻게 계산하지,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1678,train,15,Recall 과 Precision 이 자꾸 헷갈리네,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1679,train,15,F1 이 뭔지 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1680,train,16,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1681,train,16,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1682,train,16,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1683,train,16,이진 분류에서 쓰이는 Metric 을 알려줘!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1684,train,16,PR-AUC랑 ROC-AUC가 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1685,train,16,PR-AUC가 뭔지 자세히 알려줘!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1686,train,16,ROC-AUC가 뭔지 아주 자세히 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1687,train,16,True Positive Rate 가 뭐야? 궁금해!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1688,train,16,False Positive Rate 는 뭐지 그러면?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1689,train,16,Confusion Matrix 가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1690,train,16,Confusion Matrix 만드는 법을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1691,train,16,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1692,train,16,Normalization 이 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1693,train,16,정규화가 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1694,train,16,min-max 정규화가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1695,train,16,Z score normalization 이 뭐지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1696,train,16,Clipping 에 대해서 자세히 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1697,train,16,Clipping 을 하면 뭐가 좋아?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1698,train,16,로그 스케일링이 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1699,train,16,Outlier 가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1700,train,16,이상치가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1701,train,16,Outlier 를 제거해야 하는 이유는 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1702,train,16,Outlier 를 제거하는 방법에 대해 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1703,train,16,PCA 가 뭐야?,True Positive Rate : recall 의 다른 이름
1704,train,16,주성분 분석이 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1705,train,16,PCA 는 왜 하는 거지 그러면?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1706,train,16,데이터 불균형이 뭔지 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1707,train,16,데이터 불균형 해결하는 법이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1708,train,16,데이터를 새로 추가하거나 제거하는 법 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1709,train,16,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1710,train,16,Augmentation 이 뭔지 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1711,train,16,Undersampling 이랑 Oversampling 이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1712,train,16,Undersampling 이 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1713,train,16,그럼 Oversampling 은 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1714,train,16,데이터 불균형을 고려한 성능지표를 추천해 줘!,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1715,train,16,Undersampling 하는 방법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1716,train,16,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1717,train,16,차원의 저주가 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1718,train,16,차원의 저주가 구체적으로 어떤 문제야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1719,train,16,Decision Tree 가 뭔지 자세히 알고 싶어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1720,train,16,의사결정 나무,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1721,train,16,Decision Tree 로 결정하는 방법은?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1722,train,16,앙상블이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1723,train,16,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1724,train,16,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1725,train,16,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1726,train,16,보팅에 대해 자세히 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1727,train,16,앙상블 중에 Voting 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1728,train,16,보팅의 방법에는 구체적으로 뭐가 있지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1729,train,16,Bagging 이 뭔지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가
1730,train,16,그럼 Boosting 은 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1731,train,16,Stacking 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1732,train,16,Gaussian Mixture 모델이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1733,train,16,가우시안 혼합이 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1734,train,16,K-means Clustering 이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1735,train,16,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1736,train,16,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1737,train,16,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1738,train,16,지도학습 비지도학습 이런 게 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1739,train,16,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1740,train,16,강화학습? 지도학습? 그게 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1741,train,16,지도학습과 비지도학습의 차이가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1742,train,16,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1743,train,16,분류와 회귀 문제가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1744,train,16,Regression 이랑 Classification 이 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1745,train,16,Naïve Bayes 가 뭔지 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1746,train,16,서포트 벡터 머신이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1747,train,16,SVM이 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1748,train,16,K-fold Cross Validation,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1749,train,16,K-fold Cross Validation을 굳이 왜 하는 거야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1750,train,16,하이퍼파라미터가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1751,train,16,One-hot 방식이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1752,train,16,Valid 데이터가 굳이 왜 필요하지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1753,train,16,Train 데이터셋을 왜 순서를 섞어야 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1754,train,16,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1755,train,16,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1756,train,16,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1757,train,16,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1758,train,16,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1759,train,16,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1760,train,16,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1761,train,16,Overfitting 이 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1762,train,16,Overfitting 해결하는 방법은 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1763,train,16,전이학습이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1764,train,16,Transfer Learning 이 뭔지 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1765,train,16,활성화 함수? 그게 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1766,train,16,활성화 함수는 왜 필요해?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1767,train,16,CNN이 뭐야? 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1768,train,16,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1769,train,16,cosine similarity가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1770,train,16,코사인 유사도가 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1771,train,16,코사인 유사도 계산법 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1772,train,16,코사인 유사도의 특징을 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1773,train,16,머신러닝에서 많이 쓰이는 평가지표 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1774,train,16,Accuracy 는 어떻게 계산해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1775,train,16,True Positive 같은 건 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1776,train,16,True Negative 는?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1777,train,16,False Positive 는 뭐지 그럼?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1778,train,16,False Negative 는 뭐야 그러면?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1779,train,16,Recall 은 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1780,train,16,Recall 은 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1781,train,16,Precision 은 어떻게 계산하지,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1782,train,16,Recall 과 Precision 이 자꾸 헷갈리네,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1783,train,16,F1 이 뭔지 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1784,train,16,F1 Score 구하는 수식을 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1785,train,17,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1786,train,17,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1787,train,17,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1788,train,17,PR-AUC랑 ROC-AUC가 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1789,train,17,PR-AUC가 뭔지 자세히 알려줘!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1790,train,17,ROC-AUC가 뭔지 아주 자세히 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1791,train,17,True Positive Rate 가 뭐야? 궁금해!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1792,train,17,False Positive Rate 는 뭐지 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1793,train,17,Confusion Matrix 가 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1794,train,17,Confusion Matrix 만드는 법을 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1795,train,17,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1796,train,17,Normalization 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1797,train,17,정규화가 뭔지 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1798,train,17,min-max 정규화가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1799,train,17,Z score normalization 이 뭐지?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1800,train,17,Clipping 에 대해서 자세히 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1801,train,17,Clipping 을 하면 뭐가 좋아?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1802,train,17,로그 스케일링이 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1803,train,17,Outlier 가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1804,train,17,이상치가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1805,train,17,Outlier 를 제거해야 하는 이유는 뭐지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1806,train,17,Outlier 를 제거하는 방법에 대해 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1807,train,17,PCA 가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1808,train,17,주성분 분석이 뭐지?,True Positive Rate : recall 의 다른 이름
1809,train,17,PCA 는 왜 하는 거지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1810,train,17,데이터 불균형이 뭔지 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1811,train,17,데이터 불균형 해결하는 법이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1812,train,17,데이터를 새로 추가하거나 제거하는 법 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1813,train,17,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1814,train,17,Augmentation 이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1815,train,17,Undersampling 이랑 Oversampling 이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1816,train,17,Undersampling 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1817,train,17,그럼 Oversampling 은 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1818,train,17,데이터 불균형을 고려한 성능지표를 추천해 줘!,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1819,train,17,Undersampling 하는 방법 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1820,train,17,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1821,train,17,차원의 저주가 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1822,train,17,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1823,train,17,Decision Tree 가 뭔지 자세히 알고 싶어,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1824,train,17,의사결정 나무,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1825,train,17,Decision Tree 로 결정하는 방법은?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1826,train,17,앙상블이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1827,train,17,앙상블을 왜 하는 거야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1828,train,17,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1829,train,17,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1830,train,17,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1831,train,17,앙상블 중에 Voting 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1832,train,17,보팅의 방법에는 구체적으로 뭐가 있지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1833,train,17,Bagging 이 뭔지 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1834,train,17,그럼 Boosting 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가
1835,train,17,Stacking 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1836,train,17,Gaussian Mixture 모델이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1837,train,17,가우시안 혼합이 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1838,train,17,K-means Clustering 이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1839,train,17,K-means Clustering 의 방법을 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1840,train,17,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1841,train,17,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1842,train,17,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1843,train,17,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1844,train,17,강화학습? 지도학습? 그게 뭐지?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1845,train,17,지도학습과 비지도학습의 차이가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1846,train,17,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1847,train,17,분류와 회귀 문제가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1848,train,17,Regression 이랑 Classification 이 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1849,train,17,Naïve Bayes 가 뭔지 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1850,train,17,서포트 벡터 머신이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1851,train,17,SVM이 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1852,train,17,K-fold Cross Validation,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1853,train,17,K-fold Cross Validation을 굳이 왜 하는 거야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1854,train,17,하이퍼파라미터가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1855,train,17,One-hot 방식이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1856,train,17,Valid 데이터가 굳이 왜 필요하지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1857,train,17,Train 데이터셋을 왜 순서를 섞어야 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1858,train,17,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1859,train,17,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1860,train,17,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1861,train,17,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1862,train,17,딥러닝에서 학습률이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1863,train,17,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1864,train,17,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1865,train,17,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1866,train,17,Overfitting 해결하는 방법은 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1867,train,17,전이학습이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1868,train,17,Transfer Learning 이 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1869,train,17,활성화 함수? 그게 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1870,train,17,활성화 함수는 왜 필요해?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1871,train,17,CNN이 뭐야? 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1872,train,17,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1873,train,17,cosine similarity가 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1874,train,17,코사인 유사도가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1875,train,17,코사인 유사도 계산법 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1876,train,17,코사인 유사도의 특징을 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1877,train,17,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1878,train,17,Accuracy 는 어떻게 계산해?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1879,train,17,True Positive 같은 건 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1880,train,17,True Negative 는?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1881,train,17,False Positive 는 뭐지 그럼?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1882,train,17,False Negative 는 뭐야 그러면?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1883,train,17,Recall 은 어떻게 계산해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1884,train,17,Recall 은 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1885,train,17,Precision 은 어떻게 계산하지,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1886,train,17,Recall 과 Precision 이 자꾸 헷갈리네,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1887,train,17,F1 이 뭔지 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1888,train,17,F1 Score 구하는 수식을 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1889,train,17,F1 Score 장점이 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1890,train,18,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1891,train,18,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1892,train,18,PR-AUC랑 ROC-AUC가 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1893,train,18,PR-AUC가 뭔지 자세히 알려줘!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1894,train,18,ROC-AUC가 뭔지 아주 자세히 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
1895,train,18,True Positive Rate 가 뭐야? 궁금해!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
1896,train,18,False Positive Rate 는 뭐지 그러면?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
1897,train,18,Confusion Matrix 가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
1898,train,18,Confusion Matrix 만드는 법을 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
1899,train,18,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
1900,train,18,Normalization 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1901,train,18,정규화가 뭔지 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
1902,train,18,min-max 정규화가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
1903,train,18,Z score normalization 이 뭐지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
1904,train,18,Clipping 에 대해서 자세히 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
1905,train,18,Clipping 을 하면 뭐가 좋아?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
1906,train,18,로그 스케일링이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
1907,train,18,Outlier 가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
1908,train,18,이상치가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
1909,train,18,Outlier 를 제거해야 하는 이유는 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
1910,train,18,Outlier 를 제거하는 방법에 대해 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
1911,train,18,PCA 가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1912,train,18,주성분 분석이 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
1913,train,18,PCA 는 왜 하는 거지 그러면?,True Positive Rate : recall 의 다른 이름
1914,train,18,데이터 불균형이 뭔지 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
1915,train,18,데이터 불균형 해결하는 법이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
1916,train,18,데이터를 새로 추가하거나 제거하는 법 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
1917,train,18,그러면 학습 환경만 바꾸는 방법은 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
1918,train,18,Augmentation 이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1919,train,18,Undersampling 이랑 Oversampling 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
1920,train,18,Undersampling 이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
1921,train,18,그럼 Oversampling 은 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
1922,train,18,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
1923,train,18,Undersampling 하는 방법 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
1924,train,18,Oversampling 방법은 어떤 게 있어?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
1925,train,18,차원의 저주가 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1926,train,18,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
1927,train,18,Decision Tree 가 뭔지 자세히 알고 싶어,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
1928,train,18,의사결정 나무,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
1929,train,18,Decision Tree 로 결정하는 방법은?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1930,train,18,앙상블이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
1931,train,18,앙상블을 왜 하는 거야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
1932,train,18,앙상블 하는 구체적인 방법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
1933,train,18,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
1934,train,18,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
1935,train,18,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
1936,train,18,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
1937,train,18,Bagging 이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
1938,train,18,그럼 Boosting 은 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
1939,train,18,Stacking 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가
1940,train,18,Gaussian Mixture 모델이 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
1941,train,18,가우시안 혼합이 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
1942,train,18,K-means Clustering 이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
1943,train,18,K-means Clustering 의 방법을 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
1944,train,18,kNN 에 대해 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
1945,train,18,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1946,train,18,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
1947,train,18,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
1948,train,18,강화학습? 지도학습? 그게 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
1949,train,18,지도학습과 비지도학습의 차이가 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
1950,train,18,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1951,train,18,분류와 회귀 문제가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
1952,train,18,Regression 이랑 Classification 이 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1953,train,18,Naïve Bayes 가 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
1954,train,18,서포트 벡터 머신이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
1955,train,18,SVM이 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
1956,train,18,K-fold Cross Validation,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
1957,train,18,K-fold Cross Validation을 굳이 왜 하는 거야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
1958,train,18,하이퍼파라미터가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1959,train,18,One-hot 방식이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
1960,train,18,Valid 데이터가 굳이 왜 필요하지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
1961,train,18,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
1962,train,18,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1963,train,18,인공지능이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
1964,train,18,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1965,train,18,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1966,train,18,딥러닝에서 학습률이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
1967,train,18,learning rate 가 뭔지 궁금해!,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
1968,train,18,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1969,train,18,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1970,train,18,Overfitting 해결하는 방법은 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
1971,train,18,전이학습이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
1972,train,18,Transfer Learning 이 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1973,train,18,활성화 함수? 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
1974,train,18,활성화 함수는 왜 필요해?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
1975,train,18,CNN이 뭐야? 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
1976,train,18,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
1977,train,18,cosine similarity가 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
1978,train,18,코사인 유사도가 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
1979,train,18,코사인 유사도 계산법 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
1980,train,18,코사인 유사도의 특징을 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
1981,train,18,머신러닝에서 많이 쓰이는 평가지표 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
1982,train,18,Accuracy 는 어떻게 계산해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
1983,train,18,True Positive 같은 건 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
1984,train,18,True Negative 는?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1985,train,18,False Positive 는 뭐지 그럼?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
1986,train,18,False Negative 는 뭐야 그러면?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
1987,train,18,Recall 은 어떻게 계산해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
1988,train,18,Recall 은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
1989,train,18,Precision 은 어떻게 계산하지,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1990,train,18,Recall 과 Precision 이 자꾸 헷갈리네,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
1991,train,18,F1 이 뭔지 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
1992,train,18,F1 Score 구하는 수식을 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
1993,train,18,F1 Score 장점이 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
1994,train,18,IoU 가 뭔지 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
1995,train,19,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1996,train,19,PR-AUC랑 ROC-AUC가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
1997,train,19,PR-AUC가 뭔지 자세히 알려줘!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
1998,train,19,ROC-AUC가 뭔지 아주 자세히 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
1999,train,19,True Positive Rate 가 뭐야? 궁금해!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
2000,train,19,False Positive Rate 는 뭐지 그러면?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
2001,train,19,Confusion Matrix 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
2002,train,19,Confusion Matrix 만드는 법을 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
2003,train,19,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
2004,train,19,Normalization 이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
2005,train,19,정규화가 뭔지 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2006,train,19,min-max 정규화가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2007,train,19,Z score normalization 이 뭐지?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
2008,train,19,Clipping 에 대해서 자세히 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
2009,train,19,Clipping 을 하면 뭐가 좋아?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
2010,train,19,로그 스케일링이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
2011,train,19,Outlier 가 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
2012,train,19,이상치가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
2013,train,19,Outlier 를 제거해야 하는 이유는 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
2014,train,19,Outlier 를 제거하는 방법에 대해 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
2015,train,19,PCA 가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
2016,train,19,주성분 분석이 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2017,train,19,PCA 는 왜 하는 거지 그러면?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2018,train,19,데이터 불균형이 뭔지 알려줘,True Positive Rate : recall 의 다른 이름
2019,train,19,데이터 불균형 해결하는 법이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
2020,train,19,데이터를 새로 추가하거나 제거하는 법 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
2021,train,19,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
2022,train,19,Augmentation 이 뭔지 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
2023,train,19,Undersampling 이랑 Oversampling 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2024,train,19,Undersampling 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2025,train,19,그럼 Oversampling 은 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
2026,train,19,데이터 불균형을 고려한 성능지표를 추천해 줘!,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
2027,train,19,Undersampling 하는 방법 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
2028,train,19,Oversampling 방법은 어떤 게 있어?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
2029,train,19,차원의 저주가 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
2030,train,19,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2031,train,19,Decision Tree 가 뭔지 자세히 알고 싶어,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2032,train,19,의사결정 나무,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
2033,train,19,Decision Tree 로 결정하는 방법은?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
2034,train,19,앙상블이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2035,train,19,앙상블을 왜 하는 거야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2036,train,19,앙상블 하는 구체적인 방법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
2037,train,19,앙상블은 정확히 어떻게 하는 건지 궁금해,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
2038,train,19,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
2039,train,19,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
2040,train,19,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
2041,train,19,Bagging 이 뭔지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
2042,train,19,그럼 Boosting 은 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
2043,train,19,Stacking 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
2044,train,19,Gaussian Mixture 모델이 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가
2045,train,19,가우시안 혼합이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
2046,train,19,K-means Clustering 이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
2047,train,19,K-means Clustering 의 방법을 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
2048,train,19,kNN 에 대해 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
2049,train,19,k Nearest Neighbor 알고리즘이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
2050,train,19,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2051,train,19,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2052,train,19,강화학습? 지도학습? 그게 뭐지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
2053,train,19,지도학습과 비지도학습의 차이가 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
2054,train,19,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
2055,train,19,분류와 회귀 문제가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2056,train,19,Regression 이랑 Classification 이 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2057,train,19,Naïve Bayes 가 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2058,train,19,서포트 벡터 머신이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2059,train,19,SVM이 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
2060,train,19,K-fold Cross Validation,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
2061,train,19,K-fold Cross Validation을 굳이 왜 하는 거야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
2062,train,19,하이퍼파라미터가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
2063,train,19,One-hot 방식이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2064,train,19,Valid 데이터가 굳이 왜 필요하지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2065,train,19,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
2066,train,19,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
2067,train,19,인공지능이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2068,train,19,머신러닝은 그럼 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2069,train,19,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2070,train,19,딥러닝에서 학습률이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2071,train,19,learning rate 가 뭔지 궁금해!,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2072,train,19,자주 쓰는 Loss Function 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
2073,train,19,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2074,train,19,Overfitting 해결하는 방법은 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2075,train,19,전이학습이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2076,train,19,Transfer Learning 이 뭔지 궁금해!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
2077,train,19,활성화 함수? 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2078,train,19,활성화 함수는 왜 필요해?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2079,train,19,CNN이 뭐야? 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
2080,train,19,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
2081,train,19,cosine similarity가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
2082,train,19,코사인 유사도가 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
2083,train,19,코사인 유사도 계산법 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
2084,train,19,코사인 유사도의 특징을 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
2085,train,19,머신러닝에서 많이 쓰이는 평가지표 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
2086,train,19,Accuracy 는 어떻게 계산해?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
2087,train,19,True Positive 같은 건 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
2088,train,19,True Negative 는?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
2089,train,19,False Positive 는 뭐지 그럼?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2090,train,19,False Negative 는 뭐야 그러면?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2091,train,19,Recall 은 어떻게 계산해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
2092,train,19,Recall 은 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
2093,train,19,Precision 은 어떻게 계산하지,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
2094,train,19,Recall 과 Precision 이 자꾸 헷갈리네,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2095,train,19,F1 이 뭔지 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2096,train,19,F1 Score 구하는 수식을 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
2097,train,19,F1 Score 장점이 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
2098,train,19,IoU 가 뭔지 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
2099,train,19,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
2100,test,0,코사인 유사도가 뭔지 궁금해,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2101,test,0,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2102,test,0,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
2103,test,0,코사인 유사도 특징이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
2104,test,0,머신러닝 모델 평가하는 방법 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
2105,test,0,Accuracy 계산 어떻게 하지?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
2106,test,0,True Positive 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
2107,test,0,True Negative 는 뭔지 궁금해 그럼,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
2108,test,0,False Positive 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
2109,test,0,False Negative (FN),False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
2110,test,0,Recall 계산법 어떻게 하는 거지?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2111,test,0,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2112,test,0,Precision 어떻게 계산하는지 정말 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
2113,test,0,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
2114,test,0,F1 Score 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
2115,test,0,F1 Score 계산식 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
2116,test,0,F1 Score 는 왜 쓰는 거지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
2117,test,0,IoU 라는 게 있는데 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
2118,test,0,특이도는 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
2119,test,0,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
2120,test,0,"PR-AUC, ROC-AUC 가 뭐야?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
2121,test,0,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2122,test,0,ROC-AUC 는 뭔지 정말 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2123,test,0,True Positive Rate 구하는 방법을 알려줘,True Positive Rate : recall 의 다른 이름
2124,test,0,False Positive Rate 가 뭔지 정말 궁금하다,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
2125,test,0,Confusion Matrix (혼동 행렬) 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
2126,test,0,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
2127,test,0,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
2128,test,0,Normalization 정규화 그게 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2129,test,0,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2130,test,0,Min-Max 정규화가 뭔지 잘 모르겠어,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
2131,test,0,Z 스코어 정규화가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
2132,test,0,Clipping? 클리핑? 그게 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
2133,test,0,클리핑 이거 쓸데없이 하는 거 아니야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
2134,test,0,로그 스케일링도 정규화 같은데 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
2135,test,0,Outlier 개념,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2136,test,0,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2137,test,0,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
2138,test,0,Outlier 없애려면 어떻게 해야 되지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
2139,test,0,PCA에 대해 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2140,test,0,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2141,test,0,PCA 그거 왜 하는 건지 모르겠어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
2142,test,0,데이터가 불균형하다고? 그게 뭐지,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
2143,test,0,데이터 불균형 어떻게 하면 해결할 수 있지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
2144,test,0,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
2145,test,0,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
2146,test,0,데이터 증강이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
2147,test,0,언더샘플링이랑 오버샘플링이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
2148,test,0,Undersampling 에 대해서 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
2149,test,0,oversampling 이 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가
2150,test,0,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
2151,test,0,undersampling 방법은 뭐가 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
2152,test,0,Oversampling 하는 방법,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
2153,test,0,차원의 저주가 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
2154,test,0,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
2155,test,0,의사결정 나무가 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2156,test,0,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2157,test,0,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
2158,test,0,앙상블이 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
2159,test,0,앙상블 하는 이유,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
2160,test,0,앙상블 방법,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2161,test,0,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2162,test,0,Voting? 그게 뭐지,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2163,test,0,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2164,test,0,보팅 방법 구체적으로 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
2165,test,0,배깅이뭐야,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
2166,test,0,부스팅이 뭐지 그러면,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
2167,test,0,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
2168,test,0,가우시안 혼합? 그게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2169,test,0,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2170,test,0,K-means Clustering 너 알지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
2171,test,0,K-means Clustering 방법,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
2172,test,0,KNN 알고리즘 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2173,test,0,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2174,test,0,지도학습 강화학습 비지도학습 이런게 뭐지,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2175,test,0,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2176,test,0,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2177,test,0,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
2178,test,0,머신러닝 문제에는 뭐가 있지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2179,test,0,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2180,test,0,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2181,test,0,Naïve Bayes 뭐야,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
2182,test,0,서포트 벡터 머신? 그게 뭐지? 알려줘!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2183,test,0,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2184,test,0,K-fold Cross Validation 정의,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
2185,test,0,K-fold Cross Validation 하는 이유는?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
2186,test,0,Hyper parameter 가 대체 뭐지,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
2187,test,0,One-hot? 그것도 머신러닝 모델이야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
2188,test,0,Valid 데이터 쓰는 이유가 궁금해,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
2189,test,0,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
2190,test,0,인공지능 머신러닝 딥러닝의 관계는?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
2191,test,0,인공지능 정의,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
2192,test,0,머신러닝은 인공지능에 속하는 거 맞지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
2193,test,0,딥러닝이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
2194,test,0,딥러닝의 learning rate 그게 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2195,test,0,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2196,test,0,자주 쓰이는 손실 함수는 뭐가 있을까,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
2197,test,0,오버피팅이 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
2198,test,0,Overfitting 대체 어떻게 해결하지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
2199,test,0,전이학습? 그게 뭐야 도대체?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2200,test,0,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2201,test,0,활성화 함수? 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
2202,test,0,굳이 활성화 함수 왜 써?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
2203,test,0,CNN이 뭐야? 이미지 인식에 좋다던데,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
2204,test,0,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
2205,test,1,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2206,test,1,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2207,test,1,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
2208,test,1,머신러닝 모델 평가하는 방법 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
2209,test,1,Accuracy 계산 어떻게 하지?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
2210,test,1,True Positive 가 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
2211,test,1,True Negative 는 뭔지 궁금해 그럼,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
2212,test,1,False Positive 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
2213,test,1,False Negative (FN),False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
2214,test,1,Recall 계산법 어떻게 하는 거지?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
2215,test,1,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2216,test,1,Precision 어떻게 계산하는지 정말 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2217,test,1,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
2218,test,1,F1 Score 가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
2219,test,1,F1 Score 계산식 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균
2220,test,1,F1 Score 는 왜 쓰는 거지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
2221,test,1,IoU 라는 게 있는데 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
2222,test,1,특이도는 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
2223,test,1,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
2224,test,1,"PR-AUC, ROC-AUC 가 뭐야?","binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
2225,test,1,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
2226,test,1,ROC-AUC 는 뭔지 정말 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2227,test,1,True Positive Rate 구하는 방법을 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2228,test,1,False Positive Rate 가 뭔지 정말 궁금하다,True Positive Rate : recall 의 다른 이름
2229,test,1,Confusion Matrix (혼동 행렬) 이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
2230,test,1,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
2231,test,1,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
2232,test,1,Normalization 정규화 그게 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
2233,test,1,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2234,test,1,Min-Max 정규화가 뭔지 잘 모르겠어,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2235,test,1,Z 스코어 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
2236,test,1,Clipping? 클리핑? 그게 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
2237,test,1,클리핑 이거 쓸데없이 하는 거 아니야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
2238,test,1,로그 스케일링도 정규화 같은데 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
2239,test,1,Outlier 개념,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
2240,test,1,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2241,test,1,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2242,test,1,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
2243,test,1,PCA에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
2244,test,1,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2245,test,1,PCA 그거 왜 하는 건지 모르겠어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2246,test,1,데이터가 불균형하다고? 그게 뭐지,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
2247,test,1,데이터 불균형 어떻게 하면 해결할 수 있지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
2248,test,1,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
2249,test,1,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
2250,test,1,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
2251,test,1,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
2252,test,1,Undersampling 에 대해서 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
2253,test,1,oversampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
2254,test,1,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Oversampling : 데이터가 적은 Class 의 데이터 증가
2255,test,1,undersampling 방법은 뭐가 있어?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
2256,test,1,Oversampling 하는 방법,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
2257,test,1,차원의 저주가 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
2258,test,1,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
2259,test,1,의사결정 나무가 뭔지 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
2260,test,1,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2261,test,1,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2262,test,1,앙상블이 뭐지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
2263,test,1,앙상블 하는 이유,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
2264,test,1,앙상블 방법,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
2265,test,1,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2266,test,1,Voting? 그게 뭐지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2267,test,1,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2268,test,1,보팅 방법 구체적으로 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2269,test,1,배깅이뭐야,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
2270,test,1,부스팅이 뭐지 그러면,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
2271,test,1,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
2272,test,1,가우시안 혼합? 그게 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
2273,test,1,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2274,test,1,K-means Clustering 너 알지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2275,test,1,K-means Clustering 방법,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
2276,test,1,KNN 알고리즘 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
2277,test,1,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2278,test,1,지도학습 강화학습 비지도학습 이런게 뭐지,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2279,test,1,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2280,test,1,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2281,test,1,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2282,test,1,머신러닝 문제에는 뭐가 있지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
2283,test,1,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2284,test,1,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2285,test,1,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2286,test,1,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
2287,test,1,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2288,test,1,K-fold Cross Validation 정의,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2289,test,1,K-fold Cross Validation 하는 이유는?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
2290,test,1,Hyper parameter 가 대체 뭐지,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
2291,test,1,One-hot? 그것도 머신러닝 모델이야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
2292,test,1,Valid 데이터 쓰는 이유가 궁금해,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
2293,test,1,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
2294,test,1,인공지능 머신러닝 딥러닝의 관계는?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
2295,test,1,인공지능 정의,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
2296,test,1,머신러닝은 인공지능에 속하는 거 맞지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
2297,test,1,딥러닝이 뭔지 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
2298,test,1,딥러닝의 learning rate 그게 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
2299,test,1,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2300,test,1,자주 쓰이는 손실 함수는 뭐가 있을까,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2301,test,1,오버피팅이 뭐야,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
2302,test,1,Overfitting 대체 어떻게 해결하지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
2303,test,1,전이학습? 그게 뭐야 도대체?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
2304,test,1,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2305,test,1,활성화 함수? 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2306,test,1,굳이 활성화 함수 왜 써?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
2307,test,1,CNN이 뭐야? 이미지 인식에 좋다던데,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
2308,test,1,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
2309,test,1,코사인 유사도가 뭔지 궁금해,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
2310,test,2,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2311,test,2,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2312,test,2,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
2313,test,2,Accuracy 계산 어떻게 하지?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
2314,test,2,True Positive 가 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
2315,test,2,True Negative 는 뭔지 궁금해 그럼,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
2316,test,2,False Positive 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
2317,test,2,False Negative (FN),True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
2318,test,2,Recall 계산법 어떻게 하는 거지?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
2319,test,2,Recall 이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
2320,test,2,Precision 어떻게 계산하는지 정말 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2321,test,2,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2322,test,2,F1 Score 가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
2323,test,2,F1 Score 계산식 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
2324,test,2,F1 Score 는 왜 쓰는 거지?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
2325,test,2,IoU 라는 게 있는데 뭔지 궁금해,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
2326,test,2,특이도는 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
2327,test,2,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
2328,test,2,"PR-AUC, ROC-AUC 가 뭐야?",Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
2329,test,2,PR-AUC 에 대해 아주 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
2330,test,2,ROC-AUC 는 뭔지 정말 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
2331,test,2,True Positive Rate 구하는 방법을 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2332,test,2,False Positive Rate 가 뭔지 정말 궁금하다,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2333,test,2,Confusion Matrix (혼동 행렬) 이 뭐야?,True Positive Rate : recall 의 다른 이름
2334,test,2,Confusion Matrix 는 그럼 어떻게 만들어?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
2335,test,2,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
2336,test,2,Normalization 정규화 그게 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
2337,test,2,정규화가 뭐지? 정말 궁금해!,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
2338,test,2,Min-Max 정규화가 뭔지 잘 모르겠어,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2339,test,2,Z 스코어 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2340,test,2,Clipping? 클리핑? 그게 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
2341,test,2,클리핑 이거 쓸데없이 하는 거 아니야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
2342,test,2,로그 스케일링도 정규화 같은데 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
2343,test,2,Outlier 개념,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
2344,test,2,이상치가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
2345,test,2,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2346,test,2,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2347,test,2,PCA에 대해 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
2348,test,2,주성분 분석?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
2349,test,2,PCA 그거 왜 하는 건지 모르겠어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2350,test,2,데이터가 불균형하다고? 그게 뭐지,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2351,test,2,데이터 불균형 어떻게 하면 해결할 수 있지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
2352,test,2,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
2353,test,2,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
2354,test,2,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
2355,test,2,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
2356,test,2,Undersampling 에 대해서 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
2357,test,2,oversampling 이 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
2358,test,2,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
2359,test,2,undersampling 방법은 뭐가 있어?,Oversampling : 데이터가 적은 Class 의 데이터 증가
2360,test,2,Oversampling 하는 방법,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
2361,test,2,차원의 저주가 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
2362,test,2,차원의 저주는 저주인데 정확히 뭐가 문제야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
2363,test,2,의사결정 나무가 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
2364,test,2,Decision Tree 가 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
2365,test,2,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2366,test,2,앙상블이 뭐지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2367,test,2,앙상블 하는 이유,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
2368,test,2,앙상블 방법,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
2369,test,2,Ensemble 정확히 어떻게 하지,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
2370,test,2,Voting? 그게 뭐지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2371,test,2,앙상블 중에서 보팅 있잖아 그게 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2372,test,2,보팅 방법 구체적으로 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2373,test,2,배깅이뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2374,test,2,부스팅이 뭐지 그러면,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
2375,test,2,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
2376,test,2,가우시안 혼합? 그게 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
2377,test,2,Gaussian Mixture 어려운 것 같은데 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
2378,test,2,K-means Clustering 너 알지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2379,test,2,K-means Clustering 방법,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2380,test,2,KNN 알고리즘 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
2381,test,2,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
2382,test,2,지도학습 강화학습 비지도학습 이런게 뭐지,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2383,test,2,머신러닝 방법 종류 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2384,test,2,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2385,test,2,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2386,test,2,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2387,test,2,분류랑 회귀가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
2388,test,2,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2389,test,2,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2390,test,2,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2391,test,2,SVM 제발 알려줘 제발,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
2392,test,2,K-fold Cross Validation 정의,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2393,test,2,K-fold Cross Validation 하는 이유는?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2394,test,2,Hyper parameter 가 대체 뭐지,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
2395,test,2,One-hot? 그것도 머신러닝 모델이야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
2396,test,2,Valid 데이터 쓰는 이유가 궁금해,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
2397,test,2,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
2398,test,2,인공지능 머신러닝 딥러닝의 관계는?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
2399,test,2,인공지능 정의,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
2400,test,2,머신러닝은 인공지능에 속하는 거 맞지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
2401,test,2,딥러닝이 뭔지 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
2402,test,2,딥러닝의 learning rate 그게 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
2403,test,2,학습률? Learning rate? 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
2404,test,2,자주 쓰이는 손실 함수는 뭐가 있을까,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2405,test,2,오버피팅이 뭐야,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2406,test,2,Overfitting 대체 어떻게 해결하지?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
2407,test,2,전이학습? 그게 뭐야 도대체?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
2408,test,2,Transfer Learning 요즘 대세라던데 뭐야,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
2409,test,2,활성화 함수? 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2410,test,2,굳이 활성화 함수 왜 써?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2411,test,2,CNN이 뭐야? 이미지 인식에 좋다던데,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
2412,test,2,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
2413,test,2,코사인 유사도가 뭔지 궁금해,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
2414,test,2,Cosine Similarity 에 대해 알려줘!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
2415,test,3,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2416,test,3,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2417,test,3,Accuracy 계산 어떻게 하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
2418,test,3,True Positive 가 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
2419,test,3,True Negative 는 뭔지 궁금해 그럼,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
2420,test,3,False Positive 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
2421,test,3,False Negative (FN),True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
2422,test,3,Recall 계산법 어떻게 하는 거지?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
2423,test,3,Recall 이 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
2424,test,3,Precision 어떻게 계산하는지 정말 궁금해,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
2425,test,3,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2426,test,3,F1 Score 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2427,test,3,F1 Score 계산식 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
2428,test,3,F1 Score 는 왜 쓰는 거지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
2429,test,3,IoU 라는 게 있는데 뭔지 궁금해,F1 Score 개념 : Recall 과 Precision 의 조화 평균
2430,test,3,특이도는 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
2431,test,3,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
2432,test,3,"PR-AUC, ROC-AUC 가 뭐야?",IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
2433,test,3,PR-AUC 에 대해 아주 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
2434,test,3,ROC-AUC 는 뭔지 정말 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
2435,test,3,True Positive Rate 구하는 방법을 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
2436,test,3,False Positive Rate 가 뭔지 정말 궁금하다,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2437,test,3,Confusion Matrix (혼동 행렬) 이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2438,test,3,Confusion Matrix 는 그럼 어떻게 만들어?,True Positive Rate : recall 의 다른 이름
2439,test,3,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
2440,test,3,Normalization 정규화 그게 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
2441,test,3,정규화가 뭐지? 정말 궁금해!,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
2442,test,3,Min-Max 정규화가 뭔지 잘 모르겠어,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
2443,test,3,Z 스코어 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2444,test,3,Clipping? 클리핑? 그게 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2445,test,3,클리핑 이거 쓸데없이 하는 거 아니야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
2446,test,3,로그 스케일링도 정규화 같은데 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
2447,test,3,Outlier 개념,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
2448,test,3,이상치가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
2449,test,3,Outlier 없애야 되는 이유가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
2450,test,3,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2451,test,3,PCA에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2452,test,3,주성분 분석?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
2453,test,3,PCA 그거 왜 하는 건지 모르겠어,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
2454,test,3,데이터가 불균형하다고? 그게 뭐지,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2455,test,3,데이터 불균형 어떻게 하면 해결할 수 있지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2456,test,3,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
2457,test,3,학습 환경만 바꾸는 방법도 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
2458,test,3,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
2459,test,3,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
2460,test,3,Undersampling 에 대해서 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
2461,test,3,oversampling 이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
2462,test,3,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
2463,test,3,undersampling 방법은 뭐가 있어?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
2464,test,3,Oversampling 하는 방법,Oversampling : 데이터가 적은 Class 의 데이터 증가
2465,test,3,차원의 저주가 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
2466,test,3,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
2467,test,3,의사결정 나무가 뭔지 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
2468,test,3,Decision Tree 가 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
2469,test,3,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
2470,test,3,앙상블이 뭐지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2471,test,3,앙상블 하는 이유,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2472,test,3,앙상블 방법,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
2473,test,3,Ensemble 정확히 어떻게 하지,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
2474,test,3,Voting? 그게 뭐지,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
2475,test,3,앙상블 중에서 보팅 있잖아 그게 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2476,test,3,보팅 방법 구체적으로 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2477,test,3,배깅이뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2478,test,3,부스팅이 뭐지 그러면,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2479,test,3,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
2480,test,3,가우시안 혼합? 그게 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
2481,test,3,Gaussian Mixture 어려운 것 같은데 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
2482,test,3,K-means Clustering 너 알지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
2483,test,3,K-means Clustering 방법,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2484,test,3,KNN 알고리즘 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2485,test,3,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
2486,test,3,지도학습 강화학습 비지도학습 이런게 뭐지,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
2487,test,3,머신러닝 방법 종류 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2488,test,3,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2489,test,3,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2490,test,3,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2491,test,3,분류랑 회귀가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2492,test,3,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
2493,test,3,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2494,test,3,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2495,test,3,SVM 제발 알려줘 제발,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2496,test,3,K-fold Cross Validation 정의,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
2497,test,3,K-fold Cross Validation 하는 이유는?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2498,test,3,Hyper parameter 가 대체 뭐지,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2499,test,3,One-hot? 그것도 머신러닝 모델이야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
2500,test,3,Valid 데이터 쓰는 이유가 궁금해,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
2501,test,3,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
2502,test,3,인공지능 머신러닝 딥러닝의 관계는?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
2503,test,3,인공지능 정의,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
2504,test,3,머신러닝은 인공지능에 속하는 거 맞지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
2505,test,3,딥러닝이 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
2506,test,3,딥러닝의 learning rate 그게 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
2507,test,3,학습률? Learning rate? 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
2508,test,3,자주 쓰이는 손실 함수는 뭐가 있을까,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
2509,test,3,오버피팅이 뭐야,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2510,test,3,Overfitting 대체 어떻게 해결하지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2511,test,3,전이학습? 그게 뭐야 도대체?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
2512,test,3,Transfer Learning 요즘 대세라던데 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
2513,test,3,활성화 함수? 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
2514,test,3,굳이 활성화 함수 왜 써?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2515,test,3,CNN이 뭐야? 이미지 인식에 좋다던데,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2516,test,3,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
2517,test,3,코사인 유사도가 뭔지 궁금해,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
2518,test,3,Cosine Similarity 에 대해 알려줘!,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
2519,test,3,Cosine Similarity 는 어떻게 계산하지?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
2520,test,4,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2521,test,4,Accuracy 계산 어떻게 하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄
2522,test,4,True Positive 가 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값
2523,test,4,True Negative 는 뭔지 궁금해 그럼,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0"
2524,test,4,False Positive 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score"
2525,test,4,False Negative (FN),Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수)
2526,test,4,Recall 계산법 어떻게 하는 거지?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수
2527,test,4,Recall 이 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수
2528,test,4,Precision 어떻게 계산하는지 정말 궁금해,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수
2529,test,4,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수
2530,test,4,F1 Score 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2531,test,4,F1 Score 계산식 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative)
2532,test,4,F1 Score 는 왜 쓰는 거지?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive)
2533,test,4,IoU 라는 게 있는데 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소"
2534,test,4,특이도는 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균
2535,test,4,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall)
2536,test,4,"PR-AUC, ROC-AUC 가 뭐야?","F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려"
2537,test,4,PR-AUC 에 대해 아주 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative)
2538,test,4,ROC-AUC 는 뭔지 정말 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative)
2539,test,4,True Positive Rate 구하는 방법을 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC"
2540,test,4,False Positive Rate 가 뭔지 정말 궁금하다,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이"
2541,test,4,Confusion Matrix (혼동 행렬) 이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2542,test,4,Confusion Matrix 는 그럼 어떻게 만들어?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)"
2543,test,4,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,True Positive Rate : recall 의 다른 이름
2544,test,4,Normalization 정규화 그게 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative)
2545,test,4,정규화가 뭐지? 정말 궁금해!,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표"
2546,test,4,Min-Max 정규화가 뭔지 잘 모르겠어,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산"
2547,test,4,Z 스코어 정규화가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미"
2548,test,4,Clipping? 클리핑? 그게 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2549,test,4,클리핑 이거 쓸데없이 하는 거 아니야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score"
2550,test,4,로그 스케일링도 정규화 같은데 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN)
2551,test,4,Outlier 개념,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD
2552,test,4,이상치가 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)"
2553,test,4,Outlier 없애야 되는 이유가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음
2554,test,4,Outlier 없애려면 어떻게 해야 되지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것
2555,test,4,PCA에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2556,test,4,주성분 분석?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터
2557,test,4,PCA 그거 왜 하는 건지 모르겠어,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함
2558,test,4,데이터가 불균형하다고? 그게 뭐지,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등"
2559,test,4,데이터 불균형 어떻게 하면 해결할 수 있지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2560,test,4,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출"
2561,test,4,학습 환경만 바꾸는 방법도 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적
2562,test,4,데이터 증강이 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것
2563,test,4,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법"
2564,test,4,Undersampling 에 대해서 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등"
2565,test,4,oversampling 이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정"
2566,test,4,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것"
2567,test,4,undersampling 방법은 뭐가 있어?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가
2568,test,4,Oversampling 하는 방법,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거
2569,test,4,차원의 저주가 뭔지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가
2570,test,4,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC"
2571,test,4,의사결정 나무가 뭔지 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)"
2572,test,4,Decision Tree 가 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산)
2573,test,4,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것"
2574,test,4,앙상블이 뭐지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소"
2575,test,4,앙상블 하는 이유,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2576,test,4,앙상블 방법,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식
2577,test,4,Ensemble 정확히 어떻게 하지,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복
2578,test,4,Voting? 그게 뭐지,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것
2579,test,4,앙상블 중에서 보팅 있잖아 그게 뭐야,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상
2580,test,4,보팅 방법 구체적으로 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2581,test,4,배깅이뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)"
2582,test,4,부스팅이 뭐지 그러면,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2583,test,4,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출
2584,test,4,가우시안 혼합? 그게 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)"
2585,test,4,Gaussian Mixture 어려운 것 같은데 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합"
2586,test,4,K-means Clustering 너 알지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습"
2587,test,4,K-means Clustering 방법,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용"
2588,test,4,KNN 알고리즘 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2589,test,4,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘
2590,test,4,지도학습 강화학습 비지도학습 이런게 뭐지,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법"
2591,test,4,머신러닝 방법 종류 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복"
2592,test,4,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2593,test,4,지도학습이랑 비지도랑 뭐가 달라 그러면?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측"
2594,test,4,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2595,test,4,분류랑 회귀가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2596,test,4,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습"
2597,test,4,Naïve Bayes 뭐야,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음"
2598,test,4,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2599,test,4,SVM 제발 알려줘 제발,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2600,test,4,K-fold Cross Validation 정의,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것"
2601,test,4,K-fold Cross Validation 하는 이유는?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측"
2602,test,4,Hyper parameter 가 대체 뭐지,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2603,test,4,One-hot? 그것도 머신러닝 모델이야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘"
2604,test,4,Valid 데이터 쓰는 이유가 궁금해,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법"
2605,test,4,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음
2606,test,4,인공지능 머신러닝 딥러닝의 관계는?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값"
2607,test,4,인공지능 정의,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법"
2608,test,4,머신러닝은 인공지능에 속하는 거 맞지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용
2609,test,4,딥러닝이 뭔지 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지"
2610,test,4,딥러닝의 learning rate 그게 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함"
2611,test,4,학습률? Learning rate? 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술"
2612,test,4,자주 쓰이는 손실 함수는 뭐가 있을까,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술"
2613,test,4,오버피팅이 뭐야,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술
2614,test,4,Overfitting 대체 어떻게 해결하지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2615,test,4,전이학습? 그게 뭐야 도대체?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수
2616,test,4,Transfer Learning 요즘 대세라던데 뭐야,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy"
2617,test,4,활성화 함수? 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상
2618,test,4,굳이 활성화 함수 왜 써?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등"
2619,test,4,CNN이 뭐야? 이미지 인식에 좋다던데,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2620,test,4,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것
2621,test,4,코사인 유사도가 뭔지 궁금해,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수"
2622,test,4,Cosine Similarity 에 대해 알려줘!,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능
2623,test,4,Cosine Similarity 는 어떻게 계산하지?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함"
2624,test,4,코사인 유사도 특징이 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델"
