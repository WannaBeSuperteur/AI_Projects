,data_type,repeat,user_question,rag_retrieved_data,similarity_score
0,train,0,cosine similarity가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
1,train,0,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2,train,0,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,1.0
3,train,0,코사인 유사도의 특징을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",1.0
4,train,0,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",1.0
5,train,0,Accuracy 는 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),1.0
6,train,0,True Positive 같은 건 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,1.0
7,train,0,True Negative 는?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,1.0
8,train,0,False Positive 는 뭐지 그럼?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,1.0
9,train,0,False Negative 는 뭐야 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,1.0
10,train,0,Recall 은 어떻게 계산해?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
11,train,0,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
12,train,0,Precision 은 어떻게 계산하지,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),1.0
13,train,0,Recall 과 Precision 이 자꾸 헷갈리네,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",1.0
14,train,0,F1 이 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,1.0
15,train,0,F1 Score 구하는 수식을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),1.0
16,train,0,F1 Score 장점이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",1.0
17,train,0,IoU 가 뭔지 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),1.0
18,train,0,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),1.0
19,train,0,이진 분류에서 쓰이는 Metric 을 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",1.0
20,train,0,PR-AUC랑 ROC-AUC가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",1.0
21,train,0,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
22,train,0,ROC-AUC가 뭔지 아주 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
23,train,0,True Positive Rate 가 뭐야? 궁금해!,True Positive Rate : recall 의 다른 이름,1.0
24,train,0,False Positive Rate 는 뭐지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),1.0
25,train,0,Confusion Matrix 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",1.0
26,train,0,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",1.0
27,train,0,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",1.0
28,train,0,Normalization 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
29,train,0,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
30,train,0,min-max 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),1.0
31,train,0,Z score normalization 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,1.0
32,train,0,Clipping 에 대해서 자세히 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",1.0
33,train,0,Clipping 을 하면 뭐가 좋아?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,1.0
34,train,0,로그 스케일링이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,1.0
35,train,0,Outlier 가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
36,train,0,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
37,train,0,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,1.0
38,train,0,Outlier 를 제거하는 방법에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",1.0
39,train,0,PCA 가 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
40,train,0,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
41,train,0,PCA 는 왜 하는 거지 그러면?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,1.0
42,train,0,데이터 불균형이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,1.0
43,train,0,데이터 불균형 해결하는 법이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",1.0
44,train,0,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",1.0
45,train,0,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",1.0
46,train,0,Augmentation 이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",1.0
47,train,0,Undersampling 이랑 Oversampling 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,1.0
48,train,0,Undersampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,1.0
49,train,0,그럼 Oversampling 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,1.0
50,train,0,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",1.0
51,train,0,Undersampling 하는 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",1.0
52,train,0,Oversampling 방법은 어떤 게 있어?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),1.0
53,train,0,차원의 저주가 뭐지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",1.0
54,train,0,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",1.0
55,train,0,Decision Tree 가 뭔지 자세히 알고 싶어,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
56,train,0,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
57,train,0,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,1.0
58,train,0,앙상블이 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,1.0
59,train,0,앙상블을 왜 하는 거야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,1.0
60,train,0,앙상블 하는 구체적인 방법 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
61,train,0,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
62,train,0,보팅에 대해 자세히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
63,train,0,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
64,train,0,보팅의 방법에는 구체적으로 뭐가 있지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",1.0
65,train,0,Bagging 이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",1.0
66,train,0,그럼 Boosting 은 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",1.0
67,train,0,Stacking 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",1.0
68,train,0,Gaussian Mixture 모델이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
69,train,0,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
70,train,0,K-means Clustering 이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",1.0
71,train,0,K-means Clustering 의 방법을 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",1.0
72,train,0,kNN 에 대해 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
73,train,0,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
74,train,0,지도학습 비지도학습 이런 게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
75,train,0,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
76,train,0,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
77,train,0,지도학습과 비지도학습의 차이가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",1.0
78,train,0,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
79,train,0,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
80,train,0,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
81,train,0,Naïve Bayes 가 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",1.0
82,train,0,서포트 벡터 머신이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
83,train,0,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
84,train,0,K-fold Cross Validation,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",1.0
85,train,0,K-fold Cross Validation을 굳이 왜 하는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,1.0
86,train,0,하이퍼파라미터가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",1.0
87,train,0,One-hot 방식이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",1.0
88,train,0,Valid 데이터가 굳이 왜 필요하지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,1.0
89,train,0,Train 데이터셋을 왜 순서를 섞어야 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",1.0
90,train,0,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",1.0
91,train,0,인공지능이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",1.0
92,train,0,머신러닝은 그럼 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",1.0
93,train,0,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,1.0
94,train,0,딥러닝에서 학습률이 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
95,train,0,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
96,train,0,자주 쓰는 Loss Function 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",1.0
97,train,0,Overfitting 이 뭔지 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,1.0
98,train,0,Overfitting 해결하는 방법은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",1.0
99,train,0,전이학습이 뭐지?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
100,train,0,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
101,train,0,활성화 함수? 그게 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",1.0
102,train,0,활성화 함수는 왜 필요해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,1.0
103,train,0,CNN이 뭐야? 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",1.0
104,train,0,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",1.0
105,train,1,코사인 유사도가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
106,train,1,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
107,train,1,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.5
108,train,1,머신러닝에서 많이 쓰이는 평가지표 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
109,train,1,Accuracy 는 어떻게 계산해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
110,train,1,True Positive 같은 건 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.1
111,train,1,True Negative 는?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
112,train,1,False Positive 는 뭐지 그럼?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
113,train,1,False Negative 는 뭐야 그러면?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
114,train,1,Recall 은 어떻게 계산해?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
115,train,1,Recall 은 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
116,train,1,Precision 은 어떻게 계산하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
117,train,1,Recall 과 Precision 이 자꾸 헷갈리네,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.5
118,train,1,F1 이 뭔지 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
119,train,1,F1 Score 구하는 수식을 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
120,train,1,F1 Score 장점이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.5
121,train,1,IoU 가 뭔지 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
122,train,1,특이도라는 걸 봤는데 그게 뭔지 궁금해!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
123,train,1,이진 분류에서 쓰이는 Metric 을 알려줘!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
124,train,1,PR-AUC랑 ROC-AUC가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
125,train,1,PR-AUC가 뭔지 자세히 알려줘!,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.5
126,train,1,ROC-AUC가 뭔지 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
127,train,1,True Positive Rate 가 뭐야? 궁금해!,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
128,train,1,False Positive Rate 는 뭐지 그러면?,True Positive Rate : recall 의 다른 이름,0.25
129,train,1,Confusion Matrix 가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.25
130,train,1,Confusion Matrix 만드는 법을 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.5
131,train,1,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.25
132,train,1,Normalization 이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
133,train,1,정규화가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
134,train,1,min-max 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
135,train,1,Z score normalization 이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
136,train,1,Clipping 에 대해서 자세히 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
137,train,1,Clipping 을 하면 뭐가 좋아?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.5
138,train,1,로그 스케일링이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
139,train,1,Outlier 가 뭔지 궁금해,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
140,train,1,이상치가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
141,train,1,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
142,train,1,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.5
143,train,1,PCA 가 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
144,train,1,주성분 분석이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
145,train,1,PCA 는 왜 하는 거지 그러면?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
146,train,1,데이터 불균형이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
147,train,1,데이터 불균형 해결하는 법이 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.5
148,train,1,데이터를 새로 추가하거나 제거하는 법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.5
149,train,1,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
150,train,1,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.1
151,train,1,Undersampling 이랑 Oversampling 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
152,train,1,Undersampling 이 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
153,train,1,그럼 Oversampling 은 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
154,train,1,데이터 불균형을 고려한 성능지표를 추천해 줘!,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.1
155,train,1,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
156,train,1,Oversampling 방법은 어떤 게 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.25
157,train,1,차원의 저주가 뭐지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
158,train,1,차원의 저주가 구체적으로 어떤 문제야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.5
159,train,1,Decision Tree 가 뭔지 자세히 알고 싶어,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
160,train,1,의사결정 나무,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
161,train,1,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
162,train,1,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
163,train,1,앙상블을 왜 하는 거야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
164,train,1,앙상블 하는 구체적인 방법 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
165,train,1,앙상블은 정확히 어떻게 하는 건지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
166,train,1,보팅에 대해 자세히 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
167,train,1,앙상블 중에 Voting 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
168,train,1,보팅의 방법에는 구체적으로 뭐가 있지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
169,train,1,Bagging 이 뭔지 궁금해,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
170,train,1,그럼 Boosting 은 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
171,train,1,Stacking 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.25
172,train,1,Gaussian Mixture 모델이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
173,train,1,가우시안 혼합이 뭔지 궁금해,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
174,train,1,K-means Clustering 이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
175,train,1,K-means Clustering 의 방법을 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.5
176,train,1,kNN 에 대해 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
177,train,1,k Nearest Neighbor 알고리즘이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
178,train,1,지도학습 비지도학습 이런 게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
179,train,1,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
180,train,1,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
181,train,1,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
182,train,1,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
183,train,1,분류와 회귀 문제가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
184,train,1,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
185,train,1,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
186,train,1,서포트 벡터 머신이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
187,train,1,SVM이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
188,train,1,K-fold Cross Validation,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
189,train,1,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.5
190,train,1,하이퍼파라미터가 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
191,train,1,One-hot 방식이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
192,train,1,Valid 데이터가 굳이 왜 필요하지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.25
193,train,1,Train 데이터셋을 왜 순서를 섞어야 돼?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
194,train,1,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
195,train,1,인공지능이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.5
196,train,1,머신러닝은 그럼 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
197,train,1,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.25
198,train,1,딥러닝에서 학습률이 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.1
199,train,1,learning rate 가 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
200,train,1,자주 쓰는 Loss Function 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
201,train,1,Overfitting 이 뭔지 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
202,train,1,Overfitting 해결하는 방법은 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.5
203,train,1,전이학습이 뭐지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
204,train,1,Transfer Learning 이 뭔지 궁금해!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
205,train,1,활성화 함수? 그게 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
206,train,1,활성화 함수는 왜 필요해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.5
207,train,1,CNN이 뭐야? 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
208,train,1,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
209,train,1,cosine similarity가 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
210,train,2,코사인 유사도 계산법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
211,train,2,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
212,train,2,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
213,train,2,Accuracy 는 어떻게 계산해?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
214,train,2,True Positive 같은 건 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
215,train,2,True Negative 는?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
216,train,2,False Positive 는 뭐지 그럼?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
217,train,2,False Negative 는 뭐야 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
218,train,2,Recall 은 어떻게 계산해?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
219,train,2,Recall 은 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
220,train,2,Precision 은 어떻게 계산하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
221,train,2,Recall 과 Precision 이 자꾸 헷갈리네,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
222,train,2,F1 이 뭔지 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
223,train,2,F1 Score 구하는 수식을 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
224,train,2,F1 Score 장점이 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
225,train,2,IoU 가 뭔지 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
226,train,2,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
227,train,2,이진 분류에서 쓰이는 Metric 을 알려줘!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
228,train,2,PR-AUC랑 ROC-AUC가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
229,train,2,PR-AUC가 뭔지 자세히 알려줘!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
230,train,2,ROC-AUC가 뭔지 아주 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
231,train,2,True Positive Rate 가 뭐야? 궁금해!,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
232,train,2,False Positive Rate 는 뭐지 그러면?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
233,train,2,Confusion Matrix 가 뭐야?,True Positive Rate : recall 의 다른 이름,0.1
234,train,2,Confusion Matrix 만드는 법을 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
235,train,2,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.1
236,train,2,Normalization 이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
237,train,2,정규화가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
238,train,2,min-max 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
239,train,2,Z score normalization 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
240,train,2,Clipping 에 대해서 자세히 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
241,train,2,Clipping 을 하면 뭐가 좋아?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
242,train,2,로그 스케일링이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.25
243,train,2,Outlier 가 뭔지 궁금해,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
244,train,2,이상치가 뭔지 궁금해,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
245,train,2,Outlier 를 제거해야 하는 이유는 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
246,train,2,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
247,train,2,PCA 가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
248,train,2,주성분 분석이 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
249,train,2,PCA 는 왜 하는 거지 그러면?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
250,train,2,데이터 불균형이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
251,train,2,데이터 불균형 해결하는 법이 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
252,train,2,데이터를 새로 추가하거나 제거하는 법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
253,train,2,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
254,train,2,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
255,train,2,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
256,train,2,Undersampling 이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
257,train,2,그럼 Oversampling 은 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.25
258,train,2,데이터 불균형을 고려한 성능지표를 추천해 줘!,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.1
259,train,2,Undersampling 하는 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
260,train,2,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
261,train,2,차원의 저주가 뭐지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
262,train,2,차원의 저주가 구체적으로 어떤 문제야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
263,train,2,Decision Tree 가 뭔지 자세히 알고 싶어,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
264,train,2,의사결정 나무,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
265,train,2,Decision Tree 로 결정하는 방법은?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
266,train,2,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
267,train,2,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
268,train,2,앙상블 하는 구체적인 방법 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
269,train,2,앙상블은 정확히 어떻게 하는 건지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
270,train,2,보팅에 대해 자세히 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
271,train,2,앙상블 중에 Voting 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
272,train,2,보팅의 방법에는 구체적으로 뭐가 있지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
273,train,2,Bagging 이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
274,train,2,그럼 Boosting 은 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
275,train,2,Stacking 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
276,train,2,Gaussian Mixture 모델이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
277,train,2,가우시안 혼합이 뭔지 궁금해,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
278,train,2,K-means Clustering 이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
279,train,2,K-means Clustering 의 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
280,train,2,kNN 에 대해 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
281,train,2,k Nearest Neighbor 알고리즘이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
282,train,2,지도학습 비지도학습 이런 게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
283,train,2,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
284,train,2,강화학습? 지도학습? 그게 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
285,train,2,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
286,train,2,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
287,train,2,분류와 회귀 문제가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
288,train,2,Regression 이랑 Classification 이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
289,train,2,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
290,train,2,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
291,train,2,SVM이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
292,train,2,K-fold Cross Validation,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
293,train,2,K-fold Cross Validation을 굳이 왜 하는 거야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
294,train,2,하이퍼파라미터가 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
295,train,2,One-hot 방식이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
296,train,2,Valid 데이터가 굳이 왜 필요하지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
297,train,2,Train 데이터셋을 왜 순서를 섞어야 돼?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
298,train,2,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
299,train,2,인공지능이 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
300,train,2,머신러닝은 그럼 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
301,train,2,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
302,train,2,딥러닝에서 학습률이 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
303,train,2,learning rate 가 뭔지 궁금해!,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
304,train,2,자주 쓰는 Loss Function 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
305,train,2,Overfitting 이 뭔지 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
306,train,2,Overfitting 해결하는 방법은 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
307,train,2,전이학습이 뭐지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
308,train,2,Transfer Learning 이 뭔지 궁금해!,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
309,train,2,활성화 함수? 그게 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
310,train,2,활성화 함수는 왜 필요해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
311,train,2,CNN이 뭐야? 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
312,train,2,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
313,train,2,cosine similarity가 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
314,train,2,코사인 유사도가 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
315,train,3,코사인 유사도의 특징을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
316,train,3,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
317,train,3,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
318,train,3,True Positive 같은 건 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
319,train,3,True Negative 는?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
320,train,3,False Positive 는 뭐지 그럼?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
321,train,3,False Negative 는 뭐야 그러면?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
322,train,3,Recall 은 어떻게 계산해?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
323,train,3,Recall 은 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
324,train,3,Precision 은 어떻게 계산하지,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
325,train,3,Recall 과 Precision 이 자꾸 헷갈리네,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.5
326,train,3,F1 이 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
327,train,3,F1 Score 구하는 수식을 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
328,train,3,F1 Score 장점이 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
329,train,3,IoU 가 뭔지 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
330,train,3,특이도라는 걸 봤는데 그게 뭔지 궁금해!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
331,train,3,이진 분류에서 쓰이는 Metric 을 알려줘!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
332,train,3,PR-AUC랑 ROC-AUC가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
333,train,3,PR-AUC가 뭔지 자세히 알려줘!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
334,train,3,ROC-AUC가 뭔지 아주 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
335,train,3,True Positive Rate 가 뭐야? 궁금해!,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
336,train,3,False Positive Rate 는 뭐지 그러면?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
337,train,3,Confusion Matrix 가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
338,train,3,Confusion Matrix 만드는 법을 알려줘,True Positive Rate : recall 의 다른 이름,0.1
339,train,3,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
340,train,3,Normalization 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
341,train,3,정규화가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
342,train,3,min-max 정규화가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
343,train,3,Z score normalization 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
344,train,3,Clipping 에 대해서 자세히 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
345,train,3,Clipping 을 하면 뭐가 좋아?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
346,train,3,로그 스케일링이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
347,train,3,Outlier 가 뭔지 궁금해,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
348,train,3,이상치가 뭔지 궁금해,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
349,train,3,Outlier 를 제거해야 하는 이유는 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
350,train,3,Outlier 를 제거하는 방법에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
351,train,3,PCA 가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
352,train,3,주성분 분석이 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
353,train,3,PCA 는 왜 하는 거지 그러면?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
354,train,3,데이터 불균형이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
355,train,3,데이터 불균형 해결하는 법이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
356,train,3,데이터를 새로 추가하거나 제거하는 법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
357,train,3,그러면 학습 환경만 바꾸는 방법은 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
358,train,3,Augmentation 이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
359,train,3,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
360,train,3,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
361,train,3,그럼 Oversampling 은 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
362,train,3,데이터 불균형을 고려한 성능지표를 추천해 줘!,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.1
363,train,3,Undersampling 하는 방법 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
364,train,3,Oversampling 방법은 어떤 게 있어?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
365,train,3,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
366,train,3,차원의 저주가 구체적으로 어떤 문제야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
367,train,3,Decision Tree 가 뭔지 자세히 알고 싶어,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
368,train,3,의사결정 나무,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
369,train,3,Decision Tree 로 결정하는 방법은?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
370,train,3,앙상블이 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
371,train,3,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
372,train,3,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
373,train,3,앙상블은 정확히 어떻게 하는 건지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
374,train,3,보팅에 대해 자세히 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
375,train,3,앙상블 중에 Voting 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
376,train,3,보팅의 방법에는 구체적으로 뭐가 있지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
377,train,3,Bagging 이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
378,train,3,그럼 Boosting 은 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
379,train,3,Stacking 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
380,train,3,Gaussian Mixture 모델이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
381,train,3,가우시안 혼합이 뭔지 궁금해,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
382,train,3,K-means Clustering 이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
383,train,3,K-means Clustering 의 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
384,train,3,kNN 에 대해 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
385,train,3,k Nearest Neighbor 알고리즘이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
386,train,3,지도학습 비지도학습 이런 게 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
387,train,3,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
388,train,3,강화학습? 지도학습? 그게 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
389,train,3,지도학습과 비지도학습의 차이가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
390,train,3,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
391,train,3,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
392,train,3,Regression 이랑 Classification 이 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
393,train,3,Naïve Bayes 가 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
394,train,3,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
395,train,3,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
396,train,3,K-fold Cross Validation,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
397,train,3,K-fold Cross Validation을 굳이 왜 하는 거야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
398,train,3,하이퍼파라미터가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
399,train,3,One-hot 방식이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
400,train,3,Valid 데이터가 굳이 왜 필요하지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
401,train,3,Train 데이터셋을 왜 순서를 섞어야 돼?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
402,train,3,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
403,train,3,인공지능이 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
404,train,3,머신러닝은 그럼 뭐지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
405,train,3,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
406,train,3,딥러닝에서 학습률이 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
407,train,3,learning rate 가 뭔지 궁금해!,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
408,train,3,자주 쓰는 Loss Function 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
409,train,3,Overfitting 이 뭔지 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
410,train,3,Overfitting 해결하는 방법은 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
411,train,3,전이학습이 뭐지?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
412,train,3,Transfer Learning 이 뭔지 궁금해!,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
413,train,3,활성화 함수? 그게 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
414,train,3,활성화 함수는 왜 필요해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
415,train,3,CNN이 뭐야? 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
416,train,3,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
417,train,3,cosine similarity가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
418,train,3,코사인 유사도가 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
419,train,3,코사인 유사도 계산법 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
420,train,4,머신러닝에서 많이 쓰이는 평가지표 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
421,train,4,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
422,train,4,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
423,train,4,True Negative 는?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
424,train,4,False Positive 는 뭐지 그럼?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
425,train,4,False Negative 는 뭐야 그러면?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
426,train,4,Recall 은 어떻게 계산해?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
427,train,4,Recall 은 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
428,train,4,Precision 은 어떻게 계산하지,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
429,train,4,Recall 과 Precision 이 자꾸 헷갈리네,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
430,train,4,F1 이 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
431,train,4,F1 Score 구하는 수식을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
432,train,4,F1 Score 장점이 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
433,train,4,IoU 가 뭔지 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
434,train,4,특이도라는 걸 봤는데 그게 뭔지 궁금해!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
435,train,4,이진 분류에서 쓰이는 Metric 을 알려줘!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
436,train,4,PR-AUC랑 ROC-AUC가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
437,train,4,PR-AUC가 뭔지 자세히 알려줘!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
438,train,4,ROC-AUC가 뭔지 아주 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
439,train,4,True Positive Rate 가 뭐야? 궁금해!,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
440,train,4,False Positive Rate 는 뭐지 그러면?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
441,train,4,Confusion Matrix 가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
442,train,4,Confusion Matrix 만드는 법을 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
443,train,4,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",True Positive Rate : recall 의 다른 이름,0.25
444,train,4,Normalization 이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
445,train,4,정규화가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
446,train,4,min-max 정규화가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
447,train,4,Z score normalization 이 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
448,train,4,Clipping 에 대해서 자세히 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
449,train,4,Clipping 을 하면 뭐가 좋아?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
450,train,4,로그 스케일링이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
451,train,4,Outlier 가 뭔지 궁금해,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
452,train,4,이상치가 뭔지 궁금해,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
453,train,4,Outlier 를 제거해야 하는 이유는 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
454,train,4,Outlier 를 제거하는 방법에 대해 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
455,train,4,PCA 가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
456,train,4,주성분 분석이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
457,train,4,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
458,train,4,데이터 불균형이 뭔지 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
459,train,4,데이터 불균형 해결하는 법이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
460,train,4,데이터를 새로 추가하거나 제거하는 법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
461,train,4,그러면 학습 환경만 바꾸는 방법은 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
462,train,4,Augmentation 이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
463,train,4,Undersampling 이랑 Oversampling 이 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
464,train,4,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
465,train,4,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
466,train,4,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
467,train,4,Undersampling 하는 방법 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
468,train,4,Oversampling 방법은 어떤 게 있어?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
469,train,4,차원의 저주가 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
470,train,4,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
471,train,4,Decision Tree 가 뭔지 자세히 알고 싶어,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
472,train,4,의사결정 나무,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
473,train,4,Decision Tree 로 결정하는 방법은?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
474,train,4,앙상블이 뭔지 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
475,train,4,앙상블을 왜 하는 거야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
476,train,4,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
477,train,4,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
478,train,4,보팅에 대해 자세히 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
479,train,4,앙상블 중에 Voting 이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
480,train,4,보팅의 방법에는 구체적으로 뭐가 있지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
481,train,4,Bagging 이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
482,train,4,그럼 Boosting 은 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
483,train,4,Stacking 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
484,train,4,Gaussian Mixture 모델이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
485,train,4,가우시안 혼합이 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
486,train,4,K-means Clustering 이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
487,train,4,K-means Clustering 의 방법을 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
488,train,4,kNN 에 대해 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
489,train,4,k Nearest Neighbor 알고리즘이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
490,train,4,지도학습 비지도학습 이런 게 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
491,train,4,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
492,train,4,강화학습? 지도학습? 그게 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
493,train,4,지도학습과 비지도학습의 차이가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
494,train,4,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
495,train,4,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
496,train,4,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
497,train,4,Naïve Bayes 가 뭔지 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
498,train,4,서포트 벡터 머신이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
499,train,4,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
500,train,4,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
501,train,4,K-fold Cross Validation을 굳이 왜 하는 거야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
502,train,4,하이퍼파라미터가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
503,train,4,One-hot 방식이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
504,train,4,Valid 데이터가 굳이 왜 필요하지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
505,train,4,Train 데이터셋을 왜 순서를 섞어야 돼?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
506,train,4,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
507,train,4,인공지능이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
508,train,4,머신러닝은 그럼 뭐지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
509,train,4,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
510,train,4,딥러닝에서 학습률이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.1
511,train,4,learning rate 가 뭔지 궁금해!,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
512,train,4,자주 쓰는 Loss Function 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
513,train,4,Overfitting 이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
514,train,4,Overfitting 해결하는 방법은 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
515,train,4,전이학습이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
516,train,4,Transfer Learning 이 뭔지 궁금해!,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
517,train,4,활성화 함수? 그게 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
518,train,4,활성화 함수는 왜 필요해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
519,train,4,CNN이 뭐야? 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
520,train,4,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
521,train,4,cosine similarity가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
522,train,4,코사인 유사도가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
523,train,4,코사인 유사도 계산법 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
524,train,4,코사인 유사도의 특징을 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
525,train,5,Accuracy 는 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
526,train,5,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
527,train,5,True Negative 는?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
528,train,5,False Positive 는 뭐지 그럼?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
529,train,5,False Negative 는 뭐야 그러면?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
530,train,5,Recall 은 어떻게 계산해?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
531,train,5,Recall 은 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
532,train,5,Precision 은 어떻게 계산하지,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
533,train,5,Recall 과 Precision 이 자꾸 헷갈리네,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
534,train,5,F1 이 뭔지 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
535,train,5,F1 Score 구하는 수식을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
536,train,5,F1 Score 장점이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
537,train,5,IoU 가 뭔지 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
538,train,5,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
539,train,5,이진 분류에서 쓰이는 Metric 을 알려줘!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
540,train,5,PR-AUC랑 ROC-AUC가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
541,train,5,PR-AUC가 뭔지 자세히 알려줘!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
542,train,5,ROC-AUC가 뭔지 아주 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
543,train,5,True Positive Rate 가 뭐야? 궁금해!,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
544,train,5,False Positive Rate 는 뭐지 그러면?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
545,train,5,Confusion Matrix 가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.1
546,train,5,Confusion Matrix 만드는 법을 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
547,train,5,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
548,train,5,Normalization 이 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
549,train,5,정규화가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
550,train,5,min-max 정규화가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
551,train,5,Z score normalization 이 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
552,train,5,Clipping 에 대해서 자세히 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
553,train,5,Clipping 을 하면 뭐가 좋아?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
554,train,5,로그 스케일링이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
555,train,5,Outlier 가 뭔지 궁금해,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
556,train,5,이상치가 뭔지 궁금해,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
557,train,5,Outlier 를 제거해야 하는 이유는 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
558,train,5,Outlier 를 제거하는 방법에 대해 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
559,train,5,PCA 가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
560,train,5,주성분 분석이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
561,train,5,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
562,train,5,데이터 불균형이 뭔지 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
563,train,5,데이터 불균형 해결하는 법이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
564,train,5,데이터를 새로 추가하거나 제거하는 법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
565,train,5,그러면 학습 환경만 바꾸는 방법은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
566,train,5,Augmentation 이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
567,train,5,Undersampling 이랑 Oversampling 이 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
568,train,5,Undersampling 이 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
569,train,5,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
570,train,5,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.5
571,train,5,Undersampling 하는 방법 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
572,train,5,Oversampling 방법은 어떤 게 있어?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.25
573,train,5,차원의 저주가 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
574,train,5,차원의 저주가 구체적으로 어떤 문제야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
575,train,5,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
576,train,5,의사결정 나무,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
577,train,5,Decision Tree 로 결정하는 방법은?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
578,train,5,앙상블이 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
579,train,5,앙상블을 왜 하는 거야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
580,train,5,앙상블 하는 구체적인 방법 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
581,train,5,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
582,train,5,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
583,train,5,앙상블 중에 Voting 이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
584,train,5,보팅의 방법에는 구체적으로 뭐가 있지?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
585,train,5,Bagging 이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
586,train,5,그럼 Boosting 은 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
587,train,5,Stacking 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
588,train,5,Gaussian Mixture 모델이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
589,train,5,가우시안 혼합이 뭔지 궁금해,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
590,train,5,K-means Clustering 이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
591,train,5,K-means Clustering 의 방법을 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
592,train,5,kNN 에 대해 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
593,train,5,k Nearest Neighbor 알고리즘이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
594,train,5,지도학습 비지도학습 이런 게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
595,train,5,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
596,train,5,강화학습? 지도학습? 그게 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
597,train,5,지도학습과 비지도학습의 차이가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
598,train,5,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
599,train,5,분류와 회귀 문제가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
600,train,5,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
601,train,5,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
602,train,5,서포트 벡터 머신이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
603,train,5,SVM이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
604,train,5,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
605,train,5,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
606,train,5,하이퍼파라미터가 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
607,train,5,One-hot 방식이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
608,train,5,Valid 데이터가 굳이 왜 필요하지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
609,train,5,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
610,train,5,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
611,train,5,인공지능이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
612,train,5,머신러닝은 그럼 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
613,train,5,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
614,train,5,딥러닝에서 학습률이 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
615,train,5,learning rate 가 뭔지 궁금해!,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
616,train,5,자주 쓰는 Loss Function 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
617,train,5,Overfitting 이 뭔지 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
618,train,5,Overfitting 해결하는 방법은 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
619,train,5,전이학습이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
620,train,5,Transfer Learning 이 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
621,train,5,활성화 함수? 그게 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
622,train,5,활성화 함수는 왜 필요해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
623,train,5,CNN이 뭐야? 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
624,train,5,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
625,train,5,cosine similarity가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
626,train,5,코사인 유사도가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
627,train,5,코사인 유사도 계산법 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
628,train,5,코사인 유사도의 특징을 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
629,train,5,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
630,train,6,True Positive 같은 건 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
631,train,6,True Negative 는?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
632,train,6,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
633,train,6,False Negative 는 뭐야 그러면?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
634,train,6,Recall 은 어떻게 계산해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
635,train,6,Recall 은 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
636,train,6,Precision 은 어떻게 계산하지,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
637,train,6,Recall 과 Precision 이 자꾸 헷갈리네,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
638,train,6,F1 이 뭔지 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
639,train,6,F1 Score 구하는 수식을 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
640,train,6,F1 Score 장점이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
641,train,6,IoU 가 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
642,train,6,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
643,train,6,이진 분류에서 쓰이는 Metric 을 알려줘!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
644,train,6,PR-AUC랑 ROC-AUC가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
645,train,6,PR-AUC가 뭔지 자세히 알려줘!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
646,train,6,ROC-AUC가 뭔지 아주 자세히 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
647,train,6,True Positive Rate 가 뭐야? 궁금해!,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
648,train,6,False Positive Rate 는 뭐지 그러면?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
649,train,6,Confusion Matrix 가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.1
650,train,6,Confusion Matrix 만드는 법을 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.1
651,train,6,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
652,train,6,Normalization 이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
653,train,6,정규화가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
654,train,6,min-max 정규화가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
655,train,6,Z score normalization 이 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
656,train,6,Clipping 에 대해서 자세히 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
657,train,6,Clipping 을 하면 뭐가 좋아?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
658,train,6,로그 스케일링이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
659,train,6,Outlier 가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
660,train,6,이상치가 뭔지 궁금해,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
661,train,6,Outlier 를 제거해야 하는 이유는 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
662,train,6,Outlier 를 제거하는 방법에 대해 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
663,train,6,PCA 가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
664,train,6,주성분 분석이 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
665,train,6,PCA 는 왜 하는 거지 그러면?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
666,train,6,데이터 불균형이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
667,train,6,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
668,train,6,데이터를 새로 추가하거나 제거하는 법 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
669,train,6,그러면 학습 환경만 바꾸는 방법은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
670,train,6,Augmentation 이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
671,train,6,Undersampling 이랑 Oversampling 이 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
672,train,6,Undersampling 이 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
673,train,6,그럼 Oversampling 은 뭐야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
674,train,6,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.5
675,train,6,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
676,train,6,Oversampling 방법은 어떤 게 있어?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.25
677,train,6,차원의 저주가 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
678,train,6,차원의 저주가 구체적으로 어떤 문제야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
679,train,6,Decision Tree 가 뭔지 자세히 알고 싶어,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
680,train,6,의사결정 나무,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
681,train,6,Decision Tree 로 결정하는 방법은?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
682,train,6,앙상블이 뭔지 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
683,train,6,앙상블을 왜 하는 거야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
684,train,6,앙상블 하는 구체적인 방법 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
685,train,6,앙상블은 정확히 어떻게 하는 건지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
686,train,6,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
687,train,6,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
688,train,6,보팅의 방법에는 구체적으로 뭐가 있지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
689,train,6,Bagging 이 뭔지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
690,train,6,그럼 Boosting 은 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
691,train,6,Stacking 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
692,train,6,Gaussian Mixture 모델이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
693,train,6,가우시안 혼합이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
694,train,6,K-means Clustering 이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
695,train,6,K-means Clustering 의 방법을 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
696,train,6,kNN 에 대해 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
697,train,6,k Nearest Neighbor 알고리즘이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
698,train,6,지도학습 비지도학습 이런 게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
699,train,6,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
700,train,6,강화학습? 지도학습? 그게 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
701,train,6,지도학습과 비지도학습의 차이가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
702,train,6,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
703,train,6,분류와 회귀 문제가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
704,train,6,Regression 이랑 Classification 이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
705,train,6,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
706,train,6,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
707,train,6,SVM이 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
708,train,6,K-fold Cross Validation,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
709,train,6,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
710,train,6,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
711,train,6,One-hot 방식이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
712,train,6,Valid 데이터가 굳이 왜 필요하지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
713,train,6,Train 데이터셋을 왜 순서를 섞어야 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
714,train,6,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
715,train,6,인공지능이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
716,train,6,머신러닝은 그럼 뭐지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
717,train,6,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
718,train,6,딥러닝에서 학습률이 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
719,train,6,learning rate 가 뭔지 궁금해!,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
720,train,6,자주 쓰는 Loss Function 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
721,train,6,Overfitting 이 뭔지 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
722,train,6,Overfitting 해결하는 방법은 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
723,train,6,전이학습이 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.1
724,train,6,Transfer Learning 이 뭔지 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
725,train,6,활성화 함수? 그게 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
726,train,6,활성화 함수는 왜 필요해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
727,train,6,CNN이 뭐야? 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
728,train,6,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
729,train,6,cosine similarity가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
730,train,6,코사인 유사도가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
731,train,6,코사인 유사도 계산법 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
732,train,6,코사인 유사도의 특징을 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
733,train,6,머신러닝에서 많이 쓰이는 평가지표 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
734,train,6,Accuracy 는 어떻게 계산해?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
735,train,7,True Negative 는?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
736,train,7,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
737,train,7,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
738,train,7,Recall 은 어떻게 계산해?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
739,train,7,Recall 은 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
740,train,7,Precision 은 어떻게 계산하지,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
741,train,7,Recall 과 Precision 이 자꾸 헷갈리네,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
742,train,7,F1 이 뭔지 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
743,train,7,F1 Score 구하는 수식을 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
744,train,7,F1 Score 장점이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
745,train,7,IoU 가 뭔지 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
746,train,7,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
747,train,7,이진 분류에서 쓰이는 Metric 을 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
748,train,7,PR-AUC랑 ROC-AUC가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
749,train,7,PR-AUC가 뭔지 자세히 알려줘!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
750,train,7,ROC-AUC가 뭔지 아주 자세히 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
751,train,7,True Positive Rate 가 뭐야? 궁금해!,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
752,train,7,False Positive Rate 는 뭐지 그러면?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
753,train,7,Confusion Matrix 가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.1
754,train,7,Confusion Matrix 만드는 법을 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.1
755,train,7,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
756,train,7,Normalization 이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
757,train,7,정규화가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
758,train,7,min-max 정규화가 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
759,train,7,Z score normalization 이 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
760,train,7,Clipping 에 대해서 자세히 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
761,train,7,Clipping 을 하면 뭐가 좋아?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
762,train,7,로그 스케일링이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
763,train,7,Outlier 가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
764,train,7,이상치가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
765,train,7,Outlier 를 제거해야 하는 이유는 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
766,train,7,Outlier 를 제거하는 방법에 대해 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
767,train,7,PCA 가 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
768,train,7,주성분 분석이 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
769,train,7,PCA 는 왜 하는 거지 그러면?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
770,train,7,데이터 불균형이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
771,train,7,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
772,train,7,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
773,train,7,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
774,train,7,Augmentation 이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
775,train,7,Undersampling 이랑 Oversampling 이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
776,train,7,Undersampling 이 뭐지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
777,train,7,그럼 Oversampling 은 뭐야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
778,train,7,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
779,train,7,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
780,train,7,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
781,train,7,차원의 저주가 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
782,train,7,차원의 저주가 구체적으로 어떤 문제야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
783,train,7,Decision Tree 가 뭔지 자세히 알고 싶어,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
784,train,7,의사결정 나무,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
785,train,7,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
786,train,7,앙상블이 뭔지 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
787,train,7,앙상블을 왜 하는 거야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
788,train,7,앙상블 하는 구체적인 방법 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
789,train,7,앙상블은 정확히 어떻게 하는 건지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
790,train,7,보팅에 대해 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
791,train,7,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
792,train,7,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
793,train,7,Bagging 이 뭔지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
794,train,7,그럼 Boosting 은 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
795,train,7,Stacking 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.5
796,train,7,Gaussian Mixture 모델이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
797,train,7,가우시안 혼합이 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
798,train,7,K-means Clustering 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
799,train,7,K-means Clustering 의 방법을 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
800,train,7,kNN 에 대해 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
801,train,7,k Nearest Neighbor 알고리즘이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
802,train,7,지도학습 비지도학습 이런 게 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
803,train,7,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
804,train,7,강화학습? 지도학습? 그게 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
805,train,7,지도학습과 비지도학습의 차이가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
806,train,7,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
807,train,7,분류와 회귀 문제가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
808,train,7,Regression 이랑 Classification 이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
809,train,7,Naïve Bayes 가 뭔지 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
810,train,7,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
811,train,7,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
812,train,7,K-fold Cross Validation,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
813,train,7,K-fold Cross Validation을 굳이 왜 하는 거야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
814,train,7,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
815,train,7,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
816,train,7,Valid 데이터가 굳이 왜 필요하지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
817,train,7,Train 데이터셋을 왜 순서를 섞어야 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
818,train,7,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
819,train,7,인공지능이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
820,train,7,머신러닝은 그럼 뭐지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
821,train,7,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
822,train,7,딥러닝에서 학습률이 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
823,train,7,learning rate 가 뭔지 궁금해!,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
824,train,7,자주 쓰는 Loss Function 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
825,train,7,Overfitting 이 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
826,train,7,Overfitting 해결하는 방법은 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
827,train,7,전이학습이 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.1
828,train,7,Transfer Learning 이 뭔지 궁금해!,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
829,train,7,활성화 함수? 그게 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
830,train,7,활성화 함수는 왜 필요해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
831,train,7,CNN이 뭐야? 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
832,train,7,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
833,train,7,cosine similarity가 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
834,train,7,코사인 유사도가 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
835,train,7,코사인 유사도 계산법 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
836,train,7,코사인 유사도의 특징을 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
837,train,7,머신러닝에서 많이 쓰이는 평가지표 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
838,train,7,Accuracy 는 어떻게 계산해?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
839,train,7,True Positive 같은 건 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
840,train,8,False Positive 는 뭐지 그럼?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
841,train,8,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
842,train,8,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
843,train,8,Recall 은 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
844,train,8,Precision 은 어떻게 계산하지,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
845,train,8,Recall 과 Precision 이 자꾸 헷갈리네,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
846,train,8,F1 이 뭔지 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
847,train,8,F1 Score 구하는 수식을 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
848,train,8,F1 Score 장점이 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
849,train,8,IoU 가 뭔지 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
850,train,8,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
851,train,8,이진 분류에서 쓰이는 Metric 을 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
852,train,8,PR-AUC랑 ROC-AUC가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
853,train,8,PR-AUC가 뭔지 자세히 알려줘!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
854,train,8,ROC-AUC가 뭔지 아주 자세히 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
855,train,8,True Positive Rate 가 뭐야? 궁금해!,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
856,train,8,False Positive Rate 는 뭐지 그러면?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
857,train,8,Confusion Matrix 가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.1
858,train,8,Confusion Matrix 만드는 법을 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.1
859,train,8,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
860,train,8,Normalization 이 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
861,train,8,정규화가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
862,train,8,min-max 정규화가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
863,train,8,Z score normalization 이 뭐지?,True Positive Rate : recall 의 다른 이름,0.0
864,train,8,Clipping 에 대해서 자세히 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
865,train,8,Clipping 을 하면 뭐가 좋아?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
866,train,8,로그 스케일링이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
867,train,8,Outlier 가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
868,train,8,이상치가 뭔지 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
869,train,8,Outlier 를 제거해야 하는 이유는 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
870,train,8,Outlier 를 제거하는 방법에 대해 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
871,train,8,PCA 가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
872,train,8,주성분 분석이 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
873,train,8,PCA 는 왜 하는 거지 그러면?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
874,train,8,데이터 불균형이 뭔지 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
875,train,8,데이터 불균형 해결하는 법이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
876,train,8,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
877,train,8,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
878,train,8,Augmentation 이 뭔지 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
879,train,8,Undersampling 이랑 Oversampling 이 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
880,train,8,Undersampling 이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
881,train,8,그럼 Oversampling 은 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
882,train,8,데이터 불균형을 고려한 성능지표를 추천해 줘!,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
883,train,8,Undersampling 하는 방법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
884,train,8,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
885,train,8,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
886,train,8,차원의 저주가 구체적으로 어떤 문제야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
887,train,8,Decision Tree 가 뭔지 자세히 알고 싶어,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
888,train,8,의사결정 나무,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
889,train,8,Decision Tree 로 결정하는 방법은?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
890,train,8,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
891,train,8,앙상블을 왜 하는 거야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
892,train,8,앙상블 하는 구체적인 방법 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
893,train,8,앙상블은 정확히 어떻게 하는 건지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
894,train,8,보팅에 대해 자세히 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
895,train,8,앙상블 중에 Voting 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
896,train,8,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
897,train,8,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
898,train,8,그럼 Boosting 은 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
899,train,8,Stacking 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
900,train,8,Gaussian Mixture 모델이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
901,train,8,가우시안 혼합이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
902,train,8,K-means Clustering 이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
903,train,8,K-means Clustering 의 방법을 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
904,train,8,kNN 에 대해 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
905,train,8,k Nearest Neighbor 알고리즘이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
906,train,8,지도학습 비지도학습 이런 게 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
907,train,8,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
908,train,8,강화학습? 지도학습? 그게 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
909,train,8,지도학습과 비지도학습의 차이가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
910,train,8,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
911,train,8,분류와 회귀 문제가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
912,train,8,Regression 이랑 Classification 이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
913,train,8,Naïve Bayes 가 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
914,train,8,서포트 벡터 머신이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
915,train,8,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
916,train,8,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
917,train,8,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
918,train,8,하이퍼파라미터가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
919,train,8,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
920,train,8,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
921,train,8,Train 데이터셋을 왜 순서를 섞어야 돼?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
922,train,8,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
923,train,8,인공지능이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
924,train,8,머신러닝은 그럼 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
925,train,8,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
926,train,8,딥러닝에서 학습률이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
927,train,8,learning rate 가 뭔지 궁금해!,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
928,train,8,자주 쓰는 Loss Function 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
929,train,8,Overfitting 이 뭔지 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
930,train,8,Overfitting 해결하는 방법은 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
931,train,8,전이학습이 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.1
932,train,8,Transfer Learning 이 뭔지 궁금해!,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
933,train,8,활성화 함수? 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
934,train,8,활성화 함수는 왜 필요해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
935,train,8,CNN이 뭐야? 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
936,train,8,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
937,train,8,cosine similarity가 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
938,train,8,코사인 유사도가 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
939,train,8,코사인 유사도 계산법 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
940,train,8,코사인 유사도의 특징을 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
941,train,8,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
942,train,8,Accuracy 는 어떻게 계산해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
943,train,8,True Positive 같은 건 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
944,train,8,True Negative 는?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
945,train,9,False Negative 는 뭐야 그러면?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
946,train,9,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
947,train,9,Recall 은 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
948,train,9,Precision 은 어떻게 계산하지,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
949,train,9,Recall 과 Precision 이 자꾸 헷갈리네,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
950,train,9,F1 이 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
951,train,9,F1 Score 구하는 수식을 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
952,train,9,F1 Score 장점이 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
953,train,9,IoU 가 뭔지 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
954,train,9,특이도라는 걸 봤는데 그게 뭔지 궁금해!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
955,train,9,이진 분류에서 쓰이는 Metric 을 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
956,train,9,PR-AUC랑 ROC-AUC가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
957,train,9,PR-AUC가 뭔지 자세히 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
958,train,9,ROC-AUC가 뭔지 아주 자세히 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
959,train,9,True Positive Rate 가 뭐야? 궁금해!,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
960,train,9,False Positive Rate 는 뭐지 그러면?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
961,train,9,Confusion Matrix 가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.1
962,train,9,Confusion Matrix 만드는 법을 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.1
963,train,9,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
964,train,9,Normalization 이 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
965,train,9,정규화가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
966,train,9,min-max 정규화가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
967,train,9,Z score normalization 이 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
968,train,9,Clipping 에 대해서 자세히 알려줘,True Positive Rate : recall 의 다른 이름,0.0
969,train,9,Clipping 을 하면 뭐가 좋아?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
970,train,9,로그 스케일링이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
971,train,9,Outlier 가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
972,train,9,이상치가 뭔지 궁금해,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
973,train,9,Outlier 를 제거해야 하는 이유는 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
974,train,9,Outlier 를 제거하는 방법에 대해 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
975,train,9,PCA 가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
976,train,9,주성분 분석이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
977,train,9,PCA 는 왜 하는 거지 그러면?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
978,train,9,데이터 불균형이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
979,train,9,데이터 불균형 해결하는 법이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
980,train,9,데이터를 새로 추가하거나 제거하는 법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
981,train,9,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
982,train,9,Augmentation 이 뭔지 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
983,train,9,Undersampling 이랑 Oversampling 이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
984,train,9,Undersampling 이 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
985,train,9,그럼 Oversampling 은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
986,train,9,데이터 불균형을 고려한 성능지표를 추천해 줘!,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
987,train,9,Undersampling 하는 방법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
988,train,9,Oversampling 방법은 어떤 게 있어?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
989,train,9,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
990,train,9,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
991,train,9,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
992,train,9,의사결정 나무,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
993,train,9,Decision Tree 로 결정하는 방법은?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
994,train,9,앙상블이 뭔지 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
995,train,9,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
996,train,9,앙상블 하는 구체적인 방법 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
997,train,9,앙상블은 정확히 어떻게 하는 건지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
998,train,9,보팅에 대해 자세히 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
999,train,9,앙상블 중에 Voting 이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1000,train,9,보팅의 방법에는 구체적으로 뭐가 있지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1001,train,9,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1002,train,9,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1003,train,9,Stacking 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
1004,train,9,Gaussian Mixture 모델이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1005,train,9,가우시안 혼합이 뭔지 궁금해,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1006,train,9,K-means Clustering 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1007,train,9,K-means Clustering 의 방법을 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1008,train,9,kNN 에 대해 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1009,train,9,k Nearest Neighbor 알고리즘이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1010,train,9,지도학습 비지도학습 이런 게 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1011,train,9,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1012,train,9,강화학습? 지도학습? 그게 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1013,train,9,지도학습과 비지도학습의 차이가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1014,train,9,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1015,train,9,분류와 회귀 문제가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1016,train,9,Regression 이랑 Classification 이 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1017,train,9,Naïve Bayes 가 뭔지 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1018,train,9,서포트 벡터 머신이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1019,train,9,SVM이 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1020,train,9,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1021,train,9,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1022,train,9,하이퍼파라미터가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1023,train,9,One-hot 방식이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1024,train,9,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1025,train,9,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1026,train,9,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1027,train,9,인공지능이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1028,train,9,머신러닝은 그럼 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1029,train,9,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1030,train,9,딥러닝에서 학습률이 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1031,train,9,learning rate 가 뭔지 궁금해!,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.1
1032,train,9,자주 쓰는 Loss Function 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1033,train,9,Overfitting 이 뭔지 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1034,train,9,Overfitting 해결하는 방법은 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1035,train,9,전이학습이 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1036,train,9,Transfer Learning 이 뭔지 궁금해!,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1037,train,9,활성화 함수? 그게 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1038,train,9,활성화 함수는 왜 필요해?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1039,train,9,CNN이 뭐야? 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1040,train,9,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1041,train,9,cosine similarity가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1042,train,9,코사인 유사도가 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1043,train,9,코사인 유사도 계산법 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1044,train,9,코사인 유사도의 특징을 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1045,train,9,머신러닝에서 많이 쓰이는 평가지표 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1046,train,9,Accuracy 는 어떻게 계산해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1047,train,9,True Positive 같은 건 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1048,train,9,True Negative 는?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1049,train,9,False Positive 는 뭐지 그럼?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1050,train,10,Recall 은 어떻게 계산해?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1051,train,10,Recall 은 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1052,train,10,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1053,train,10,Recall 과 Precision 이 자꾸 헷갈리네,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1054,train,10,F1 이 뭔지 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1055,train,10,F1 Score 구하는 수식을 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1056,train,10,F1 Score 장점이 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1057,train,10,IoU 가 뭔지 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1058,train,10,특이도라는 걸 봤는데 그게 뭔지 궁금해!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1059,train,10,이진 분류에서 쓰이는 Metric 을 알려줘!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1060,train,10,PR-AUC랑 ROC-AUC가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1061,train,10,PR-AUC가 뭔지 자세히 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1062,train,10,ROC-AUC가 뭔지 아주 자세히 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1063,train,10,True Positive Rate 가 뭐야? 궁금해!,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
1064,train,10,False Positive Rate 는 뭐지 그러면?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
1065,train,10,Confusion Matrix 가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.1
1066,train,10,Confusion Matrix 만드는 법을 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.1
1067,train,10,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
1068,train,10,Normalization 이 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1069,train,10,정규화가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1070,train,10,min-max 정규화가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1071,train,10,Z score normalization 이 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1072,train,10,Clipping 에 대해서 자세히 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1073,train,10,Clipping 을 하면 뭐가 좋아?,True Positive Rate : recall 의 다른 이름,0.0
1074,train,10,로그 스케일링이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1075,train,10,Outlier 가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1076,train,10,이상치가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1077,train,10,Outlier 를 제거해야 하는 이유는 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1078,train,10,Outlier 를 제거하는 방법에 대해 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1079,train,10,PCA 가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1080,train,10,주성분 분석이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1081,train,10,PCA 는 왜 하는 거지 그러면?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1082,train,10,데이터 불균형이 뭔지 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1083,train,10,데이터 불균형 해결하는 법이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1084,train,10,데이터를 새로 추가하거나 제거하는 법 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1085,train,10,그러면 학습 환경만 바꾸는 방법은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1086,train,10,Augmentation 이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1087,train,10,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1088,train,10,Undersampling 이 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1089,train,10,그럼 Oversampling 은 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1090,train,10,데이터 불균형을 고려한 성능지표를 추천해 줘!,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1091,train,10,Undersampling 하는 방법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1092,train,10,Oversampling 방법은 어떤 게 있어?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
1093,train,10,차원의 저주가 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1094,train,10,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1095,train,10,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1096,train,10,의사결정 나무,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1097,train,10,Decision Tree 로 결정하는 방법은?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1098,train,10,앙상블이 뭔지 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1099,train,10,앙상블을 왜 하는 거야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1100,train,10,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1101,train,10,앙상블은 정확히 어떻게 하는 건지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1102,train,10,보팅에 대해 자세히 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1103,train,10,앙상블 중에 Voting 이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1104,train,10,보팅의 방법에는 구체적으로 뭐가 있지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1105,train,10,Bagging 이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1106,train,10,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1107,train,10,Stacking 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1108,train,10,Gaussian Mixture 모델이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1109,train,10,가우시안 혼합이 뭔지 궁금해,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1110,train,10,K-means Clustering 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1111,train,10,K-means Clustering 의 방법을 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1112,train,10,kNN 에 대해 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1113,train,10,k Nearest Neighbor 알고리즘이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1114,train,10,지도학습 비지도학습 이런 게 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1115,train,10,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1116,train,10,강화학습? 지도학습? 그게 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1117,train,10,지도학습과 비지도학습의 차이가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1118,train,10,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1119,train,10,분류와 회귀 문제가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1120,train,10,Regression 이랑 Classification 이 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1121,train,10,Naïve Bayes 가 뭔지 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1122,train,10,서포트 벡터 머신이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1123,train,10,SVM이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1124,train,10,K-fold Cross Validation,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1125,train,10,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1126,train,10,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1127,train,10,One-hot 방식이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1128,train,10,Valid 데이터가 굳이 왜 필요하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1129,train,10,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1130,train,10,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1131,train,10,인공지능이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1132,train,10,머신러닝은 그럼 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1133,train,10,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1134,train,10,딥러닝에서 학습률이 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1135,train,10,learning rate 가 뭔지 궁금해!,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1136,train,10,자주 쓰는 Loss Function 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1137,train,10,Overfitting 이 뭔지 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1138,train,10,Overfitting 해결하는 방법은 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1139,train,10,전이학습이 뭐지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1140,train,10,Transfer Learning 이 뭔지 궁금해!,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1141,train,10,활성화 함수? 그게 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1142,train,10,활성화 함수는 왜 필요해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1143,train,10,CNN이 뭐야? 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1144,train,10,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1145,train,10,cosine similarity가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1146,train,10,코사인 유사도가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1147,train,10,코사인 유사도 계산법 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1148,train,10,코사인 유사도의 특징을 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1149,train,10,머신러닝에서 많이 쓰이는 평가지표 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1150,train,10,Accuracy 는 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1151,train,10,True Positive 같은 건 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1152,train,10,True Negative 는?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1153,train,10,False Positive 는 뭐지 그럼?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1154,train,10,False Negative 는 뭐야 그러면?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1155,train,11,Recall 은 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1156,train,11,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1157,train,11,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1158,train,11,F1 이 뭔지 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1159,train,11,F1 Score 구하는 수식을 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1160,train,11,F1 Score 장점이 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1161,train,11,IoU 가 뭔지 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1162,train,11,특이도라는 걸 봤는데 그게 뭔지 궁금해!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1163,train,11,이진 분류에서 쓰이는 Metric 을 알려줘!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1164,train,11,PR-AUC랑 ROC-AUC가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1165,train,11,PR-AUC가 뭔지 자세히 알려줘!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1166,train,11,ROC-AUC가 뭔지 아주 자세히 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1167,train,11,True Positive Rate 가 뭐야? 궁금해!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1168,train,11,False Positive Rate 는 뭐지 그러면?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
1169,train,11,Confusion Matrix 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.1
1170,train,11,Confusion Matrix 만드는 법을 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.1
1171,train,11,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
1172,train,11,Normalization 이 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1173,train,11,정규화가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1174,train,11,min-max 정규화가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1175,train,11,Z score normalization 이 뭐지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1176,train,11,Clipping 에 대해서 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1177,train,11,Clipping 을 하면 뭐가 좋아?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1178,train,11,로그 스케일링이 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
1179,train,11,Outlier 가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1180,train,11,이상치가 뭔지 궁금해,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1181,train,11,Outlier 를 제거해야 하는 이유는 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1182,train,11,Outlier 를 제거하는 방법에 대해 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1183,train,11,PCA 가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1184,train,11,주성분 분석이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1185,train,11,PCA 는 왜 하는 거지 그러면?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1186,train,11,데이터 불균형이 뭔지 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1187,train,11,데이터 불균형 해결하는 법이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1188,train,11,데이터를 새로 추가하거나 제거하는 법 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1189,train,11,그러면 학습 환경만 바꾸는 방법은 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1190,train,11,Augmentation 이 뭔지 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1191,train,11,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1192,train,11,Undersampling 이 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1193,train,11,그럼 Oversampling 은 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1194,train,11,데이터 불균형을 고려한 성능지표를 추천해 줘!,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1195,train,11,Undersampling 하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1196,train,11,Oversampling 방법은 어떤 게 있어?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1197,train,11,차원의 저주가 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1198,train,11,차원의 저주가 구체적으로 어떤 문제야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1199,train,11,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1200,train,11,의사결정 나무,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1201,train,11,Decision Tree 로 결정하는 방법은?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1202,train,11,앙상블이 뭔지 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1203,train,11,앙상블을 왜 하는 거야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1204,train,11,앙상블 하는 구체적인 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1205,train,11,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1206,train,11,보팅에 대해 자세히 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1207,train,11,앙상블 중에 Voting 이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1208,train,11,보팅의 방법에는 구체적으로 뭐가 있지?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1209,train,11,Bagging 이 뭔지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1210,train,11,그럼 Boosting 은 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1211,train,11,Stacking 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1212,train,11,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1213,train,11,가우시안 혼합이 뭔지 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1214,train,11,K-means Clustering 이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1215,train,11,K-means Clustering 의 방법을 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1216,train,11,kNN 에 대해 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1217,train,11,k Nearest Neighbor 알고리즘이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1218,train,11,지도학습 비지도학습 이런 게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1219,train,11,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1220,train,11,강화학습? 지도학습? 그게 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1221,train,11,지도학습과 비지도학습의 차이가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1222,train,11,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1223,train,11,분류와 회귀 문제가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1224,train,11,Regression 이랑 Classification 이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1225,train,11,Naïve Bayes 가 뭔지 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1226,train,11,서포트 벡터 머신이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1227,train,11,SVM이 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1228,train,11,K-fold Cross Validation,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1229,train,11,K-fold Cross Validation을 굳이 왜 하는 거야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1230,train,11,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1231,train,11,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1232,train,11,Valid 데이터가 굳이 왜 필요하지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1233,train,11,Train 데이터셋을 왜 순서를 섞어야 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1234,train,11,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1235,train,11,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1236,train,11,머신러닝은 그럼 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1237,train,11,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1238,train,11,딥러닝에서 학습률이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1239,train,11,learning rate 가 뭔지 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1240,train,11,자주 쓰는 Loss Function 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1241,train,11,Overfitting 이 뭔지 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1242,train,11,Overfitting 해결하는 방법은 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1243,train,11,전이학습이 뭐지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1244,train,11,Transfer Learning 이 뭔지 궁금해!,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1245,train,11,활성화 함수? 그게 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1246,train,11,활성화 함수는 왜 필요해?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1247,train,11,CNN이 뭐야? 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1248,train,11,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1249,train,11,cosine similarity가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1250,train,11,코사인 유사도가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1251,train,11,코사인 유사도 계산법 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1252,train,11,코사인 유사도의 특징을 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1253,train,11,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1254,train,11,Accuracy 는 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1255,train,11,True Positive 같은 건 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1256,train,11,True Negative 는?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1257,train,11,False Positive 는 뭐지 그럼?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1258,train,11,False Negative 는 뭐야 그러면?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1259,train,11,Recall 은 어떻게 계산해?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1260,train,12,Precision 은 어떻게 계산하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1261,train,12,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1262,train,12,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1263,train,12,F1 Score 구하는 수식을 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1264,train,12,F1 Score 장점이 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1265,train,12,IoU 가 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1266,train,12,특이도라는 걸 봤는데 그게 뭔지 궁금해!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1267,train,12,이진 분류에서 쓰이는 Metric 을 알려줘!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1268,train,12,PR-AUC랑 ROC-AUC가 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1269,train,12,PR-AUC가 뭔지 자세히 알려줘!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1270,train,12,ROC-AUC가 뭔지 아주 자세히 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1271,train,12,True Positive Rate 가 뭐야? 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1272,train,12,False Positive Rate 는 뭐지 그러면?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1273,train,12,Confusion Matrix 가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.1
1274,train,12,Confusion Matrix 만드는 법을 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.1
1275,train,12,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
1276,train,12,Normalization 이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1277,train,12,정규화가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1278,train,12,min-max 정규화가 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1279,train,12,Z score normalization 이 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1280,train,12,Clipping 에 대해서 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1281,train,12,Clipping 을 하면 뭐가 좋아?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1282,train,12,로그 스케일링이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1283,train,12,Outlier 가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
1284,train,12,이상치가 뭔지 궁금해,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1285,train,12,Outlier 를 제거해야 하는 이유는 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1286,train,12,Outlier 를 제거하는 방법에 대해 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1287,train,12,PCA 가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1288,train,12,주성분 분석이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1289,train,12,PCA 는 왜 하는 거지 그러면?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1290,train,12,데이터 불균형이 뭔지 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1291,train,12,데이터 불균형 해결하는 법이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1292,train,12,데이터를 새로 추가하거나 제거하는 법 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1293,train,12,그러면 학습 환경만 바꾸는 방법은 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1294,train,12,Augmentation 이 뭔지 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1295,train,12,Undersampling 이랑 Oversampling 이 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1296,train,12,Undersampling 이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1297,train,12,그럼 Oversampling 은 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1298,train,12,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1299,train,12,Undersampling 하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1300,train,12,Oversampling 방법은 어떤 게 있어?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1301,train,12,차원의 저주가 뭐지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1302,train,12,차원의 저주가 구체적으로 어떤 문제야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1303,train,12,Decision Tree 가 뭔지 자세히 알고 싶어,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1304,train,12,의사결정 나무,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1305,train,12,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1306,train,12,앙상블이 뭔지 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1307,train,12,앙상블을 왜 하는 거야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1308,train,12,앙상블 하는 구체적인 방법 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1309,train,12,앙상블은 정확히 어떻게 하는 건지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1310,train,12,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1311,train,12,앙상블 중에 Voting 이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1312,train,12,보팅의 방법에는 구체적으로 뭐가 있지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1313,train,12,Bagging 이 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1314,train,12,그럼 Boosting 은 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1315,train,12,Stacking 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1316,train,12,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1317,train,12,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1318,train,12,K-means Clustering 이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1319,train,12,K-means Clustering 의 방법을 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1320,train,12,kNN 에 대해 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1321,train,12,k Nearest Neighbor 알고리즘이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1322,train,12,지도학습 비지도학습 이런 게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1323,train,12,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1324,train,12,강화학습? 지도학습? 그게 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1325,train,12,지도학습과 비지도학습의 차이가 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1326,train,12,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1327,train,12,분류와 회귀 문제가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1328,train,12,Regression 이랑 Classification 이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1329,train,12,Naïve Bayes 가 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1330,train,12,서포트 벡터 머신이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1331,train,12,SVM이 뭐지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1332,train,12,K-fold Cross Validation,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1333,train,12,K-fold Cross Validation을 굳이 왜 하는 거야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1334,train,12,하이퍼파라미터가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1335,train,12,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1336,train,12,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1337,train,12,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1338,train,12,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1339,train,12,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1340,train,12,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.1
1341,train,12,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1342,train,12,딥러닝에서 학습률이 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1343,train,12,learning rate 가 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1344,train,12,자주 쓰는 Loss Function 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1345,train,12,Overfitting 이 뭔지 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1346,train,12,Overfitting 해결하는 방법은 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1347,train,12,전이학습이 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1348,train,12,Transfer Learning 이 뭔지 궁금해!,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1349,train,12,활성화 함수? 그게 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1350,train,12,활성화 함수는 왜 필요해?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1351,train,12,CNN이 뭐야? 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1352,train,12,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1353,train,12,cosine similarity가 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1354,train,12,코사인 유사도가 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1355,train,12,코사인 유사도 계산법 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1356,train,12,코사인 유사도의 특징을 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1357,train,12,머신러닝에서 많이 쓰이는 평가지표 알려줘,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1358,train,12,Accuracy 는 어떻게 계산해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1359,train,12,True Positive 같은 건 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1360,train,12,True Negative 는?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1361,train,12,False Positive 는 뭐지 그럼?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1362,train,12,False Negative 는 뭐야 그러면?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1363,train,12,Recall 은 어떻게 계산해?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1364,train,12,Recall 은 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1365,train,13,Recall 과 Precision 이 자꾸 헷갈리네,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1366,train,13,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1367,train,13,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1368,train,13,F1 Score 장점이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1369,train,13,IoU 가 뭔지 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1370,train,13,특이도라는 걸 봤는데 그게 뭔지 궁금해!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1371,train,13,이진 분류에서 쓰이는 Metric 을 알려줘!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1372,train,13,PR-AUC랑 ROC-AUC가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1373,train,13,PR-AUC가 뭔지 자세히 알려줘!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1374,train,13,ROC-AUC가 뭔지 아주 자세히 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1375,train,13,True Positive Rate 가 뭐야? 궁금해!,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1376,train,13,False Positive Rate 는 뭐지 그러면?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1377,train,13,Confusion Matrix 가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.1
1378,train,13,Confusion Matrix 만드는 법을 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.1
1379,train,13,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
1380,train,13,Normalization 이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1381,train,13,정규화가 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1382,train,13,min-max 정규화가 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1383,train,13,Z score normalization 이 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1384,train,13,Clipping 에 대해서 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1385,train,13,Clipping 을 하면 뭐가 좋아?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1386,train,13,로그 스케일링이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1387,train,13,Outlier 가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1388,train,13,이상치가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
1389,train,13,Outlier 를 제거해야 하는 이유는 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1390,train,13,Outlier 를 제거하는 방법에 대해 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1391,train,13,PCA 가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1392,train,13,주성분 분석이 뭐지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1393,train,13,PCA 는 왜 하는 거지 그러면?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1394,train,13,데이터 불균형이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1395,train,13,데이터 불균형 해결하는 법이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1396,train,13,데이터를 새로 추가하거나 제거하는 법 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1397,train,13,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1398,train,13,Augmentation 이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1399,train,13,Undersampling 이랑 Oversampling 이 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1400,train,13,Undersampling 이 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1401,train,13,그럼 Oversampling 은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1402,train,13,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1403,train,13,Undersampling 하는 방법 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1404,train,13,Oversampling 방법은 어떤 게 있어?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1405,train,13,차원의 저주가 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1406,train,13,차원의 저주가 구체적으로 어떤 문제야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1407,train,13,Decision Tree 가 뭔지 자세히 알고 싶어,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1408,train,13,의사결정 나무,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1409,train,13,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1410,train,13,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1411,train,13,앙상블을 왜 하는 거야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1412,train,13,앙상블 하는 구체적인 방법 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1413,train,13,앙상블은 정확히 어떻게 하는 건지 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1414,train,13,보팅에 대해 자세히 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1415,train,13,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1416,train,13,보팅의 방법에는 구체적으로 뭐가 있지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1417,train,13,Bagging 이 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1418,train,13,그럼 Boosting 은 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1419,train,13,Stacking 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1420,train,13,Gaussian Mixture 모델이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1421,train,13,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1422,train,13,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1423,train,13,K-means Clustering 의 방법을 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1424,train,13,kNN 에 대해 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1425,train,13,k Nearest Neighbor 알고리즘이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1426,train,13,지도학습 비지도학습 이런 게 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1427,train,13,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1428,train,13,강화학습? 지도학습? 그게 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1429,train,13,지도학습과 비지도학습의 차이가 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1430,train,13,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1431,train,13,분류와 회귀 문제가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1432,train,13,Regression 이랑 Classification 이 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1433,train,13,Naïve Bayes 가 뭔지 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1434,train,13,서포트 벡터 머신이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1435,train,13,SVM이 뭐지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1436,train,13,K-fold Cross Validation,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1437,train,13,K-fold Cross Validation을 굳이 왜 하는 거야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1438,train,13,하이퍼파라미터가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1439,train,13,One-hot 방식이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1440,train,13,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1441,train,13,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1442,train,13,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1443,train,13,인공지능이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1444,train,13,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.1
1445,train,13,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1446,train,13,딥러닝에서 학습률이 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1447,train,13,learning rate 가 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1448,train,13,자주 쓰는 Loss Function 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1449,train,13,Overfitting 이 뭔지 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1450,train,13,Overfitting 해결하는 방법은 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1451,train,13,전이학습이 뭐지?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1452,train,13,Transfer Learning 이 뭔지 궁금해!,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1453,train,13,활성화 함수? 그게 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1454,train,13,활성화 함수는 왜 필요해?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1455,train,13,CNN이 뭐야? 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1456,train,13,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1457,train,13,cosine similarity가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1458,train,13,코사인 유사도가 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1459,train,13,코사인 유사도 계산법 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1460,train,13,코사인 유사도의 특징을 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1461,train,13,머신러닝에서 많이 쓰이는 평가지표 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1462,train,13,Accuracy 는 어떻게 계산해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1463,train,13,True Positive 같은 건 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1464,train,13,True Negative 는?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1465,train,13,False Positive 는 뭐지 그럼?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1466,train,13,False Negative 는 뭐야 그러면?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1467,train,13,Recall 은 어떻게 계산해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1468,train,13,Recall 은 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1469,train,13,Precision 은 어떻게 계산하지,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1470,train,14,F1 이 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1471,train,14,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1472,train,14,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1473,train,14,IoU 가 뭔지 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1474,train,14,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1475,train,14,이진 분류에서 쓰이는 Metric 을 알려줘!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1476,train,14,PR-AUC랑 ROC-AUC가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1477,train,14,PR-AUC가 뭔지 자세히 알려줘!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1478,train,14,ROC-AUC가 뭔지 아주 자세히 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1479,train,14,True Positive Rate 가 뭐야? 궁금해!,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1480,train,14,False Positive Rate 는 뭐지 그러면?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1481,train,14,Confusion Matrix 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1482,train,14,Confusion Matrix 만드는 법을 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.1
1483,train,14,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?","Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
1484,train,14,Normalization 이 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1485,train,14,정규화가 뭔지 궁금해,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1486,train,14,min-max 정규화가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1487,train,14,Z score normalization 이 뭐지?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1488,train,14,Clipping 에 대해서 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1489,train,14,Clipping 을 하면 뭐가 좋아?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1490,train,14,로그 스케일링이 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1491,train,14,Outlier 가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1492,train,14,이상치가 뭔지 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1493,train,14,Outlier 를 제거해야 하는 이유는 뭐지?,True Positive Rate : recall 의 다른 이름,0.0
1494,train,14,Outlier 를 제거하는 방법에 대해 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1495,train,14,PCA 가 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1496,train,14,주성분 분석이 뭐지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1497,train,14,PCA 는 왜 하는 거지 그러면?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1498,train,14,데이터 불균형이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1499,train,14,데이터 불균형 해결하는 법이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1500,train,14,데이터를 새로 추가하거나 제거하는 법 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1501,train,14,그러면 학습 환경만 바꾸는 방법은 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1502,train,14,Augmentation 이 뭔지 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1503,train,14,Undersampling 이랑 Oversampling 이 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1504,train,14,Undersampling 이 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1505,train,14,그럼 Oversampling 은 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1506,train,14,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1507,train,14,Undersampling 하는 방법 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1508,train,14,Oversampling 방법은 어떤 게 있어?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1509,train,14,차원의 저주가 뭐지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1510,train,14,차원의 저주가 구체적으로 어떤 문제야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1511,train,14,Decision Tree 가 뭔지 자세히 알고 싶어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1512,train,14,의사결정 나무,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1513,train,14,Decision Tree 로 결정하는 방법은?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1514,train,14,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1515,train,14,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1516,train,14,앙상블 하는 구체적인 방법 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1517,train,14,앙상블은 정확히 어떻게 하는 건지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1518,train,14,보팅에 대해 자세히 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1519,train,14,앙상블 중에 Voting 이 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1520,train,14,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1521,train,14,Bagging 이 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1522,train,14,그럼 Boosting 은 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1523,train,14,Stacking 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1524,train,14,Gaussian Mixture 모델이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1525,train,14,가우시안 혼합이 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1526,train,14,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1527,train,14,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1528,train,14,kNN 에 대해 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1529,train,14,k Nearest Neighbor 알고리즘이 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1530,train,14,지도학습 비지도학습 이런 게 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1531,train,14,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1532,train,14,강화학습? 지도학습? 그게 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1533,train,14,지도학습과 비지도학습의 차이가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1534,train,14,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1535,train,14,분류와 회귀 문제가 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1536,train,14,Regression 이랑 Classification 이 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1537,train,14,Naïve Bayes 가 뭔지 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1538,train,14,서포트 벡터 머신이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1539,train,14,SVM이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1540,train,14,K-fold Cross Validation,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1541,train,14,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1542,train,14,하이퍼파라미터가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1543,train,14,One-hot 방식이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1544,train,14,Valid 데이터가 굳이 왜 필요하지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1545,train,14,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1546,train,14,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1547,train,14,인공지능이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.1
1548,train,14,머신러닝은 그럼 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.1
1549,train,14,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1550,train,14,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1551,train,14,learning rate 가 뭔지 궁금해!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1552,train,14,자주 쓰는 Loss Function 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1553,train,14,Overfitting 이 뭔지 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1554,train,14,Overfitting 해결하는 방법은 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1555,train,14,전이학습이 뭐지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1556,train,14,Transfer Learning 이 뭔지 궁금해!,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1557,train,14,활성화 함수? 그게 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1558,train,14,활성화 함수는 왜 필요해?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1559,train,14,CNN이 뭐야? 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1560,train,14,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1561,train,14,cosine similarity가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1562,train,14,코사인 유사도가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1563,train,14,코사인 유사도 계산법 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1564,train,14,코사인 유사도의 특징을 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1565,train,14,머신러닝에서 많이 쓰이는 평가지표 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1566,train,14,Accuracy 는 어떻게 계산해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1567,train,14,True Positive 같은 건 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1568,train,14,True Negative 는?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1569,train,14,False Positive 는 뭐지 그럼?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1570,train,14,False Negative 는 뭐야 그러면?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1571,train,14,Recall 은 어떻게 계산해?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1572,train,14,Recall 은 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1573,train,14,Precision 은 어떻게 계산하지,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1574,train,14,Recall 과 Precision 이 자꾸 헷갈리네,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1575,train,15,F1 Score 구하는 수식을 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1576,train,15,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1577,train,15,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1578,train,15,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1579,train,15,이진 분류에서 쓰이는 Metric 을 알려줘!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1580,train,15,PR-AUC랑 ROC-AUC가 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1581,train,15,PR-AUC가 뭔지 자세히 알려줘!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1582,train,15,ROC-AUC가 뭔지 아주 자세히 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1583,train,15,True Positive Rate 가 뭐야? 궁금해!,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1584,train,15,False Positive Rate 는 뭐지 그러면?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1585,train,15,Confusion Matrix 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1586,train,15,Confusion Matrix 만드는 법을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1587,train,15,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
1588,train,15,Normalization 이 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1589,train,15,정규화가 뭔지 궁금해,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1590,train,15,min-max 정규화가 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1591,train,15,Z score normalization 이 뭐지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1592,train,15,Clipping 에 대해서 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1593,train,15,Clipping 을 하면 뭐가 좋아?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1594,train,15,로그 스케일링이 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1595,train,15,Outlier 가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1596,train,15,이상치가 뭔지 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1597,train,15,Outlier 를 제거해야 하는 이유는 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1598,train,15,Outlier 를 제거하는 방법에 대해 알려줘,True Positive Rate : recall 의 다른 이름,0.0
1599,train,15,PCA 가 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1600,train,15,주성분 분석이 뭐지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1601,train,15,PCA 는 왜 하는 거지 그러면?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1602,train,15,데이터 불균형이 뭔지 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1603,train,15,데이터 불균형 해결하는 법이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1604,train,15,데이터를 새로 추가하거나 제거하는 법 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1605,train,15,그러면 학습 환경만 바꾸는 방법은 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1606,train,15,Augmentation 이 뭔지 알려줘,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1607,train,15,Undersampling 이랑 Oversampling 이 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1608,train,15,Undersampling 이 뭐지?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1609,train,15,그럼 Oversampling 은 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1610,train,15,데이터 불균형을 고려한 성능지표를 추천해 줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1611,train,15,Undersampling 하는 방법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1612,train,15,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1613,train,15,차원의 저주가 뭐지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1614,train,15,차원의 저주가 구체적으로 어떤 문제야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1615,train,15,Decision Tree 가 뭔지 자세히 알고 싶어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1616,train,15,의사결정 나무,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1617,train,15,Decision Tree 로 결정하는 방법은?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1618,train,15,앙상블이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1619,train,15,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1620,train,15,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1621,train,15,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1622,train,15,보팅에 대해 자세히 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1623,train,15,앙상블 중에 Voting 이 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1624,train,15,보팅의 방법에는 구체적으로 뭐가 있지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1625,train,15,Bagging 이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1626,train,15,그럼 Boosting 은 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1627,train,15,Stacking 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1628,train,15,Gaussian Mixture 모델이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1629,train,15,가우시안 혼합이 뭔지 궁금해,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1630,train,15,K-means Clustering 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1631,train,15,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1632,train,15,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1633,train,15,k Nearest Neighbor 알고리즘이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1634,train,15,지도학습 비지도학습 이런 게 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1635,train,15,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1636,train,15,강화학습? 지도학습? 그게 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1637,train,15,지도학습과 비지도학습의 차이가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1638,train,15,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1639,train,15,분류와 회귀 문제가 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1640,train,15,Regression 이랑 Classification 이 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1641,train,15,Naïve Bayes 가 뭔지 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1642,train,15,서포트 벡터 머신이 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1643,train,15,SVM이 뭐지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1644,train,15,K-fold Cross Validation,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1645,train,15,K-fold Cross Validation을 굳이 왜 하는 거야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1646,train,15,하이퍼파라미터가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1647,train,15,One-hot 방식이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1648,train,15,Valid 데이터가 굳이 왜 필요하지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1649,train,15,Train 데이터셋을 왜 순서를 섞어야 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1650,train,15,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1651,train,15,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1652,train,15,머신러닝은 그럼 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.1
1653,train,15,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1654,train,15,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1655,train,15,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1656,train,15,자주 쓰는 Loss Function 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1657,train,15,Overfitting 이 뭔지 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1658,train,15,Overfitting 해결하는 방법은 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1659,train,15,전이학습이 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1660,train,15,Transfer Learning 이 뭔지 궁금해!,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1661,train,15,활성화 함수? 그게 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1662,train,15,활성화 함수는 왜 필요해?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1663,train,15,CNN이 뭐야? 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1664,train,15,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1665,train,15,cosine similarity가 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1666,train,15,코사인 유사도가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1667,train,15,코사인 유사도 계산법 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1668,train,15,코사인 유사도의 특징을 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1669,train,15,머신러닝에서 많이 쓰이는 평가지표 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1670,train,15,Accuracy 는 어떻게 계산해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1671,train,15,True Positive 같은 건 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1672,train,15,True Negative 는?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1673,train,15,False Positive 는 뭐지 그럼?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1674,train,15,False Negative 는 뭐야 그러면?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1675,train,15,Recall 은 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1676,train,15,Recall 은 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1677,train,15,Precision 은 어떻게 계산하지,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1678,train,15,Recall 과 Precision 이 자꾸 헷갈리네,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1679,train,15,F1 이 뭔지 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1680,train,16,F1 Score 장점이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1681,train,16,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1682,train,16,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1683,train,16,이진 분류에서 쓰이는 Metric 을 알려줘!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1684,train,16,PR-AUC랑 ROC-AUC가 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1685,train,16,PR-AUC가 뭔지 자세히 알려줘!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1686,train,16,ROC-AUC가 뭔지 아주 자세히 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1687,train,16,True Positive Rate 가 뭐야? 궁금해!,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1688,train,16,False Positive Rate 는 뭐지 그러면?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
1689,train,16,Confusion Matrix 가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.1
1690,train,16,Confusion Matrix 만드는 법을 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.1
1691,train,16,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1692,train,16,Normalization 이 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
1693,train,16,정규화가 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1694,train,16,min-max 정규화가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1695,train,16,Z score normalization 이 뭐지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1696,train,16,Clipping 에 대해서 자세히 알려줘,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1697,train,16,Clipping 을 하면 뭐가 좋아?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1698,train,16,로그 스케일링이 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1699,train,16,Outlier 가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1700,train,16,이상치가 뭔지 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1701,train,16,Outlier 를 제거해야 하는 이유는 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1702,train,16,Outlier 를 제거하는 방법에 대해 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1703,train,16,PCA 가 뭐야?,True Positive Rate : recall 의 다른 이름,0.0
1704,train,16,주성분 분석이 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1705,train,16,PCA 는 왜 하는 거지 그러면?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1706,train,16,데이터 불균형이 뭔지 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1707,train,16,데이터 불균형 해결하는 법이 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1708,train,16,데이터를 새로 추가하거나 제거하는 법 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1709,train,16,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1710,train,16,Augmentation 이 뭔지 알려줘,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1711,train,16,Undersampling 이랑 Oversampling 이 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1712,train,16,Undersampling 이 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1713,train,16,그럼 Oversampling 은 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1714,train,16,데이터 불균형을 고려한 성능지표를 추천해 줘!,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1715,train,16,Undersampling 하는 방법 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1716,train,16,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1717,train,16,차원의 저주가 뭐지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1718,train,16,차원의 저주가 구체적으로 어떤 문제야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1719,train,16,Decision Tree 가 뭔지 자세히 알고 싶어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1720,train,16,의사결정 나무,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1721,train,16,Decision Tree 로 결정하는 방법은?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1722,train,16,앙상블이 뭔지 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1723,train,16,앙상블을 왜 하는 거야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1724,train,16,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1725,train,16,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1726,train,16,보팅에 대해 자세히 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1727,train,16,앙상블 중에 Voting 이 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1728,train,16,보팅의 방법에는 구체적으로 뭐가 있지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1729,train,16,Bagging 이 뭔지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1730,train,16,그럼 Boosting 은 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1731,train,16,Stacking 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1732,train,16,Gaussian Mixture 모델이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1733,train,16,가우시안 혼합이 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1734,train,16,K-means Clustering 이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1735,train,16,K-means Clustering 의 방법을 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1736,train,16,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1737,train,16,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1738,train,16,지도학습 비지도학습 이런 게 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1739,train,16,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1740,train,16,강화학습? 지도학습? 그게 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1741,train,16,지도학습과 비지도학습의 차이가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1742,train,16,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1743,train,16,분류와 회귀 문제가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1744,train,16,Regression 이랑 Classification 이 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1745,train,16,Naïve Bayes 가 뭔지 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1746,train,16,서포트 벡터 머신이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1747,train,16,SVM이 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1748,train,16,K-fold Cross Validation,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1749,train,16,K-fold Cross Validation을 굳이 왜 하는 거야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1750,train,16,하이퍼파라미터가 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1751,train,16,One-hot 방식이 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1752,train,16,Valid 데이터가 굳이 왜 필요하지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1753,train,16,Train 데이터셋을 왜 순서를 섞어야 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1754,train,16,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1755,train,16,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1756,train,16,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1757,train,16,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1758,train,16,딥러닝에서 학습률이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1759,train,16,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1760,train,16,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1761,train,16,Overfitting 이 뭔지 알려줘,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1762,train,16,Overfitting 해결하는 방법은 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1763,train,16,전이학습이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1764,train,16,Transfer Learning 이 뭔지 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1765,train,16,활성화 함수? 그게 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1766,train,16,활성화 함수는 왜 필요해?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1767,train,16,CNN이 뭐야? 알려줘,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1768,train,16,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1769,train,16,cosine similarity가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1770,train,16,코사인 유사도가 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1771,train,16,코사인 유사도 계산법 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1772,train,16,코사인 유사도의 특징을 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1773,train,16,머신러닝에서 많이 쓰이는 평가지표 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1774,train,16,Accuracy 는 어떻게 계산해?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1775,train,16,True Positive 같은 건 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1776,train,16,True Negative 는?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1777,train,16,False Positive 는 뭐지 그럼?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1778,train,16,False Negative 는 뭐야 그러면?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1779,train,16,Recall 은 어떻게 계산해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1780,train,16,Recall 은 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1781,train,16,Precision 은 어떻게 계산하지,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1782,train,16,Recall 과 Precision 이 자꾸 헷갈리네,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1783,train,16,F1 이 뭔지 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1784,train,16,F1 Score 구하는 수식을 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1785,train,17,IoU 가 뭔지 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1786,train,17,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1787,train,17,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1788,train,17,PR-AUC랑 ROC-AUC가 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1789,train,17,PR-AUC가 뭔지 자세히 알려줘!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1790,train,17,ROC-AUC가 뭔지 아주 자세히 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1791,train,17,True Positive Rate 가 뭐야? 궁금해!,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1792,train,17,False Positive Rate 는 뭐지 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
1793,train,17,Confusion Matrix 가 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.1
1794,train,17,Confusion Matrix 만드는 법을 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.1
1795,train,17,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
1796,train,17,Normalization 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
1797,train,17,정규화가 뭔지 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
1798,train,17,min-max 정규화가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1799,train,17,Z score normalization 이 뭐지?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1800,train,17,Clipping 에 대해서 자세히 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1801,train,17,Clipping 을 하면 뭐가 좋아?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1802,train,17,로그 스케일링이 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1803,train,17,Outlier 가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1804,train,17,이상치가 뭔지 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1805,train,17,Outlier 를 제거해야 하는 이유는 뭐지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1806,train,17,Outlier 를 제거하는 방법에 대해 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1807,train,17,PCA 가 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1808,train,17,주성분 분석이 뭐지?,True Positive Rate : recall 의 다른 이름,0.0
1809,train,17,PCA 는 왜 하는 거지 그러면?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1810,train,17,데이터 불균형이 뭔지 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1811,train,17,데이터 불균형 해결하는 법이 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1812,train,17,데이터를 새로 추가하거나 제거하는 법 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1813,train,17,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1814,train,17,Augmentation 이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1815,train,17,Undersampling 이랑 Oversampling 이 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1816,train,17,Undersampling 이 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1817,train,17,그럼 Oversampling 은 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1818,train,17,데이터 불균형을 고려한 성능지표를 추천해 줘!,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1819,train,17,Undersampling 하는 방법 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1820,train,17,Oversampling 방법은 어떤 게 있어?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1821,train,17,차원의 저주가 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1822,train,17,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1823,train,17,Decision Tree 가 뭔지 자세히 알고 싶어,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1824,train,17,의사결정 나무,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1825,train,17,Decision Tree 로 결정하는 방법은?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1826,train,17,앙상블이 뭔지 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1827,train,17,앙상블을 왜 하는 거야?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1828,train,17,앙상블 하는 구체적인 방법 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1829,train,17,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1830,train,17,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1831,train,17,앙상블 중에 Voting 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1832,train,17,보팅의 방법에는 구체적으로 뭐가 있지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1833,train,17,Bagging 이 뭔지 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1834,train,17,그럼 Boosting 은 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1835,train,17,Stacking 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1836,train,17,Gaussian Mixture 모델이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1837,train,17,가우시안 혼합이 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1838,train,17,K-means Clustering 이 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1839,train,17,K-means Clustering 의 방법을 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1840,train,17,kNN 에 대해 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1841,train,17,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1842,train,17,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1843,train,17,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1844,train,17,강화학습? 지도학습? 그게 뭐지?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1845,train,17,지도학습과 비지도학습의 차이가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1846,train,17,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1847,train,17,분류와 회귀 문제가 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1848,train,17,Regression 이랑 Classification 이 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1849,train,17,Naïve Bayes 가 뭔지 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1850,train,17,서포트 벡터 머신이 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1851,train,17,SVM이 뭐지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1852,train,17,K-fold Cross Validation,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1853,train,17,K-fold Cross Validation을 굳이 왜 하는 거야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1854,train,17,하이퍼파라미터가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1855,train,17,One-hot 방식이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1856,train,17,Valid 데이터가 굳이 왜 필요하지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1857,train,17,Train 데이터셋을 왜 순서를 섞어야 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1858,train,17,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1859,train,17,인공지능이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1860,train,17,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1861,train,17,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1862,train,17,딥러닝에서 학습률이 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1863,train,17,learning rate 가 뭔지 궁금해!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1864,train,17,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1865,train,17,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1866,train,17,Overfitting 해결하는 방법은 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1867,train,17,전이학습이 뭐지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1868,train,17,Transfer Learning 이 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1869,train,17,활성화 함수? 그게 뭐야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1870,train,17,활성화 함수는 왜 필요해?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1871,train,17,CNN이 뭐야? 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1872,train,17,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1873,train,17,cosine similarity가 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1874,train,17,코사인 유사도가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1875,train,17,코사인 유사도 계산법 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1876,train,17,코사인 유사도의 특징을 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1877,train,17,머신러닝에서 많이 쓰이는 평가지표 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.1
1878,train,17,Accuracy 는 어떻게 계산해?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1879,train,17,True Positive 같은 건 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1880,train,17,True Negative 는?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1881,train,17,False Positive 는 뭐지 그럼?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1882,train,17,False Negative 는 뭐야 그러면?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1883,train,17,Recall 은 어떻게 계산해?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1884,train,17,Recall 은 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1885,train,17,Precision 은 어떻게 계산하지,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1886,train,17,Recall 과 Precision 이 자꾸 헷갈리네,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1887,train,17,F1 이 뭔지 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1888,train,17,F1 Score 구하는 수식을 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1889,train,17,F1 Score 장점이 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1890,train,18,특이도라는 걸 봤는데 그게 뭔지 궁금해!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1891,train,18,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1892,train,18,PR-AUC랑 ROC-AUC가 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1893,train,18,PR-AUC가 뭔지 자세히 알려줘!,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1894,train,18,ROC-AUC가 뭔지 아주 자세히 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
1895,train,18,True Positive Rate 가 뭐야? 궁금해!,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
1896,train,18,False Positive Rate 는 뭐지 그러면?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
1897,train,18,Confusion Matrix 가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.1
1898,train,18,Confusion Matrix 만드는 법을 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.1
1899,train,18,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
1900,train,18,Normalization 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
1901,train,18,정규화가 뭔지 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
1902,train,18,min-max 정규화가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
1903,train,18,Z score normalization 이 뭐지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
1904,train,18,Clipping 에 대해서 자세히 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
1905,train,18,Clipping 을 하면 뭐가 좋아?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
1906,train,18,로그 스케일링이 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
1907,train,18,Outlier 가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
1908,train,18,이상치가 뭔지 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
1909,train,18,Outlier 를 제거해야 하는 이유는 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
1910,train,18,Outlier 를 제거하는 방법에 대해 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
1911,train,18,PCA 가 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1912,train,18,주성분 분석이 뭐지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
1913,train,18,PCA 는 왜 하는 거지 그러면?,True Positive Rate : recall 의 다른 이름,0.0
1914,train,18,데이터 불균형이 뭔지 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
1915,train,18,데이터 불균형 해결하는 법이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
1916,train,18,데이터를 새로 추가하거나 제거하는 법 알려줘,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
1917,train,18,그러면 학습 환경만 바꾸는 방법은 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
1918,train,18,Augmentation 이 뭔지 알려줘,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1919,train,18,Undersampling 이랑 Oversampling 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
1920,train,18,Undersampling 이 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
1921,train,18,그럼 Oversampling 은 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
1922,train,18,데이터 불균형을 고려한 성능지표를 추천해 줘!,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
1923,train,18,Undersampling 하는 방법 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
1924,train,18,Oversampling 방법은 어떤 게 있어?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
1925,train,18,차원의 저주가 뭐지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1926,train,18,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
1927,train,18,Decision Tree 가 뭔지 자세히 알고 싶어,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
1928,train,18,의사결정 나무,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
1929,train,18,Decision Tree 로 결정하는 방법은?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1930,train,18,앙상블이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
1931,train,18,앙상블을 왜 하는 거야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
1932,train,18,앙상블 하는 구체적인 방법 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
1933,train,18,앙상블은 정확히 어떻게 하는 건지 궁금해,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
1934,train,18,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
1935,train,18,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
1936,train,18,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
1937,train,18,Bagging 이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
1938,train,18,그럼 Boosting 은 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
1939,train,18,Stacking 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
1940,train,18,Gaussian Mixture 모델이 뭐야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
1941,train,18,가우시안 혼합이 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
1942,train,18,K-means Clustering 이 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
1943,train,18,K-means Clustering 의 방법을 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
1944,train,18,kNN 에 대해 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
1945,train,18,k Nearest Neighbor 알고리즘이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1946,train,18,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
1947,train,18,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
1948,train,18,강화학습? 지도학습? 그게 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
1949,train,18,지도학습과 비지도학습의 차이가 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
1950,train,18,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1951,train,18,분류와 회귀 문제가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
1952,train,18,Regression 이랑 Classification 이 뭐지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1953,train,18,Naïve Bayes 가 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
1954,train,18,서포트 벡터 머신이 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
1955,train,18,SVM이 뭐지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
1956,train,18,K-fold Cross Validation,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
1957,train,18,K-fold Cross Validation을 굳이 왜 하는 거야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
1958,train,18,하이퍼파라미터가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1959,train,18,One-hot 방식이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
1960,train,18,Valid 데이터가 굳이 왜 필요하지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
1961,train,18,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
1962,train,18,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1963,train,18,인공지능이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
1964,train,18,머신러닝은 그럼 뭐지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.1
1965,train,18,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1966,train,18,딥러닝에서 학습률이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
1967,train,18,learning rate 가 뭔지 궁금해!,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
1968,train,18,자주 쓰는 Loss Function 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1969,train,18,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1970,train,18,Overfitting 해결하는 방법은 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
1971,train,18,전이학습이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
1972,train,18,Transfer Learning 이 뭔지 궁금해!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1973,train,18,활성화 함수? 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
1974,train,18,활성화 함수는 왜 필요해?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
1975,train,18,CNN이 뭐야? 알려줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
1976,train,18,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
1977,train,18,cosine similarity가 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
1978,train,18,코사인 유사도가 뭐야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
1979,train,18,코사인 유사도 계산법 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
1980,train,18,코사인 유사도의 특징을 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
1981,train,18,머신러닝에서 많이 쓰이는 평가지표 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
1982,train,18,Accuracy 는 어떻게 계산해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
1983,train,18,True Positive 같은 건 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
1984,train,18,True Negative 는?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1985,train,18,False Positive 는 뭐지 그럼?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
1986,train,18,False Negative 는 뭐야 그러면?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
1987,train,18,Recall 은 어떻게 계산해?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
1988,train,18,Recall 은 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
1989,train,18,Precision 은 어떻게 계산하지,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1990,train,18,Recall 과 Precision 이 자꾸 헷갈리네,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
1991,train,18,F1 이 뭔지 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
1992,train,18,F1 Score 구하는 수식을 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
1993,train,18,F1 Score 장점이 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
1994,train,18,IoU 가 뭔지 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
1995,train,19,이진 분류에서 쓰이는 Metric 을 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1996,train,19,PR-AUC랑 ROC-AUC가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
1997,train,19,PR-AUC가 뭔지 자세히 알려줘!,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
1998,train,19,ROC-AUC가 뭔지 아주 자세히 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
1999,train,19,True Positive Rate 가 뭐야? 궁금해!,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2000,train,19,False Positive Rate 는 뭐지 그러면?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2001,train,19,Confusion Matrix 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.1
2002,train,19,Confusion Matrix 만드는 법을 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.1
2003,train,19,"실제 산업에서 불량품을 Positive 라고 하면 Precision, Recall 중 뭐가 더 중요해?",False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2004,train,19,Normalization 이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
2005,train,19,정규화가 뭔지 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2006,train,19,min-max 정규화가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2007,train,19,Z score normalization 이 뭐지?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
2008,train,19,Clipping 에 대해서 자세히 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
2009,train,19,Clipping 을 하면 뭐가 좋아?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
2010,train,19,로그 스케일링이 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
2011,train,19,Outlier 가 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
2012,train,19,이상치가 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
2013,train,19,Outlier 를 제거해야 하는 이유는 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
2014,train,19,Outlier 를 제거하는 방법에 대해 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
2015,train,19,PCA 가 뭐야?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
2016,train,19,주성분 분석이 뭐지?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2017,train,19,PCA 는 왜 하는 거지 그러면?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2018,train,19,데이터 불균형이 뭔지 알려줘,True Positive Rate : recall 의 다른 이름,0.0
2019,train,19,데이터 불균형 해결하는 법이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2020,train,19,데이터를 새로 추가하거나 제거하는 법 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2021,train,19,그러면 학습 환경만 바꾸는 방법은 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2022,train,19,Augmentation 이 뭔지 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2023,train,19,Undersampling 이랑 Oversampling 이 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2024,train,19,Undersampling 이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2025,train,19,그럼 Oversampling 은 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
2026,train,19,데이터 불균형을 고려한 성능지표를 추천해 줘!,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2027,train,19,Undersampling 하는 방법 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2028,train,19,Oversampling 방법은 어떤 게 있어?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2029,train,19,차원의 저주가 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2030,train,19,차원의 저주가 구체적으로 어떤 문제야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2031,train,19,Decision Tree 가 뭔지 자세히 알고 싶어,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2032,train,19,의사결정 나무,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2033,train,19,Decision Tree 로 결정하는 방법은?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2034,train,19,앙상블이 뭔지 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2035,train,19,앙상블을 왜 하는 거야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2036,train,19,앙상블 하는 구체적인 방법 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2037,train,19,앙상블은 정확히 어떻게 하는 건지 궁금해,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
2038,train,19,보팅에 대해 자세히 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
2039,train,19,앙상블 중에 Voting 이 뭐야?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
2040,train,19,보팅의 방법에는 구체적으로 뭐가 있지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
2041,train,19,Bagging 이 뭔지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
2042,train,19,그럼 Boosting 은 뭐야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
2043,train,19,Stacking 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
2044,train,19,Gaussian Mixture 모델이 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2045,train,19,가우시안 혼합이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2046,train,19,K-means Clustering 이 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2047,train,19,K-means Clustering 의 방법을 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2048,train,19,kNN 에 대해 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2049,train,19,k Nearest Neighbor 알고리즘이 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2050,train,19,지도학습 비지도학습 이런 게 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2051,train,19,머신러닝도 여러 가지가 있는데 그게 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2052,train,19,강화학습? 지도학습? 그게 뭐지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2053,train,19,지도학습과 비지도학습의 차이가 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
2054,train,19,머신러닝으로 해결해야 하는 문제의 종류를 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
2055,train,19,분류와 회귀 문제가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2056,train,19,Regression 이랑 Classification 이 뭐지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2057,train,19,Naïve Bayes 가 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2058,train,19,서포트 벡터 머신이 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2059,train,19,SVM이 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2060,train,19,K-fold Cross Validation,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2061,train,19,K-fold Cross Validation을 굳이 왜 하는 거야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2062,train,19,하이퍼파라미터가 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2063,train,19,One-hot 방식이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2064,train,19,Valid 데이터가 굳이 왜 필요하지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2065,train,19,Train 데이터셋을 왜 순서를 섞어야 돼?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2066,train,19,인공지능 머신러닝 딥러닝 이거 관계가 어떻게 돼?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2067,train,19,인공지능이 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2068,train,19,머신러닝은 그럼 뭐지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2069,train,19,요즘 딥러닝 딥러닝 하는데 그게 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2070,train,19,딥러닝에서 학습률이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2071,train,19,learning rate 가 뭔지 궁금해!,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2072,train,19,자주 쓰는 Loss Function 알려줘,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2073,train,19,Overfitting 이 뭔지 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2074,train,19,Overfitting 해결하는 방법은 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2075,train,19,전이학습이 뭐지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2076,train,19,Transfer Learning 이 뭔지 궁금해!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2077,train,19,활성화 함수? 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2078,train,19,활성화 함수는 왜 필요해?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2079,train,19,CNN이 뭐야? 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2080,train,19,거대 언어 모델 요즘 핫하다던데 정확히 뭐야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2081,train,19,cosine similarity가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2082,train,19,코사인 유사도가 뭐야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2083,train,19,코사인 유사도 계산법 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2084,train,19,코사인 유사도의 특징을 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2085,train,19,머신러닝에서 많이 쓰이는 평가지표 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
2086,train,19,Accuracy 는 어떻게 계산해?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2087,train,19,True Positive 같은 건 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2088,train,19,True Negative 는?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2089,train,19,False Positive 는 뭐지 그럼?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2090,train,19,False Negative 는 뭐야 그러면?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2091,train,19,Recall 은 어떻게 계산해?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2092,train,19,Recall 은 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2093,train,19,Precision 은 어떻게 계산하지,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2094,train,19,Recall 과 Precision 이 자꾸 헷갈리네,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2095,train,19,F1 이 뭔지 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2096,train,19,F1 Score 구하는 수식을 알려줘,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2097,train,19,F1 Score 장점이 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2098,train,19,IoU 가 뭔지 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2099,train,19,특이도라는 걸 봤는데 그게 뭔지 궁금해!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2100,test,0,코사인 유사도가 뭔지 궁금해,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2101,test,0,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2102,test,0,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,1.0
2103,test,0,코사인 유사도 특징이 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",1.0
2104,test,0,머신러닝 모델 평가하는 방법 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",1.0
2105,test,0,Accuracy 계산 어떻게 하지?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),1.0
2106,test,0,True Positive 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,1.0
2107,test,0,True Negative 는 뭔지 궁금해 그럼,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,1.0
2108,test,0,False Positive 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,1.0
2109,test,0,False Negative (FN),False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,1.0
2110,test,0,Recall 계산법 어떻게 하는 거지?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
2111,test,0,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
2112,test,0,Precision 어떻게 계산하는지 정말 궁금해,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),1.0
2113,test,0,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",1.0
2114,test,0,F1 Score 가 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,1.0
2115,test,0,F1 Score 계산식 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),1.0
2116,test,0,F1 Score 는 왜 쓰는 거지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",1.0
2117,test,0,IoU 라는 게 있는데 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),1.0
2118,test,0,특이도는 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),1.0
2119,test,0,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",1.0
2120,test,0,"PR-AUC, ROC-AUC 가 뭐야?","PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",1.0
2121,test,0,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
2122,test,0,ROC-AUC 는 뭔지 정말 궁금해,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",1.0
2123,test,0,True Positive Rate 구하는 방법을 알려줘,True Positive Rate : recall 의 다른 이름,1.0
2124,test,0,False Positive Rate 가 뭔지 정말 궁금하다,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),1.0
2125,test,0,Confusion Matrix (혼동 행렬) 이 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",1.0
2126,test,0,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",1.0
2127,test,0,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",1.0
2128,test,0,Normalization 정규화 그게 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
2129,test,0,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
2130,test,0,Min-Max 정규화가 뭔지 잘 모르겠어,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),1.0
2131,test,0,Z 스코어 정규화가 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,1.0
2132,test,0,Clipping? 클리핑? 그게 뭐지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",1.0
2133,test,0,클리핑 이거 쓸데없이 하는 거 아니야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,1.0
2134,test,0,로그 스케일링도 정규화 같은데 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,1.0
2135,test,0,Outlier 개념,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
2136,test,0,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
2137,test,0,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,1.0
2138,test,0,Outlier 없애려면 어떻게 해야 되지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",1.0
2139,test,0,PCA에 대해 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
2140,test,0,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
2141,test,0,PCA 그거 왜 하는 건지 모르겠어,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,1.0
2142,test,0,데이터가 불균형하다고? 그게 뭐지,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,1.0
2143,test,0,데이터 불균형 어떻게 하면 해결할 수 있지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",1.0
2144,test,0,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",1.0
2145,test,0,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",1.0
2146,test,0,데이터 증강이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",1.0
2147,test,0,언더샘플링이랑 오버샘플링이 뭔지 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,1.0
2148,test,0,Undersampling 에 대해서 알려줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,1.0
2149,test,0,oversampling 이 뭐지?,Oversampling : 데이터가 적은 Class 의 데이터 증가,1.0
2150,test,0,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",1.0
2151,test,0,undersampling 방법은 뭐가 있어?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",1.0
2152,test,0,Oversampling 하는 방법,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),1.0
2153,test,0,차원의 저주가 뭔지 궁금해,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",1.0
2154,test,0,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",1.0
2155,test,0,의사결정 나무가 뭔지 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
2156,test,0,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
2157,test,0,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,1.0
2158,test,0,앙상블이 뭐지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,1.0
2159,test,0,앙상블 하는 이유,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,1.0
2160,test,0,앙상블 방법,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
2161,test,0,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
2162,test,0,Voting? 그게 뭐지,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
2163,test,0,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
2164,test,0,보팅 방법 구체적으로 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",1.0
2165,test,0,배깅이뭐야,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",1.0
2166,test,0,부스팅이 뭐지 그러면,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",1.0
2167,test,0,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",1.0
2168,test,0,가우시안 혼합? 그게 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
2169,test,0,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
2170,test,0,K-means Clustering 너 알지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",1.0
2171,test,0,K-means Clustering 방법,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",1.0
2172,test,0,KNN 알고리즘 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
2173,test,0,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
2174,test,0,지도학습 강화학습 비지도학습 이런게 뭐지,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2175,test,0,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2176,test,0,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2177,test,0,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",1.0
2178,test,0,머신러닝 문제에는 뭐가 있지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2179,test,0,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2180,test,0,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2181,test,0,Naïve Bayes 뭐야,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",1.0
2182,test,0,서포트 벡터 머신? 그게 뭐지? 알려줘!,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
2183,test,0,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
2184,test,0,K-fold Cross Validation 정의,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",1.0
2185,test,0,K-fold Cross Validation 하는 이유는?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,1.0
2186,test,0,Hyper parameter 가 대체 뭐지,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",1.0
2187,test,0,One-hot? 그것도 머신러닝 모델이야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",1.0
2188,test,0,Valid 데이터 쓰는 이유가 궁금해,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,1.0
2189,test,0,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",1.0
2190,test,0,인공지능 머신러닝 딥러닝의 관계는?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",1.0
2191,test,0,인공지능 정의,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",1.0
2192,test,0,머신러닝은 인공지능에 속하는 거 맞지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",1.0
2193,test,0,딥러닝이 뭔지 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,1.0
2194,test,0,딥러닝의 learning rate 그게 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
2195,test,0,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
2196,test,0,자주 쓰이는 손실 함수는 뭐가 있을까,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",1.0
2197,test,0,오버피팅이 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,1.0
2198,test,0,Overfitting 대체 어떻게 해결하지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",1.0
2199,test,0,전이학습? 그게 뭐야 도대체?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
2200,test,0,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
2201,test,0,활성화 함수? 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",1.0
2202,test,0,굳이 활성화 함수 왜 써?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,1.0
2203,test,0,CNN이 뭐야? 이미지 인식에 좋다던데,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",1.0
2204,test,0,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",1.0
2205,test,1,Cosine Similarity 에 대해 알려줘!,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,1.0
2206,test,1,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2207,test,1,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.5
2208,test,1,머신러닝 모델 평가하는 방법 알려줘,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2209,test,1,Accuracy 계산 어떻게 하지?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2210,test,1,True Positive 가 뭐야?,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.1
2211,test,1,True Negative 는 뭔지 궁금해 그럼,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2212,test,1,False Positive 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2213,test,1,False Negative (FN),False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2214,test,1,Recall 계산법 어떻게 하는 거지?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2215,test,1,Recall 이 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),1.0
2216,test,1,Precision 어떻게 계산하는지 정말 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2217,test,1,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.5
2218,test,1,F1 Score 가 뭐야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2219,test,1,F1 Score 계산식 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
2220,test,1,F1 Score 는 왜 쓰는 거지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.5
2221,test,1,IoU 라는 게 있는데 뭔지 궁금해,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2222,test,1,특이도는 뭐야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2223,test,1,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2224,test,1,"PR-AUC, ROC-AUC 가 뭐야?","binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2225,test,1,PR-AUC 에 대해 아주 자세히 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.5
2226,test,1,ROC-AUC 는 뭔지 정말 궁금해,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2227,test,1,True Positive Rate 구하는 방법을 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2228,test,1,False Positive Rate 가 뭔지 정말 궁금하다,True Positive Rate : recall 의 다른 이름,0.25
2229,test,1,Confusion Matrix (혼동 행렬) 이 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.25
2230,test,1,Confusion Matrix 는 그럼 어떻게 만들어?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.5
2231,test,1,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.25
2232,test,1,Normalization 정규화 그게 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2233,test,1,정규화가 뭐지? 정말 궁금해!,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",1.0
2234,test,1,Min-Max 정규화가 뭔지 잘 모르겠어,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2235,test,1,Z 스코어 정규화가 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2236,test,1,Clipping? 클리핑? 그게 뭐지?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
2237,test,1,클리핑 이거 쓸데없이 하는 거 아니야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.5
2238,test,1,로그 스케일링도 정규화 같은데 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
2239,test,1,Outlier 개념,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2240,test,1,이상치가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,1.0
2241,test,1,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2242,test,1,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.5
2243,test,1,PCA에 대해 알려줘,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2244,test,1,주성분 분석?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",1.0
2245,test,1,PCA 그거 왜 하는 건지 모르겠어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
2246,test,1,데이터가 불균형하다고? 그게 뭐지,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2247,test,1,데이터 불균형 어떻게 하면 해결할 수 있지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.5
2248,test,1,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.5
2249,test,1,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2250,test,1,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.1
2251,test,1,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2252,test,1,Undersampling 에 대해서 알려줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
2253,test,1,oversampling 이 뭐지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
2254,test,1,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.1
2255,test,1,undersampling 방법은 뭐가 있어?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
2256,test,1,Oversampling 하는 방법,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.25
2257,test,1,차원의 저주가 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2258,test,1,차원의 저주는 저주인데 정확히 뭐가 문제야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.5
2259,test,1,의사결정 나무가 뭔지 알려줘,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2260,test,1,Decision Tree 가 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,1.0
2261,test,1,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
2262,test,1,앙상블이 뭐지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2263,test,1,앙상블 하는 이유,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
2264,test,1,앙상블 방법,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
2265,test,1,Ensemble 정확히 어떻게 하지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",1.0
2266,test,1,Voting? 그게 뭐지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2267,test,1,앙상블 중에서 보팅 있잖아 그게 뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,1.0
2268,test,1,보팅 방법 구체적으로 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
2269,test,1,배깅이뭐야,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
2270,test,1,부스팅이 뭐지 그러면,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
2271,test,1,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.25
2272,test,1,가우시안 혼합? 그게 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2273,test,1,Gaussian Mixture 어려운 것 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,1.0
2274,test,1,K-means Clustering 너 알지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2275,test,1,K-means Clustering 방법,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.5
2276,test,1,KNN 알고리즘 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2277,test,1,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",1.0
2278,test,1,지도학습 강화학습 비지도학습 이런게 뭐지,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2279,test,1,머신러닝 방법 종류 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2280,test,1,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2281,test,1,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
2282,test,1,머신러닝 문제에는 뭐가 있지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2283,test,1,분류랑 회귀가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2284,test,1,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2285,test,1,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2286,test,1,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2287,test,1,SVM 제발 알려줘 제발,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",1.0
2288,test,1,K-fold Cross Validation 정의,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2289,test,1,K-fold Cross Validation 하는 이유는?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.5
2290,test,1,Hyper parameter 가 대체 뭐지,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2291,test,1,One-hot? 그것도 머신러닝 모델이야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2292,test,1,Valid 데이터 쓰는 이유가 궁금해,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.25
2293,test,1,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2294,test,1,인공지능 머신러닝 딥러닝의 관계는?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2295,test,1,인공지능 정의,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.5
2296,test,1,머신러닝은 인공지능에 속하는 거 맞지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
2297,test,1,딥러닝이 뭔지 알려줘,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.25
2298,test,1,딥러닝의 learning rate 그게 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.1
2299,test,1,학습률? Learning rate? 뭐야?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,1.0
2300,test,1,자주 쓰이는 손실 함수는 뭐가 있을까,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2301,test,1,오버피팅이 뭐야,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2302,test,1,Overfitting 대체 어떻게 해결하지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.5
2303,test,1,전이학습? 그게 뭐야 도대체?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2304,test,1,Transfer Learning 요즘 대세라던데 뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,1.0
2305,test,1,활성화 함수? 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2306,test,1,굳이 활성화 함수 왜 써?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.5
2307,test,1,CNN이 뭐야? 이미지 인식에 좋다던데,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2308,test,1,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2309,test,1,코사인 유사도가 뭔지 궁금해,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2310,test,2,Cosine Similarity 는 어떻게 계산하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2311,test,2,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2312,test,2,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2313,test,2,Accuracy 계산 어떻게 하지?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2314,test,2,True Positive 가 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2315,test,2,True Negative 는 뭔지 궁금해 그럼,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2316,test,2,False Positive 알려줘,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2317,test,2,False Negative (FN),True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2318,test,2,Recall 계산법 어떻게 하는 거지?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2319,test,2,Recall 이 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2320,test,2,Precision 어떻게 계산하는지 정말 궁금해,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2321,test,2,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2322,test,2,F1 Score 가 뭐야?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
2323,test,2,F1 Score 계산식 알려줘,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2324,test,2,F1 Score 는 왜 쓰는 거지?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.5
2325,test,2,IoU 라는 게 있는데 뭔지 궁금해,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
2326,test,2,특이도는 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2327,test,2,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2328,test,2,"PR-AUC, ROC-AUC 가 뭐야?",Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2329,test,2,PR-AUC 에 대해 아주 자세히 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2330,test,2,ROC-AUC 는 뭔지 정말 궁금해,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
2331,test,2,True Positive Rate 구하는 방법을 알려줘,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2332,test,2,False Positive Rate 가 뭔지 정말 궁금하다,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2333,test,2,Confusion Matrix (혼동 행렬) 이 뭐야?,True Positive Rate : recall 의 다른 이름,0.1
2334,test,2,Confusion Matrix 는 그럼 어떻게 만들어?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
2335,test,2,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.1
2336,test,2,Normalization 정규화 그게 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2337,test,2,정규화가 뭐지? 정말 궁금해!,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2338,test,2,Min-Max 정규화가 뭔지 잘 모르겠어,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2339,test,2,Z 스코어 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2340,test,2,Clipping? 클리핑? 그게 뭐지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2341,test,2,클리핑 이거 쓸데없이 하는 거 아니야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
2342,test,2,로그 스케일링도 정규화 같은데 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.25
2343,test,2,Outlier 개념,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.25
2344,test,2,이상치가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2345,test,2,Outlier 없애야 되는 이유가 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2346,test,2,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2347,test,2,PCA에 대해 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2348,test,2,주성분 분석?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2349,test,2,PCA 그거 왜 하는 건지 모르겠어,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.5
2350,test,2,데이터가 불균형하다고? 그게 뭐지,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2351,test,2,데이터 불균형 어떻게 하면 해결할 수 있지?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2352,test,2,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
2353,test,2,학습 환경만 바꾸는 방법도 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
2354,test,2,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2355,test,2,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
2356,test,2,Undersampling 에 대해서 알려줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2357,test,2,oversampling 이 뭐지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.25
2358,test,2,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.1
2359,test,2,undersampling 방법은 뭐가 있어?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
2360,test,2,Oversampling 하는 방법,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.1
2361,test,2,차원의 저주가 뭔지 궁금해,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2362,test,2,차원의 저주는 저주인데 정확히 뭐가 문제야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2363,test,2,의사결정 나무가 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2364,test,2,Decision Tree 가 뭐야?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2365,test,2,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.5
2366,test,2,앙상블이 뭐지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2367,test,2,앙상블 하는 이유,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2368,test,2,앙상블 방법,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
2369,test,2,Ensemble 정확히 어떻게 하지,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.5
2370,test,2,Voting? 그게 뭐지,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2371,test,2,앙상블 중에서 보팅 있잖아 그게 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2372,test,2,보팅 방법 구체적으로 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.5
2373,test,2,배깅이뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2374,test,2,부스팅이 뭐지 그러면,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
2375,test,2,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.25
2376,test,2,가우시안 혼합? 그게 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2377,test,2,Gaussian Mixture 어려운 것 같은데 뭐야?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2378,test,2,K-means Clustering 너 알지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2379,test,2,K-means Clustering 방법,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2380,test,2,KNN 알고리즘 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2381,test,2,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2382,test,2,지도학습 강화학습 비지도학습 이런게 뭐지,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2383,test,2,머신러닝 방법 종류 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2384,test,2,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",1.0
2385,test,2,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
2386,test,2,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2387,test,2,분류랑 회귀가 뭐야?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2388,test,2,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",1.0
2389,test,2,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2390,test,2,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2391,test,2,SVM 제발 알려줘 제발,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2392,test,2,K-fold Cross Validation 정의,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2393,test,2,K-fold Cross Validation 하는 이유는?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2394,test,2,Hyper parameter 가 대체 뭐지,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2395,test,2,One-hot? 그것도 머신러닝 모델이야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2396,test,2,Valid 데이터 쓰는 이유가 궁금해,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2397,test,2,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2398,test,2,인공지능 머신러닝 딥러닝의 관계는?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2399,test,2,인공지능 정의,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2400,test,2,머신러닝은 인공지능에 속하는 거 맞지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
2401,test,2,딥러닝이 뭔지 알려줘,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.25
2402,test,2,딥러닝의 learning rate 그게 뭐지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2403,test,2,학습률? Learning rate? 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2404,test,2,자주 쓰이는 손실 함수는 뭐가 있을까,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2405,test,2,오버피팅이 뭐야,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2406,test,2,Overfitting 대체 어떻게 해결하지?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2407,test,2,전이학습? 그게 뭐야 도대체?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2408,test,2,Transfer Learning 요즘 대세라던데 뭐야,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2409,test,2,활성화 함수? 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2410,test,2,굳이 활성화 함수 왜 써?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2411,test,2,CNN이 뭐야? 이미지 인식에 좋다던데,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2412,test,2,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2413,test,2,코사인 유사도가 뭔지 궁금해,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2414,test,2,Cosine Similarity 에 대해 알려줘!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2415,test,3,코사인 유사도 특징이 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.5
2416,test,3,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2417,test,3,Accuracy 계산 어떻게 하지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2418,test,3,True Positive 가 뭐야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2419,test,3,True Negative 는 뭔지 궁금해 그럼,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2420,test,3,False Positive 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2421,test,3,False Negative (FN),True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2422,test,3,Recall 계산법 어떻게 하는 거지?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2423,test,3,Recall 이 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2424,test,3,Precision 어떻게 계산하는지 정말 궁금해,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2425,test,3,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.5
2426,test,3,F1 Score 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2427,test,3,F1 Score 계산식 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
2428,test,3,F1 Score 는 왜 쓰는 거지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2429,test,3,IoU 라는 게 있는데 뭔지 궁금해,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
2430,test,3,특이도는 뭐야?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
2431,test,3,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2432,test,3,"PR-AUC, ROC-AUC 가 뭐야?",IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2433,test,3,PR-AUC 에 대해 아주 자세히 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2434,test,3,ROC-AUC 는 뭔지 정말 궁금해,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2435,test,3,True Positive Rate 구하는 방법을 알려줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
2436,test,3,False Positive Rate 가 뭔지 정말 궁금하다,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.25
2437,test,3,Confusion Matrix (혼동 행렬) 이 뭐야?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
2438,test,3,Confusion Matrix 는 그럼 어떻게 만들어?,True Positive Rate : recall 의 다른 이름,0.1
2439,test,3,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.1
2440,test,3,Normalization 정규화 그게 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2441,test,3,정규화가 뭐지? 정말 궁금해!,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2442,test,3,Min-Max 정규화가 뭔지 잘 모르겠어,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2443,test,3,Z 스코어 정규화가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2444,test,3,Clipping? 클리핑? 그게 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2445,test,3,클리핑 이거 쓸데없이 하는 거 아니야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2446,test,3,로그 스케일링도 정규화 같은데 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.25
2447,test,3,Outlier 개념,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2448,test,3,이상치가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2449,test,3,Outlier 없애야 되는 이유가 뭐야?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2450,test,3,Outlier 없애려면 어떻게 해야 되지?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.5
2451,test,3,PCA에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2452,test,3,주성분 분석?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2453,test,3,PCA 그거 왜 하는 건지 모르겠어,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2454,test,3,데이터가 불균형하다고? 그게 뭐지,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2455,test,3,데이터 불균형 어떻게 하면 해결할 수 있지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2456,test,3,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2457,test,3,학습 환경만 바꾸는 방법도 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
2458,test,3,데이터 증강이 뭐지?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
2459,test,3,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2460,test,3,Undersampling 에 대해서 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
2461,test,3,oversampling 이 뭐지?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2462,test,3,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.1
2463,test,3,undersampling 방법은 뭐가 있어?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
2464,test,3,Oversampling 하는 방법,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.25
2465,test,3,차원의 저주가 뭔지 궁금해,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2466,test,3,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2467,test,3,의사결정 나무가 뭔지 알려줘,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2468,test,3,Decision Tree 가 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2469,test,3,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2470,test,3,앙상블이 뭐지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2471,test,3,앙상블 하는 이유,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2472,test,3,앙상블 방법,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2473,test,3,Ensemble 정확히 어떻게 하지,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.5
2474,test,3,Voting? 그게 뭐지,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
2475,test,3,앙상블 중에서 보팅 있잖아 그게 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2476,test,3,보팅 방법 구체적으로 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2477,test,3,배깅이뭐야,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2478,test,3,부스팅이 뭐지 그러면,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2479,test,3,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.25
2480,test,3,가우시안 혼합? 그게 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2481,test,3,Gaussian Mixture 어려운 것 같은데 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2482,test,3,K-means Clustering 너 알지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2483,test,3,K-means Clustering 방법,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2484,test,3,KNN 알고리즘 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2485,test,3,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2486,test,3,지도학습 강화학습 비지도학습 이런게 뭐지,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2487,test,3,머신러닝 방법 종류 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2488,test,3,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2489,test,3,지도학습이랑 비지도랑 뭐가 달라 그러면?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.5
2490,test,3,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2491,test,3,분류랑 회귀가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2492,test,3,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2493,test,3,Naïve Bayes 뭐야,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2494,test,3,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2495,test,3,SVM 제발 알려줘 제발,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2496,test,3,K-fold Cross Validation 정의,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2497,test,3,K-fold Cross Validation 하는 이유는?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2498,test,3,Hyper parameter 가 대체 뭐지,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2499,test,3,One-hot? 그것도 머신러닝 모델이야?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2500,test,3,Valid 데이터 쓰는 이유가 궁금해,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2501,test,3,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2502,test,3,인공지능 머신러닝 딥러닝의 관계는?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2503,test,3,인공지능 정의,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2504,test,3,머신러닝은 인공지능에 속하는 거 맞지?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2505,test,3,딥러닝이 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.25
2506,test,3,딥러닝의 learning rate 그게 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2507,test,3,학습률? Learning rate? 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2508,test,3,자주 쓰이는 손실 함수는 뭐가 있을까,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2509,test,3,오버피팅이 뭐야,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2510,test,3,Overfitting 대체 어떻게 해결하지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2511,test,3,전이학습? 그게 뭐야 도대체?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2512,test,3,Transfer Learning 요즘 대세라던데 뭐야,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2513,test,3,활성화 함수? 뭐야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2514,test,3,굳이 활성화 함수 왜 써?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2515,test,3,CNN이 뭐야? 이미지 인식에 좋다던데,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2516,test,3,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2517,test,3,코사인 유사도가 뭔지 궁금해,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2518,test,3,Cosine Similarity 에 대해 알려줘!,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2519,test,3,Cosine Similarity 는 어떻게 계산하지?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2520,test,4,머신러닝 모델 평가하는 방법 알려줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2521,test,4,Accuracy 계산 어떻게 하지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2522,test,4,True Positive 가 뭐야?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2523,test,4,True Negative 는 뭔지 궁금해 그럼,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2524,test,4,False Positive 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.25
2525,test,4,False Negative (FN),Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.25
2526,test,4,Recall 계산법 어떻게 하는 거지?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.25
2527,test,4,Recall 이 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.25
2528,test,4,Precision 어떻게 계산하는지 정말 궁금해,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.25
2529,test,4,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.25
2530,test,4,F1 Score 가 뭐야?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2531,test,4,F1 Score 계산식 알려줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.25
2532,test,4,F1 Score 는 왜 쓰는 거지?,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.25
2533,test,4,IoU 라는 게 있는데 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.25
2534,test,4,특이도는 뭐야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.25
2535,test,4,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.25
2536,test,4,"PR-AUC, ROC-AUC 가 뭐야?","F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.25
2537,test,4,PR-AUC 에 대해 아주 자세히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.25
2538,test,4,ROC-AUC 는 뭔지 정말 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.25
2539,test,4,True Positive Rate 구하는 방법을 알려줘,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.25
2540,test,4,False Positive Rate 가 뭔지 정말 궁금하다,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.25
2541,test,4,Confusion Matrix (혼동 행렬) 이 뭐야?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
2542,test,4,Confusion Matrix 는 그럼 어떻게 만들어?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.1
2543,test,4,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,True Positive Rate : recall 의 다른 이름,0.25
2544,test,4,Normalization 정규화 그게 뭐야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2545,test,4,정규화가 뭐지? 정말 궁금해!,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2546,test,4,Min-Max 정규화가 뭔지 잘 모르겠어,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2547,test,4,Z 스코어 정규화가 뭐야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2548,test,4,Clipping? 클리핑? 그게 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2549,test,4,클리핑 이거 쓸데없이 하는 거 아니야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.25
2550,test,4,로그 스케일링도 정규화 같은데 뭐야?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.25
2551,test,4,Outlier 개념,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2552,test,4,이상치가 뭐야?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2553,test,4,Outlier 없애야 되는 이유가 뭐야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2554,test,4,Outlier 없애려면 어떻게 해야 되지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2555,test,4,PCA에 대해 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2556,test,4,주성분 분석?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2557,test,4,PCA 그거 왜 하는 건지 모르겠어,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2558,test,4,데이터가 불균형하다고? 그게 뭐지,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2559,test,4,데이터 불균형 어떻게 하면 해결할 수 있지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2560,test,4,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2561,test,4,학습 환경만 바꾸는 방법도 알려줘,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2562,test,4,데이터 증강이 뭐지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.25
2563,test,4,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.25
2564,test,4,Undersampling 에 대해서 알려줘,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.25
2565,test,4,oversampling 이 뭐지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.25
2566,test,4,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.1
2567,test,4,undersampling 방법은 뭐가 있어?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.5
2568,test,4,Oversampling 하는 방법,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.25
2569,test,4,차원의 저주가 뭔지 궁금해,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2570,test,4,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2571,test,4,의사결정 나무가 뭔지 알려줘,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2572,test,4,Decision Tree 가 뭐야?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2573,test,4,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2574,test,4,앙상블이 뭐지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2575,test,4,앙상블 하는 이유,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2576,test,4,앙상블 방법,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2577,test,4,Ensemble 정확히 어떻게 하지,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2578,test,4,Voting? 그게 뭐지,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.25
2579,test,4,앙상블 중에서 보팅 있잖아 그게 뭐야,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.25
2580,test,4,보팅 방법 구체적으로 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2581,test,4,배깅이뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.25
2582,test,4,부스팅이 뭐지 그러면,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2583,test,4,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.25
2584,test,4,가우시안 혼합? 그게 뭐야?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2585,test,4,Gaussian Mixture 어려운 것 같은데 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2586,test,4,K-means Clustering 너 알지?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2587,test,4,K-means Clustering 방법,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2588,test,4,KNN 알고리즘 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2589,test,4,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2590,test,4,지도학습 강화학습 비지도학습 이런게 뭐지,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2591,test,4,머신러닝 방법 종류 알려줘,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2592,test,4,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2593,test,4,지도학습이랑 비지도랑 뭐가 달라 그러면?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2594,test,4,머신러닝 문제에는 뭐가 있지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2595,test,4,분류랑 회귀가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2596,test,4,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2597,test,4,Naïve Bayes 뭐야,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2598,test,4,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2599,test,4,SVM 제발 알려줘 제발,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2600,test,4,K-fold Cross Validation 정의,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2601,test,4,K-fold Cross Validation 하는 이유는?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2602,test,4,Hyper parameter 가 대체 뭐지,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2603,test,4,One-hot? 그것도 머신러닝 모델이야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2604,test,4,Valid 데이터 쓰는 이유가 궁금해,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2605,test,4,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2606,test,4,인공지능 머신러닝 딥러닝의 관계는?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2607,test,4,인공지능 정의,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2608,test,4,머신러닝은 인공지능에 속하는 거 맞지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2609,test,4,딥러닝이 뭔지 알려줘,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2610,test,4,딥러닝의 learning rate 그게 뭐지?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.1
2611,test,4,학습률? Learning rate? 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2612,test,4,자주 쓰이는 손실 함수는 뭐가 있을까,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2613,test,4,오버피팅이 뭐야,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2614,test,4,Overfitting 대체 어떻게 해결하지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2615,test,4,전이학습? 그게 뭐야 도대체?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2616,test,4,Transfer Learning 요즘 대세라던데 뭐야,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2617,test,4,활성화 함수? 뭐야?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2618,test,4,굳이 활성화 함수 왜 써?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2619,test,4,CNN이 뭐야? 이미지 인식에 좋다던데,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2620,test,4,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2621,test,4,코사인 유사도가 뭔지 궁금해,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2622,test,4,Cosine Similarity 에 대해 알려줘!,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2623,test,4,Cosine Similarity 는 어떻게 계산하지?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2624,test,4,코사인 유사도 특징이 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2625,test,5,Min-Max 정규화가 뭔지 잘 모르겠어,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2626,test,5,Z 스코어 정규화가 뭐야?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2627,test,5,Clipping? 클리핑? 그게 뭐지?,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2628,test,5,클리핑 이거 쓸데없이 하는 거 아니야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2629,test,5,로그 스케일링도 정규화 같은데 뭐야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
2630,test,5,Outlier 개념,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.0
2631,test,5,이상치가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.0
2632,test,5,Outlier 없애야 되는 이유가 뭐야?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.0
2633,test,5,Outlier 없애려면 어떻게 해야 되지?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.0
2634,test,5,PCA에 대해 알려줘,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
2635,test,5,주성분 분석?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2636,test,5,PCA 그거 왜 하는 건지 모르겠어,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2637,test,5,데이터가 불균형하다고? 그게 뭐지,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
2638,test,5,데이터 불균형 어떻게 하면 해결할 수 있지?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
2639,test,5,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
2640,test,5,학습 환경만 바꾸는 방법도 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
2641,test,5,데이터 증강이 뭐지?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
2642,test,5,언더샘플링이랑 오버샘플링이 뭔지 궁금해,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
2643,test,5,Undersampling 에 대해서 알려줘,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
2644,test,5,oversampling 이 뭐지?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
2645,test,5,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
2646,test,5,undersampling 방법은 뭐가 있어?,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2647,test,5,Oversampling 하는 방법,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2648,test,5,차원의 저주가 뭔지 궁금해,True Positive Rate : recall 의 다른 이름,0.0
2649,test,5,차원의 저주는 저주인데 정확히 뭐가 문제야?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2650,test,5,의사결정 나무가 뭔지 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2651,test,5,Decision Tree 가 뭐야?,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2652,test,5,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2653,test,5,앙상블이 뭐지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2654,test,5,앙상블 하는 이유,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2655,test,5,앙상블 방법,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
2656,test,5,Ensemble 정확히 어떻게 하지,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2657,test,5,Voting? 그게 뭐지,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2658,test,5,앙상블 중에서 보팅 있잖아 그게 뭐야,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2659,test,5,보팅 방법 구체적으로 알려줘,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2660,test,5,배깅이뭐야,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2661,test,5,부스팅이 뭐지 그러면,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2662,test,5,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2663,test,5,가우시안 혼합? 그게 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2664,test,5,Gaussian Mixture 어려운 것 같은데 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2665,test,5,K-means Clustering 너 알지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2666,test,5,K-means Clustering 방법,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2667,test,5,KNN 알고리즘 알려줘,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
2668,test,5,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
2669,test,5,지도학습 강화학습 비지도학습 이런게 뭐지,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
2670,test,5,머신러닝 방법 종류 알려줘,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
2671,test,5,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
2672,test,5,지도학습이랑 비지도랑 뭐가 달라 그러면?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
2673,test,5,머신러닝 문제에는 뭐가 있지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
2674,test,5,분류랑 회귀가 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2675,test,5,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2676,test,5,Naïve Bayes 뭐야,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2677,test,5,서포트 벡터 머신? 그게 뭐지? 알려줘!,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2678,test,5,SVM 제발 알려줘 제발,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2679,test,5,K-fold Cross Validation 정의,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2680,test,5,K-fold Cross Validation 하는 이유는?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2681,test,5,Hyper parameter 가 대체 뭐지,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2682,test,5,One-hot? 그것도 머신러닝 모델이야?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2683,test,5,Valid 데이터 쓰는 이유가 궁금해,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
2684,test,5,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
2685,test,5,인공지능 머신러닝 딥러닝의 관계는?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2686,test,5,인공지능 정의,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2687,test,5,머신러닝은 인공지능에 속하는 거 맞지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2688,test,5,딥러닝이 뭔지 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2689,test,5,딥러닝의 learning rate 그게 뭐지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2690,test,5,학습률? Learning rate? 뭐야?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2691,test,5,자주 쓰이는 손실 함수는 뭐가 있을까,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2692,test,5,오버피팅이 뭐야,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2693,test,5,Overfitting 대체 어떻게 해결하지?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2694,test,5,전이학습? 그게 뭐야 도대체?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2695,test,5,Transfer Learning 요즘 대세라던데 뭐야,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2696,test,5,활성화 함수? 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2697,test,5,굳이 활성화 함수 왜 써?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2698,test,5,CNN이 뭐야? 이미지 인식에 좋다던데,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2699,test,5,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2700,test,5,코사인 유사도가 뭔지 궁금해,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2701,test,5,Cosine Similarity 에 대해 알려줘!,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2702,test,5,Cosine Similarity 는 어떻게 계산하지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2703,test,5,코사인 유사도 특징이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2704,test,5,머신러닝 모델 평가하는 방법 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2705,test,5,Accuracy 계산 어떻게 하지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2706,test,5,True Positive 가 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2707,test,5,True Negative 는 뭔지 궁금해 그럼,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2708,test,5,False Positive 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2709,test,5,False Negative (FN),"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2710,test,5,Recall 계산법 어떻게 하는 거지?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2711,test,5,Recall 이 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2712,test,5,Precision 어떻게 계산하는지 정말 궁금해,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2713,test,5,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2714,test,5,F1 Score 가 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2715,test,5,F1 Score 계산식 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
2716,test,5,F1 Score 는 왜 쓰는 거지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2717,test,5,IoU 라는 게 있는데 뭔지 궁금해,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2718,test,5,특이도는 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2719,test,5,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2720,test,5,"PR-AUC, ROC-AUC 가 뭐야?",Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2721,test,5,PR-AUC 에 대해 아주 자세히 알려줘,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2722,test,5,ROC-AUC 는 뭔지 정말 궁금해,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2723,test,5,True Positive Rate 구하는 방법을 알려줘,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2724,test,5,False Positive Rate 가 뭔지 정말 궁금하다,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2725,test,5,Confusion Matrix (혼동 행렬) 이 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2726,test,5,Confusion Matrix 는 그럼 어떻게 만들어?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2727,test,5,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2728,test,5,Normalization 정규화 그게 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2729,test,5,정규화가 뭐지? 정말 궁금해!,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2730,test,6,주성분 분석?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2731,test,6,PCA 그거 왜 하는 건지 모르겠어,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2732,test,6,데이터가 불균형하다고? 그게 뭐지,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2733,test,6,데이터 불균형 어떻게 하면 해결할 수 있지?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2734,test,6,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
2735,test,6,학습 환경만 바꾸는 방법도 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.0
2736,test,6,데이터 증강이 뭐지?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.0
2737,test,6,언더샘플링이랑 오버샘플링이 뭔지 궁금해,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.0
2738,test,6,Undersampling 에 대해서 알려줘,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.0
2739,test,6,oversampling 이 뭐지?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
2740,test,6,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2741,test,6,undersampling 방법은 뭐가 있어?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2742,test,6,Oversampling 하는 방법,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
2743,test,6,차원의 저주가 뭔지 궁금해,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
2744,test,6,차원의 저주는 저주인데 정확히 뭐가 문제야?,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
2745,test,6,의사결정 나무가 뭔지 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
2746,test,6,Decision Tree 가 뭐야?,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
2747,test,6,Decision Tree 로 새로운 데이터를 어떻게 예측해?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
2748,test,6,앙상블이 뭐지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
2749,test,6,앙상블 하는 이유,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
2750,test,6,앙상블 방법,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
2751,test,6,Ensemble 정확히 어떻게 하지,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2752,test,6,Voting? 그게 뭐지,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2753,test,6,앙상블 중에서 보팅 있잖아 그게 뭐야,True Positive Rate : recall 의 다른 이름,0.0
2754,test,6,보팅 방법 구체적으로 알려줘,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2755,test,6,배깅이뭐야,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2756,test,6,부스팅이 뭐지 그러면,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2757,test,6,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2758,test,6,가우시안 혼합? 그게 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2759,test,6,Gaussian Mixture 어려운 것 같은데 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2760,test,6,K-means Clustering 너 알지?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
2761,test,6,K-means Clustering 방법,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2762,test,6,KNN 알고리즘 알려줘,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2763,test,6,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2764,test,6,지도학습 강화학습 비지도학습 이런게 뭐지,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2765,test,6,머신러닝 방법 종류 알려줘,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2766,test,6,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2767,test,6,지도학습이랑 비지도랑 뭐가 달라 그러면?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2768,test,6,머신러닝 문제에는 뭐가 있지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2769,test,6,분류랑 회귀가 뭐야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2770,test,6,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2771,test,6,Naïve Bayes 뭐야,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2772,test,6,서포트 벡터 머신? 그게 뭐지? 알려줘!,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
2773,test,6,SVM 제발 알려줘 제발,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
2774,test,6,K-fold Cross Validation 정의,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
2775,test,6,K-fold Cross Validation 하는 이유는?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
2776,test,6,Hyper parameter 가 대체 뭐지,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
2777,test,6,One-hot? 그것도 머신러닝 모델이야?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
2778,test,6,Valid 데이터 쓰는 이유가 궁금해,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
2779,test,6,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2780,test,6,인공지능 머신러닝 딥러닝의 관계는?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2781,test,6,인공지능 정의,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2782,test,6,머신러닝은 인공지능에 속하는 거 맞지?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2783,test,6,딥러닝이 뭔지 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2784,test,6,딥러닝의 learning rate 그게 뭐지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2785,test,6,학습률? Learning rate? 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2786,test,6,자주 쓰이는 손실 함수는 뭐가 있을까,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2787,test,6,오버피팅이 뭐야,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2788,test,6,Overfitting 대체 어떻게 해결하지?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
2789,test,6,전이학습? 그게 뭐야 도대체?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
2790,test,6,Transfer Learning 요즘 대세라던데 뭐야,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2791,test,6,활성화 함수? 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2792,test,6,굳이 활성화 함수 왜 써?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2793,test,6,CNN이 뭐야? 이미지 인식에 좋다던데,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2794,test,6,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2795,test,6,코사인 유사도가 뭔지 궁금해,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2796,test,6,Cosine Similarity 에 대해 알려줘!,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2797,test,6,Cosine Similarity 는 어떻게 계산하지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2798,test,6,코사인 유사도 특징이 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2799,test,6,머신러닝 모델 평가하는 방법 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2800,test,6,Accuracy 계산 어떻게 하지?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2801,test,6,True Positive 가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2802,test,6,True Negative 는 뭔지 궁금해 그럼,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2803,test,6,False Positive 알려줘,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2804,test,6,False Negative (FN),"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2805,test,6,Recall 계산법 어떻게 하는 거지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2806,test,6,Recall 이 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2807,test,6,Precision 어떻게 계산하는지 정말 궁금해,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2808,test,6,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2809,test,6,F1 Score 가 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2810,test,6,F1 Score 계산식 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2811,test,6,F1 Score 는 왜 쓰는 거지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2812,test,6,IoU 라는 게 있는데 뭔지 궁금해,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2813,test,6,특이도는 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2814,test,6,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2815,test,6,"PR-AUC, ROC-AUC 가 뭐야?",K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2816,test,6,PR-AUC 에 대해 아주 자세히 알려줘,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2817,test,6,ROC-AUC 는 뭔지 정말 궁금해,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2818,test,6,True Positive Rate 구하는 방법을 알려줘,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2819,test,6,False Positive Rate 가 뭔지 정말 궁금하다,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2820,test,6,Confusion Matrix (혼동 행렬) 이 뭐야?,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
2821,test,6,Confusion Matrix 는 그럼 어떻게 만들어?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2822,test,6,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2823,test,6,Normalization 정규화 그게 뭐야?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2824,test,6,정규화가 뭐지? 정말 궁금해!,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2825,test,6,Min-Max 정규화가 뭔지 잘 모르겠어,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2826,test,6,Z 스코어 정규화가 뭐야?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2827,test,6,Clipping? 클리핑? 그게 뭐지?,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2828,test,6,클리핑 이거 쓸데없이 하는 거 아니야?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2829,test,6,로그 스케일링도 정규화 같은데 뭐야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2830,test,6,Outlier 개념,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2831,test,6,이상치가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2832,test,6,Outlier 없애야 되는 이유가 뭐야?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2833,test,6,Outlier 없애려면 어떻게 해야 되지?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2834,test,6,PCA에 대해 알려줘,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2835,test,7,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2836,test,7,undersampling 방법은 뭐가 있어?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2837,test,7,Oversampling 하는 방법,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2838,test,7,차원의 저주가 뭔지 궁금해,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2839,test,7,차원의 저주는 저주인데 정확히 뭐가 문제야?,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
2840,test,7,의사결정 나무가 뭔지 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.0
2841,test,7,Decision Tree 가 뭐야?,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.0
2842,test,7,Decision Tree 로 새로운 데이터를 어떻게 예측해?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.0
2843,test,7,앙상블이 뭐지?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.0
2844,test,7,앙상블 하는 이유,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
2845,test,7,앙상블 방법,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2846,test,7,Ensemble 정확히 어떻게 하지,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2847,test,7,Voting? 그게 뭐지,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
2848,test,7,앙상블 중에서 보팅 있잖아 그게 뭐야,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
2849,test,7,보팅 방법 구체적으로 알려줘,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
2850,test,7,배깅이뭐야,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
2851,test,7,부스팅이 뭐지 그러면,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
2852,test,7,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
2853,test,7,가우시안 혼합? 그게 뭐야?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
2854,test,7,Gaussian Mixture 어려운 것 같은데 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
2855,test,7,K-means Clustering 너 알지?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
2856,test,7,K-means Clustering 방법,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2857,test,7,KNN 알고리즘 알려줘,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2858,test,7,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,True Positive Rate : recall 의 다른 이름,0.0
2859,test,7,지도학습 강화학습 비지도학습 이런게 뭐지,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2860,test,7,머신러닝 방법 종류 알려줘,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2861,test,7,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2862,test,7,지도학습이랑 비지도랑 뭐가 달라 그러면?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2863,test,7,머신러닝 문제에는 뭐가 있지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2864,test,7,분류랑 회귀가 뭐야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2865,test,7,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
2866,test,7,Naïve Bayes 뭐야,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2867,test,7,서포트 벡터 머신? 그게 뭐지? 알려줘!,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2868,test,7,SVM 제발 알려줘 제발,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2869,test,7,K-fold Cross Validation 정의,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2870,test,7,K-fold Cross Validation 하는 이유는?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2871,test,7,Hyper parameter 가 대체 뭐지,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2872,test,7,One-hot? 그것도 머신러닝 모델이야?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2873,test,7,Valid 데이터 쓰는 이유가 궁금해,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2874,test,7,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2875,test,7,인공지능 머신러닝 딥러닝의 관계는?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2876,test,7,인공지능 정의,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2877,test,7,머신러닝은 인공지능에 속하는 거 맞지?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
2878,test,7,딥러닝이 뭔지 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
2879,test,7,딥러닝의 learning rate 그게 뭐지?,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
2880,test,7,학습률? Learning rate? 뭐야?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
2881,test,7,자주 쓰이는 손실 함수는 뭐가 있을까,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
2882,test,7,오버피팅이 뭐야,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
2883,test,7,Overfitting 대체 어떻게 해결하지?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
2884,test,7,전이학습? 그게 뭐야 도대체?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2885,test,7,Transfer Learning 요즘 대세라던데 뭐야,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2886,test,7,활성화 함수? 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2887,test,7,굳이 활성화 함수 왜 써?,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2888,test,7,CNN이 뭐야? 이미지 인식에 좋다던데,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2889,test,7,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2890,test,7,코사인 유사도가 뭔지 궁금해,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2891,test,7,Cosine Similarity 에 대해 알려줘!,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2892,test,7,Cosine Similarity 는 어떻게 계산하지?,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2893,test,7,코사인 유사도 특징이 뭐야?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
2894,test,7,머신러닝 모델 평가하는 방법 알려줘,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
2895,test,7,Accuracy 계산 어떻게 하지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2896,test,7,True Positive 가 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
2897,test,7,True Negative 는 뭔지 궁금해 그럼,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2898,test,7,False Positive 알려줘,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
2899,test,7,False Negative (FN),"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
2900,test,7,Recall 계산법 어떻게 하는 거지?,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
2901,test,7,Recall 이 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
2902,test,7,Precision 어떻게 계산하는지 정말 궁금해,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
2903,test,7,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2904,test,7,F1 Score 가 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
2905,test,7,F1 Score 계산식 알려줘,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
2906,test,7,F1 Score 는 왜 쓰는 거지?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
2907,test,7,IoU 라는 게 있는데 뭔지 궁금해,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2908,test,7,특이도는 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
2909,test,7,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2910,test,7,"PR-AUC, ROC-AUC 가 뭐야?","지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2911,test,7,PR-AUC 에 대해 아주 자세히 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
2912,test,7,ROC-AUC 는 뭔지 정말 궁금해,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
2913,test,7,True Positive Rate 구하는 방법을 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2914,test,7,False Positive Rate 가 뭔지 정말 궁금하다,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2915,test,7,Confusion Matrix (혼동 행렬) 이 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
2916,test,7,Confusion Matrix 는 그럼 어떻게 만들어?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
2917,test,7,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2918,test,7,Normalization 정규화 그게 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
2919,test,7,정규화가 뭐지? 정말 궁금해!,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
2920,test,7,Min-Max 정규화가 뭔지 잘 모르겠어,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
2921,test,7,Z 스코어 정규화가 뭐야?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
2922,test,7,Clipping? 클리핑? 그게 뭐지?,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
2923,test,7,클리핑 이거 쓸데없이 하는 거 아니야?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
2924,test,7,로그 스케일링도 정규화 같은데 뭐야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
2925,test,7,Outlier 개념,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
2926,test,7,이상치가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
2927,test,7,Outlier 없애야 되는 이유가 뭐야?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
2928,test,7,Outlier 없애려면 어떻게 해야 되지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
2929,test,7,PCA에 대해 알려줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2930,test,7,주성분 분석?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
2931,test,7,PCA 그거 왜 하는 건지 모르겠어,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
2932,test,7,데이터가 불균형하다고? 그게 뭐지,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
2933,test,7,데이터 불균형 어떻게 하면 해결할 수 있지?,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
2934,test,7,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2935,test,7,학습 환경만 바꾸는 방법도 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
2936,test,7,데이터 증강이 뭐지?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
2937,test,7,언더샘플링이랑 오버샘플링이 뭔지 궁금해,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
2938,test,7,Undersampling 에 대해서 알려줘,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
2939,test,7,oversampling 이 뭐지?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
2940,test,8,앙상블 방법,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2941,test,8,Ensemble 정확히 어떻게 하지,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
2942,test,8,Voting? 그게 뭐지,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
2943,test,8,앙상블 중에서 보팅 있잖아 그게 뭐야,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
2944,test,8,보팅 방법 구체적으로 알려줘,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
2945,test,8,배깅이뭐야,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.0
2946,test,8,부스팅이 뭐지 그러면,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.0
2947,test,8,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.0
2948,test,8,가우시안 혼합? 그게 뭐야?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.0
2949,test,8,Gaussian Mixture 어려운 것 같은데 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
2950,test,8,K-means Clustering 너 알지?,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2951,test,8,K-means Clustering 방법,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
2952,test,8,KNN 알고리즘 알려줘,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
2953,test,8,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
2954,test,8,지도학습 강화학습 비지도학습 이런게 뭐지,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
2955,test,8,머신러닝 방법 종류 알려줘,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
2956,test,8,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
2957,test,8,지도학습이랑 비지도랑 뭐가 달라 그러면?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
2958,test,8,머신러닝 문제에는 뭐가 있지?,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
2959,test,8,분류랑 회귀가 뭐야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
2960,test,8,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
2961,test,8,Naïve Bayes 뭐야,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2962,test,8,서포트 벡터 머신? 그게 뭐지? 알려줘!,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
2963,test,8,SVM 제발 알려줘 제발,True Positive Rate : recall 의 다른 이름,0.0
2964,test,8,K-fold Cross Validation 정의,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
2965,test,8,K-fold Cross Validation 하는 이유는?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
2966,test,8,Hyper parameter 가 대체 뭐지,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
2967,test,8,One-hot? 그것도 머신러닝 모델이야?,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
2968,test,8,Valid 데이터 쓰는 이유가 궁금해,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2969,test,8,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
2970,test,8,인공지능 머신러닝 딥러닝의 관계는?,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
2971,test,8,인공지능 정의,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
2972,test,8,머신러닝은 인공지능에 속하는 거 맞지?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
2973,test,8,딥러닝이 뭔지 알려줘,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
2974,test,8,딥러닝의 learning rate 그게 뭐지?,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
2975,test,8,학습률? Learning rate? 뭐야?,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2976,test,8,자주 쓰이는 손실 함수는 뭐가 있을까,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
2977,test,8,오버피팅이 뭐야,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
2978,test,8,Overfitting 대체 어떻게 해결하지?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
2979,test,8,전이학습? 그게 뭐야 도대체?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2980,test,8,Transfer Learning 요즘 대세라던데 뭐야,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
2981,test,8,활성화 함수? 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
2982,test,8,굳이 활성화 함수 왜 써?,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
2983,test,8,CNN이 뭐야? 이미지 인식에 좋다던데,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
2984,test,8,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
2985,test,8,코사인 유사도가 뭔지 궁금해,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
2986,test,8,Cosine Similarity 에 대해 알려줘!,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
2987,test,8,Cosine Similarity 는 어떻게 계산하지?,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
2988,test,8,코사인 유사도 특징이 뭐야?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
2989,test,8,머신러닝 모델 평가하는 방법 알려줘,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
2990,test,8,Accuracy 계산 어떻게 하지?,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
2991,test,8,True Positive 가 뭐야?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
2992,test,8,True Negative 는 뭔지 궁금해 그럼,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
2993,test,8,False Positive 알려줘,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
2994,test,8,False Negative (FN),"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
2995,test,8,Recall 계산법 어떻게 하는 거지?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2996,test,8,Recall 이 뭐야?,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
2997,test,8,Precision 어떻게 계산하는지 정말 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
2998,test,8,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
2999,test,8,F1 Score 가 뭐야?,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
3000,test,8,F1 Score 계산식 알려줘,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
3001,test,8,F1 Score 는 왜 쓰는 거지?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
3002,test,8,IoU 라는 게 있는데 뭔지 궁금해,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
3003,test,8,특이도는 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
3004,test,8,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
3005,test,8,"PR-AUC, ROC-AUC 가 뭐야?","Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
3006,test,8,PR-AUC 에 대해 아주 자세히 알려줘,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
3007,test,8,ROC-AUC 는 뭔지 정말 궁금해,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
3008,test,8,True Positive Rate 구하는 방법을 알려줘,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
3009,test,8,False Positive Rate 가 뭔지 정말 궁금하다,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
3010,test,8,Confusion Matrix (혼동 행렬) 이 뭐야?,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
3011,test,8,Confusion Matrix 는 그럼 어떻게 만들어?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
3012,test,8,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
3013,test,8,Normalization 정규화 그게 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
3014,test,8,정규화가 뭐지? 정말 궁금해!,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
3015,test,8,Min-Max 정규화가 뭔지 잘 모르겠어,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
3016,test,8,Z 스코어 정규화가 뭐야?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
3017,test,8,Clipping? 클리핑? 그게 뭐지?,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
3018,test,8,클리핑 이거 쓸데없이 하는 거 아니야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
3019,test,8,로그 스케일링도 정규화 같은데 뭐야?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
3020,test,8,Outlier 개념,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
3021,test,8,이상치가 뭐야?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
3022,test,8,Outlier 없애야 되는 이유가 뭐야?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
3023,test,8,Outlier 없애려면 어떻게 해야 되지?,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
3024,test,8,PCA에 대해 알려줘,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
3025,test,8,주성분 분석?,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
3026,test,8,PCA 그거 왜 하는 건지 모르겠어,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
3027,test,8,데이터가 불균형하다고? 그게 뭐지,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
3028,test,8,데이터 불균형 어떻게 하면 해결할 수 있지?,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
3029,test,8,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
3030,test,8,학습 환경만 바꾸는 방법도 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
3031,test,8,데이터 증강이 뭐지?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
3032,test,8,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
3033,test,8,Undersampling 에 대해서 알려줘,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
3034,test,8,oversampling 이 뭐지?,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
3035,test,8,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
3036,test,8,undersampling 방법은 뭐가 있어?,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
3037,test,8,Oversampling 하는 방법,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
3038,test,8,차원의 저주가 뭔지 궁금해,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
3039,test,8,차원의 저주는 저주인데 정확히 뭐가 문제야?,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
3040,test,8,의사결정 나무가 뭔지 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
3041,test,8,Decision Tree 가 뭐야?,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
3042,test,8,Decision Tree 로 새로운 데이터를 어떻게 예측해?,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
3043,test,8,앙상블이 뭐지?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
3044,test,8,앙상블 하는 이유,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
3045,test,9,K-means Clustering 너 알지?,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
3046,test,9,K-means Clustering 방법,cosine similarity (코사인 유사도) : 두 벡터의 방향 유사도를 -1.0 ~ +1.0 으로 나타냄 | 핵심 아이디어: 벡터 크기 대신 방향을 봄,0.0
3047,test,9,KNN 알고리즘 알려줘,cosine similarity (코사인 유사도) 계산법 : 원소 개수가 같은 2개의 벡터의 각도의 코사인 값,0.0
3048,test,9,k Nearest Neighbor 가 도대체 어떤 알고리즘이야?,"cosine similarity (코사인 유사도) 특징 : 방향 일치하면 +1.0, 수직이면 0.0, 반대 방향이면 -1.0",0.0
3049,test,9,지도학습 강화학습 비지도학습 이런게 뭐지,"머신러닝 모델 성능 평가 지표 : Accuracy (정확도), Recall, Precision, F1 Score",0.0
3050,test,9,머신러닝 방법 종류 알려줘,Accuracy (정확도) : 모델이 얼마나 잘 맞혔는지를 평가하는 정확도 | 수식: (True Positive + True Negative) / (전체 테스트 데이터 개수),0.0
3051,test,9,지도학습? 강화학습? 이게 도대체 뭐야? 처음 들어 보는데,True Positive (TP) : 모델 예측이 참이면서 실제로도 참인 데이터 개수,0.0
3052,test,9,지도학습이랑 비지도랑 뭐가 달라 그러면?,True Negative (TN) : 모델 예측이 거짓이면서 실제로도 거짓인 데이터 개수,0.0
3053,test,9,머신러닝 문제에는 뭐가 있지?,False Positive (FP) : 모델 예측이 참이지만 실제로는 거짓인 데이터 개수,0.0
3054,test,9,분류랑 회귀가 뭐야?,False Negative (FN) : 모델 예측이 거짓이지만 실제로는 참인 데이터 개수,0.0
3055,test,9,머신러닝에 분류랑 회귀가 있다는데 그게 뭐야,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
3056,test,9,Naïve Bayes 뭐야,Recall (재현율) : 실제로 참인 것을 모델이 얼마나 찾았는지의 비율 | 수식: (True Positive) / (True Positive + False Negative),0.0
3057,test,9,서포트 벡터 머신? 그게 뭐지? 알려줘!,Precision (정밀도) : 모델이 참으로 예측한 것 중 실제 참인 것의 비율 | 수식: (True Positive) / (True Positive + False Positive),0.0
3058,test,9,SVM 제발 알려줘 제발,"Recall 과 Precision 차이 : Recall 은 False Negative 에 의해서, Precision 은 False Positive 에 의해서 감소",0.0
3059,test,9,K-fold Cross Validation 정의,F1 Score 개념 : Recall 과 Precision 의 조화 평균,0.0
3060,test,9,K-fold Cross Validation 하는 이유는?,F1 Score 수식 : 2 * Precision * Recall / (Precision + Recall),0.0
3061,test,9,Hyper parameter 가 대체 뭐지,"F1 Score 장점 : 모델의 2가지 예측 실패 (False Negative, False Positive) 를 모두 고려",0.0
3062,test,9,One-hot? 그것도 머신러닝 모델이야?,IoU : (교집합의 크기) / (합집합의 크기) | 수식 : (True Positive) / (True Positive + False Positive + False Negative),0.0
3063,test,9,Valid 데이터 쓰는 이유가 궁금해,Specificity (특이도) : 실제로 False 인 데이터 중 모델이 False 로 예측한 비율 | 수식: (True Negative) / (False Positive + True Negative),0.0
3064,test,9,Train 데이터셋 순서 섞잖아. 왜 그러는 거야?,"binary classification (이진 분류) metric : PR-AUC, ROC-AUC",0.0
3065,test,9,인공지능 머신러닝 딥러닝의 관계는?,"PR-AUC 와 ROC-AUC : PR-AUC는 x축이 recall, y축이 precision 일 때, ROC-AUC는 x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이",0.0
3066,test,9,인공지능 정의,"PR-AUC : x축이 recall, y축이 precision 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
3067,test,9,머신러닝은 인공지능에 속하는 거 맞지?,"ROC-AUC : x축이 False Positive Rate, y축이 True Positive Rate 일 때 이 측정값들을 연결한 그래프 아래쪽의 넓이 (1에 가까울수록 성능 좋음)",0.0
3068,test,9,딥러닝이 뭔지 알려줘,True Positive Rate : recall 의 다른 이름,0.0
3069,test,9,딥러닝의 learning rate 그게 뭐지?,False Positive Rate : 실제 Negative 인 것들 중 모델이 Positive 로 예측한 비율 | 수식: (False Positive) / (False Positive + True Negative),0.0
3070,test,9,학습률? Learning rate? 뭐야?,"Confusion Matrix (혼동 행렬) : 모델의 예측 중 True Positive, True Negative, False Positive, False Negative 의 개수와 Recall, Precision 을 알기 쉽게 나타낸 표",0.0
3071,test,9,자주 쓰이는 손실 함수는 뭐가 있을까,"Confusion Matrix (혼동 행렬) 작성 방법 : 첫 행은 '실제 값 = True', '실제 값 = False', 'Precision', 첫 열에는 '예측 = True', '예측 = False', 'Recall' 순서로 쓴 후 각 값을 계산",0.0
3072,test,9,오버피팅이 뭐야,"불량품 예측에서의 Recall, Precision 사용 : Recall 은 불량품을 모델이 불량품으로 검출한 비율 | 해당 비율이 낮으면 불량품 검출 성능이 떨어짐을 의미",0.0
3073,test,9,Overfitting 대체 어떻게 해결하지?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
3074,test,9,전이학습? 그게 뭐야 도대체?,"Normalization (정규화) : 데이터를 모델이 학습할 수 있도록 일정한 규칙에 따라 값을 변환하는 것 | 데이터 전처리에서 필수적 | 예시: min-max, z-score",0.0
3075,test,9,Transfer Learning 요즘 대세라던데 뭐야,Min-max normalization (Min-max 정규화) : 데이터의 최솟값과 최댓값을 기준으로 정규화 | 수식: y = (x - MIN) / (MAX - MIN),0.0
3076,test,9,활성화 함수? 뭐야?,Z score normalization (Z score 정규화) : 데이터를 평균과 표준편차를 이용한 Z score 값으로 정규화 | 수식: y = (x - MEAN) / STD,0.0
3077,test,9,굳이 활성화 함수 왜 써?,"Clipping : 데이터를 특정 범위의 값에 속하도록 변환하는 것 (x > MAX 인 경우 MAX, x < MIN 인 경우 MIN 으로 변환)",0.0
3078,test,9,CNN이 뭐야? 이미지 인식에 좋다던데,Clipping 장점 : Outlier 의 영향을 잘 받지 않음,0.0
3079,test,9,LLM이 정확히 뭐야? 나도 AI 트렌드 따라잡자!!,Log Scaling : 주어진 데이터 x를 log(x) 또는 log(1+x) 값으로 변환하는 것,0.0
3080,test,9,코사인 유사도가 뭔지 궁금해,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
3081,test,9,Cosine Similarity 에 대해 알려줘!,Outlier (이상치) : 데이터셋에서 일반적인 분포 범위를 크게 벗어난 데이터,0.0
3082,test,9,Cosine Similarity 는 어떻게 계산하지?,Outlier (이상치) 제거 이유 : 데이터 시각화 결과의 가독성 향상 및 머신러닝 학습에 지장이 없게 함,0.0
3083,test,9,코사인 유사도 특징이 뭐야?,"Outlier (이상치) 제거 방법 : 상자 수염 그림 이용, 평균 및 표준편차 이용 등",0.0
3084,test,9,머신러닝 모델 평가하는 방법 알려줘,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
3085,test,9,Accuracy 계산 어떻게 하지?,"PCA (주성분 분석) : Principal Component Analysis 라고 하며, 데이터셋의 분산을 최대한 보존하는 특징의 결합을 추출",0.0
3086,test,9,True Positive 가 뭐야?,PCA (주성분 분석) 사용 이유 : 데이터 압축 및 차원 축소 목적,0.0
3087,test,9,True Negative 는 뭔지 궁금해 그럼,Data Imbalance (데이터 불균형) : Classification Task 에서 Class 간 데이터 개수가 유의미하게 차이 나는 것,0.0
3088,test,9,False Positive 알려줘,"Data Imbalance (데이터 불균형) 해결 방법 : 데이터를 새로 추가/제거하거나, 학습 환경만 바꾸는 방법",0.0
3089,test,9,False Negative (FN),"Data Imbalance (데이터 불균형) 데이터 추가/제거 : Minority Class 데이터 추가 수집, Data Augmentation, Undersampling, Oversampling 등",0.0
3090,test,9,Recall 계산법 어떻게 하는 거지?,"Data Imbalance (데이터 불균형) 학습 환경 변경 : 적절한 성능 평가 지표 선택, Loss Function 에서 Class 별 가중치 조정",0.0
3091,test,9,Recall 이 뭐야?,"Data Augmentation (데이터 증강) : 학습 데이터 부족, 데이터 불균형 해결 목적으로 학습 데이터에 기존과 유사한 데이터를 추가하여 늘리는 것",0.0
3092,test,9,Precision 어떻게 계산하는지 정말 궁금해,Undersampling 과 Oversampling : Undersampling은 데이터가 많은 Class 의 일부 데이터를 제거 | Oversampling 은 데이터가 적은 Class 의 데이터 증가,0.0
3093,test,9,Recall Precision 이거 헷갈리는데 잘 외우는 법 없을까?,Undersampling : 데이터가 많은 Class 의 일부 데이터를 제거,0.0
3094,test,9,F1 Score 가 뭐야?,Oversampling : 데이터가 적은 Class 의 데이터 증가,0.0
3095,test,9,F1 Score 계산식 알려줘,"Data Imbalance (데이터 불균형) 고려 성능지표 : F1 Score, AUROC, ROC-AUC",0.0
3096,test,9,F1 Score 는 왜 쓰는 거지?,"Undersampling 방법 : Tomek Links (Class 경계선 상의 데이터 삭제), Random Sampling (랜덤 샘플링)",0.0
3097,test,9,IoU 라는 게 있는데 뭔지 궁금해,Oversampling 방법 : SMOTE (Minority Class 데이터 2개의 벡터의 중간값 계산),0.0
3098,test,9,특이도는 뭐야?,"차원의 저주 : 학습 데이터의 차원, 즉 feature 개수가 너무 많아서 학습에 문제가 발생하는 것",0.0
3099,test,9,이진 분류에서는 어떤 성능평가 지표가 쓰이지?,"차원의 저주의 문제점 : 계산량, 학습 시간, 메모리 사용량 증가, 성능 감소",0.0
3100,test,9,"PR-AUC, ROC-AUC 가 뭐야?",Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
3101,test,9,PR-AUC 에 대해 아주 자세히 알려줘,Decision Tree (의사결정 나무) : 학습 데이터의 feature 조건에 따라 가지치기를 하여 Tree 를 만드는 학습 방식,0.0
3102,test,9,ROC-AUC 는 뭔지 정말 궁금해,Decision Tree (의사결정 나무) 의 추론 : 입력 데이터가 주어졌을 때 학습된 조건에 따라 판단하는 것을 반복,0.0
3103,test,9,True Positive Rate 구하는 방법을 알려줘,Ensemble (앙상블) : 머신러닝에서 여러 알고리즘 또는 모델을 결합하여 학습하는 것,0.0
3104,test,9,False Positive Rate 가 뭔지 정말 궁금하다,Ensemble (앙상블) 장점 : 여러 개의 모델을 이용하여 단일 모델 이용 시보다 성능 향상,0.0
3105,test,9,Confusion Matrix (혼동 행렬) 이 뭐야?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
3106,test,9,Confusion Matrix 는 그럼 어떻게 만들어?,"Ensemble (앙상블) 방법 : Voting (보팅), Bagging (배깅), Boosting (부스팅), Stacking (스태킹)",0.0
3107,test,9,불량품 최소화해야 하면 불량이 Positive 일 때 Recall 이랑 Precision 중에 뭐가 더 좋지?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
3108,test,9,Normalization 정규화 그게 뭐야?,Voting (보팅) : 여러 모델의 예측 결과를 종합하여 최종 결론 도출,0.0
3109,test,9,정규화가 뭐지? 정말 궁금해!,"Voting (보팅) 방법 : Hard Voting (다수결 투표), Soft Voting (예측 결과 평균)",0.0
3110,test,9,Min-Max 정규화가 뭔지 잘 모르겠어,"Bagging (배깅) : 원본 데이터셋에서 랜덤 샘플링된 다수의 데이터셋을 각 모델로 학습, 해당 모델들의 결과 종합",0.0
3111,test,9,Z 스코어 정규화가 뭐야?,"Boosting (부스팅) : 랜덤 샘플링된 데이터셋 여러 개로 여러 개의 모델 학습, 직전 모델이 오답을 한 데이터의 가중치를 높여서 순차 학습",0.0
3112,test,9,Clipping? 클리핑? 그게 뭐지?,"Stacking (스태킹) : 학습 데이터의 개별 모델들의 예측값을 입력, 실제 출력값을 출력하는 메타 모델을 만들고, 메타 모델 예측값을 최종 예측값으로 사용",0.0
3113,test,9,클리핑 이거 쓸데없이 하는 거 아니야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
3114,test,9,로그 스케일링도 정규화 같은데 뭐야?,Gaussian Mixture (가우시안 혼합) : 가우시안 분포 (정규분포) 의 혼합을 통해 데이터를 근사하는 머신러닝 알고리즘,0.0
3115,test,9,Outlier 개념,"K-means Clustering : 비지도학습 방법으로, 데이터를 K개의 클러스터 (집단) 으로 나누는 방법",0.0
3116,test,9,이상치가 뭐야?,"K-means Clustering 방법 : feature space 에서 K개의 점을 임의 지정 후, 각 data point 를 가장 가까운 점에 할당 -> K개의 각 점을 매칭되는 data point 의 값으로 갱신을 수렴할 때까지 반복",0.0
3117,test,9,Outlier 없애야 되는 이유가 뭐야?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
3118,test,9,Outlier 없애려면 어떻게 해야 되지?,"kNN (k-Nearest-Neighbor) : 어떤 data point 를 분류할 때, 가장 가까운 k개의 data point 의 Class 값 중 빈도가 가장 큰 Class 로 예측",0.0
3119,test,9,PCA에 대해 알려줘,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
3120,test,9,주성분 분석?,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
3121,test,9,PCA 그거 왜 하는 건지 모르겠어,"지도학습, 비지도학습, 강화학습 : 지도학습은 입력값 및 출력값을 학습 데이터로 하며, 출력값 (label) 필요 | 비지도학습은 출력값 (label) 이 없는 방식의 학습 | 강화학습은 AI 모델이 환경에서 어떤 행동을 하고, 그 보상을 받아서 보상을 최대화하는 방식의 학습",0.0
3122,test,9,데이터가 불균형하다고? 그게 뭐지,"지도학습과 비지도학습의 차이 : 지도학습은 모델이 입력 값에 대해 특정 출력을 하도록 학습시키기 위한 출력값 (label) 이 있지만, 비지도학습은 출력값이 없음",0.0
3123,test,9,데이터 불균형 어떻게 하면 해결할 수 있지?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
3124,test,9,그러면 데이터 추가 제거해서 불균형 어떻게 해결해?,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
3125,test,9,학습 환경만 바꾸는 방법도 알려줘,"Classification (분류) 및 Regression (회귀) : Classification 문제는 대상의 Class 를 분류 (예: 개, 고양이, 뱀) 하는 것 | Regression 문제는 연속적인 숫자 값 (예: 강수량) 을 예측하는 것",0.0
3126,test,9,데이터 증강이 뭐지?,"Naïve Bayes : 확률 기반 지도학습 분류 모델 | 핵심 아이디어: 각 Class 별 (전체 데이터 중 해당 Class 의 비율) x (새로운 데이터의 각 특징 조건 별 해당 Class 의 데이터의 비율의 곱) 을 계산하고, 그 값이 가장 큰 Class 로 예측",0.0
3127,test,9,언더샘플링이랑 오버샘플링이 뭔지 궁금해,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
3128,test,9,Undersampling 에 대해서 알려줘,"SVM (Support Vector Machine) : 2개의 Class 가 있을 때, 각 Class 에 속하는 원소들과의 거리가 가장 큰 '구분선'을 찾는 방식의 지도학습 알고리즘",0.0
3129,test,9,oversampling 이 뭐지?,"K-fold Cross Validation : 학습 데이터셋을 크기가 같은 K 개의 fold 로 나누고, 각 fold 를 validation data 로, 나머지 fold 를 train data 로 하는 학습 방법",0.0
3130,test,9,데이터 불균형 생각해서 어떤 성능지표 할지 추천해 줘,K-fold Cross Validation 사용 이유 : valid data 가 부족할 때 그 양을 늘리는 효과가 있음,0.0
3131,test,9,undersampling 방법은 뭐가 있어?,"하이퍼파라미터 : 머신러닝 알고리즘을 통해 적절한 값을 찾는 것인 파라미터가 아니라, 그 알고리즘 설계 단계에서의 설정값",0.0
3132,test,9,Oversampling 하는 방법,"One-hot Encoding : 데이터셋의 각 데이터 (row) 를 특정 index 는 1, 나머지 index 는 모두 0으로 처리하는 방법",0.0
3133,test,9,차원의 저주가 뭔지 궁금해,Valid dataset 사용 이유 : 모델 학습 중 성능 평가 및 성능 개선을 위한 하이퍼파라미터 조정 등의 목적으로 사용,0.0
3134,test,9,차원의 저주는 저주인데 정확히 뭐가 문제야?,"Train dataset 순서 섞기 이유 : 딥러닝에서 batch 단위로 학습 시 각 batch 가 전체 데이터셋 특징을 반영하게 함, 데이터 순서 자체에 대한 학습 방지",0.0
3135,test,9,의사결정 나무가 뭔지 알려줘,"인공지능, 머신러닝, 딥러닝 포함 관계 : 머신러닝은 인공지능에 포함, 딥러닝은 머신러닝에 포함",0.0
3136,test,9,Decision Tree 가 뭐야?,"인공지능 정의 : 사람의 인지 능력 (학습, 추론 등) 을 컴퓨터 알고리즘으로 구현하는 기술",0.0
3137,test,9,Decision Tree 로 새로운 데이터를 어떻게 예측해?,"머신러닝 정의 : 컴퓨터 알고리즘을 통해, 데이터의 패턴을 학습하여 새로운 데이터에 대해 추론하게 하는 기술",0.0
3138,test,9,앙상블이 뭐지?,딥러닝 정의 : 사람의 두뇌를 모방한 인공신경망을 이용한 머신러닝 기술,0.0
3139,test,9,앙상블 하는 이유,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
3140,test,9,앙상블 방법,Learning Rate (학습률) : 딥러닝 모델에서 오차 역전파를 하기 위한 미분값 (기울기) 에 곱하는 배수,0.0
3141,test,9,Ensemble 정확히 어떻게 하지,"Loss Function (손실 함수) 예시 : MSE (Mean-Squared Error), Binary Cross Entropy, Categorical Cross Entropy",0.0
3142,test,9,Voting? 그게 뭐지,Overfitting (과적합) : 딥러닝 모델 학습이 과도하게 train data 에 최적화되어 오히려 성능이 떨어지는 현상,0.0
3143,test,9,앙상블 중에서 보팅 있잖아 그게 뭐야,"Overfitting (과적합) 해결 방법 : Early Stopping, Cross Validation, Batch Normalization, Dropout 등",0.0
3144,test,9,보팅 방법 구체적으로 알려줘,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
3145,test,9,배깅이뭐야,Transfer Learning (전이학습) : 이미 학습된 모델을 다른 문제에 최적화하도록 추가 학습시키는 것,0.0
3146,test,9,부스팅이 뭐지 그러면,"Activation Function (활성화 함수) : 딥러닝 신경망의 특정 층에서, 데이터의 총합을 변형하여 다음 층으로 전달하기 위한 함수",0.0
3147,test,9,Stacking 이라고 아주 복잡한 방법인 거 같은데 정확히 알려줘,Activation Function (활성화 함수) 사용 이유 : 비선형의 활성화 함수가 없으면 아무리 학습해도 선형 결합만 학습 가능,0.0
3148,test,9,가우시안 혼합? 그게 뭐야?,"CNN (합성곱 신경망) : 인간의 시각 지능을 모방한 딥러닝 알고리즘으로, 이미지 인식을 위해 주로 사용 | 핵심 가정 : 이미지에서 이웃한 픽셀의 값이 서로 비슷함",0.0
3149,test,9,Gaussian Mixture 어려운 것 같은데 뭐야?,"Large Language Model (LLM, 거대 언어 모델) : 텍스트로 주어지는 사용자의 질문에 대해 적절한 답변을 생성하는 생성형 AI 모델",0.0
