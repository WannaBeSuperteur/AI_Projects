
## ëª©ì°¨

* [1. ê°œìš”](#1-ê°œìš”)
* [2. LLM Fine-Tuning](#2-llm-fine-tuning)
* [3. S-BERT (for RAG concept)](#3-s-bert-for-rag-concept)
* [4. ì½”ë“œ ì‹¤í–‰ ë°©ë²•](#4-ì½”ë“œ-ì‹¤í–‰-ë°©ë²•)
  * [4-1. LLM Fine-Tuning](#4-1-llm-fine-tuning)
  * [4-2. RAG Concept S-BERT Fine-Tuning](#4-2-rag-concept-s-bert-fine-tuning)

## 1. ê°œìš”

**Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) ML Tutor** ì˜ ê¸°ëŠ¥ ì¤‘ **ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì•¼ Q&A** íŒŒíŠ¸ êµ¬í˜„ ë‚´ìš© ì •ë¦¬

| êµ¬ë¶„                       | ì„¤ëª…                                                                      | ë°ì´í„°ì…‹                                                                                         | êµ¬í˜„ ì½”ë“œ                     |
|--------------------------|-------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|---------------------------|
| LLM Fine-Tuning          | - RAG ì„ í†µí•´ DBì—ì„œ ì •ë³´ ì¶”ì¶œ<br>- ì´ ì •ë³´ë¥¼ ê²°í•©í•œ final input ì„ LLM ì— ì…ë ¥ í›„ LLM ë‹µë³€ ë°˜í™˜ | [ë°ì´í„°ì…‹](fine_tuning_dataset/SFT_final.csv)                                                    | [êµ¬í˜„ ì½”ë“œ ë””ë ‰í† ë¦¬](fine_tuning) |
| S-BERT (for RAG concept) | - ì‚¬ìš©ì ì§ˆë¬¸ (user question) ê³¼ DB ì— ì €ì¥ëœ ì •ë³´ì˜ ìœ ì‚¬ë„ ê³„ì‚° (RAG ëª©ì )                 | [í•™ìŠµ ë°ì´í„°ì…‹](rag_sbert/dataset/train_final.csv)<br>[í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹](rag_sbert/dataset/test_final.csv) | [êµ¬í˜„ ì½”ë“œ ë””ë ‰í† ë¦¬](rag_sbert)   |

* [ì¢…í•© ì„±ëŠ¥ ë¦¬í¬íŠ¸](comprehensive_report.md)

## 2. LLM Fine-Tuning

* LLM ì „ì²´ êµ¬ì¡°

![image](../../images/250702_1.PNG)

* ì‘ë™ ë°©ì‹
  * **1.** ì‚¬ìš©ì ì§ˆë¬¸ì„ S-BERT ëª¨ë¸ì˜ BERT + Pooling Layer ì— ì…ë ¥
  * **2.** ì‚¬ìš©ì ì§ˆë¬¸ì„ ì„ë² ë”©í•œ vector ë„ì¶œ
  * **3.** ì‚¬ìš©ì ì§ˆë¬¸ì„ ì„ë² ë”©í•œ vector ì™€ **RAG concept DB ì— ì €ì¥ëœ ê° vector ì¤‘ ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ vector** ë¥¼ ì¶”ì¶œ
  * **4.** í•´ë‹¹ **ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ vector** ì— ëŒ€ì‘ë˜ëŠ” Plain Text ë¥¼ **ì‚¬ìš©ì ì§ˆë¬¸ê³¼ concatenate**
  * **5.** ìµœì¢…ì ìœ¼ë¡œ Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) LLM ì— ì „ë‹¬
  * **6.** Oh-LoRA ğŸ‘±â€â™€ï¸ (ì˜¤ë¡œë¼) LLM ì´ ìƒì„±í•œ ë‹µë³€ì„ **ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ í‘œì‹œ**
* RAG ìœ ì‚¬ ì»¨ì…‰ DB
  * [RAG ìœ ì‚¬ ì»¨ì…‰ DB](rag_sbert/db/rag_data_text.csv)

## 3. S-BERT (for RAG concept)

* ì•„ë˜ì™€ ê°™ì´ í•™ìŠµ ë°ì´í„°ë¥¼ êµ¬ì„±í•˜ì—¬ RAG ì»¨ì…‰ì„ ìœ„í•œ [S-BERT (Sentence BERT)](https://github.com/WannaBeSuperteur/AI-study/blob/main/Natural%20Language%20Processing/Basics_BERT%2C%20SBERT%20%EB%AA%A8%EB%8D%B8.md#sbert-%EB%AA%A8%EB%8D%B8) ëª¨ë¸ í•™ìŠµ
* [í•™ìŠµ ë°ì´í„° ì›ë³¸](rag_sbert/dataset/train_final.csv)

![image](../../images/250702_2.PNG)

## 4. ì½”ë“œ ì‹¤í–‰ ë°©ë²•

ëª¨ë“  ì½”ë“œëŠ” **ë¨¼ì € LLM ëª¨ë¸ ì •ë³´ ë° ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì•ˆë‚´ (TBU) ë° í•´ë‹¹ ê° HuggingFace ë§í¬ì— ìˆëŠ” Model Card ì— ë‚˜íƒ€ë‚œ ì €ì¥ ê²½ë¡œ (Save Path) ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í›„,** ```2025_06_24_OhLoRA_v4``` (í”„ë¡œì íŠ¸ ë©”ì¸ ë””ë ‰í† ë¦¬) ì—ì„œ ì‹¤í–‰

### 4-1. LLM Fine-Tuning

ì§€ì •ëœ ê²½ë¡œì— í•´ë‹¹ LLM ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°, Fine-Tuning ëŒ€ì‹  **inference test ì‹¤í–‰ë¨**

```python ai_qna/run_fine_tuning.py```

### 4-2. RAG Concept S-BERT Fine-Tuning

ì§€ì •ëœ ê²½ë¡œì— í•´ë‹¹ S-BERT ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°, Fine-Tuning ëŒ€ì‹  **inference test ì‹¤í–‰ë¨**

```python ai_qna/run_rag_concept.py```