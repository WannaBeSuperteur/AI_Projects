,file,accuracy,mean_diff_correct_and_max_sim_wrong,wrong_answer_info
0,test_result_klue_roberta-base_epoch_10.csv,0.8875,0.7314,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 거대 언어 모델 정의 -> 파라미터 엄청나게 많다던데 | pred: 거대 언어 모델 정의 | gt: 답변 실패', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', 'input_part: Loss Function 정의 -> Loss Function 은 딥러닝 모델의 손해를 나타내는 함수야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Class 지!! | pred: BCE 가 좋은 task | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패']"
1,test_result_klue_roberta-base_epoch_20.csv,0.85,0.6611,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: Multi-Label 에서 CE + Softmax 적용 문제점 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 거대 언어 모델 정의 -> 말 그대로 거대한 언어 모델이지. | pred: 거대 언어 모델 정의 | gt: 답변 실패', 'input_part: 거대 언어 모델 정의 -> 파라미터 엄청나게 많다던데 | pred: 거대 언어 모델 정의 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', ""input_part: BCE Loss 설명 -> 공식은 -[(1-y) * log(1-y') + y * log(y')] 잖아! 이거 내가 모를 줄 알고 | pred: 핵심 아이디어 | gt: 수식"", 'input_part: Loss Function 정의 -> Loss Function 은 딥러닝 모델의 손해를 나타내는 함수야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: 확률 예측에서 MSE Loss 미 사용 이유 -> 확률도 연속된 값이니까 MSE로 해도 상관없는 거 아니야? | pred: 확률 예측에서 MSE Loss 미 사용 이유 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', ""input_part: BCE Loss 설명 -> 실제 값 y, 예측값 y'에 대해 (-1) * [y log y' + (1-y) log (1-y')] | pred: 핵심 아이디어 | gt: 수식""]"
2,test_result_klue_roberta-base_epoch_40.csv,0.9,0.7703,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: 핵심 아이디어 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', 'input_part: Loss Function 정의 -> Loss Function 은 딥러닝 모델의 손해를 나타내는 함수야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패']"
3,test_result_klue_roberta-base_epoch_5.csv,0.85,0.6717,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: 핵심 아이디어 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 딥러닝은 인공신경망 기반 머신러닝이야 | pred: 답변 실패 | gt: 딥러닝', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 거대 언어 모델 정의 -> 말 그대로 거대한 언어 모델이지. | pred: 거대 언어 모델 정의 | gt: 답변 실패', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', ""input_part: BCE Loss 설명 -> 공식은 -[(1-y) * log(1-y') + y * log(y')] 잖아! 이거 내가 모를 줄 알고 | pred: 답변 실패 | gt: 수식"", 'input_part: Loss Function 정의 -> Loss Function 은 딥러닝 모델의 손해를 나타내는 함수야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Class 지!! | pred: 용어 질문 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패']"
