,file,accuracy,mean_diff_correct_and_max_sim_wrong,wrong_answer_info
0,test_result_klue_roberta-base_epoch_10.csv,0.9,0.7828,"['input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: 거대 언어 모델 정의 -> 파라미터 엄청나게 많다던데 | pred: 거대 언어 모델 정의 | gt: 답변 실패', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: 핵심 아이디어 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험']"
1,test_result_klue_roberta-base_epoch_20.csv,0.925,0.8537,"['input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', ""input_part: BCE Loss 설명 -> 공식은 -[(1-y) * log(1-y') + y * log(y')] 잖아! 이거 내가 모를 줄 알고 | pred: 답변 실패 | gt: 수식"", 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: 수식 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험']"
2,test_result_klue_roberta-base_epoch_40.csv,0.9125,0.8155,"['input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 인공지능 나도 개발해보고 싶은데 | pred: 기본 경험 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: Multi-Label 에서 CE + Softmax 적용 문제점 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험']"
3,test_result_klue_roberta-base_epoch_5.csv,0.8875,0.7218,"['input_part: Loss Function 관련 실무 경험 -> 물체 인식에서 Loss Function 조절해서 mAP@50:95 3% 올렸다 ㅎㅎ | pred: 상세 경험 | gt: 기본 경험', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: 거대 언어 모델 정의 -> 파라미터 엄청나게 많다던데 | pred: 거대 언어 모델 정의 | gt: 답변 실패', ""input_part: BCE Loss 설명 -> 실제 값 y, 예측값 y'에 대해 (-1) * [y log y' + (1-y) log (1-y')] | pred: 핵심 아이디어 | gt: 수식"", 'input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Class 지!! | pred: 용어 질문 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험']"
