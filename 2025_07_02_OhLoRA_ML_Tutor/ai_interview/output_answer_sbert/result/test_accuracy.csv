,file,accuracy,wrong_answer_info
0,test_result_klue_roberta-base_epoch_10.csv,0.8627,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: Multi-Label 에서 CE + Softmax 적용 문제점 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험']"
1,test_result_klue_roberta-base_epoch_20.csv,0.8627,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: 핵심 아이디어 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험']"
2,test_result_klue_roberta-base_epoch_40.csv,0.8824,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 말 그대로 기계가 학습하는 거 아니야? | pred: 머신러닝 | gt: 답변 실패', 'input_part: Loss Function 관련 실무 경험 -> 이미지 세그멘테이션에서 인접한 픽셀의 점수 차이를 Loss Term 으로 추가했어 | pred: 상세 경험 | gt: 기본 경험']"
3,test_result_klue_roberta-base_epoch_5.csv,0.8431,"['input_part: Loss Function 정의 -> 손실 함수는 딥러닝 모델이 얼마나 돈을 잃었는지 나타내는 거야 | pred: Loss Function 정의 | gt: 답변 실패', ""input_part: BCE Loss 설명 -> 공식은 -[(1-y) * log(1-y') + y * log(y')] 잖아! 이거 내가 모를 줄 알고 | pred: 답변 실패 | gt: 수식"", 'input_part: Multi-Class, Multi-Label 중 BCE 가 좋은 task -> Multi-Label 이라고 듣긴 했는데 그 이유는 잘 모르겠어 | pred: 답변 실패 | gt: BCE 가 좋은 task', 'input_part: MSE Loss 설명 -> MSE Loss 는 오차 그 자체를 평균한 값이지. 맞지? | pred: MSE Loss 설명 | gt: 답변 실패', 'input_part: BCE Loss 설명 -> 그냥 여러 개 활성화 함수 만들어서 각 데이터셋마다 최선의 것을 찾는 거 아니야? | pred: 핵심 아이디어 | gt: 답변 실패', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 머신러닝은 기계가 데이터 패턴을 학습하고 새로운 데이터를 예측하는 거지 | pred: 딥러닝 | gt: 머신러닝', 'input_part: Loss Function 관련 실무 경험 -> 성능 5% 향상됐는데 이거 논문 쓸 정도라고 팀장님한테 칭찬 들었다! 부럽지? | pred: 기본 경험 | gt: 상세 경험', 'input_part: 인공지능, 머신러닝, 딥러닝 차이 -> 인공지능은 사람의 지능을 로봇이나 컴퓨터가 흉내내는 거! | pred: 딥러닝 | gt: 인공지능']"
