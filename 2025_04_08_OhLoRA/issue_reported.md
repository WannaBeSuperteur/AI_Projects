## ëª©ì°¨

* [1. ì „ì²´ ì´ìŠˆ ìš”ì•½](#1-ì „ì²´-ì´ìŠˆ-ìš”ì•½)
* [2. ì´ìŠˆ ìƒì„¸](#2-ì´ìŠˆ-ìƒì„¸)
  * [2-1. StyleGAN Fine-Tuning Tensor ìë£Œí˜• ë¶ˆì¼ì¹˜](#2-1-stylegan-fine-tuning-tensor-ìë£Œí˜•-ë¶ˆì¼ì¹˜) 
  * [2-2. StyleGAN-FineTune-v2 ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œ Memory Leak](#2-2-stylegan-finetune-v2-ì´ë¯¸ì§€-ìƒì„±-í…ŒìŠ¤íŠ¸-ì‹œ-memory-leak)
  * [2-3. LLM Fine-Tuning ì‹œ Batch size ì˜¤ë¥˜](#2-3-llm-fine-tuning-ì‹œ-batch-size-ì˜¤ë¥˜)

## 1. ì „ì²´ ì´ìŠˆ ìš”ì•½

| ì´ìŠˆ ë¶„ë¥˜    | ì´ìŠˆ                                            | ë‚ ì§œ         | ì‹¬ê°ì„±    | ìƒíƒœ    | ì›ì¸ (ë° í•´ê²° ë°©ë²•)                                                                                  | ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨í•œ í•´ê²° ë°©ë²•                                                                        |
|----------|-----------------------------------------------|------------|--------|-------|-----------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------|
| StyleGAN | Fine-tuning ì‹œ Tensor ìë£Œí˜• ë¶ˆì¼ì¹˜                  | 2025.04.12 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ | property score vector ë¥¼ Float32 ë¡œ type casting í•˜ì—¬ í•´ê²°                                          | - property score vector ë¥¼ Float64 ë¡œ type casting **(í•´ê²° ì•ˆë¨)**                           |
| StyleGAN | StyleGAN-FineTune-v2 ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œ Memory Leak | 2025.04.15 | ë³´í†µ     | í•´ê²° ì™„ë£Œ | ```with torch.no_grad()``` ì—†ì´ CUDA ì— ì˜¬ë¼ì˜¨ tensor ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±                                 |                                                                                        |
| LLM      | LLM Fine-Tuning ì‹œ Batch size ì˜¤ë¥˜               | 2025.04.21 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ | ì¸ì‹ ê°€ëŠ¥í•œ CUDA GPU ê°€ 2ëŒ€ì¸ ìƒí™©ì—ì„œ **ì‹¤ì œ batch size = (GPU ê°œìˆ˜ * ì˜ë„í•œ batch size)** ë¥¼ ì ìš©, batch size ë¶ˆì¼ì¹˜ | - ì¸ì‹ ê°€ëŠ¥í•œ CUDA GPU ì œí•œ (ì˜ëª»ëœ ì½”ë“œ ìœ„ì¹˜)<br>- LLM Training Config ì—ì„œ ```use_liger = True``` ì„¤ì • | 

## 2. ì´ìŠˆ ìƒì„¸

### 2-1. StyleGAN Fine-Tuning Tensor ìë£Œí˜• ë¶ˆì¼ì¹˜

**1. ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* StyleGAN ì—ì„œ ì¸ë¬¼ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚´ëŠ” property score ([ì°¸ê³ ](stylegan_and_segmentation/README.md#2-í•µì‹¬-ì†ì„±-ê°’)) ë²¡í„°ì¸ ```concatenated_labels``` ì˜ Tensor ë¥¼ StyleGAN Fine-Tuning ì„ ìœ„í•´ StyleGAN ì— ì…ë ¥ ì‹œ,
* StyleGAN ì—ì„œ **í•´ë‹¹ Tensor ì™€ Label Weight í–‰ë ¬ì„ matmul í•  ë•Œ ìë£Œí˜• ë¶ˆì¼ì¹˜ (double != float) ì˜¤ë¥˜ ë°œìƒ**

```
  File "C:\Users\20151\Documents\AI_Projects\2025_04_08_OhLoRA\stylegan_and_segmentation\stylegan_modified\stylegan_generator.py", line 287, in forward
    embedding = torch.matmul(label, self.label_weight)
RuntimeError: expected mat1 and mat2 to have the same dtype, but got: double != float
```

* ì¶œë ¥ ê²°ê³¼

| Tensor                                         | ì¶œë ¥ ê²°ê³¼                                                                                       |
|------------------------------------------------|---------------------------------------------------------------------------------------------|
| label (property score ë¥¼ ë‚˜íƒ€ë‚¸ ë²¡í„°)                | ```[-1.7069, -0.7809,  0.5124, -0.4403,  0.0337]], device='cuda:0', dtype=torch.float64)``` |
| self.label_weight (StyleGAN ì˜ Label Weight í–‰ë ¬) | ```[ 2.8673,  1.6306,  0.5414,  ...,  0.3971, -0.9557, -1.0875]], device='cuda:0')```       |

**2. í•´ê²° ì‹œë„ ë°©ë²•**

* 1. ```concatenated_labels``` ë¥¼ **Double** ë¡œ Type Casting
  * ì‹¤íŒ¨ (ì´ë¯¸ Float64 = Double ì„)
* 2. ```concatenated_labels``` ë¥¼ **Float32** ë¡œ Type Casting
  * ì„±ê³µ ğŸ‰

**3. êµí›ˆ**

* Float64 = Double ì„ì„ í™•ì‹¤íˆ ì•Œì•„ ë‘ì.

### 2-2. StyleGAN-FineTune-v2 ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œ Memory Leak

**1. ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* [StyleGAN-FineTune-v2](stylegan_and_segmentation/README.md#3-1-image-generation-model-stylegan) í•™ìŠµ ì¤‘ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œ, Memory Leak ë°œìƒ
* ì´ë¯¸ì§€ ìƒì„± ì½”ë“œì—ì„œ, ```with torch.no_grad()``` ì—†ì´ CUDA ì— ì˜¬ë¼ì˜¨ tensor ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆê¸° ë•Œë¬¸ì— Memory Leak ë°œìƒ

**2. í•´ê²° ì‹œë„ ë°©ë²•**

* ì´ë¯¸ì§€ ìƒì„± ì½”ë“œë¥¼ ```with torch.no_grad()``` ë¡œ ê°ìŒˆ
  * [í•´ë‹¹ commit](https://github.com/WannaBeSuperteur/AI_Projects/commit/d063afb17016a1b08b15b68102e679b8c302d109) 
  * ê²°ê³¼ : í•´ê²° ì„±ê³µ ğŸ‰ 

**3. êµí›ˆ**

* ëª¨ë¸ì˜ Train ì—†ì´ Validation ë˜ëŠ” Inference ë§Œ í•„ìš”í•œ ì‘ì—…ì—ì„œëŠ” ```with torch.no_grad()``` ë¥¼ **ë°˜ë“œì‹œ** ì‚¬ìš©í•˜ì.

### 2-3. LLM Fine-Tuning ì‹œ Batch size ì˜¤ë¥˜

**1. ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

```
Traceback (most recent call last):
  File "C:\Users\20151\Documents\AI_Projects\2025_04_08_OhLoRA\llm\unsloth_test\test_without_unsloth.py", line 78, in <module>
    trainer.train()
  File "C:\Users\20151\Documents\AI_Projects\venv\lib\site-packages\transformers\trainer.py", line 2245, in train
    return inner_training_loop(
  File "C:\Users\20151\Documents\AI_Projects\venv\lib\site-packages\transformers\trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "C:\Users\20151\Documents\AI_Projects\venv\lib\site-packages\transformers\trainer.py", line 3736, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "C:\Users\20151\Documents\AI_Projects\venv\lib\site-packages\trl\trainer\sft_trainer.py", line 490, in compute_loss
    correct_predictions = (predictions == shift_labels) & mask
RuntimeError: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0
```

* [Unsloth ì‚¬ìš© ì‹œ ì†ë„ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸](llm/README.md#4-2-unsloth-use-test) ì¤‘, **Train batch size ì™€ ì‹¤ì œ prediction ê²°ê³¼ì˜ batch size ê°€ ë§ì§€ ì•Šì•„ì„œ size error ë°œìƒ**
* ì¸ì‹ ê°€ëŠ¥í•œ CUDA GPU ```torch.cuda.device_count()``` ëŠ” 2ëŒ€ì¸ë°, LLM ì˜ Fine-Tuning ì— í•„ìš”í•œ Trainer ê°ì²´ëŠ” **ê° CUDA GPU ë³„ë¡œ Batch Size ë¥¼ ê³„ì‚°** í•˜ëŠ” ë°©ì‹
  * ì´ë¡œ ì¸í•´ ì¸ì‹ ê°€ëŠ¥í•œ CUDA GPUê°€ 2ëŒ€ì´ë©´, **ì˜ë„í•œ batch size ê°€ 2 ì¼ ë•Œ (ì‹¤ì œ train batch size) = 2 * 2 = 4** ê°€ ë˜ê¸° ë•Œë¬¸ì— í¬ê¸°ê°€ ë§ì§€ ì•ŠëŠ” ì˜¤ë¥˜ ë°œìƒ

**2. í•´ê²° ì‹œë„ ë°©ë²•**

* ```os.environ["CUDA_VISIBLE_DEVICES"] = "0"``` ì„ ```test_without_unsloth.py``` ì˜ ìƒë‹¨ì— ì¶”ê°€
  * **ë°©ë²•ì€ ë§ì§€ë§Œ, ì½”ë“œ ìœ„ì¹˜ê°€ ì˜ëª»ë¨**  
  * ì¸ì‹ ê°€ëŠ¥í•œ GPU ëŠ” ì—¬ì „íˆ 2ëŒ€
  * ë”°ë¼ì„œ ì—¬ì „íˆ train batch size = 4 ì´ë©°, ì˜¤ë¥˜ ë°œìƒ
* ```use_liger=True``` ê°•ì œ ì„¤ì •
  * ì´ë ‡ê²Œ í•˜ë©´ trl ë¼ì´ë¸ŒëŸ¬ë¦¬ ì½”ë“œ êµ¬ì¡°ìƒ í•´ë‹¹ ì˜¤ë¥˜ë¥¼ íšŒí”¼ ê°€ëŠ¥
  * âŒ ê·¼ë³¸ì ì¸ í•´ê²° ë°©ë²•ì´ ì•„ë‹˜
  * âŒ ì•„ë˜ì™€ ê°™ì´ **CUDA OOM** ë°œìƒ

```
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 10.90 GiB is allocated by PyTorch, and 518.10 MiB is reserved by 
PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```

* ```os.environ["CUDA_VISIBLE_DEVICES"] = "0"``` ì„ ```test_unsloth_common.py``` ì˜ ìƒë‹¨ì— ì¶”ê°€
  * ğŸ‰ ì´ ë°©ë²•ìœ¼ë¡œ **í•´ê²° ì„±ê³µ**
  * ì¸ì‹ ê°€ëŠ¥í•œ GPU ë¥¼ **1ëŒ€ë¡œ ì œí•œí•˜ëŠ” ì˜¬ë°”ë¥¸ ë°©ë²•ì´ì ê·¼ë³¸ì ì¸ í•´ê²°ì±…**
  * **ë°©ë²•ê³¼ ì½”ë“œ ìœ„ì¹˜ê°€ ëª¨ë‘ ì•Œë§ìŒ**
    * train batch size ê°€ 4 ê°€ ë˜ëŠ” ì›ì¸ì€ training argument (SFTConfig) ì— ìˆìŒ
    * training argument ëŠ” ```test_without_unsloth.py``` ì˜ ìµœìƒë‹¨ì—ì„œ ```from test_unsloth_common import ...``` í•  ë•Œ ì´ë¯¸ ì •ì˜ê°€ ì™„ë£Œë˜ë¯€ë¡œ, ìœ„ **ì˜ëª»ëœ ìœ„ì¹˜** ì˜ ê²½ìš°ëŠ” ì¸ì‹ ê°€ëŠ¥í•œ GPU ëŒ€ìˆ˜ ì œí•œ ì„¤ì •ì´ **ì´ë¯¸ ëŠ¦ì€ ê²ƒì„**
  * ì°¸ê³ 
    * ì‹¤ì œ transformers==4.51.3 ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œì˜ ```train_batch_size``` ê°’ ê²°ì • ì½”ë“œ
    * ```training_args.py``` Line 2286
      * ```self._n_gpu = torch.cuda.device_count()```
    * ```training_args.py``` Line 2137
      * ```train_batch_size = per_device_batch_size * max(1, self.n_gpu)```