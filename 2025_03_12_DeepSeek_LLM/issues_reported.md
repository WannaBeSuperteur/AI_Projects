# í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ì´ìŠˆ ë° í•´ê²° ë°©ë²•

## ëª©ì°¨

* [1. **```flash_attn``` ì‹¤í–‰ ë¶ˆê°€ (í•´ê²° ë³´ë¥˜)**](#1-flashattn-ì‹¤í–‰-ë¶ˆê°€-í•´ê²°-ë³´ë¥˜)
* [2. LLM ì¶œë ¥ì´ ë§¤ë²ˆ ë™ì¼í•¨ (í•´ê²° ì™„ë£Œ)](#2-llm-ì¶œë ¥ì´-ë§¤ë²ˆ-ë™ì¼í•¨-í•´ê²°-ì™„ë£Œ)
* [3. ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ over-write (í•´ê²° ì™„ë£Œ)](#3-ë‹¤ì´ì–´ê·¸ë¨-ì´ë¯¸ì§€-over-write-í•´ê²°-ì™„ë£Œ)
* [4. CUBLAS_STATUS_NOT_SUPPORTED (í•´ê²° ì™„ë£Œ)](#4-cublas_status_not_supported-í•´ê²°-ì™„ë£Œ)
* [5. SFT ì¤‘ CUDA error: unknown error (í•´ê²° ì™„ë£Œ)](#5-sft-ì¤‘-cuda-error-unknown-error-í•´ê²°-ì™„ë£Œ)
* [6. **Fine-Tuning ëœ ëª¨ë¸ ì¶”ë¡  ì†ë„ ì €í•˜ (í•´ê²° ë³´ë¥˜)**](#6-fine-tuning-ëœ-ëª¨ë¸-ì¶”ë¡ -ì†ë„-ì €í•˜-í•´ê²°-ë³´ë¥˜)
* [7. ORPO í•™ìŠµ ì¤‘ ê²½ê³  ë©”ì‹œì§€ ë° ì˜¤ë¥˜ (í•´ê²° ì™„ë£Œ)](#7-orpo-í•™ìŠµ-ì¤‘-ê²½ê³ -ë©”ì‹œì§€-ë°-ì˜¤ë¥˜-í•´ê²°-ì™„ë£Œ)
* [8. **ORPO í•™ìŠµ ì‹œ CUDA Out of memory (í•´ê²° ì‹¤íŒ¨)**](#8-orpo-í•™ìŠµ-ì‹œ-cuda-out-of-memory-í•´ê²°-ì‹¤íŒ¨)
* [9. CNN í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)](#9-cnn-í•™ìŠµì´-ì‹¤ì§ˆì ìœ¼ë¡œ-ì•ˆ-ë¨-í•´ê²°-ì™„ë£Œ)
* [10. Auto-Encoder í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)](#10-auto-encoder-í•™ìŠµì´-ì‹¤ì§ˆì ìœ¼ë¡œ-ì•ˆ-ë¨-í•´ê²°-ì™„ë£Œ)

## ì´ìŠˆ ìš”ì•½

**ì´ìŠˆ ìš”ì•½**

| ì´ìŠˆ ë¶„ë¥˜        | ì´ìŠˆ                                                                                                                                                    | ë‚ ì§œ         | ì‹¬ê°ì„±    | ìƒíƒœ        | ì›ì¸ (ë° í•´ê²° ë°©ë²•)                                              | ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨í•œ í•´ê²° ë°©ë²•                                                                                                                                                                                                                                                           |
|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|------------|--------|-----------|-----------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| LLM          | ```flash_attn``` ì‚¬ìš© ë¶ˆê°€                                                                                                                                | 2025.03.14 | ë‚®ìŒ     | ë³´ë¥˜        | ```nvcc -V``` ê¸°ì¤€ì˜ CUDA ë²„ì „ ì´ìŠˆ                              | - Windows í™˜ê²½ ë³€ìˆ˜ í¸ì§‘ **(í•´ê²° ì•ˆë¨)**<br>- flash_attn ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì´ì „ ë²„ì „ ì„¤ì¹˜ **(ì‹¤íŒ¨)**<br>- Visual C++ 14.0 ì„¤ì¹˜ **(ì‹¤íŒ¨)**                                                                                                                                                                  |
| LLM          | LLM ì¶œë ¥ì´ ë§¤ë²ˆ ë™ì¼í•¨                                                                                                                                        | 2025.03.15 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | ```llm.generate()``` í•¨ìˆ˜ì˜ ëœë¤ ìƒì„± ì¸ìˆ˜ ì„¤ì • ëˆ„ë½                   | - ```torch.manual_seed()``` ì„¤ì • **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                                                                                |
| êµ¬í˜„           | ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ê°€ overwrite ë¨                                                                                                                                | 2025.03.18 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | í…ìŠ¤íŠ¸ íŒŒì‹± ë° ë„í˜• ê·¸ë¦¬ê¸° ì•Œê³ ë¦¬ì¦˜ì˜ **êµ¬í˜„ìƒ ì´ìŠˆ**                          | - ì¼ì • ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± **(í•´ê²° ì•ˆë¨)**<br>- ```canvas.copy()``` ì´ìš© **(í•´ê²° ì•ˆë¨)**<br>- garbage collection ì´ìš© **(í•´ê²° ì•ˆë¨)**                                                                                                                                                          |
| LLM - SFT    | ```CUBLAS_STATUS_NOT_SUPPORTED``` (SFT í•™ìŠµ ì¤‘ ì˜¤ë¥˜)                                                                                                       | 2025.03.20 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ     | pre-trained LLM ì„ ê°€ì ¸ì˜¬ ë•Œ ìë£Œí˜•ì´ ```bfloat16``` ì„             | - batch size ì„¤ì •                                                                                                                                                                                                                                                           |
| LLM - SFT    | SFT ì¤‘ CUDA error: unknown error                                                                                                                       | 2025.03.20 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ     | í° batch size ì— ë”°ë¥¸ Out-of-memory                           | - ```CUDA_LAUNCH_BLOCKING=1``` ì„¤ì • **(í•´ê²° ì•ˆë¨)**<br> - ```TORCH_USE_CUDA_DSA=1``` ì„¤ì • **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                             |           |
| LLM          | Fine-Tuning ëœ ëª¨ë¸ ì¶”ë¡  ì†ë„ ì €í•˜                                                                                                                             | 2025.03.22 | ë³´í†µ     | ë³´ë¥˜        | í™˜ê²½ ì œì•½ & task íŠ¹ì„± (ì¶”ì •)                                      | - Auto-GPTQ ì‚¬ìš© **(í•´ê²° ì•ˆë¨)**<br>- ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© **(ì‹¤íŒ¨)**<br>- LLM ê´€ë ¨ ì„¤ì •ê°’ ë³€ê²½ **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                                       |
| LLM - ORPO   | ORPO í•™ìŠµ ì¤‘ ê²½ê³  ë° ì˜¤ë¥˜<br>- ```Trainer.tokenizer is now deprecated.``` ê²½ê³  ë©”ì‹œì§€<br>- ```AttributeError: 'generator' object has no attribute 'generate'``` ì˜¤ë¥˜ | 2025.03.23 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ     | transformers, trl ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ ì•ˆë¨ â†’ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ê·¸ë ˆì´ë“œ | - trl ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ê·¸ë ˆì´ë“œ **(ì‹¤íŒ¨)**                                                                                                                                                                                                                                                |
| LLM - ORPO   | ORPO í•™ìŠµ ì‹œ Out of memory                                                                                                                               | 2025.03.23 | **ì‹¬ê°** | **í•´ê²° ì‹¤íŒ¨** | CUDA Out of memory                                        | - ```prepare_model_for_kbit_training``` ì„ ì´ìš©í•œ ì–‘ìí™” ì‹œë„ **(í•´ê²° ì•ˆë¨)**<br> - 8bitì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ AdamW Optimizer ì‚¬ìš© **(í•´ê²° ì•ˆë¨)**<br>- Unsloth ì„¤ì¹˜ **(ì‹¤íŒ¨)**                                                                                                                             |
| CNN          | CNN í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨                                                                                                                                     | 2025.03.23 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ ë¶€ë¶„ì— ëŒ€í•œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì •ë³´ê°€ ì˜¤íˆë ¤ í•™ìŠµì„ ë°©í•´ (ì¶”ì •)               | - í™œì„±í™” í•¨ìˆ˜ ìˆ˜ì • **(í•´ê²° ì•ˆë¨)**<br>- ì´ë¯¸ì§€ í¬ê¸° í™•ëŒ€ **(í•´ê²° ì•ˆë¨)**<br>- ì´ë¯¸ì§€ ìƒ‰ìƒ ë³€í™˜ (ì „ì²˜ë¦¬) **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                                       |
| Auto-Encoder | Auto-Encoder í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨                                                                                                                            | 2025.03.25 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | ë°ì´í„°ì…‹ íŠ¹ì„±ìœ¼ë¡œ ì¶”ì •í•˜ë‚˜, ëª…í™•í•˜ì§€ ì•ŠìŒ                                   | - Fully-Connected Layer ì˜ [Dropout](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Overfitting_Dropout.md#3-dropout) ì œê±° **(í•´ê²° ì•ˆë¨)**<br>- Conv, DeConv ë ˆì´ì–´ 4ê°œ â†’ 3ê°œ **(í•´ê²° ì•ˆë¨)** |

## 1. ```flash_attn``` ì‹¤í–‰ ë¶ˆê°€ (í•´ê²° ë³´ë¥˜)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* [LLM í›„ë³´ ëª¨ë¸](test/README.md#2-2-í›„ë³´-ëª¨ë¸-ì„ ì •) ì¤‘ ì¼ë¶€ë¥¼ ì–‘ìí™”í•˜ì§€ ì•Šê³  ì‹¤í–‰ ì‹œ, ```flash_attn``` (Flash Attention) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í•„ìš”ë¡œ í•¨
* í•´ë‹¹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ CUDA ë²„ì „ ì´ìŠˆ (```nvcc -V``` ë¡œ í™•ì¸ë˜ëŠ” ë²„ì „ ê¸°ì¤€ CUDA 11.7 ì´ìƒì—ì„œë§Œ ì„¤ì¹˜ ê°€ëŠ¥) ë¡œ ì¸í•´ ì„¤ì¹˜ ì•ˆë¨

**í•´ê²° ë³´ë¥˜ ì‚¬ìœ **

* ```flash_attn``` ì˜¤ë¥˜ëŠ” Local í™˜ê²½ì´ ì•„ë‹Œ Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì‹œ ë°œìƒí•˜ì§€ ì•ŠìŒ
* Flash Attention ì„ ìš”êµ¬í•˜ëŠ” LLM (DeepSeek-V2 ë“±) ì€ ëª¨ë‘ Auto-[GPTQ](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Quantization.md#2-4-gptq-post-training-quantization-for-gpt-models) (ì–‘ìí™” ë°©ë²•) Not Supported ì¸ í° ëª¨ë¸ì„
  * ì´ëŠ” Local í™˜ê²½ì—ì„œëŠ” GPTQë¥¼ ì´ìš©í•œ ì–‘ìí™” ìì²´ê°€ ì–´ë ¤ìš°ë©°, ë”°ë¼ì„œ **í° ê·œëª¨ë¡œ ì¸í•œ OOMì„ í•´ê²°í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì—, ```flash_attn``` ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ì‚¬ìš© ìì²´ê°€ ì–´ë ¤ìš´ ëª¨ë¸**ì„ì„ ì˜ë¯¸í•¨.  
  * ì˜¤ë¥˜ ë©”ì‹œì§€ : ```deepseek_v2 isn't supported yet.``` 
* í•´ë‹¹ ë¬¸ì œ í•´ê²° ì—†ì´ë„ [Supervised Fine-Tuning](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_SFT.md) ì˜ ì„  ì§„í–‰ì„ í†µí•´ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ë³´ì¼ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ëŠ” ëª¨ë¸ ì¡´ì¬

**í•´ê²° ì‹œë„ ë°©ë²• (ëª¨ë‘ ì‹¤íŒ¨, í•´ê²° ë³´ë¥˜ ì¤‘)**

* **1. Windows í™˜ê²½ ë³€ìˆ˜ í¸ì§‘**
  * ```CUDA_PATH``` í™˜ê²½ ë³€ìˆ˜ë¥¼ í˜„ì¬ ì„¤ì¹˜ëœ 11.7 ì´ìƒì˜ CUDA ë²„ì „ìœ¼ë¡œ ê°±ì‹ 
  * ```PATH``` ì˜ ```CUDA\bin``` ë¶€ë¶„ì„ í˜„ì¬ ì„¤ì¹˜ëœ 11.7 ì´ìƒì˜ CUDA ë²„ì „ìœ¼ë¡œ ê°±ì‹ 
  * ê²°ê³¼
    * ```nvcc -V``` ë¡œ í™•ì¸ë˜ëŠ” ë²„ì „ì€ CUDA 11.7 ì´ìƒìœ¼ë¡œ ì˜¬ë¼ê°
    * ```pip install flash_attn``` ì„¤ì¹˜ ì‹œë„ ì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ
      * ```ERROR: Failed to build installable wheels for some pyproject.toml based projects (flash_attn)``` 

* **2. flash_attn ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì´ì „ ë²„ì „ ì„¤ì¹˜**
  * ```pip install flash_attn==2.5.7``` ì‹œë„ [(ì°¸ê³ )](https://github.com/Dao-AILab/flash-attention/issues/224)
  * ê²°ê³¼
    * ```error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/``` ì˜¤ë¥˜ ë°œìƒ

* **3. Visual C++ 14.0 ì„¤ì¹˜**
  * [ì„¤ì¹˜ ë§í¬](https://visualstudio.microsoft.com/ko/downloads/) ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ
  * ì„¤ì¹˜ í”„ë¡œê·¸ë¨ì—ì„œ "C++ë¥¼ ì‚¬ìš©í•œ ë°ìŠ¤í¬í†± ê°œë°œ" ì²´í¬ í›„ ì„¤ì¹˜
  * ```pip install flash_attn``` ì‹¤í–‰ ì‹œë„ ê²°ê³¼
    * ```C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.2\include\crt/host_config.h(157): fatal error C1189: #error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2022 (inclusive) are supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk. error: command 'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\bin\\nvcc.exe' failed: Error``` ì˜¤ë¥˜ ë°œìƒ
  * Visual Studio Build Tools ì—ì„œ ë™ì¼í•˜ê²Œ ì‹¤í–‰ ì‹œë„ ê²°ê³¼ 
    * ```pip install flash_attn==2.5.7```
      * ì‹¤íŒ¨
      * ```urllib.error.HTTPError: HTTP Error 404: Not Found```
    * ```pip install flash_attn==2.3.3```
      * ì‹¤íŒ¨
      * ```urllib.error.HTTPError: HTTP Error 404: Not Found```
    * ```pip install flash_attn==2.3.6```
      * ì‹¤íŒ¨
      * ```urllib.error.HTTPError: HTTP Error 404: Not Found```
    * ```pip install https://github.com/oobabooga/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu122torch2.4.0cxx11abiFALSE-cp311-cp311-win_amd64.whl```
      * ì‹¤íŒ¨
      * ```ERROR: flash_attn-2.6.3+cu122torch2.4.0cxx11abiFALSE-cp311-cp311-win_amd64.whl is not a supported wheel on this platform.```

## 2. LLM ì¶œë ¥ì´ ë§¤ë²ˆ ë™ì¼í•¨ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ LLM ì´ ìƒì„±í•˜ëŠ” ë‹µë³€ì´ ë§¤ë²ˆ ë™ì¼í•¨
* LLM ì„ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ```generate()``` í•¨ìˆ˜ì˜ ```do_sample=True``` ëˆ„ë½ì´ ì›ì¸

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. torch.manual_seed() ì„¤ì • (ì‹¤íŒ¨)**
  * ë§¤ë²ˆ ìƒì„± ì‹œë„í•  ë•Œë§ˆë‹¤, ```seed``` ì˜ ê°’ì„ 1ì”© ì¦ê°€ì‹œí‚¨ í›„ ```torch.manual_seed(seed)``` ë¥¼ ì ìš©í•˜ì—¬ seed ê°’ ì—…ë°ì´íŠ¸
  * ê²°ê³¼: í•´ê²° ì•ˆë¨

* **2. LLM ì„ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ```generate()``` í•¨ìˆ˜ ìˆ˜ì •**
  * í•´ë‹¹ í•¨ìˆ˜ì— ëŒ€í•´ ëœë¤í•˜ê²Œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì•„ë˜ì™€ ê°™ì´ ```do_sample=True``` ë¥¼ ì¶”ê°€
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²° ì„±ê³µğŸ‰

```python
with torch.no_grad():
    outputs = llm.generate(**inputs,
                           max_length=768,
                           do_sample=True)  # ëœë¤ ì¶œë ¥ (ì—¬ê¸°ì„œë¶€í„° ëœë¤ ì¶œë ¥ ìƒì„±ë˜ê²Œ í•˜ê¸° ìœ„í•¨)
```

## 3. ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ over-write (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* [ë‹¤ì´ì–´ê·¸ë¨ ì‘ì„± ì½”ë“œì¸ draw_diagram.py](draw_diagram/draw_diagram.py) ì˜ ```generate_diagram_from_lines``` í•¨ìˆ˜ë¥¼ í†µí•´ ì´ë¯¸ì§€ ë°˜ë³µ ìƒì„± ì‹œ,
* ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ **NumPy array (canvas) ë¥¼ ë§¤ ìƒì„± ì‹œë§ˆë‹¤ ì´ˆê¸°í™”í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³  overwrite** ë¨
* ë„í˜• ê·¸ë¦¬ê¸° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ìƒì˜ ì˜¤ë¥˜ê°€ ì›ì¸

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. ì¼ì • ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (í•´ê²° ì•ˆë¨)**
  * ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì‹œë§ˆë‹¤ 0.35 ì´ˆì˜ ê°„ê²©ì„ ë‘ê³  ìƒì„±í•˜ë„ë¡ interval ì§€ì •
    * ```time.sleep(0.35)  # to prevent image overwriting``` ë¥¼ ì´ìš©
  * ê·¼ë³¸ì ì¸ í•´ê²° ë°©ë²•ì€ ì•„ë‹ˆë¼ê³  íŒë‹¨ë¨

* **2. ```canvas.copy()``` ì´ìš© (í•´ê²° ì•ˆë¨)**
  * canvas ë¥¼ ì´ˆê¸°í™”í•´ë„ OpenCV ì— ì´ì „ì˜ ë©”ëª¨ë¦¬ê°€ ë‚¨ì•„ ìˆì„ ìˆ˜ ìˆìŒ
  * ë”°ë¼ì„œ, ì´ë¥¼ **ì›ë³¸ì´ ì•„ë‹Œ ë³µì‚¬ëœ canvas ì— ë„í˜•ì„ ê·¸ë¦¬ëŠ”** ë°©ì‹ìœ¼ë¡œ í•´ê²° ì‹œë„
  * ì½”ë“œ

```
canvas = np.ones((HEIGHT, WIDTH, 3), dtype=np.uint8) * 255
canvas = canvas.copy()
```

* **3. garbage collection (í•´ê²° ì•ˆë¨)**
  * OpenCVì˜ í•´ë‹¹ ë©”ëª¨ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•œ ë°©ë²•ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ garbage collection ì‹¤ì‹œ 
  * ì½”ë“œ 

```
del canvas
gc.collect()
```

* **4. êµ¬í˜„ìƒì˜ ì˜¤ë¥˜ í•´ê²°**
  * í…ìŠ¤íŠ¸ íŒŒì‹± ë° ë„í˜• ê·¸ë¦¬ê¸° ì•Œê³ ë¦¬ì¦˜ì˜ **êµ¬í˜„ìƒ ì´ìŠˆ** ë¡œ íŒë‹¨í•˜ì—¬ ì´ë¥¼ í•´ê²°
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²° ì„±ê³µğŸ‰

## 4. CUBLAS_STATUS_NOT_SUPPORTED (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* LLMì˜ Supervised Fine-tuning (SFT) í•™ìŠµ ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ
  * ```RuntimeError: CUDA error: CUBLAS_STATUS_NOT_SUPPORTED when calling `cublasGemmStridedBatchedEx(handle, opa, opb, (int)m, (int)n, (int)k, (void*)&falpha, a, CUDA_R_16BF, (int)lda, stridea, b, CUDA_R_16BF, (int)ldb, strideb, (void*)&fbeta, c, CUDA_R_16BF, (int)ldc, stridec, (int)num_batches, compute_type, CUBLAS_GEMM_DEFAULT_TENSOR_OP)```
* ì›ì¸ : Pre-trained LLM ì„ ê°€ì ¸ì˜¬ ë•Œ, ```torch.dtype = bfloat16``` ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í•´ë‹¹ ì˜¤ë¥˜ ë°œìƒ

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. batch size ë³€ê²½ (í•´ê²° ì•ˆë¨)**
  * ```training_args``` ì— ë‹¤ìŒì„ ì¶”ê°€
    * ```per_device_train_batch_size=4,  # batch size per device during training```
    * ```per_device_eval_batch_size=4  # batch size per device during validation```
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²°ë˜ì§€ ì•ŠìŒ

* **2. bfloat16 ì„ float16 ìœ¼ë¡œ ë³€ê²½**
  * LLM ì„ ê°€ì ¸ì˜¬ ë•Œ ```bfloat16``` ìë£Œí˜•ì„ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— í•´ë‹¹ ì˜¤ë¥˜ ë°œìƒ, ```float16``` ìœ¼ë¡œ ìˆ˜ì •
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²° ì„±ê³µğŸ‰

```python
original_llm = AutoModelForCausalLM.from_pretrained(model_path,
                                                    torch_dtype=torch.float16).cuda()
```

## 5. SFT ì¤‘ CUDA error: unknown error (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™©**

* SFT ì‹¤í–‰ ì¤‘ ì•½ 30ë¶„ í›„ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ

```
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: the launch timed out and was terminated
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                                       | 30/280 [28:16<3:55:40, 56.56s/it]
```

![image](../images/250312_5.PNG)

* ```gradient_checkpointing``` (ê°€ì¤‘ì¹˜ë¥¼ ë©”ëª¨ë¦¬ì— ì¼ë¶€ë§Œ ì €ì¥í•˜ëŠ” ë°©ì‹) ì„ í•˜ì§€ ì•Šì„ ë•ŒëŠ” **í•™ìŠµ ì‹œì‘ ì§í›„** ë‹¤ìŒê³¼ ê°™ì´ **CUBLAS_STATUS_EXECUTION_FAILED** ì˜¤ë¥˜ ë°œìƒ

```
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\transformers\models\llama\modeling_llama.py", line 258, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\modules\linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DEFAULT_TENSOR_OP)`
  0%|                                                                                                                                                                                                      | 0/280 [00:09<?, ?it/s]
```

**ë¬¸ì œ ì›ì¸**

* **í° batch size ë¡œ ì¸í•œ GPU ë©”ëª¨ë¦¬ ì´ˆê³¼ë¡œ ì¶”ì •**
* Gradient Checkpointing ë¯¸ ì ìš© ì‹œ, **batch size 4 ë¡œë„ GPU ë©”ëª¨ë¦¬ (12GB) ë¥¼ ì´ˆê³¼** í•˜ê²Œ ë¨

![image](../images/250312_6.PNG)

* Out of memory ëŒ€ì‹  ```CUBLAS_STATUS_EXECUTION_FAILED``` ê°€ ë°œìƒí•˜ëŠ” ì´ìœ ëŠ” ë¶ˆëª…
* Gradient Checkpointing ê³¼ì˜ ì—°ê´€ì„± (ì¶”ì •)
  * **Gradient Checkpointing ì„ í•˜ëŠ” ê²½ìš°, ì´ë¡œ ì¸í•´ ë©”ëª¨ë¦¬ê°€ ì ˆì•½ë¨**
  * ì´ë¡œ ì¸í•´ Gradient Checkpointing ì—†ì´ í•™ìŠµí•  ë•Œ batch size 4 ì—ì„œ ë°”ë¡œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, batch size 4 ë¡œë„ 30ë¶„ ë™ì•ˆì€ í•™ìŠµ ì§„í–‰ ê°€ëŠ¥
  * ê·¸ëŸ¬ë‹¤ 30ë¶„ ì •ë„ ì‹œì ì—ì„œ ë©”ëª¨ë¦¬ ì´ˆê³¼ê°€ ë°œìƒí•˜ì—¬ í•™ìŠµì´ ê°•ì œ ì¤‘ì§€ë¨ 

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. ```CUDA_LAUNCH_BLOCKING=1``` ì„¤ì • (í•´ê²° ì•ˆë¨)**
  * ```fine_tuning/sft_fine_tuning.py``` ì˜ ìƒë‹¨ì— ë‹¤ìŒ ì„¤ì • ì¶”ê°€
    * ```os.environ['CUDA_LAUNCH_BLOCKING'] = "1"``` 
  * ê²°ê³¼: í•´ê²° ì•ˆë¨

```
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: unknown error
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                                                                    | 34/280 [33:23<4:01:37, 58.93s/it]
```

* **2. ```TORCH_USE_CUDA_DSA=1``` ì„¤ì • (í•´ê²° ì•ˆë¨)**
  * ```fine_tuning/sft_fine_tuning.py``` ì˜ ìƒë‹¨ì— ë‹¤ìŒ ì„¤ì • ì¶”ê°€
    * ```os.environ["TORCH_USE_CUDA_DSA"] = '1'``` 
  * ê²°ê³¼: í•´ê²° ì•ˆë¨

```
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: unknown error
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                                                                    | 34/280 [32:00<3:51:33, 56.48s/it]
```

* **3. LLM í•™ìŠµ ì‹œ, batch size ê°ì†Œ (4 â†’ 1 or 2)** 
  * ê²°ê³¼
    * Gradient Checkpointing ì ìš© ì‹œ, batch size 2 ì—ì„œ í•™ìŠµ ì •ìƒ ì¢…ë£Œ
    * [ìƒì„¸ í•™ìŠµ ë¡œê·¸](fine_tuning/log/log_train_sft_batch_size_2)
  * ìƒì„¸ ì½”ë“œ

```python
    training_args = SFTConfig(
        learning_rate=0.0002,  # lower learning rate is recommended for fine tuning
        num_train_epochs=2,
        logging_steps=1,  # logging frequency
#        gradient_checkpointing=True,
        output_dir=output_dir,
        save_total_limit=3,  # max checkpoint count to save
        per_device_train_batch_size=1,  # batch size per device during training
        per_device_eval_batch_size=1  # batch size per device during validation
    )
```

## 6. Fine-Tuning ëœ ëª¨ë¸ ì¶”ë¡  ì†ë„ ì €í•˜ (í•´ê²° ë³´ë¥˜)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* LLM Fine Tuning í›„, Diagram 1ê°œë¥¼ ìƒì„±í•˜ëŠ” ë° 3ë¶„ ì´ìƒ ì†Œìš”
* ë³¸ í”„ë¡œì íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì œí’ˆì´ë¼ê³  í•˜ë©´, ì œí’ˆì„ ì‚¬ìš©í•˜ëŠ” ìœ ì € ì…ì¥ì—ì„œ ì¢‹ì€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ê¸° ì–´ë ¤ìš´ ìƒí™©

**í•´ê²° ë³´ë¥˜ ì‚¬ìœ **

* GPU ì„±ëŠ¥ ì œì•½, Windows 10 OS ì—ì„œì˜ vLLM ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ë¶ˆê°€ ë“± í™˜ê²½ì  ì œì•½ì„ í”„ë¡œì íŠ¸ ì¼ì • ë‚´ì— ê·¹ë³µí•˜ê¸° ì–´ë µë‹¤ê³  íŒë‹¨
* task ì˜ íŠ¹ì„±ìƒ response ì˜ token ê°œìˆ˜ê°€ 1000ê°œ ì´ìƒìœ¼ë¡œ ë§ì´ í•„ìš”í•˜ê³ , ì´ë¡œ ì¸í•´ ê¸´ ì‹œê°„ì´ ì†Œìš”ë¨. ì¦‰ **ê¸´ ì‹œê°„ ì†Œìš”ëŠ” task ì˜ íŠ¹ì„±ì´ë¼ëŠ” ê·¼ë³¸ì ì¸ ì´ìœ  ë•Œë¬¸ì„**

**í•´ê²° ì‹œë„í•œ ë°©ë²•**

* Auto-GPTQ ì‚¬ìš© **(ì†ë„ í–¥ìƒ ì•ˆë¨)**
  * [ê¸°ì¡´ ëª¨ë¸ì˜ GPTQ ì ìš©ëœ ë²„ì „](https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GPTQ) ì„ ì´ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì‹œë„ ìì²´ëŠ” ì„±ê³µí–ˆìœ¼ë‚˜, **í•™ìŠµ ë° ì¶”ë¡  ì†ë„ í–¥ìƒì´ ì²´ê°ë˜ì§€ ì•ŠìŒ**
  * [ê¸°ì¡´ ëª¨ë¸ì˜ GPTQ ì ìš©ëœ ë²„ì „](https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GPTQ) ì ìš© ì‹œ,
    * ì ìš© ìì²´ëŠ” **ì„±ê³µ**
    * GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†ŒëŠ” ì²´ê°ë˜ì§€ë§Œ, **í•™ìŠµ/ì¶”ë¡  ì†ë„ ê°œì„ ì€ ì²´ê° ì•ˆë¨**
    * ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê°ì†Œë¡œ, ì‹¤ì œ ìœ ì € ì‚¬ìš© ì‹œ ì„±ëŠ¥ ì €í•˜ ìš°ë ¤
    * ì¶”ë¡  ì†ë„ê°€ **ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ë„ ì˜¤íˆë ¤ ëŠë¦°** ê²ƒìœ¼ë¡œ ì˜ì‹¬
  * [ìƒì„¸ ì‹œë„ ê¸°ë¡](fine_tuning/log/log_try_apply_GPTQ.md) 
* ëª¨ë¸ ìƒì„± ê³¼ì •ì—ì„œì˜ num_return_sequences (ìƒì„±í•˜ëŠ” answer ì˜ ê°œìˆ˜) ìˆ˜ì • **(ì†ë„ í–¥ìƒ ë¶ˆê°€)**
  * ê¸°ë³¸ê°’ì´ '1'ì´ê¸° ë•Œë¬¸ 
* vLLM ì‚¬ìš© **(í˜„ì¬ Linux ì—ì„œë§Œ ì§€ì›, Windows ì—ì„œ ì§€ì› ì•ˆë¨)**
* LoRA Config ì—ì„œ ```inference mode = True``` ì ìš© **(ì†ë„ í–¥ìƒ ì•ˆë¨)**

```python
def load_sft_llm():
    print('loading LLM ...')

    try:
        model = AutoModelForCausalLM.from_pretrained("sft_model").cuda()

        lora_config = LoraConfig(
            r=16,  # Rank of LoRA
            lora_alpha=16,
            lora_dropout=0.05,  # Dropout for LoRA
            init_lora_weights="gaussian",  # LoRA weight initialization
            inference_mode=True,
            target_modules=['q_proj', 'v_proj', 'k_proj', 'o_proj']
        )
        model = get_peft_model(model, lora_config)
```

* ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© **(ì‹¤íŒ¨)**
  * [Intel Extension (streamer ë„ ê°™ì´ ì ìš©)](https://discuss.pytorch.kr/t/transformer-intel-extension/2997)

```
FAILED:  No module named 'neural_compressor.conf'
```

* ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ streamer ë§Œ ì‚¬ìš© **(ì†ë„ í–¥ìƒ ì•ˆë¨)**
  * ëª¨ë¸ ì¶œë ¥ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ëŠ” íš¨ê³¼ë§Œ ìˆìŒ
* ê¸°íƒ€ ë°©ë²•ë“¤ **(```model.eval()``` ì—ì„œ 5% ì •ë„ ì†ë„ í–¥ìƒ ì¶”ì •)**
  * ```model = torch.compile(model)``` : ì†ë„ í–¥ìƒ ì—†ìŒ
  * **```model.eval()``` : 5% ì •ë„ í–¥ìƒ ì¶”ì •**
  * ```model.half()``` + ```float16``` ì ìš© : ì˜¤ë¥˜ ë°œìƒ
    * ```inputs = tokenizer(prompt, return_tensors="pt").to("cuda", torch.float16)``` í˜•ì‹
  * ```do_sample=False``` : ì†ë„ í–¥ìƒ ì—†ìŒ + **ë™ì¼ context ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë¬¸ì¥ ìƒì„± ì•ˆë¨**

## 7. ORPO í•™ìŠµ ì¤‘ ê²½ê³  ë©”ì‹œì§€ ë° ì˜¤ë¥˜ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* ORPO í•™ìŠµ ì´ˆë°˜ mapping ë‹¨ê³„ì—ì„œ ì•„ë˜ì™€ ê°™ì€ ê²½ê³ 
  * ```Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.```
* ORPO í•™ìŠµ ì¤‘ ```'generator' object has no attribute 'generate'``` ì˜¤ë¥˜

```
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\trl\trainer\orpo_trainer.py", line 852, in get_batch_samples
    policy_output = model.generate(
AttributeError: 'generator' object has no attribute 'generate'
```

* ë¬¸ì œ ì›ì¸
  * ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ ì´ìŠˆ 
  * í˜„ì¬ ì„¤ì¹˜ëœ ```transformers==4.46.3``` ê³¼ ```trl==0.11.4``` ê°€ í˜¸í™˜ë˜ì§€ ì•ŠìŒ 

**í•´ê²° ì‹œë„í•œ ë°©ë²•**

* pip ì„ ì´ìš©í•˜ì—¬ ```trl==0.12.0``` ì„¤ì¹˜ **(ì‹¤íŒ¨)**
  * ëª…ë ¹ì–´ : ```pip install trl==0.12.0```
  * ì‹¤íŒ¨ ì´ìœ  : Python 3.8.1 ê¸°ì¤€ pip ì—ì„œ trl ì˜ ìµœëŒ€ ë²„ì „ì´ ```0.11.4``` ì„
* GitHub release ëœ ë§í¬ë¥¼ í†µí•´ ```trl``` ë¼ì´ë¸ŒëŸ¬ë¦¬ ìµœì‹  ë²„ì „ ì„¤ì¹˜ **(ì‹¤íŒ¨)**
  * ëª…ë ¹ì–´ : ```pip wheel git+https://github.com/huggingface/trl.git```
  * ì‹¤íŒ¨ ì´ìœ  : Python 3.9.0 ì´ìƒ í•„ìš”
    * ```ERROR: Package 'trl' requires a different Python: 3.8.1 not in '>=3.9'``` 
* ```transformers==4.45.0``` ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ
  * ì˜ì‚¬ê²°ì • ì´ìœ  
    * Python ì„ 3.8.1 ì—ì„œ 3.9.0 ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ì‹œ, ëª¨ë“  ì½”ë“œì— ëŒ€í•œ ì •ìƒ ì‘ë™ ì—¬ë¶€ ì¬í™•ì¸ í•„ìš”
    * ê·¸ëŸ¬ë‚˜, í˜„ì‹¤ì ìœ¼ë¡œ ìì› ì†Œë¹„ê°€ í¬ë‹¤ê³  íŒë‹¨
    * ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ```transformers==4.45.0``` ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ, ë‹¤ìŒ í”„ë¡œì íŠ¸ë¶€í„° Python version up
  * ê²°ê³¼
    * ì´ ë°©ë²•ìœ¼ë¡œ **ê²½ê³  ë©”ì‹œì§€ ë° ì˜¤ë¥˜ ëª¨ë‘ í•´ê²° ì„±ê³µ ğŸ‰**
    * SFT Fine-Tuning í•™ìŠµ ë° í…ŒìŠ¤íŠ¸, SFT ëœ ëª¨ë¸ì„ ì´ìš©í•œ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ëª¨ë‘ ì •ìƒ ì‘ë™ í™•ì¸

## 8. ORPO í•™ìŠµ ì‹œ CUDA Out of memory (í•´ê²° ì‹¤íŒ¨)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* ORPO í•™ìŠµ ì‹œ CUDA Out of memory ë°œìƒ (Quadro M6000, 12GB)

**í•´ê²° ë³´ë¥˜ ì‚¬ìœ **

* **OOM ì˜ ê·¼ë³¸ì ì¸ ì›ì¸ì¸, Windows 10 + Python 3.8.1 + 12GB GPU ë¼ëŠ” í™˜ê²½ì  ë¬¸ì œë¥¼ ê°œë°œ ì¼ì • ë‚´ì— ê·¹ë³µí•˜ê¸° ì–´ë µë‹¤ê³  íŒë‹¨**
* ë‹¤ìŒ í”„ë¡œì íŠ¸ë¶€í„° Python 3.12 ë“± version-up í•˜ì—¬ ê°œë°œ ì˜ˆì •
* ORPO í•™ìŠµ ì—†ì´ë„ Supervised Fine-Tuning ë§Œìœ¼ë¡œ ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©ì ì„ ì–´ëŠ ì •ë„ ë‹¬ì„±í•  ìˆ˜ ìˆìŒ

**í•´ê²° ì‹œë„í•œ ë°©ë²•**

* SFT í•™ìŠµëœ ëª¨ë¸ ì–‘ìí™” **(í•´ê²° ì•ˆë¨)**
  * ```sft_llm = prepare_model_for_kbit_training(sft_llm)```
* 8bit í˜•íƒœì˜ [AdamW Optimizer](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Optimizer.md#2-3-adamw) ì‚¬ìš© **(í•´ê²° ì•ˆë¨)**
  * ```optim="adamw_8bit"``` 
* Unsloth ì„¤ì¹˜ **(ì‹¤íŒ¨)**
  * Unsloth ëŠ” Python 3.9 ì´ìƒì—ì„œë§Œ ì„¤ì¹˜ ê°€ëŠ¥
  * Python 3.8.1 ì—ì„œëŠ” ì„¤ì¹˜ ë¶ˆê°€

## 9. CNN í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ CNN ì˜ í•™ìŠµì´ ì „í˜€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŒ
  * valid output ì„ ì¶œë ¥í•œ ê²°ê³¼, ê°’ì´ ëª¨ë‘ ë™ì¼í•˜ê²Œ ë‚˜ì˜´
* ì›ì¸ì€ **ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ ë¶€ë¶„ì˜, ê±°ì˜ ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ ê³µë°±ì¸ ì‚¬ì‹¤ìƒ ì˜ë¯¸ ì—†ëŠ” ë¶€ë¶„ì— ëŒ€í•œ ì •ë³´ê°€, ì˜¤íˆë ¤ í•™ìŠµì— ì§€ì¥** ì„ ì£¼ì—ˆê¸° ë•Œë¬¸ìœ¼ë¡œ ì¶”ì •
  * í•™ìŠµ ë°ì´í„°ê°€ 1,000 ê°œ ë‚´ì™¸ë¡œ ë¹„êµì  ë¶€ì¡±í•œ ìƒí™©ì—ì„œ ì´ë¡œ ì¸í•´ í•™ìŠµì´ ì „í˜€ ì•ˆ ë˜ì—ˆìŒ
  * [ì°¨ì›ì˜ ì €ì£¼](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Data%20Science%20Basics/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4_%EA%B8%B0%EC%B4%88_%EC%B0%A8%EC%9B%90%EC%9D%98_%EC%A0%80%EC%A3%BC.md) ì™€ ê´€ë ¨ ìˆì„ ê²ƒìœ¼ë¡œ ì¶”ì •

**í•´ê²° ì‹œë„ ë°©ë²•**

* **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ ì‹œê¹Œì§€ ì‹œë„í•œ ë¶€ë¶„**
  * Conv. + Pool Layer ì´í›„ ì²«ë²ˆì§¸ Fully-Connected Layer ì˜ [í™œì„±í™” í•¨ìˆ˜](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_%ED%99%9C%EC%84%B1%ED%99%94_%ED%95%A8%EC%88%98.md) ë¥¼ Tanh ë¡œ ìˆ˜ì •
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 64 x 64 -> 128 x 128 ë¡œ í™•ëŒ€
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * ëª¨ë“  í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ë°ê¸° ì¡°ì • (ê¸°ì¡´ë³´ë‹¤ 5ë°° ì–´ë‘¡ê²Œ)
    * ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ê°€ ë°°ê²½ìƒ‰ì€ í°ìƒ‰, ë„í˜• ë°°ê²½ìƒ‰ ì—­ì‹œ ë°ì€ ìƒ‰ìœ¼ë¡œ ì „ì²´ì ìœ¼ë¡œ í°ìƒ‰ì— ìƒë‹¹íˆ ê°€ê¹Œì›€
    * í°ìƒ‰ì´ ì•„ë‹Œ ìƒ‰ì˜ ëª¨ë“  í”½ì…€ì— ëŒ€í•´, ê·¸ **í°ìƒ‰ë³´ë‹¤ ì–´ë‘ìš´ ì •ë„ë¥¼ 5ë°°** ë¡œ í•˜ì—¬ **ì´ë¯¸ì§€ë¥¼ ì–´ë‘¡ê²Œ ì¡°ì •**
      * ì¼ì¢…ì˜ [ì…ë ¥ ë°ì´í„° ì •ê·œí™”](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Data%20Science%20Basics/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4_%EA%B8%B0%EC%B4%88_Normalization.md) ëª©ì 
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * ì´ë¯¸ì§€ì˜ ì‹¤ì œ í•™ìŠµ ë²”ìœ„ë¥¼ **ì „ì²´ 128 x 128 ì´ ì•„ë‹Œ, ê°€ìš´ë° 64 x 64 ë§Œ í•™ìŠµì— ì‚¬ìš©**
    * ê°€ì¥ìë¦¬ ë¶€ë¶„ì€ ëŒ€ë¶€ë¶„ì´ í°ìƒ‰ì˜ ë°°ê²½ìƒ‰ì¸, ì‚¬ì‹¤ìƒ ë¬´ì˜ë¯¸í•œ ì •ë³´ì´ë¯€ë¡œ í•™ìŠµ ëŒ€ìƒì—ì„œ ì œì™¸
    * ê²°ê³¼ : **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ (ì•½ 40% í™•ë¥ ë¡œ í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§)** ğŸ‰

* **ë¶€ë¶„ì  í•´ê²° ì„±ê³µ ì´í›„, ì¶”ê°€ì ìœ¼ë¡œ ì‹œë„í•œ ë¶€ë¶„**
  * Conv. Layer ì¶”ê°€
    * âŒ **ë¯¸ ì ìš©**
    * ì ìš© ê²°ê³¼, í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§ˆ í™•ë¥  ì˜¤íˆë ¤ ê°ì†Œ
  * ëª¨ë¸ì´ ìƒì„±í•œ ë‹¤ì´ì–´ê·¸ë¨ ë°ì´í„° ì¶”ê°€ ìƒì„±
    * âœ… **ì ìš©ë¨**
    * ê¸°ì¡´ 200ì¥ + ì¶”ê°€ 200ì¥ = 400ì¥
  * Conv. Layer ì˜ í•„í„° ê°œìˆ˜ë¥¼ ì¤„ì—¬ì„œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê°ì†Œ
    * âœ… **ì ìš©ë¨**
    * í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§ˆ í™•ë¥  ì•½ 70% ë¡œ ì¦ê°€ ì¶”ì •
  * [Weight initialization](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md) ê°œì„ 
    * âŒ **ë¯¸ ì ìš©**
    * Conv. Layer -> [He init](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md#5-he-initialization), Fully-Connected Layer -> [Xavier init](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md#4-xavier-initialization)
    * ì ìš© ê²°ê³¼, í•™ìŠµ ì‹¤íŒ¨ìœ¨ ê¸‰ì¦ & ì•½ 50%ì˜ í™•ë¥ ë¡œ ëª¨ë¸ì˜ output ê°’ì´ í•­ìƒ 1.0 ì´ ë¨

* **ì¶”ê°€ ì•„ì´ë””ì–´**
  * Pre-train ëœ ResNet ë“±ì„ ì´ìš©í•˜ì—¬ [Transfer Learning (ì „ì´í•™ìŠµ)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Transfer_Learning.md) ì„ í• ê¹Œë„ ìƒê°í•´ ë´„
  * ëª¨ë¸ ë³µì¡ë„ ë° í•„ìš” ì´ìƒì˜ ìì› ì†Œë¹„ê°€ ìš°ë ¤ë˜ì–´, ì¼ë‹¨ ë³´ë¥˜

## 10. Auto-Encoder í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ìš”ì•½**

* ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ CNN ì˜ í•™ìŠµì´ ì „í˜€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŒ
  * latent vector ë¥¼ ì¶œë ¥í•œ ê²°ê³¼, ê°’ì´ ëª¨ë‘ ë™ì¼í•˜ê²Œ ë‚˜ì˜´

**í•´ê²° ì‹œë„ ë°©ë²•**

* **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ ì‹œê¹Œì§€ ì‹œë„í•œ ë¶€ë¶„**
  * Fully-Connected Layer ì˜ [Dropout](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Overfitting_Dropout.md#3-dropout) ì œê±°
    * ê¸°ë³¸ ì•„ì´ë””ì–´ : [Conv Layer ì— Dropout ì„ ì ìš©í•˜ë©´ Auto-Encoder í•™ìŠµì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìˆëŠ”ë°](final_recommend_score/README.md#4-ì°¸ê³ --conv-layer-ì—-dropout-ì ìš©ëœ-auto-encoder-í•™ìŠµì´-ì–´ë ¤ìš´-ì´ìœ ), Fully-Connected ë„ ë§ˆì°¬ê°€ì§€ì¼ ìˆ˜ ìˆë‹¤ 
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * Encoder ì˜ Conv. Layer ì™€ Decoder ì˜ DeConv. Layer ë¥¼ 4 â†’ 3 ê°œë¡œ ì¡°ì •
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * Encoder ì…ë ¥ ~ Latent Vector ì‚¬ì´ì—, **ê¸°ì¡´ Conv. Layer ë¥¼ ê±°ì¹˜ëŠ” íë¦„ ì™¸ì— Dense Layer 1ê°œë¥¼ ê±°ì¹˜ëŠ” íë¦„ì„ ì¶”ê°€**
    * Encoder ì˜ Conv. Layer ê°€ ëë‚˜ê³  Fully-Connected Layer ê°€ ì‹œì‘ë˜ëŠ” ì‹œì ì—ì„œ, **ì´ 2ê°œì˜ íë¦„ì— ì˜í•´ ìƒì„±ëœ feature ë¥¼ concatenate**
    * ê²°ê³¼
      * **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ (ì•½ 40% í™•ë¥ ë¡œ í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§)** ğŸ‰
      * **Minimum Train Loss = ì•½ 1.7K** (í•™ìŠµ ì•ˆë  ë•Œ) **â†’ 632.68**

* **ë¶€ë¶„ì  í•´ê²° ì„±ê³µ ì´í›„, ì¶”ê°€ì ìœ¼ë¡œ ì‹œë„í•œ ë¶€ë¶„**
  * Learning Rate Scheduler ì¡°ì • (warm-up ì¶”ê°€)
    * âœ… **ì ìš©ë¨**
    * before : warm-up ì—†ëŠ” [Cosine-Annealing LR Scheduler](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Learning_Rate_Scheduler.md#2-6-cosine-annealing-scheduler)
    * after : 5 epoch ì˜ warm-up + ì´í›„ì— learning rate ê°€ ë§¤ epoch ë§ˆë‹¤ 1.0% or 1.5% ì”© ì§€ìˆ˜ì ìœ¼ë¡œ ê°ì†Œ
    * ê²°ê³¼ (133 epoch ë™ì•ˆ í•™ìŠµ ì‹œ ê¸°ì¤€)
      * **í•™ìŠµ ì„±ê³µë¥  í–¥ìƒ (ì•½ 40% â†’ ì•½ 80% ì¶”ì •)** ğŸ‰
      * L.R. **1.0%** ì”© ê°ì†Œ ì‹œ : **Minimum Train Loss = 632.68 â†’ 433.28 (ğŸ”» 31.5 %)** ğŸ‰
      * L.R. **1.5%** ì”© ê°ì†Œ ì‹œ : **Minimum Train Loss = 632.68 â†’ 425.79 (ğŸ”» 32.7 %)** ğŸ‰