## ëª©ì°¨

* [1. í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
  * [1-1. í”„ë¡œì íŠ¸ ì§„í–‰ ë°°ê²½](#1-1-í”„ë¡œì íŠ¸-ì§„í–‰-ë°°ê²½)
  * [1-2. ì‹¤ì œ ìƒì„±ëœ ë‹¤ì´ì–´ê·¸ë¨](#1-2-ì‹¤ì œ-ìƒì„±ëœ-ë‹¤ì´ì–´ê·¸ë¨)
* [2. ê¸°ìˆ  ë¶„ì•¼ ë° ì‚¬ìš© ê¸°ìˆ ](#2-ê¸°ìˆ -ë¶„ì•¼-ë°-ì‚¬ìš©-ê¸°ìˆ )
  * [2-1. ê´€ë ¨ ë…¼ë¬¸](#2-1-ê´€ë ¨-ë…¼ë¬¸)
  * [2-2. ì‚¬ìš©í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì‹œìŠ¤í…œ í™˜ê²½](#2-2-ì‚¬ìš©í•œ-python-ë¼ì´ë¸ŒëŸ¬ë¦¬-ë°-ì‹œìŠ¤í…œ-í™˜ê²½)
* [3. í”„ë¡œì íŠ¸ ì¼ì •](#3-í”„ë¡œì íŠ¸-ì¼ì •)
* [4. í”„ë¡œì íŠ¸ ìƒì„¸ ì„¤ëª…](#4-í”„ë¡œì íŠ¸-ìƒì„¸-ì„¤ëª…)
  * [4-1. ë„ì‹ ìƒì„±ì„ ìœ„í•œ LLM í”„ë¡¬í”„íŠ¸](#4-1-ë„ì‹-ìƒì„±ì„-ìœ„í•œ-llm-í”„ë¡¬í”„íŠ¸)
  * [4-2. LLM Fine-Tuning](#4-2-llm-fine-tuning)
  * [4-3. LLM Fine-Tuning ìš© ë°ì´í„°ì…‹ ìƒì„±](#4-3-llm-fine-tuning-ìš©-ë°ì´í„°ì…‹-ìƒì„±)
  * [4-4. ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì ìˆ˜ ë° ìˆœìœ„ ì‚°ì¶œ](#4-4-ìƒì„±ëœ-ì´ë¯¸ì§€ì˜-ì ìˆ˜-ë°-ìˆœìœ„-ì‚°ì¶œ)
* [5. í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ì´ìŠˆ ë° í•´ê²° ë°©ë²•](#5-í”„ë¡œì íŠ¸-ì§„í–‰-ì¤‘-ì´ìŠˆ-ë°-í•´ê²°-ë°©ë²•)
  * [5-1. **```flash_attn``` ì‹¤í–‰ ë¶ˆê°€ (í•´ê²° ë³´ë¥˜)**](#5-1-flashattn-ì‹¤í–‰-ë¶ˆê°€-í•´ê²°-ë³´ë¥˜)
  * [5-2. LLM ì¶œë ¥ì´ ë§¤ë²ˆ ë™ì¼í•¨ (í•´ê²° ì™„ë£Œ)](#5-2-llm-ì¶œë ¥ì´-ë§¤ë²ˆ-ë™ì¼í•¨-í•´ê²°-ì™„ë£Œ)
  * [5-3. ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ over-write (í•´ê²° ì™„ë£Œ)](#5-3-ë‹¤ì´ì–´ê·¸ë¨-ì´ë¯¸ì§€-over-write-í•´ê²°-ì™„ë£Œ)
  * [5-4. CUBLAS_STATUS_NOT_SUPPORTED (í•´ê²° ì™„ë£Œ)](#5-4-cublas_status_not_supported-í•´ê²°-ì™„ë£Œ)
  * [5-5. SFT ì¤‘ CUDA error: unknown error (í•´ê²° ì™„ë£Œ)](#5-5-sft-ì¤‘-cuda-error-unknown-error-í•´ê²°-ì™„ë£Œ)
  * [5-6. **Fine-Tuning ëœ ëª¨ë¸ ì¶”ë¡  ì†ë„ ì €í•˜ (í•´ê²° ë³´ë¥˜)**](#5-6-fine-tuning-ëœ-ëª¨ë¸-ì¶”ë¡ -ì†ë„-ì €í•˜-í•´ê²°-ë³´ë¥˜)
  * [5-7. ORPO í•™ìŠµ ì¤‘ ê²½ê³  ë©”ì‹œì§€ ë° ì˜¤ë¥˜ (í•´ê²° ì™„ë£Œ)](#5-7-orpo-í•™ìŠµ-ì¤‘-ê²½ê³ -ë©”ì‹œì§€-ë°-ì˜¤ë¥˜-í•´ê²°-ì™„ë£Œ)
  * [5-8. **ORPO í•™ìŠµ ì‹œ CUDA Out of memory (í•´ê²° ì‹¤íŒ¨)**](#5-8-orpo-í•™ìŠµ-ì‹œ-cuda-out-of-memory-í•´ê²°-ì‹¤íŒ¨)
  * [5-9. CNN í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)](#5-9-cnn-í•™ìŠµì´-ì‹¤ì§ˆì ìœ¼ë¡œ-ì•ˆ-ë¨-í•´ê²°-ì™„ë£Œ)
  * [5-10. Auto-Encoder í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)](#5-10-auto-encoder-í•™ìŠµì´-ì‹¤ì§ˆì ìœ¼ë¡œ-ì•ˆ-ë¨-í•´ê²°-ì™„ë£Œ)
* [6. ì‚¬ìš©ì ê°€ì´ë“œ](#6-ì‚¬ìš©ì-ê°€ì´ë“œ)
* [7. í”„ë¡œì íŠ¸ ì†Œê°](#7-í”„ë¡œì íŠ¸-ì†Œê°)

## 1. í”„ë¡œì íŠ¸ ê°œìš”

* DeepSeek LLM ì„ ì´ìš©í•˜ì—¬ **ì‚¬ìš©ìì˜ ìš”êµ¬ ì‚¬í•­ì— ë§ëŠ”** ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì„¸ìŠ¤ ë˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ ë“±ì„ ì„¤ëª…í•˜ê¸° ìœ„í•œ **Diagram ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ì •í˜•í™”ëœ í¬ë§·ì˜ í…ìŠ¤íŠ¸** ë¥¼ ìƒì„±í•œë‹¤.
* í•´ë‹¹ í…ìŠ¤íŠ¸ë¥¼ ì´ìš©í•˜ì—¬ ì¼ë°˜ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ Diagram ì„ ìƒì„±í•œë‹¤.
* ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ì´ìš©í•˜ì—¬ ë³´ë‹¤ ê°€ë…ì„± ì¢‹ì€ Diagram ì„ ìƒì„±í•œë‹¤.
  * **[DPO ë˜ëŠ” ORPO](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_ê¸°ì´ˆ_Fine_Tuning_DPO_ORPO.md) ì™€ ê°™ì€ ê¸°ìˆ ë¡œ LLM ì„ Fine-Tuning** í•˜ì—¬, LLM ìì²´ì ìœ¼ë¡œ ì‚¬ìš©ì ì…ì¥ì—ì„œ ê°€ë…ì„± ë†’ì€ Diagram ìƒì„±
* ê°€ë…ì„±ì´ ë”ìš± í–¥ìƒëœ **ê°œë³„ ì‚¬ìš©ì ë§ì¶¤í˜•** Diagram ìƒì„±ì„ ìœ„í•´ ë‹¤ìŒì„ ì ìš©í•œë‹¤.
  * ì—¬ëŸ¬ ê°œì˜ Diagram ì„ ìƒì„±í•œ í›„, **ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜ + ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜** ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ê¶Œì˜ Diagram ë“¤ì„ ì‚¬ìš©ìì—ê²Œ í‘œì‹œ
  * [CNN (Conv. Neural Network)](https://github.com/WannaBeSuperteur/AI-study/blob/main/Image%20Processing/Basics_CNN.md) ì„ ì´ìš©í•˜ì—¬ ê°€ë…ì„± ë†’ì€ Diagram ì¸ì§€ì˜ **ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜** ì‚°ì¶œ
  * ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ [Auto-Encoder](https://github.com/WannaBeSuperteur/AI-study/blob/main/Generative%20AI/Basics_Auto%20Encoder.md) ë¡œ ì €ì°¨ì› ë²¡í„°í™”í•˜ê³ , [k-Nearest Neighbor](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Machine%20Learning%20Models/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%AA%A8%EB%8D%B8_KNN.md) ì˜ ì•„ì´ë””ì–´ë¥¼ ì´ìš©í•˜ì—¬ **ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜** ì‚°ì¶œ

![image](../images/250312_1.PNG)

### 1-1. í”„ë¡œì íŠ¸ ì§„í–‰ ë°°ê²½

* [DS/ML/DL/LLM ê¸°ì´ˆ ì •ë¦¬](https://github.com/WannaBeSuperteur/AI-study/tree/main/AI%20Basics) ì¤‘ ëª¨ë¸ ì„¤ëª…ì„ ìœ„í•œ ë‹¤ì´ì–´ê·¸ë¨ì„ PowerPoint ë“±ì„ ì´ìš©í•˜ì—¬ ê·¸ë¦¬ëŠ” ë° ì˜¤ëœ ì‹œê°„ í•„ìš”
  * ê¸°ì´ˆì ì¸ ë¶€ë¶„ì€ AIì—ê²Œ ë§¡ê¸¸ ìˆ˜ ì—†ì„ê¹Œ?
* ChatGPT ì—ì„œ ì œê³µí•˜ëŠ” DALL-E ë“±ì„ ì´ìš©í•˜ì—¬ ìƒì„±í•  ì‹œ, ì•„ë˜ì™€ ê°™ì´ **ì˜ë„ì— ì „í˜€ ë§ì§€ ì•Šê³ , ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ì´ ìˆëŠ” ì´ë¯¸ì§€** ê°€ ìƒì„±ë¨
  * ë”°ë¼ì„œ, ì´ ë¬¸ì œ í•´ê²°ì— **DALL-E ë¥¼ ì´ìš©í•˜ê¸°ëŠ” ì–´ë ¤ì›€**

| ì‚¬ìš©ì ì¿¼ë¦¬                                                                                                                     |
|----------------------------------------------------------------------------------------------------------------------------|
| Draw a diagram of a deep learning model with 2 input nodes, 3 and 5 hidden nodes for each hidden layer, and 1 output node. |

| ê²°ê³¼ë¬¼ (ì¶œì²˜: ChatGPT DALL-E)         |
|----------------------------------|
| ![image](../images/250312_2.PNG) |

* ìµœê·¼ DeepSeek ë“± ì˜¤í”ˆì†ŒìŠ¤ LLM í™•ëŒ€ë¡œ, ë³¸ í”„ë¡œì íŠ¸ ì§„í–‰ì˜ ê¸°ìˆ ì  ì–´ë ¤ì›€ì´ í¬ê²Œ ë‚®ì•„ì§

### 1-2. ì‹¤ì œ ìƒì„±ëœ ë‹¤ì´ì–´ê·¸ë¨

* LLM ì…ë ¥ í”„ë¡¬í”„íŠ¸

```
DL model with 4 input layer nodes, 6, 10 and 6 nodes in 3 hidden layers, and 1 output element
```

* ì‹¤ì œ ìƒì„±ëœ ë‹¤ì´ì–´ê·¸ë¨

![image](../images/250312_22.PNG)

## 2. ê¸°ìˆ  ë¶„ì•¼ ë° ì‚¬ìš© ê¸°ìˆ 

* ê¸°ìˆ  ë¶„ì•¼
  * LLM (Large Language Model)
  * Computer Vision
* ì‚¬ìš© ê¸°ìˆ 

| ì‚¬ìš© ê¸°ìˆ                                                                                                                                                      | ì„¤ëª…                                                                                         |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|
| [SFT (Supervised Fine-Tuning)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_SFT.md) | Diagram í˜•ì‹ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ í•˜ëŠ” ê°•ë ¥í•œ LLM Fine-tuning ë°©ë²•                                       |
| CNN (Conv. NN)                                                                                                                                            | ìƒì„±ëœ ë‹¤ì´ì–´ê·¸ë¨ì˜ ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜ ì‚°ì¶œ                                                                    |
| Auto-Encoder                                                                                                                                              | ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì €ì°¨ì› ë²¡í„°í™”ë¥¼ í†µí•´, k-NN ì„ í†µí•œ ì‚¬ìš©ì í‰ê°€ ì˜ˆìƒ ì ìˆ˜ ê³„ì‚° ì‹œ **ì´ì›ƒí•œ ì´ë¯¸ì§€ì™€ì˜ ê±°ë¦¬ ê³„ì‚°ì´ ì •í™•í•´ì§€ê³ , ì—°ì‚°ëŸ‰ì´ ê°ì†Œí•˜ëŠ”** íš¨ê³¼ |
| k-NN                                                                                                                                                      | ê° ì‚¬ìš©ìë³„ ìƒì„±í•œ Diagram ì— ëŒ€í•œ í‰ê°€ ë°ì´í„°ì— ê¸°ë°˜í•œ, **í•´ë‹¹ ì‚¬ìš©ìì— ëŒ€í•œ ë§ì¶¤í˜•** ì‚¬ìš©ì í‰ê°€ ì˜ˆìƒ ì ìˆ˜ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜               |

### 2-1. ê´€ë ¨ ë…¼ë¬¸

ë³¸ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  LLM ì¸ DeepSeek LLM ì— ëŒ€í•œ **íƒ„íƒ„í•œ ê¸°ì´ˆê°€ ì¤‘ìš”í•˜ë‹¤** ëŠ” íŒë‹¨ ì•„ë˜ ì‘ì„±í•œ, ê´€ë ¨ ë…¼ë¬¸ì— ê´€í•œ ìŠ¤í„°ë”” ìë£Œì´ë‹¤.

* [(ë…¼ë¬¸ ìŠ¤í„°ë”” ìë£Œ) LLaMA: Open and Efficient Foundation Language Models, 2023](https://github.com/WannaBeSuperteur/AI-study/blob/main/Paper%20Study/Large%20Language%20Model/%5B2025.03.12%5D%20LLaMA%20-%20Open%20and%20Efficient%20Foundation%20Language%20Models.md)
* [(ë…¼ë¬¸ ìŠ¤í„°ë”” ìë£Œ) DeepSeek LLM Scaling Open-Source Language Models with Longtermism, 2024](https://github.com/WannaBeSuperteur/AI-study/blob/main/Paper%20Study/Large%20Language%20Model/%5B2025.03.13%5D%20DeepSeek%20LLM%20Scaling%20Open-Source%20Language%20Models%20with%20Longtermism.md)
* [(ë…¼ë¬¸ ìŠ¤í„°ë”” ìë£Œ) DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025](https://github.com/WannaBeSuperteur/AI-study/blob/main/Paper%20Study/Large%20Language%20Model/%5B2025.03.13%5D%20DeepSeek-R1%20-%20Incentivizing%20Reasoning%20Capability%20in%20LLM%20via%20Reinforcement%20Learning.md)

### 2-2. ì‚¬ìš©í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì‹œìŠ¤í…œ í™˜ê²½

* ì‚¬ìš©í•œ ëŒ€í‘œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬
  * PyTorch
  * Numpy
  * Pandas
  * Plotly (ë°ì´í„° ë¶„ì„ìš©)
* [ì‹œìŠ¤í…œ í™˜ê²½ ë° ì‚¬ìš©í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„¸ ì •ë³´](additional_info.md#1-ì‹œìŠ¤í…œ-í™˜ê²½)

## 3. í”„ë¡œì íŠ¸ ì¼ì •

* ì „ì²´ ì¼ì • : **2025.03.12 ìˆ˜ - 03.27 ëª© (16d)**
* ìƒíƒœ : â¬œ (TODO), ğŸ’¨ (ING), âœ… (DONE), âŒ (FAILED)

| ê³„íš ë‚´ìš©                                        | ì¼ì •                     | branch                                                                                                                                  | ìƒíƒœ |
|----------------------------------------------|------------------------|-----------------------------------------------------------------------------------------------------------------------------------------|----|
| ë…¼ë¬¸ ìŠ¤í„°ë”” (LLaMA + DeepSeek ì´ 3ê°œ)               | 03.12 ìˆ˜ - 03.13 ëª© (2d) |                                                                                                                                         | âœ…  |
| í”„ë¡œì íŠ¸ ê°œìš” ì‘ì„±                                   | 03.14 ê¸ˆ (1d)           |                                                                                                                                         | âœ…  |
| DeepSeek LLM ëª¨ë¸ ì„ íƒ (1ì°¨)                      | 03.14 ê¸ˆ - 03.15 í†  (2d) | [```P001-001-SelectLLM```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-001-SelectLLM/2025_03_12_DeepSeek_LLM)             | âœ…  |
| LLM Fine-tuning í•™ìŠµ ë°ì´í„°ì˜ Diagram ìƒì„± ì•Œê³ ë¦¬ì¦˜ ê°œë°œ   | 03.15 í†  - 03.17 ì›” (3d) | [```P001-002-DiagAlgo```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-002-DiagAlgo/2025_03_12_DeepSeek_LLM)               | âœ…  |
| DeepSeek LLM ëª¨ë¸ ì„ íƒ (2ì°¨, **ë³€ê²½ëœ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì´ìš©**) | 03.15 í†  - 03.16 ì¼ (2d) | [```P001-003-SelectLLM2```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-003-SelectLLM2/2025_03_12_DeepSeek_LLM)           | âœ…  |
| LLM Fine-tuning í•™ìŠµ ë°ì´í„° ìƒì„±                    | 03.17 ì›” - 03.19 ìˆ˜ (3d) | [```P001-004-Data```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-004-Data/2025_03_12_DeepSeek_LLM)                       | âœ…  |
| **(FIX)** Diagram ìƒì„± ì½”ë“œì— ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ì¶”ê°€        | 03.17 ì›” (1d)           | [```P001-005-AddImgPath```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-005-AddImgPath/2025_03_12_DeepSeek_LLM)           | âœ…  |
| LLM Fine-tuning ì‹¤ì‹œ (SFT)                     | 03.19 ìˆ˜ - 03.21 ê¸ˆ (3d) | [```P001-006-FineTune```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-006-FineTune/2025_03_12_DeepSeek_LLM)               | âœ…  |
| LLM Fine-tuning ì˜ Flow-Chart í•™ìŠµ ë°ì´í„° ë‹¤ì–‘í™”      | 03.20 ëª© (1d)           | [```P001-007-UpdateFlowchart```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-007-UpdateFlowchart/2025_03_12_DeepSeek_LLM) | âœ…  |
| LLM Fine-tuning ì‹¤ì‹œ (ORPO)                    | 03.22 í†  - 03.23 ì¼ (2d) | [```P001-006-FineTune```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-006-FineTune/2025_03_12_DeepSeek_LLM)               | âŒ  |
| CNN ê°œë°œ ë° í•™ìŠµ                                  | 03.23 ì¼ - 03.24 ì›” (2d) | [```P001-008-CNN```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-008-CNN/2025_03_12_DeepSeek_LLM)                         | âœ…  |
| Auto-Encoder ê°œë°œ ë° í•™ìŠµ                         | 03.25 í™” - 03.26 ìˆ˜ (2d) | [```P001-009-AE```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-009-AE/2025_03_12_DeepSeek_LLM)                           | âœ…  |
| k-NN ê°œë°œ ë° í•™ìŠµ                                 | 03.26 ìˆ˜ (1d)           | [```P001-010-kNN```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-010-kNN/2025_03_12_DeepSeek_LLM)                         | âœ…  |
| ê¸°ë³¸ ê°€ë…ì„± + ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ ê°œë°œ             | 03.26 ìˆ˜ (1d)           | [```P001-011-Score```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-011-Score/2025_03_12_DeepSeek_LLM)                     | âœ…  |
| ì „ì²´ ê¸°ëŠ¥ ì‹¤í–‰ ì½”ë“œ ê°œë°œ (ì‚¬ìš©ì ì‹¤í–‰ìš©)                     | 03.26 ìˆ˜ (1d)           | [```P001-012-ForUser```](https://github.com/WannaBeSuperteur/AI_Projects/tree/P001-012-ForUser/2025_03_12_DeepSeek_LLM)                 | âœ…  |
| í”„ë¡œì íŠ¸ ìƒì„¸ ì„¤ëª… ì •ë¦¬ ë° ë§í¬ ì¶”ê°€                        | 03.26 ìˆ˜ - 03.27 ëª© (2d) |                                                                                                                                         | âœ…  |
| í”„ë¡œì íŠ¸ ìµœì¢… í…ŒìŠ¤íŠ¸ (QA)                             | 03.27 ëª© (1d)           |                                                                                                                                         | âœ…  |

## 4. í”„ë¡œì íŠ¸ ìƒì„¸ ì„¤ëª…

### 4-1. ë„ì‹ ìƒì„±ì„ ìœ„í•œ LLM í”„ë¡¬í”„íŠ¸

LLM í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ [2ì°¨ í”„ë¡¬í”„íŠ¸](test/README.md#3-1-ì½”ë“œ-íŒŒì¼-ì„¤ëª…-ë°-í…ŒìŠ¤íŠ¸-í”„ë¡¬í”„íŠ¸) ì—ì„œ connection line shape ì˜ ì¢…ë¥˜ê°€ 2ê°€ì§€ì—ì„œ 3ê°€ì§€ë¡œ í™•ëŒ€ëœ ê²ƒì„ ì œì™¸í•˜ê³  ì™„ì „íˆ ë™ì¼í•˜ë‹¤.

```
Represent below as a Python list.

A deep learning model with 2 input nodes, 4 and 6 nodes in each of the 2 hidden layers,
and 1 node in the output layer in the following format.

At this time, each node is represented in the format of Python list "[node No.,
X position (px), Y position (px), shape (rectangle, round rectangle or circle),
width (px), height (px), connection line shape (solid arrow, solid line or dashed line),
background color, connection line color, list of node No. s of other nodes pointed to by the connection line]".

At this time, the color is represented in the format of tuple (R, G, B), between 0 and 255, and
X position range is 0-1000 and Y position range is 0-600.

It is important to draw a representation of high readability.
```

ìœ„ í”„ë¡¬í”„íŠ¸ì—ì„œ **5ê°œ ë¬¸ë‹¨ ì¤‘ 2ë²ˆì§¸ ë¬¸ë‹¨ì¸ ë‹¤ìŒ ë¶€ë¶„ì´ ì‹¤ì œ User Prompt** ì´ê³ , ë‚˜ë¨¸ì§€ëŠ” Prompt Engineering ì„ ìœ„í•´ ì¶”ê°€ëœ Prefix / Suffix ì´ë‹¤.

```
A deep learning model with 2 input nodes, 4 and 6 nodes in each of the 2 hidden layers,
and 1 node in the output layer in the following format.
```

### 4-2. LLM Fine-Tuning

* **ê¸°ë³¸ ì‚¬í•­**
  * ì‚¬ìš©í•œ LLM : **deepseek-coder-1.3b-instruct**
  * ì‚¬ìš©í•œ ë°©ë²•ë¡  : [Supervised Fine-Tuning (SFT)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_SFT.md)
  * ì‹œë„í•œ ë°©ë²•ë¡  : [Odd-Ratio Preference Optimization (ORPO)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_DPO_ORPO.md#3-orpo-odds-ratio-preference-optimization) - **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨**

* ìƒì„¸ ì„¤ëª…
  * LLaMA ë“± ê¸°ì¡´ LLM ë³´ë‹¤ëŠ”, **ìµœì‹  íŠ¸ë Œë“œì¸ DeepSeek ëª¨ë¸ì„ Fine-tuning** í•˜ëŠ” ê²ƒì„ ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©í‘œë¡œ í•¨.
  * DPO ëŠ” ì°¸ì¡° ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤ëŠ” ë¶€ë‹´ì´ ìˆì§€ë§Œ, ORPO ëŠ” LLM 1ê°œë§Œ ì‚¬ìš©í•˜ë©´ ë˜ë¯€ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš© ë° Out-of-memory ë¶€ë‹´ì´ ë‚®ìŒ

* ê´€ë ¨ ìë£Œ
  * [LLM Fine-Tuning ìƒì„¸ ì„¤ëª…](fine_tuning/README.md)
  * [LLM í›„ë³´ ì„ ì • ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ëª¨ë¸ 14ê°œ)](test_llm/README.md)

### 4-3. LLM Fine-Tuning ìš© ë°ì´í„°ì…‹ ìƒì„±

* **ê¸°ë³¸ ì‚¬í•­**
  * SFT ìš© í•™ìŠµ ë°ì´í„° 700 ê°œ
  * ORPO ìš© í•™ìŠµ ë°ì´í„° 200 ê°œ **(ORPO í•™ìŠµ ì‹¤íŒ¨)**

* ìƒì„¸ ì„¤ëª…
  * SFT ìš© í•™ìŠµ ë°ì´í„°ëŠ” ì¼ì •í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•˜ì—¬ User Prompt ë° LLM ì˜ ëª©í‘œ Answer ë¥¼ ìƒì„±
  * ORPO ìš© í•™ìŠµ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ìƒì„±
    * Prompt + Accepted Answer ìŒ 200 ê°œ
      * SFT ìš© í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ë°©ë²•ìœ¼ë¡œ ìƒì„± 
    * Rejected Answer 199 ê°œ
      * ìœ„ Prompt 200 ê°œì— ëŒ€í•´ SFT Fine-Tuning ëœ LLM ì„ ì´ìš©í•˜ì—¬ Answer ìƒì„±
      * ì´ê²ƒ ì¤‘ í‰ê°€ ìˆ˜ì‹ì— ì˜í•œ ì ìˆ˜ê°€ ë§Œì ì´ ì•„ë‹Œ ê²ƒì€ ëª¨ë‘ Rejected Answer ë¡œ ê°„ì£¼ (ë§Œì ì¸ ê²ƒ 1ê°œ ì¡´ì¬)

* ê´€ë ¨ ìë£Œ
  * [LLM Fine-Tuning ë°ì´í„°ì…‹ ìƒì„± ìƒì„¸ ì„¤ëª…](create_dataset/README.md) 

### 4-4. ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì ìˆ˜ ë° ìˆœìœ„ ì‚°ì¶œ

* **ê¸°ë³¸ ì‚¬í•­**
  * ìµœì¢… ì ìˆ˜ = **ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜ (50%) + ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜ (50%)**
  * Conv. Neural Network (CNN) ì„ ì´ìš©í•˜ì—¬ **ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜** ê³„ì‚°
  * Diagram ì„ Auto-Encoder ë¡œ ì¸ì½”ë”©í•œ latent vector ë¥¼ ì´ìš©í•˜ì—¬, ì´ì›ƒí•œ Diagram ë“¤ì— ëŒ€í•œ ê°€ì¤‘ í‰ê·  ì ìˆ˜ë¡œ **ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜** ê³„ì‚°

* ìƒì„¸ ì„¤ëª…
  * LLM ì„ ì´ìš©í•˜ì—¬ ìƒì„±í•œ Diagram ë“¤ì— ëŒ€í•´, ìœ„ ìµœì¢… ì ìˆ˜ë¥¼ ê³„ì‚°
  * ìœ„ ìµœì¢… ì ìˆ˜ê°€ ì¼ì • ìˆœìœ„ ì´ë‚´ì¸ Diagram ì„ ìµœì¢… ì¶”ì²œ

* ê´€ë ¨ ìë£Œ
  * [ìµœì¢… ì ìˆ˜ ê³„ì‚°ë²• ìƒì„¸ ì„¤ëª…](final_recommend_score/README.md)

## 5. í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ì´ìŠˆ ë° í•´ê²° ë°©ë²•

**ì´ìŠˆ ìš”ì•½**

| ì´ìŠˆ ë¶„ë¥˜        | ì´ìŠˆ                                                                                                                                                    | ë‚ ì§œ         | ì‹¬ê°ì„±    | ìƒíƒœ        | ì›ì¸ (ë° í•´ê²° ë°©ë²•)                                              | ì‹œë„í–ˆìœ¼ë‚˜ ì‹¤íŒ¨í•œ í•´ê²° ë°©ë²•                                                                                                                                                                                                                                                           |
|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|------------|--------|-----------|-----------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| LLM          | ```flash_attn``` ì‚¬ìš© ë¶ˆê°€                                                                                                                                | 2025.03.14 | ë‚®ìŒ     | ë³´ë¥˜        | ```nvcc -V``` ê¸°ì¤€ì˜ CUDA ë²„ì „ ì´ìŠˆ                              | - Windows í™˜ê²½ ë³€ìˆ˜ í¸ì§‘ **(í•´ê²° ì•ˆë¨)**<br>- flash_attn ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì´ì „ ë²„ì „ ì„¤ì¹˜ **(ì‹¤íŒ¨)**<br>- Visual C++ 14.0 ì„¤ì¹˜ **(ì‹¤íŒ¨)**                                                                                                                                                                  |
| LLM          | LLM ì¶œë ¥ì´ ë§¤ë²ˆ ë™ì¼í•¨                                                                                                                                        | 2025.03.15 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | ```llm.generate()``` í•¨ìˆ˜ì˜ ëœë¤ ìƒì„± ì¸ìˆ˜ ì„¤ì • ëˆ„ë½                   | - ```torch.manual_seed()``` ì„¤ì • **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                                                                                |
| êµ¬í˜„           | ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ê°€ overwrite ë¨                                                                                                                                | 2025.03.18 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | í…ìŠ¤íŠ¸ íŒŒì‹± ë° ë„í˜• ê·¸ë¦¬ê¸° ì•Œê³ ë¦¬ì¦˜ì˜ **êµ¬í˜„ìƒ ì´ìŠˆ**                          | - ì¼ì • ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± **(í•´ê²° ì•ˆë¨)**<br>- ```canvas.copy()``` ì´ìš© **(í•´ê²° ì•ˆë¨)**<br>- garbage collection ì´ìš© **(í•´ê²° ì•ˆë¨)**                                                                                                                                                          |
| LLM - SFT    | ```CUBLAS_STATUS_NOT_SUPPORTED``` (SFT í•™ìŠµ ì¤‘ ì˜¤ë¥˜)                                                                                                       | 2025.03.20 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ     | pre-trained LLM ì„ ê°€ì ¸ì˜¬ ë•Œ ìë£Œí˜•ì´ ```bfloat16``` ì„             | - batch size ì„¤ì •                                                                                                                                                                                                                                                           |
| LLM - SFT    | SFT ì¤‘ CUDA error: unknown error                                                                                                                       | 2025.03.20 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ     | í° batch size ì— ë”°ë¥¸ Out-of-memory                           | - ```CUDA_LAUNCH_BLOCKING=1``` ì„¤ì • **(í•´ê²° ì•ˆë¨)**<br> - ```TORCH_USE_CUDA_DSA=1``` ì„¤ì • **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                             |           |
| LLM          | Fine-Tuning ëœ ëª¨ë¸ ì¶”ë¡  ì†ë„ ì €í•˜                                                                                                                             | 2025.03.22 | ë³´í†µ     | ë³´ë¥˜        | í™˜ê²½ ì œì•½ & task íŠ¹ì„± (ì¶”ì •)                                      | - Auto-GPTQ ì‚¬ìš© **(í•´ê²° ì•ˆë¨)**<br>- ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© **(ì‹¤íŒ¨)**<br>- LLM ê´€ë ¨ ì„¤ì •ê°’ ë³€ê²½ **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                                       |
| LLM - ORPO   | ORPO í•™ìŠµ ì¤‘ ê²½ê³  ë° ì˜¤ë¥˜<br>- ```Trainer.tokenizer is now deprecated.``` ê²½ê³  ë©”ì‹œì§€<br>- ```AttributeError: 'generator' object has no attribute 'generate'``` ì˜¤ë¥˜ | 2025.03.23 | **ì‹¬ê°** | í•´ê²° ì™„ë£Œ     | transformers, trl ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ ì•ˆë¨ â†’ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ê·¸ë ˆì´ë“œ | - trl ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ê·¸ë ˆì´ë“œ **(ì‹¤íŒ¨)**                                                                                                                                                                                                                                                |
| LLM - ORPO   | ORPO í•™ìŠµ ì‹œ Out of memory                                                                                                                               | 2025.03.23 | **ì‹¬ê°** | **í•´ê²° ì‹¤íŒ¨** | CUDA Out of memory                                        | - ```prepare_model_for_kbit_training``` ì„ ì´ìš©í•œ ì–‘ìí™” ì‹œë„ **(í•´ê²° ì•ˆë¨)**<br> - 8bitì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ AdamW Optimizer ì‚¬ìš© **(í•´ê²° ì•ˆë¨)**<br>- Unsloth ì„¤ì¹˜ **(ì‹¤íŒ¨)**                                                                                                                             |
| CNN          | CNN í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨                                                                                                                                     | 2025.03.23 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ ë¶€ë¶„ì— ëŒ€í•œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì •ë³´ê°€ ì˜¤íˆë ¤ í•™ìŠµì„ ë°©í•´ (ì¶”ì •)               | - í™œì„±í™” í•¨ìˆ˜ ìˆ˜ì • **(í•´ê²° ì•ˆë¨)**<br>- ì´ë¯¸ì§€ í¬ê¸° í™•ëŒ€ **(í•´ê²° ì•ˆë¨)**<br>- ì´ë¯¸ì§€ ìƒ‰ìƒ ë³€í™˜ (ì „ì²˜ë¦¬) **(í•´ê²° ì•ˆë¨)**                                                                                                                                                                                       |
| Auto-Encoder | Auto-Encoder í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨                                                                                                                            | 2025.03.25 | ë³´í†µ     | í•´ê²° ì™„ë£Œ     | ë°ì´í„°ì…‹ íŠ¹ì„±ìœ¼ë¡œ ì¶”ì •í•˜ë‚˜, ëª…í™•í•˜ì§€ ì•ŠìŒ                                   | - Fully-Connected Layer ì˜ [Dropout](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Overfitting_Dropout.md#3-dropout) ì œê±° **(í•´ê²° ì•ˆë¨)**<br>- Conv, DeConv ë ˆì´ì–´ 4ê°œ â†’ 3ê°œ **(í•´ê²° ì•ˆë¨)** |

### 5-1. ```flash_attn``` ì‹¤í–‰ ë¶ˆê°€ (í•´ê²° ë³´ë¥˜)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* [LLM í›„ë³´ ëª¨ë¸](test/README.md#2-2-í›„ë³´-ëª¨ë¸-ì„ ì •) ì¤‘ ì¼ë¶€ë¥¼ ì–‘ìí™”í•˜ì§€ ì•Šê³  ì‹¤í–‰ ì‹œ, ```flash_attn``` (Flash Attention) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í•„ìš”ë¡œ í•¨
* í•´ë‹¹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ CUDA ë²„ì „ ì´ìŠˆ (```nvcc -V``` ë¡œ í™•ì¸ë˜ëŠ” ë²„ì „ ê¸°ì¤€ CUDA 11.7 ì´ìƒì—ì„œë§Œ ì„¤ì¹˜ ê°€ëŠ¥) ë¡œ ì¸í•´ ì„¤ì¹˜ ì•ˆë¨

**í•´ê²° ë³´ë¥˜ ì‚¬ìœ **

* ```flash_attn``` ì˜¤ë¥˜ëŠ” Local í™˜ê²½ì´ ì•„ë‹Œ Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì‹œ ë°œìƒí•˜ì§€ ì•ŠìŒ
* Flash Attention ì„ ìš”êµ¬í•˜ëŠ” LLM (DeepSeek-V2 ë“±) ì€ ëª¨ë‘ Auto-[GPTQ](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Quantization.md#2-4-gptq-post-training-quantization-for-gpt-models) (ì–‘ìí™” ë°©ë²•) Not Supported ì¸ í° ëª¨ë¸ì„
  * ì´ëŠ” Local í™˜ê²½ì—ì„œëŠ” GPTQë¥¼ ì´ìš©í•œ ì–‘ìí™” ìì²´ê°€ ì–´ë ¤ìš°ë©°, ë”°ë¼ì„œ **í° ê·œëª¨ë¡œ ì¸í•œ OOMì„ í•´ê²°í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì—, ```flash_attn``` ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ì‚¬ìš© ìì²´ê°€ ì–´ë ¤ìš´ ëª¨ë¸**ì„ì„ ì˜ë¯¸í•¨.  
  * ì˜¤ë¥˜ ë©”ì‹œì§€ : ```deepseek_v2 isn't supported yet.``` 
* í•´ë‹¹ ë¬¸ì œ í•´ê²° ì—†ì´ë„ [Supervised Fine-Tuning](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_SFT.md) ì˜ ì„  ì§„í–‰ì„ í†µí•´ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ë³´ì¼ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ëŠ” ëª¨ë¸ ì¡´ì¬

**í•´ê²° ì‹œë„ ë°©ë²• (ëª¨ë‘ ì‹¤íŒ¨, í•´ê²° ë³´ë¥˜ ì¤‘)**

* **1. Windows í™˜ê²½ ë³€ìˆ˜ í¸ì§‘**
  * ```CUDA_PATH``` í™˜ê²½ ë³€ìˆ˜ë¥¼ í˜„ì¬ ì„¤ì¹˜ëœ 11.7 ì´ìƒì˜ CUDA ë²„ì „ìœ¼ë¡œ ê°±ì‹ 
  * ```PATH``` ì˜ ```CUDA\bin``` ë¶€ë¶„ì„ í˜„ì¬ ì„¤ì¹˜ëœ 11.7 ì´ìƒì˜ CUDA ë²„ì „ìœ¼ë¡œ ê°±ì‹ 
  * ê²°ê³¼
    * ```nvcc -V``` ë¡œ í™•ì¸ë˜ëŠ” ë²„ì „ì€ CUDA 11.7 ì´ìƒìœ¼ë¡œ ì˜¬ë¼ê°
    * ```pip install flash_attn``` ì„¤ì¹˜ ì‹œë„ ì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ
      * ```ERROR: Failed to build installable wheels for some pyproject.toml based projects (flash_attn)``` 

* **2. flash_attn ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì´ì „ ë²„ì „ ì„¤ì¹˜**
  * ```pip install flash_attn==2.5.7``` ì‹œë„ [(ì°¸ê³ )](https://github.com/Dao-AILab/flash-attention/issues/224)
  * ê²°ê³¼
    * ```error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/``` ì˜¤ë¥˜ ë°œìƒ

* **3. Visual C++ 14.0 ì„¤ì¹˜**
  * [ì„¤ì¹˜ ë§í¬](https://visualstudio.microsoft.com/ko/downloads/) ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ
  * ì„¤ì¹˜ í”„ë¡œê·¸ë¨ì—ì„œ "C++ë¥¼ ì‚¬ìš©í•œ ë°ìŠ¤í¬í†± ê°œë°œ" ì²´í¬ í›„ ì„¤ì¹˜
  * ```pip install flash_attn``` ì‹¤í–‰ ì‹œë„ ê²°ê³¼
    * ```C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.2\include\crt/host_config.h(157): fatal error C1189: #error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2022 (inclusive) are supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk. error: command 'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\bin\\nvcc.exe' failed: Error``` ì˜¤ë¥˜ ë°œìƒ
  * Visual Studio Build Tools ì—ì„œ ë™ì¼í•˜ê²Œ ì‹¤í–‰ ì‹œë„ ê²°ê³¼ 
    * ```pip install flash_attn==2.5.7```
      * ì‹¤íŒ¨
      * ```urllib.error.HTTPError: HTTP Error 404: Not Found```
    * ```pip install flash_attn==2.3.3```
      * ì‹¤íŒ¨
      * ```urllib.error.HTTPError: HTTP Error 404: Not Found```
    * ```pip install flash_attn==2.3.6```
      * ì‹¤íŒ¨
      * ```urllib.error.HTTPError: HTTP Error 404: Not Found```
    * ```pip install https://github.com/oobabooga/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu122torch2.4.0cxx11abiFALSE-cp311-cp311-win_amd64.whl```
      * ì‹¤íŒ¨
      * ```ERROR: flash_attn-2.6.3+cu122torch2.4.0cxx11abiFALSE-cp311-cp311-win_amd64.whl is not a supported wheel on this platform.```

### 5-2. LLM ì¶œë ¥ì´ ë§¤ë²ˆ ë™ì¼í•¨ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ LLM ì´ ìƒì„±í•˜ëŠ” ë‹µë³€ì´ ë§¤ë²ˆ ë™ì¼í•¨
* LLM ì„ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ```generate()``` í•¨ìˆ˜ì˜ ```do_sample=True``` ëˆ„ë½ì´ ì›ì¸

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. torch.manual_seed() ì„¤ì • (ì‹¤íŒ¨)**
  * ë§¤ë²ˆ ìƒì„± ì‹œë„í•  ë•Œë§ˆë‹¤, ```seed``` ì˜ ê°’ì„ 1ì”© ì¦ê°€ì‹œí‚¨ í›„ ```torch.manual_seed(seed)``` ë¥¼ ì ìš©í•˜ì—¬ seed ê°’ ì—…ë°ì´íŠ¸
  * ê²°ê³¼: í•´ê²° ì•ˆë¨

* **2. LLM ì„ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ```generate()``` í•¨ìˆ˜ ìˆ˜ì •**
  * í•´ë‹¹ í•¨ìˆ˜ì— ëŒ€í•´ ëœë¤í•˜ê²Œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì•„ë˜ì™€ ê°™ì´ ```do_sample=True``` ë¥¼ ì¶”ê°€
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²° ì„±ê³µğŸ‰

```python
with torch.no_grad():
    outputs = llm.generate(**inputs,
                           max_length=768,
                           do_sample=True)  # ëœë¤ ì¶œë ¥ (ì—¬ê¸°ì„œë¶€í„° ëœë¤ ì¶œë ¥ ìƒì„±ë˜ê²Œ í•˜ê¸° ìœ„í•¨)
```

### 5-3. ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ over-write (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* [ë‹¤ì´ì–´ê·¸ë¨ ì‘ì„± ì½”ë“œì¸ draw_diagram.py](draw_diagram/draw_diagram.py) ì˜ ```generate_diagram_from_lines``` í•¨ìˆ˜ë¥¼ í†µí•´ ì´ë¯¸ì§€ ë°˜ë³µ ìƒì„± ì‹œ,
* ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ **NumPy array (canvas) ë¥¼ ë§¤ ìƒì„± ì‹œë§ˆë‹¤ ì´ˆê¸°í™”í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³  overwrite** ë¨
* ë„í˜• ê·¸ë¦¬ê¸° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ìƒì˜ ì˜¤ë¥˜ê°€ ì›ì¸

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. ì¼ì • ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (í•´ê²° ì•ˆë¨)**
  * ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì‹œë§ˆë‹¤ 0.35 ì´ˆì˜ ê°„ê²©ì„ ë‘ê³  ìƒì„±í•˜ë„ë¡ interval ì§€ì •
    * ```time.sleep(0.35)  # to prevent image overwriting``` ë¥¼ ì´ìš©
  * ê·¼ë³¸ì ì¸ í•´ê²° ë°©ë²•ì€ ì•„ë‹ˆë¼ê³  íŒë‹¨ë¨

* **2. ```canvas.copy()``` ì´ìš© (í•´ê²° ì•ˆë¨)**
  * canvas ë¥¼ ì´ˆê¸°í™”í•´ë„ OpenCV ì— ì´ì „ì˜ ë©”ëª¨ë¦¬ê°€ ë‚¨ì•„ ìˆì„ ìˆ˜ ìˆìŒ
  * ë”°ë¼ì„œ, ì´ë¥¼ **ì›ë³¸ì´ ì•„ë‹Œ ë³µì‚¬ëœ canvas ì— ë„í˜•ì„ ê·¸ë¦¬ëŠ”** ë°©ì‹ìœ¼ë¡œ í•´ê²° ì‹œë„
  * ì½”ë“œ

```
canvas = np.ones((HEIGHT, WIDTH, 3), dtype=np.uint8) * 255
canvas = canvas.copy()
```

* **3. garbage collection (í•´ê²° ì•ˆë¨)**
  * OpenCVì˜ í•´ë‹¹ ë©”ëª¨ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•œ ë°©ë²•ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ garbage collection ì‹¤ì‹œ 
  * ì½”ë“œ 

```
del canvas
gc.collect()
```

* **4. êµ¬í˜„ìƒì˜ ì˜¤ë¥˜ í•´ê²°**
  * í…ìŠ¤íŠ¸ íŒŒì‹± ë° ë„í˜• ê·¸ë¦¬ê¸° ì•Œê³ ë¦¬ì¦˜ì˜ **êµ¬í˜„ìƒ ì´ìŠˆ** ë¡œ íŒë‹¨í•˜ì—¬ ì´ë¥¼ í•´ê²°
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²° ì„±ê³µğŸ‰

### 5-4. CUBLAS_STATUS_NOT_SUPPORTED (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* LLMì˜ Supervised Fine-tuning (SFT) í•™ìŠµ ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ
  * ```RuntimeError: CUDA error: CUBLAS_STATUS_NOT_SUPPORTED when calling `cublasGemmStridedBatchedEx(handle, opa, opb, (int)m, (int)n, (int)k, (void*)&falpha, a, CUDA_R_16BF, (int)lda, stridea, b, CUDA_R_16BF, (int)ldb, strideb, (void*)&fbeta, c, CUDA_R_16BF, (int)ldc, stridec, (int)num_batches, compute_type, CUBLAS_GEMM_DEFAULT_TENSOR_OP)```
* ì›ì¸ : Pre-trained LLM ì„ ê°€ì ¸ì˜¬ ë•Œ, ```torch.dtype = bfloat16``` ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í•´ë‹¹ ì˜¤ë¥˜ ë°œìƒ

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. batch size ë³€ê²½ (í•´ê²° ì•ˆë¨)**
  * ```training_args``` ì— ë‹¤ìŒì„ ì¶”ê°€
    * ```per_device_train_batch_size=4,  # batch size per device during training```
    * ```per_device_eval_batch_size=4  # batch size per device during validation```
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²°ë˜ì§€ ì•ŠìŒ

* **2. bfloat16 ì„ float16 ìœ¼ë¡œ ë³€ê²½**
  * LLM ì„ ê°€ì ¸ì˜¬ ë•Œ ```bfloat16``` ìë£Œí˜•ì„ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— í•´ë‹¹ ì˜¤ë¥˜ ë°œìƒ, ```float16``` ìœ¼ë¡œ ìˆ˜ì •
  * ê²°ê³¼: ì´ ë°©ë²•ìœ¼ë¡œ í•´ê²° ì„±ê³µğŸ‰

```python
original_llm = AutoModelForCausalLM.from_pretrained(model_path,
                                                    torch_dtype=torch.float16).cuda()
```

### 5-5. SFT ì¤‘ CUDA error: unknown error (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™©**

* SFT ì‹¤í–‰ ì¤‘ ì•½ 30ë¶„ í›„ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ ë°œìƒ

```
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: the launch timed out and was terminated
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                                       | 30/280 [28:16<3:55:40, 56.56s/it]
```

![image](../images/250312_5.PNG)

* ```gradient_checkpointing``` (ê°€ì¤‘ì¹˜ë¥¼ ë©”ëª¨ë¦¬ì— ì¼ë¶€ë§Œ ì €ì¥í•˜ëŠ” ë°©ì‹) ì„ í•˜ì§€ ì•Šì„ ë•ŒëŠ” **í•™ìŠµ ì‹œì‘ ì§í›„** ë‹¤ìŒê³¼ ê°™ì´ **CUBLAS_STATUS_EXECUTION_FAILED** ì˜¤ë¥˜ ë°œìƒ

```
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\transformers\models\llama\modeling_llama.py", line 258, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\modules\linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DEFAULT_TENSOR_OP)`
  0%|                                                                                                                                                                                                      | 0/280 [00:09<?, ?it/s]
```

**ë¬¸ì œ ì›ì¸**

* **í° batch size ë¡œ ì¸í•œ GPU ë©”ëª¨ë¦¬ ì´ˆê³¼ë¡œ ì¶”ì •**
* Gradient Checkpointing ë¯¸ ì ìš© ì‹œ, **batch size 4 ë¡œë„ GPU ë©”ëª¨ë¦¬ (12GB) ë¥¼ ì´ˆê³¼** í•˜ê²Œ ë¨

![image](../images/250312_6.PNG)

* Out of memory ëŒ€ì‹  ```CUBLAS_STATUS_EXECUTION_FAILED``` ê°€ ë°œìƒí•˜ëŠ” ì´ìœ ëŠ” ë¶ˆëª…
* Gradient Checkpointing ê³¼ì˜ ì—°ê´€ì„± (ì¶”ì •)
  * **Gradient Checkpointing ì„ í•˜ëŠ” ê²½ìš°, ì´ë¡œ ì¸í•´ ë©”ëª¨ë¦¬ê°€ ì ˆì•½ë¨**
  * ì´ë¡œ ì¸í•´ Gradient Checkpointing ì—†ì´ í•™ìŠµí•  ë•Œ batch size 4 ì—ì„œ ë°”ë¡œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, batch size 4 ë¡œë„ 30ë¶„ ë™ì•ˆì€ í•™ìŠµ ì§„í–‰ ê°€ëŠ¥
  * ê·¸ëŸ¬ë‹¤ 30ë¶„ ì •ë„ ì‹œì ì—ì„œ ë©”ëª¨ë¦¬ ì´ˆê³¼ê°€ ë°œìƒí•˜ì—¬ í•™ìŠµì´ ê°•ì œ ì¤‘ì§€ë¨ 

**í•´ê²° ì‹œë„ ë°©ë²•**

* **1. ```CUDA_LAUNCH_BLOCKING=1``` ì„¤ì • (í•´ê²° ì•ˆë¨)**
  * ```fine_tuning/sft_fine_tuning.py``` ì˜ ìƒë‹¨ì— ë‹¤ìŒ ì„¤ì • ì¶”ê°€
    * ```os.environ['CUDA_LAUNCH_BLOCKING'] = "1"``` 
  * ê²°ê³¼: í•´ê²° ì•ˆë¨

```
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: unknown error
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                                                                    | 34/280 [33:23<4:01:37, 58.93s/it]
```

* **2. ```TORCH_USE_CUDA_DSA=1``` ì„¤ì • (í•´ê²° ì•ˆë¨)**
  * ```fine_tuning/sft_fine_tuning.py``` ì˜ ìƒë‹¨ì— ë‹¤ìŒ ì„¤ì • ì¶”ê°€
    * ```os.environ["TORCH_USE_CUDA_DSA"] = '1'``` 
  * ê²°ê³¼: í•´ê²° ì•ˆë¨

```
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: unknown error
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                                                                    | 34/280 [32:00<3:51:33, 56.48s/it]
```

* **3. LLM í•™ìŠµ ì‹œ, batch size ê°ì†Œ (4 â†’ 1 or 2)** 
  * ê²°ê³¼
    * Gradient Checkpointing ì ìš© ì‹œ, batch size 2 ì—ì„œ í•™ìŠµ ì •ìƒ ì¢…ë£Œ
    * [ìƒì„¸ í•™ìŠµ ë¡œê·¸](fine_tuning/log/log_train_sft_batch_size_2)
  * ìƒì„¸ ì½”ë“œ

```python
    training_args = SFTConfig(
        learning_rate=0.0002,  # lower learning rate is recommended for fine tuning
        num_train_epochs=2,
        logging_steps=1,  # logging frequency
#        gradient_checkpointing=True,
        output_dir=output_dir,
        save_total_limit=3,  # max checkpoint count to save
        per_device_train_batch_size=1,  # batch size per device during training
        per_device_eval_batch_size=1  # batch size per device during validation
    )
```

### 5-6. Fine-Tuning ëœ ëª¨ë¸ ì¶”ë¡  ì†ë„ ì €í•˜ (í•´ê²° ë³´ë¥˜)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* LLM Fine Tuning í›„, Diagram 1ê°œë¥¼ ìƒì„±í•˜ëŠ” ë° 3ë¶„ ì´ìƒ ì†Œìš”
* ë³¸ í”„ë¡œì íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì œí’ˆì´ë¼ê³  í•˜ë©´, ì œí’ˆì„ ì‚¬ìš©í•˜ëŠ” ìœ ì € ì…ì¥ì—ì„œ ì¢‹ì€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ê¸° ì–´ë ¤ìš´ ìƒí™©

**í•´ê²° ë³´ë¥˜ ì‚¬ìœ **

* GPU ì„±ëŠ¥ ì œì•½, Windows 10 OS ì—ì„œì˜ vLLM ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ë¶ˆê°€ ë“± í™˜ê²½ì  ì œì•½ì„ í”„ë¡œì íŠ¸ ì¼ì • ë‚´ì— ê·¹ë³µí•˜ê¸° ì–´ë µë‹¤ê³  íŒë‹¨
* task ì˜ íŠ¹ì„±ìƒ response ì˜ token ê°œìˆ˜ê°€ 1000ê°œ ì´ìƒìœ¼ë¡œ ë§ì´ í•„ìš”í•˜ê³ , ì´ë¡œ ì¸í•´ ê¸´ ì‹œê°„ì´ ì†Œìš”ë¨. ì¦‰ **ê¸´ ì‹œê°„ ì†Œìš”ëŠ” task ì˜ íŠ¹ì„±ì´ë¼ëŠ” ê·¼ë³¸ì ì¸ ì´ìœ  ë•Œë¬¸ì„**

**í•´ê²° ì‹œë„í•œ ë°©ë²•**

* Auto-GPTQ ì‚¬ìš© **(ì†ë„ í–¥ìƒ ì•ˆë¨)**
  * [ê¸°ì¡´ ëª¨ë¸ì˜ GPTQ ì ìš©ëœ ë²„ì „](https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GPTQ) ì„ ì´ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì‹œë„ ìì²´ëŠ” ì„±ê³µí–ˆìœ¼ë‚˜, **í•™ìŠµ ë° ì¶”ë¡  ì†ë„ í–¥ìƒì´ ì²´ê°ë˜ì§€ ì•ŠìŒ**
  * [ê¸°ì¡´ ëª¨ë¸ì˜ GPTQ ì ìš©ëœ ë²„ì „](https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GPTQ) ì ìš© ì‹œ,
    * ì ìš© ìì²´ëŠ” **ì„±ê³µ**
    * GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†ŒëŠ” ì²´ê°ë˜ì§€ë§Œ, **í•™ìŠµ/ì¶”ë¡  ì†ë„ ê°œì„ ì€ ì²´ê° ì•ˆë¨**
    * ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê°ì†Œë¡œ, ì‹¤ì œ ìœ ì € ì‚¬ìš© ì‹œ ì„±ëŠ¥ ì €í•˜ ìš°ë ¤
    * ì¶”ë¡  ì†ë„ê°€ **ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ë„ ì˜¤íˆë ¤ ëŠë¦°** ê²ƒìœ¼ë¡œ ì˜ì‹¬
  * [ìƒì„¸ ì‹œë„ ê¸°ë¡](fine_tuning/log/log_try_apply_GPTQ.md) 
* ëª¨ë¸ ìƒì„± ê³¼ì •ì—ì„œì˜ num_return_sequences (ìƒì„±í•˜ëŠ” answer ì˜ ê°œìˆ˜) ìˆ˜ì • **(ì†ë„ í–¥ìƒ ë¶ˆê°€)**
  * ê¸°ë³¸ê°’ì´ '1'ì´ê¸° ë•Œë¬¸ 
* vLLM ì‚¬ìš© **(í˜„ì¬ Linux ì—ì„œë§Œ ì§€ì›, Windows ì—ì„œ ì§€ì› ì•ˆë¨)**
* LoRA Config ì—ì„œ ```inference mode = True``` ì ìš© **(ì†ë„ í–¥ìƒ ì•ˆë¨)**

```python
def load_sft_llm():
    print('loading LLM ...')

    try:
        model = AutoModelForCausalLM.from_pretrained("sft_model").cuda()

        lora_config = LoraConfig(
            r=16,  # Rank of LoRA
            lora_alpha=16,
            lora_dropout=0.05,  # Dropout for LoRA
            init_lora_weights="gaussian",  # LoRA weight initialization
            inference_mode=True,
            target_modules=['q_proj', 'v_proj', 'k_proj', 'o_proj']
        )
        model = get_peft_model(model, lora_config)
```

* ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© **(ì‹¤íŒ¨)**
  * [Intel Extension (streamer ë„ ê°™ì´ ì ìš©)](https://discuss.pytorch.kr/t/transformer-intel-extension/2997)

```
FAILED:  No module named 'neural_compressor.conf'
```

* ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ streamer ë§Œ ì‚¬ìš© **(ì†ë„ í–¥ìƒ ì•ˆë¨)**
  * ëª¨ë¸ ì¶œë ¥ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ëŠ” íš¨ê³¼ë§Œ ìˆìŒ
* ê¸°íƒ€ ë°©ë²•ë“¤ **(```model.eval()``` ì—ì„œ 5% ì •ë„ ì†ë„ í–¥ìƒ ì¶”ì •)**
  * ```model = torch.compile(model)``` : ì†ë„ í–¥ìƒ ì—†ìŒ
  * **```model.eval()``` : 5% ì •ë„ í–¥ìƒ ì¶”ì •**
  * ```model.half()``` + ```float16``` ì ìš© : ì˜¤ë¥˜ ë°œìƒ
    * ```inputs = tokenizer(prompt, return_tensors="pt").to("cuda", torch.float16)``` í˜•ì‹
  * ```do_sample=False``` : ì†ë„ í–¥ìƒ ì—†ìŒ + **ë™ì¼ context ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë¬¸ì¥ ìƒì„± ì•ˆë¨**

### 5-7. ORPO í•™ìŠµ ì¤‘ ê²½ê³  ë©”ì‹œì§€ ë° ì˜¤ë¥˜ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* ORPO í•™ìŠµ ì´ˆë°˜ mapping ë‹¨ê³„ì—ì„œ ì•„ë˜ì™€ ê°™ì€ ê²½ê³ 
  * ```Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.```
* ORPO í•™ìŠµ ì¤‘ ```'generator' object has no attribute 'generate'``` ì˜¤ë¥˜

```
  File "C:\Users\20151\AppData\Local\Programs\Python\Python38\lib\site-packages\trl\trainer\orpo_trainer.py", line 852, in get_batch_samples
    policy_output = model.generate(
AttributeError: 'generator' object has no attribute 'generate'
```

* ë¬¸ì œ ì›ì¸
  * ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ ì´ìŠˆ 
  * í˜„ì¬ ì„¤ì¹˜ëœ ```transformers==4.46.3``` ê³¼ ```trl==0.11.4``` ê°€ í˜¸í™˜ë˜ì§€ ì•ŠìŒ 

**í•´ê²° ì‹œë„í•œ ë°©ë²•**

* pip ì„ ì´ìš©í•˜ì—¬ ```trl==0.12.0``` ì„¤ì¹˜ **(ì‹¤íŒ¨)**
  * ëª…ë ¹ì–´ : ```pip install trl==0.12.0```
  * ì‹¤íŒ¨ ì´ìœ  : Python 3.8.1 ê¸°ì¤€ pip ì—ì„œ trl ì˜ ìµœëŒ€ ë²„ì „ì´ ```0.11.4``` ì„
* GitHub release ëœ ë§í¬ë¥¼ í†µí•´ ```trl``` ë¼ì´ë¸ŒëŸ¬ë¦¬ ìµœì‹  ë²„ì „ ì„¤ì¹˜ **(ì‹¤íŒ¨)**
  * ëª…ë ¹ì–´ : ```pip wheel git+https://github.com/huggingface/trl.git```
  * ì‹¤íŒ¨ ì´ìœ  : Python 3.9.0 ì´ìƒ í•„ìš”
    * ```ERROR: Package 'trl' requires a different Python: 3.8.1 not in '>=3.9'``` 
* ```transformers==4.45.0``` ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ
  * ì˜ì‚¬ê²°ì • ì´ìœ  
    * Python ì„ 3.8.1 ì—ì„œ 3.9.0 ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ì‹œ, ëª¨ë“  ì½”ë“œì— ëŒ€í•œ ì •ìƒ ì‘ë™ ì—¬ë¶€ ì¬í™•ì¸ í•„ìš”
    * ê·¸ëŸ¬ë‚˜, í˜„ì‹¤ì ìœ¼ë¡œ ìì› ì†Œë¹„ê°€ í¬ë‹¤ê³  íŒë‹¨
    * ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ```transformers==4.45.0``` ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ, ë‹¤ìŒ í”„ë¡œì íŠ¸ë¶€í„° Python version up
  * ê²°ê³¼
    * ì´ ë°©ë²•ìœ¼ë¡œ **ê²½ê³  ë©”ì‹œì§€ ë° ì˜¤ë¥˜ ëª¨ë‘ í•´ê²° ì„±ê³µ ğŸ‰**
    * SFT Fine-Tuning í•™ìŠµ ë° í…ŒìŠ¤íŠ¸, SFT ëœ ëª¨ë¸ì„ ì´ìš©í•œ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ëª¨ë‘ ì •ìƒ ì‘ë™ í™•ì¸

### 5-8. ORPO í•™ìŠµ ì‹œ CUDA Out of memory (í•´ê²° ì‹¤íŒ¨)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* ORPO í•™ìŠµ ì‹œ CUDA Out of memory ë°œìƒ (Quadro M6000, 12GB)

**í•´ê²° ë³´ë¥˜ ì‚¬ìœ **

* **OOM ì˜ ê·¼ë³¸ì ì¸ ì›ì¸ì¸, Windows 10 + Python 3.8.1 + 12GB GPU ë¼ëŠ” í™˜ê²½ì  ë¬¸ì œë¥¼ ê°œë°œ ì¼ì • ë‚´ì— ê·¹ë³µí•˜ê¸° ì–´ë µë‹¤ê³  íŒë‹¨**
* ë‹¤ìŒ í”„ë¡œì íŠ¸ë¶€í„° Python 3.12 ë“± version-up í•˜ì—¬ ê°œë°œ ì˜ˆì •
* ORPO í•™ìŠµ ì—†ì´ë„ Supervised Fine-Tuning ë§Œìœ¼ë¡œ ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©ì ì„ ì–´ëŠ ì •ë„ ë‹¬ì„±í•  ìˆ˜ ìˆìŒ

**í•´ê²° ì‹œë„í•œ ë°©ë²•**

* SFT í•™ìŠµëœ ëª¨ë¸ ì–‘ìí™” **(í•´ê²° ì•ˆë¨)**
  * ```sft_llm = prepare_model_for_kbit_training(sft_llm)```
* 8bit í˜•íƒœì˜ [AdamW Optimizer](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Optimizer.md#2-3-adamw) ì‚¬ìš© **(í•´ê²° ì•ˆë¨)**
  * ```optim="adamw_8bit"``` 
* Unsloth ì„¤ì¹˜ **(ì‹¤íŒ¨)**
  * Unsloth ëŠ” Python 3.9 ì´ìƒì—ì„œë§Œ ì„¤ì¹˜ ê°€ëŠ¥
  * Python 3.8.1 ì—ì„œëŠ” ì„¤ì¹˜ ë¶ˆê°€

### 5-9. CNN í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ë° ì›ì¸ ìš”ì•½**

* ê¸°ë³¸ ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ CNN ì˜ í•™ìŠµì´ ì „í˜€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŒ
  * valid output ì„ ì¶œë ¥í•œ ê²°ê³¼, ê°’ì´ ëª¨ë‘ ë™ì¼í•˜ê²Œ ë‚˜ì˜´
* ì›ì¸ì€ **ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ ë¶€ë¶„ì˜, ê±°ì˜ ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ ê³µë°±ì¸ ì‚¬ì‹¤ìƒ ì˜ë¯¸ ì—†ëŠ” ë¶€ë¶„ì— ëŒ€í•œ ì •ë³´ê°€, ì˜¤íˆë ¤ í•™ìŠµì— ì§€ì¥** ì„ ì£¼ì—ˆê¸° ë•Œë¬¸ìœ¼ë¡œ ì¶”ì •
  * í•™ìŠµ ë°ì´í„°ê°€ 1,000 ê°œ ë‚´ì™¸ë¡œ ë¹„êµì  ë¶€ì¡±í•œ ìƒí™©ì—ì„œ ì´ë¡œ ì¸í•´ í•™ìŠµì´ ì „í˜€ ì•ˆ ë˜ì—ˆìŒ
  * [ì°¨ì›ì˜ ì €ì£¼](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Data%20Science%20Basics/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4_%EA%B8%B0%EC%B4%88_%EC%B0%A8%EC%9B%90%EC%9D%98_%EC%A0%80%EC%A3%BC.md) ì™€ ê´€ë ¨ ìˆì„ ê²ƒìœ¼ë¡œ ì¶”ì •

**í•´ê²° ì‹œë„ ë°©ë²•**

* **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ ì‹œê¹Œì§€ ì‹œë„í•œ ë¶€ë¶„**
  * Conv. + Pool Layer ì´í›„ ì²«ë²ˆì§¸ Fully-Connected Layer ì˜ [í™œì„±í™” í•¨ìˆ˜](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_%ED%99%9C%EC%84%B1%ED%99%94_%ED%95%A8%EC%88%98.md) ë¥¼ Tanh ë¡œ ìˆ˜ì •
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 64 x 64 -> 128 x 128 ë¡œ í™•ëŒ€
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * ëª¨ë“  í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ë°ê¸° ì¡°ì • (ê¸°ì¡´ë³´ë‹¤ 5ë°° ì–´ë‘¡ê²Œ)
    * ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ê°€ ë°°ê²½ìƒ‰ì€ í°ìƒ‰, ë„í˜• ë°°ê²½ìƒ‰ ì—­ì‹œ ë°ì€ ìƒ‰ìœ¼ë¡œ ì „ì²´ì ìœ¼ë¡œ í°ìƒ‰ì— ìƒë‹¹íˆ ê°€ê¹Œì›€
    * í°ìƒ‰ì´ ì•„ë‹Œ ìƒ‰ì˜ ëª¨ë“  í”½ì…€ì— ëŒ€í•´, ê·¸ **í°ìƒ‰ë³´ë‹¤ ì–´ë‘ìš´ ì •ë„ë¥¼ 5ë°°** ë¡œ í•˜ì—¬ **ì´ë¯¸ì§€ë¥¼ ì–´ë‘¡ê²Œ ì¡°ì •**
      * ì¼ì¢…ì˜ [ì…ë ¥ ë°ì´í„° ì •ê·œí™”](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Data%20Science%20Basics/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4_%EA%B8%B0%EC%B4%88_Normalization.md) ëª©ì 
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * ì´ë¯¸ì§€ì˜ ì‹¤ì œ í•™ìŠµ ë²”ìœ„ë¥¼ **ì „ì²´ 128 x 128 ì´ ì•„ë‹Œ, ê°€ìš´ë° 64 x 64 ë§Œ í•™ìŠµì— ì‚¬ìš©**
    * ê°€ì¥ìë¦¬ ë¶€ë¶„ì€ ëŒ€ë¶€ë¶„ì´ í°ìƒ‰ì˜ ë°°ê²½ìƒ‰ì¸, ì‚¬ì‹¤ìƒ ë¬´ì˜ë¯¸í•œ ì •ë³´ì´ë¯€ë¡œ í•™ìŠµ ëŒ€ìƒì—ì„œ ì œì™¸
    * ê²°ê³¼ : **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ (ì•½ 40% í™•ë¥ ë¡œ í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§)** ğŸ‰

* **ë¶€ë¶„ì  í•´ê²° ì„±ê³µ ì´í›„, ì¶”ê°€ì ìœ¼ë¡œ ì‹œë„í•œ ë¶€ë¶„**
  * Conv. Layer ì¶”ê°€
    * âŒ **ë¯¸ ì ìš©**
    * ì ìš© ê²°ê³¼, í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§ˆ í™•ë¥  ì˜¤íˆë ¤ ê°ì†Œ
  * ëª¨ë¸ì´ ìƒì„±í•œ ë‹¤ì´ì–´ê·¸ë¨ ë°ì´í„° ì¶”ê°€ ìƒì„±
    * âœ… **ì ìš©ë¨**
    * ê¸°ì¡´ 200ì¥ + ì¶”ê°€ 200ì¥ = 400ì¥
  * Conv. Layer ì˜ í•„í„° ê°œìˆ˜ë¥¼ ì¤„ì—¬ì„œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê°ì†Œ
    * âœ… **ì ìš©ë¨**
    * í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§ˆ í™•ë¥  ì•½ 70% ë¡œ ì¦ê°€ ì¶”ì •
  * [Weight initialization](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md) ê°œì„ 
    * âŒ **ë¯¸ ì ìš©**
    * Conv. Layer -> [He init](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md#5-he-initialization), Fully-Connected Layer -> [Xavier init](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Weight_initialization.md#4-xavier-initialization)
    * ì ìš© ê²°ê³¼, í•™ìŠµ ì‹¤íŒ¨ìœ¨ ê¸‰ì¦ & ì•½ 50%ì˜ í™•ë¥ ë¡œ ëª¨ë¸ì˜ output ê°’ì´ í•­ìƒ 1.0 ì´ ë¨

* **ì¶”ê°€ ì•„ì´ë””ì–´**
  * Pre-train ëœ ResNet ë“±ì„ ì´ìš©í•˜ì—¬ [Transfer Learning (ì „ì´í•™ìŠµ)](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Transfer_Learning.md) ì„ í• ê¹Œë„ ìƒê°í•´ ë´„
  * ëª¨ë¸ ë³µì¡ë„ ë° í•„ìš” ì´ìƒì˜ ìì› ì†Œë¹„ê°€ ìš°ë ¤ë˜ì–´, ì¼ë‹¨ ë³´ë¥˜

### 5-10. Auto-Encoder í•™ìŠµì´ ì‹¤ì§ˆì ìœ¼ë¡œ ì•ˆ ë¨ (í•´ê²° ì™„ë£Œ)

**ë¬¸ì œ ìƒí™© ìš”ì•½**

* ì˜ˆìƒ ì‚¬ìš©ì í‰ê°€ ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ CNN ì˜ í•™ìŠµì´ ì „í˜€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŒ
  * latent vector ë¥¼ ì¶œë ¥í•œ ê²°ê³¼, ê°’ì´ ëª¨ë‘ ë™ì¼í•˜ê²Œ ë‚˜ì˜´

**í•´ê²° ì‹œë„ ë°©ë²•**

* **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ ì‹œê¹Œì§€ ì‹œë„í•œ ë¶€ë¶„**
  * Fully-Connected Layer ì˜ [Dropout](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Overfitting_Dropout.md#3-dropout) ì œê±°
    * ê¸°ë³¸ ì•„ì´ë””ì–´ : [Conv Layer ì— Dropout ì„ ì ìš©í•˜ë©´ Auto-Encoder í•™ìŠµì´ ì–´ë ¤ì›Œì§ˆ ìˆ˜ ìˆëŠ”ë°](final_recommend_score/README.md#4-ì°¸ê³ --conv-layer-ì—-dropout-ì ìš©ëœ-auto-encoder-í•™ìŠµì´-ì–´ë ¤ìš´-ì´ìœ ), Fully-Connected ë„ ë§ˆì°¬ê°€ì§€ì¼ ìˆ˜ ìˆë‹¤ 
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * Encoder ì˜ Conv. Layer ì™€ Decoder ì˜ DeConv. Layer ë¥¼ 4 â†’ 3 ê°œë¡œ ì¡°ì •
    * ê²°ê³¼ : **í•´ê²° ì•ˆë¨**
  * Encoder ì…ë ¥ ~ Latent Vector ì‚¬ì´ì—, **ê¸°ì¡´ Conv. Layer ë¥¼ ê±°ì¹˜ëŠ” íë¦„ ì™¸ì— Dense Layer 1ê°œë¥¼ ê±°ì¹˜ëŠ” íë¦„ì„ ì¶”ê°€**
    * Encoder ì˜ Conv. Layer ê°€ ëë‚˜ê³  Fully-Connected Layer ê°€ ì‹œì‘ë˜ëŠ” ì‹œì ì—ì„œ, **ì´ 2ê°œì˜ íë¦„ì— ì˜í•´ ìƒì„±ëœ feature ë¥¼ concatenate**
    * ê²°ê³¼
      * **ë¬¸ì œ í•´ê²° ë¶€ë¶„ì  ì„±ê³µ (ì•½ 40% í™•ë¥ ë¡œ í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§)** ğŸ‰
      * **Minimum Train Loss = ì•½ 1.7K** (í•™ìŠµ ì•ˆë  ë•Œ) **â†’ 632.68**

* **ë¶€ë¶„ì  í•´ê²° ì„±ê³µ ì´í›„, ì¶”ê°€ì ìœ¼ë¡œ ì‹œë„í•œ ë¶€ë¶„**
  * Learning Rate Scheduler ì¡°ì • (warm-up ì¶”ê°€)
    * âœ… **ì ìš©ë¨**
    * before : warm-up ì—†ëŠ” [Cosine-Annealing LR Scheduler](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Deep%20Learning%20Basics/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_Learning_Rate_Scheduler.md#2-6-cosine-annealing-scheduler)
    * after : 5 epoch ì˜ warm-up + ì´í›„ì— learning rate ê°€ ë§¤ epoch ë§ˆë‹¤ 1.0% or 1.5% ì”© ì§€ìˆ˜ì ìœ¼ë¡œ ê°ì†Œ
    * ê²°ê³¼ (133 epoch ë™ì•ˆ í•™ìŠµ ì‹œ ê¸°ì¤€)
      * **í•™ìŠµ ì„±ê³µë¥  í–¥ìƒ (ì•½ 40% â†’ ì•½ 80% ì¶”ì •)** ğŸ‰
      * L.R. **1.0%** ì”© ê°ì†Œ ì‹œ : **Minimum Train Loss = 632.68 â†’ 433.28 (ğŸ”» 31.5 %)** ğŸ‰
      * L.R. **1.5%** ì”© ê°ì†Œ ì‹œ : **Minimum Train Loss = 632.68 â†’ 425.79 (ğŸ”» 32.7 %)** ğŸ‰

## 6. ì‚¬ìš©ì ê°€ì´ë“œ

* [í•´ë‹¹ ë¬¸ì„œ](additional_info.md#2-ì‚¬ìš©ì-ê°€ì´ë“œ) ì°¸ê³ .

## 7. í”„ë¡œì íŠ¸ ì†Œê°

* ê¸ì •ì ì¸ ë¶€ë¶„
  * í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë©´ì„œ LLM Fine-Tuning ì˜ ê¸°ì´ˆ ì§€ì‹ ë° ë‹¤ì–‘í•œ ì´ìŠˆë¥¼ ì„­ë µ
  * ë‹¤ìŒê³¼ ê°™ì´ AI ê¸°ìˆ ì˜ ê°€ëŠ¥ì„± í™•ì¸
    * LLM Fine-Tuning ì„ ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì‘ìš©í•  ìˆ˜ ìˆëŠ” ë¬´í•œí•œ ê°€ëŠ¥ì„±
    * [ì°¨ì›ì˜ ì €ì£¼](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Data%20Science%20Basics/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4_%EA%B8%B0%EC%B4%88_%EC%B0%A8%EC%9B%90%EC%9D%98_%EC%A0%80%EC%A3%BC.md) í•´ê²° ë°©ë²•ë“¤ ([Auto-Encoder](https://github.com/WannaBeSuperteur/AI-study/blob/main/Generative%20AI/Basics_Auto%20Encoder.md), [PCA](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Machine%20Learning%20Models/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%AA%A8%EB%8D%B8_PCA.md), ...) + [k-NN](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/Machine%20Learning%20Models/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%AA%A8%EB%8D%B8_KNN.md) ì˜ ì•„ì´ë””ì–´ì˜ **ì¶”ì²œ ì‹œìŠ¤í…œ** ìœ¼ë¡œì„œì˜ ê°€ëŠ¥ì„±

* ì•„ì‰¬ìš´ ë¶€ë¶„
  * LLM Fine-Tuning ì˜ ì†ë„ ë° ë©”ëª¨ë¦¬ ì´ìŠˆë¥¼ í•´ê²°í•˜ëŠ” **Unsloth** ë¥¼ **í”„ë¡œì íŠ¸ ì¤‘ë°˜ ì´í›„ì— ì•Œê²Œ ë˜ì–´, ë‹¤ìŒ í”„ë¡œì íŠ¸ë¶€í„° ì‚¬ìš©í•´ì•¼ í–ˆë˜ ì ** ì´ ê°€ì¥ ì•„ì‰¬ì›€
    * ì´ë¡œ ì¸í•´ **LLM ì´ Diagram ì„ 1ê°œ ìƒì„±í•˜ëŠ” ë° ëª‡ ë¶„** ì´ ê±¸ë¦¬ëŠ” ë“± ì‚¬ìš©ì ê²½í—˜ì´ ì €í•˜ë¨
  * LLM ì— ì˜í•´ ìƒì„±ëœ ë‹¤ì´ì–´ê·¸ë¨ì´ ì˜ë„ì™€ ë§ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆìŒ
    * Prompt ì˜ ì˜ë„ì— ë§ëŠ” ë‹¤ì´ì–´ê·¸ë¨ì„ ì™„ë²½íˆ ìƒì„±í•˜ë ¤ë©´ **í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì •í™•í•œ í•´ì„ì„ í†µí•´ Diagram Format Text ë¥¼ ìƒì„±** í•´ì•¼ í•˜ë¯€ë¡œ, [ì¶”ë¡ í˜• ëª¨ë¸](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_%EC%B6%94%EB%A1%A0%ED%98%95_%EB%AA%A8%EB%8D%B8.md) ì´ í•„ìš”í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë¨

* ë‹¤ìŒ í”„ë¡œì íŠ¸ ë‹¤ì§
  * Unsloth ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ Python version ì„ 3.9.0 ì´ìƒìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•œ í™˜ê²½ì„ ë¯¸ë¦¬ ì¤€ë¹„í•˜ì.
  * [ëª¨ë¸ í›„ë³´ ìµœì¢… ì„ ì •](test_llm/README.md) ì‹œ, ê° í›„ë³´ ëª¨ë¸ì— ëŒ€í•´ [SFT](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_SFT.md), [ORPO](https://github.com/WannaBeSuperteur/AI-study/blob/main/AI%20Basics/LLM%20Basics/LLM_%EA%B8%B0%EC%B4%88_Fine_Tuning_DPO_ORPO.md#3-orpo-odds-ratio-preference-optimization) ë“± ê³„íší–ˆë˜ Fine-Tuning ë°©ë²•ë¡ ì´ ì‹¤í–‰ë˜ëŠ”ì§€ ë¨¼ì € íŒŒì•…í•˜ê³ , ì´ë¥¼ ëª¨ë¸ ì„ ì • ê¸°ì¤€ìœ¼ë¡œ í™œìš©í•˜ë©´ ì¢‹ì„ ë“¯í•¨
    * ì¶”ê°€ì ìœ¼ë¡œ, Unsloth ì§€ì› ì—¬ë¶€ë„ ëª¨ë¸ ì„ ì • ê¸°ì¤€ì— í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ì„ ë“¯í•¨

* ê¸°íƒ€
  * Diagram Format í…ìŠ¤íŠ¸ ìƒì„±ì´ ```MAX_TOKENS``` (ìµœëŒ€ token ê°œìˆ˜) ì— ì´ë¥´ê¸° ì „ì— ëë‚˜ì§€ ì•ŠìŒ
  * ì´ëŠ” LLM í•™ìŠµ ë°ì´í„°ì˜ **ëª©í‘œ LLM output ì´ ì™„ì „íˆ ëë‚˜ëŠ” ì§€ì ** ì—ì„œì˜ ì§ì „ token ë“¤ì´, ë³´í†µ **1ê°œì˜ ë„í˜• ì •ë³´ê°€ ëë‚˜ëŠ” ì‹œì ** ì˜ ì§ì „ token ë“¤ì˜ ë°°ì¹˜ì™€ ì‚¬ì‹¤ìƒ ê°™ê¸° ë•Œë¬¸
    * ì¦‰, ì´ í† í°ì´ ë‚˜íƒ€ë‚  ë•ŒëŠ” **LLM output ì˜ ë ì‹œì ** ë„ ìˆì§€ë§Œ, ì´ë³´ë‹¤ëŠ” **ë‹¤ìŒ ë„í˜•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ì‹œì ** ì´ ë” ë§ìœ¼ë¯€ë¡œ,
    * LLM ì´ **ìµœì¢… í† í°ì´ ì•„ë‹ í™•ë¥ ì´ í›¨ì”¬ ë†’ë‹¤** ê³  íŒë‹¨í–ˆê¸° ë•Œë¬¸ìœ¼ë¡œ ì¶”ì •
    * ì°¸ê³  : [ì‹¤ì œ LLM í•™ìŠµ ë°ì´í„°ì…‹](create_dataset/sft_dataset.csv)
      * í•´ë‹¹ íŒŒì¼ì˜ ```output_data``` ì»¬ëŸ¼ì´ ëª©í‘œ LLM output
  * ë‹¤ìŒ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì´ë¥¼ ê³ ë ¤í•˜ì—¬ **LLM ì´ ë‹µë³€ì˜ ëì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ í”„ë¡¬í”„íŠ¸ ì„¤ê³„ë¥¼ í•˜ì!**

